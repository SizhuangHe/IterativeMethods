{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils import load_data, test, train, accuracy\n",
    "from models import GCN_2, GCN_3\n",
    "from layers import GraphConvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n"
     ]
    }
   ],
   "source": [
    "adj, features, labels, idx_train, idx_val, idx_test = load_data(path=\"../data/cora/\", dataset=\"cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 16\n",
    "dropout = 0.5\n",
    "lr = 0.01\n",
    "weight_decay = 5e-4\n",
    "num_epochs = 200\n",
    "smooth_fac = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ite_GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nclass, dropout, train_nite, eval_nite=0, allow_grad=True, smooth_fac=0):\n",
    "        '''     \n",
    "        - This model is a 1-layer GCN with nite iterations, followed by a linear layer and a log_softmax\n",
    "            - GC layer:     nfeat to nfeat\n",
    "            - linear layer: nfeat to nclass, (to cast hidden representations of nodes to a dimension of nclass)\n",
    "        - Activation: ReLu\n",
    "        - Input:\n",
    "            - nfeat:        the number of features of each node\n",
    "            - nclass:       the number of target classes (we are doing a node classification task here)\n",
    "            - dropout:      dropout rate\n",
    "            - train_nite:   the number of iterations during training\n",
    "            - eval_nite:    the number of iterations during evaluation, \n",
    "                            if not specified (or invalid), intialize to the same as train_nite\n",
    "            - allow_grad:   (bool) defaulted to True. \n",
    "                            whether or nor allow gradients to flow through all GC iterations, \n",
    "                            if False, gradients will only flow to the last iteration\n",
    "            - smooth_fac:   a number in [0,1], smoothing factor, controls how much of the OLD iteration result is\n",
    "                            counted in the skip connection in each iteration\n",
    "                            for example, smooth_fac = x means y_{i+1} = x * y_i + (1-x) * y_{i+1}\n",
    "                            Invalid inputs will be treated as 0.\n",
    "        - Output:\n",
    "            - A probability vector of length nclass, by log_softmax\n",
    "        '''\n",
    "        super(ite_GCN, self).__init__()\n",
    "\n",
    "        self.gc = GraphConvolution(nfeat, nfeat)\n",
    "        self.linear_no_bias = nn.Linear(nfeat, nclass, bias=False)\n",
    "        self.dropout = dropout\n",
    "        self.train_nite = train_nite\n",
    "        self.allow_grad = allow_grad\n",
    "        self.smooth_fac = smooth_fac\n",
    "        self.eval_nite = eval_nite\n",
    "        \n",
    "        if (smooth_fac > 1) or (smooth_fac < 0):\n",
    "            print(\"Invalid smoothing factor. Treat as 0.\")\n",
    "            self.smooth_fac = 0\n",
    "        if (eval_nite <= 0):\n",
    "            print(\"Unspecified or invalid number of iterations for inference. Treat as the same as training iterations.\")\n",
    "            self.eval_nite = self.train_nite\n",
    "        \n",
    "        print(\"Initialize a 1-layer GCN with \", self.train_nite, \"iterations\")\n",
    "        print(\"Gradient flows to all iterations: \", allow_grad)\n",
    "\n",
    "    def run_one_layer(self, x, adj):\n",
    "        x_old = x\n",
    "        x_new = self.gc(x, adj)\n",
    "        x = F.relu(self.smooth_fac * x_old + (1 - self.smooth_fac) * x_new)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        if self.training:\n",
    "            for i in range(self.train_nite):\n",
    "                if not self.allow_grad:\n",
    "                    # print(\"no no no! new new\")\n",
    "                    x = x.detach()\n",
    "                    x = self.run_one_layer(x, adj)\n",
    "                    # x.requires_grad_()\n",
    "                    # self.gc.weight.requires_grad_()\n",
    "                    # self.gc.weight.retain_grad()\n",
    "                    # print(self.gc.weight.requires_grad)\n",
    "                    # for name, param in self.named_parameters():\n",
    "                    #         print(name, param.grad)\n",
    "                else:\n",
    "                    # print(\"yea yea yea\")\n",
    "                    x = self.run_one_layer(x, adj)\n",
    "                    # for name, param in self.named_parameters():\n",
    "                    #         print(name, param.grad)\n",
    "        else:\n",
    "            for i in range(self.eval_nite):\n",
    "                x = self.run_one_layer(x, adj)\n",
    "\n",
    "        x = self.linear_no_bias(x)\n",
    "        # self.gc.weight.requires_grad_()\n",
    "        # print(\"???\")\n",
    "        # for name, param in self.named_parameters():\n",
    "        #     if param.grad is not None:\n",
    "        #         print(name, param.grad.abs().sum())\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(num_epochs, model, lr, weight_decay, features, adj, idx_train, idx_val, idx_test, labels):\n",
    "    print(\"runrunrun!\")\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=lr, weight_decay=weight_decay)\n",
    "    t_total = time.time()\n",
    "    loss_TRAIN = []\n",
    "    acc_TRAIN = []\n",
    "    loss_VAL = []\n",
    "    acc_VAL = []\n",
    "    for epoch in range(num_epochs):\n",
    "        t = time.time()\n",
    "    \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(features, adj)\n",
    "        \n",
    "        loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "        loss_TRAIN.append(loss_train)\n",
    "        acc_train = accuracy(output[idx_train], labels[idx_train])\n",
    "        acc_TRAIN.append(acc_train)\n",
    "\n",
    "        # t3 = time.time()\n",
    "        loss_train.backward()\n",
    "        # t4 = time.time()\n",
    "        # print(\"backward: \", t4-t3)\n",
    "        # print(\"before step: \", model.gc.weight)\n",
    "        optimizer.step()\n",
    "        # print(\"after step: \", model.gc.weight)\n",
    "\n",
    "        \n",
    "        # Evaluate validation set performance separately,\n",
    "        # deactivates dropout during validation run.\n",
    "        model.eval()\n",
    "        # t1 = time.time()\n",
    "        output = model(features, adj)\n",
    "        # print(\"eval output: \", output)\n",
    "        # t2 = time.time()\n",
    "        # print(\"forward time: \", t2-t1)\n",
    "\n",
    "        loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
    "        loss_VAL.append(loss_val)\n",
    "        acc_val = accuracy(output[idx_val], labels[idx_val])\n",
    "        acc_VAL.append(acc_val)\n",
    "        print('Epoch: {:04d}'.format(epoch+1),\n",
    "            'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "            'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "            'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "            'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "            'time: {:.4f}s'.format(time.time() - t))\n",
    "        \n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "    # Testing\n",
    "    test(model, features, adj, idx_test, labels)\n",
    "    return loss_TRAIN, acc_TRAIN, loss_VAL, acc_VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = ite_GCN(nfeat=features.shape[1],\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=dropout,\n",
    "            train_nite = 3,\n",
    "            allow_grad=True,\n",
    "            smooth_fac=0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# totally messed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_TRAIN, acc_TRAIN, loss_VAL, acc_VAL = run_experiment(num_epochs=200, model=model3, lr=lr, weight_decay=weight_decay, features=features, adj=adj, idx_train=idx_train, idx_val=idx_val, idx_test=idx_test, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_t = []\n",
    "for ten in loss_TRAIN:\n",
    "    l_t.append(ten.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(l_t, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_t = []\n",
    "for ten in acc_TRAIN:\n",
    "    a_t.append(ten.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(a_t, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_v = []\n",
    "for ten in loss_VAL:\n",
    "    l_v.append(ten.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(l_v, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_v = []\n",
    "for ten in acc_VAL:\n",
    "    a_v.append(ten.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(a_v, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = ite_GCN(nfeat=features.shape[1],\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=dropout,\n",
    "            train_nite = 3,\n",
    "            allow_grad=False,\n",
    "            smooth_fac=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(num_epochs=400, model=model4, lr=lr, weight_decay=weight_decay, features=features, adj=adj, idx_train=idx_train, idx_val=idx_val, idx_test=idx_test, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model3.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        print(name, param.grad.abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = GCN_3(nfeat=features.shape[1],\n",
    "            nhid=hidden,\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unspecified or invalid number of iterations for inference. Treat as the same as training iterations.\n",
      "Initialize a 1-layer GCN with  2 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "runrunrun!\n",
      "Epoch: 0001 loss_train: 1.9463 acc_train: 0.2000 loss_val: 1.8221 acc_val: 0.3500 time: 0.4371s\n",
      "Epoch: 0002 loss_train: 1.8292 acc_train: 0.2929 loss_val: 2.0807 acc_val: 0.3500 time: 0.3771s\n",
      "Epoch: 0003 loss_train: 2.1051 acc_train: 0.2929 loss_val: 1.7790 acc_val: 0.3500 time: 0.3797s\n",
      "Epoch: 0004 loss_train: 1.7740 acc_train: 0.2929 loss_val: 1.8437 acc_val: 0.3500 time: 0.3782s\n",
      "Epoch: 0005 loss_train: 1.8328 acc_train: 0.2929 loss_val: 1.8414 acc_val: 0.3500 time: 0.3758s\n",
      "Epoch: 0006 loss_train: 1.8273 acc_train: 0.2929 loss_val: 1.7934 acc_val: 0.3500 time: 0.3801s\n",
      "Epoch: 0007 loss_train: 1.7722 acc_train: 0.2929 loss_val: 1.7071 acc_val: 0.3500 time: 0.3750s\n",
      "Epoch: 0008 loss_train: 1.6709 acc_train: 0.2929 loss_val: 1.6272 acc_val: 0.3500 time: 0.3811s\n",
      "Epoch: 0009 loss_train: 1.5764 acc_train: 0.2929 loss_val: 1.4873 acc_val: 0.3533 time: 0.4247s\n",
      "Epoch: 0010 loss_train: 1.4373 acc_train: 0.3000 loss_val: 1.4148 acc_val: 0.4933 time: 0.3833s\n",
      "Epoch: 0011 loss_train: 1.3436 acc_train: 0.4500 loss_val: 1.3150 acc_val: 0.5467 time: 0.4583s\n",
      "Epoch: 0012 loss_train: 1.2215 acc_train: 0.5143 loss_val: 1.2526 acc_val: 0.5000 time: 0.4477s\n",
      "Epoch: 0013 loss_train: 1.1095 acc_train: 0.5286 loss_val: 1.2066 acc_val: 0.4933 time: 0.3699s\n",
      "Epoch: 0014 loss_train: 0.9965 acc_train: 0.5571 loss_val: 1.1245 acc_val: 0.5533 time: 0.3718s\n",
      "Epoch: 0015 loss_train: 0.8795 acc_train: 0.6500 loss_val: 1.0451 acc_val: 0.6933 time: 0.3703s\n",
      "Epoch: 0016 loss_train: 0.7624 acc_train: 0.7786 loss_val: 1.0192 acc_val: 0.6233 time: 0.3791s\n",
      "Epoch: 0017 loss_train: 0.6655 acc_train: 0.7500 loss_val: 0.9745 acc_val: 0.6900 time: 0.3706s\n",
      "Epoch: 0018 loss_train: 0.5517 acc_train: 0.8571 loss_val: 0.9455 acc_val: 0.6567 time: 0.3964s\n",
      "Epoch: 0019 loss_train: 0.4700 acc_train: 0.8357 loss_val: 0.9399 acc_val: 0.7167 time: 0.3745s\n",
      "Epoch: 0020 loss_train: 0.4049 acc_train: 0.8357 loss_val: 0.8533 acc_val: 0.7300 time: 0.3742s\n",
      "Epoch: 0021 loss_train: 0.3456 acc_train: 0.8857 loss_val: 0.8290 acc_val: 0.7433 time: 0.3732s\n",
      "Epoch: 0022 loss_train: 0.3004 acc_train: 0.9071 loss_val: 0.9119 acc_val: 0.7567 time: 0.4374s\n",
      "Epoch: 0023 loss_train: 0.2577 acc_train: 0.9429 loss_val: 0.8450 acc_val: 0.7900 time: 0.4775s\n",
      "Epoch: 0024 loss_train: 0.2099 acc_train: 0.9857 loss_val: 0.8731 acc_val: 0.7700 time: 0.3810s\n",
      "Epoch: 0025 loss_train: 0.1664 acc_train: 0.9929 loss_val: 0.8606 acc_val: 0.7700 time: 0.3721s\n",
      "Epoch: 0026 loss_train: 0.1231 acc_train: 1.0000 loss_val: 0.8042 acc_val: 0.8000 time: 0.3792s\n",
      "Epoch: 0027 loss_train: 0.0953 acc_train: 1.0000 loss_val: 0.8830 acc_val: 0.7833 time: 0.3762s\n",
      "Epoch: 0028 loss_train: 0.0791 acc_train: 1.0000 loss_val: 0.8111 acc_val: 0.7967 time: 0.3745s\n",
      "Epoch: 0029 loss_train: 0.0708 acc_train: 0.9929 loss_val: 0.9120 acc_val: 0.7733 time: 0.3868s\n",
      "Epoch: 0030 loss_train: 0.0609 acc_train: 0.9929 loss_val: 0.8228 acc_val: 0.8067 time: 0.3757s\n",
      "Epoch: 0031 loss_train: 0.0509 acc_train: 1.0000 loss_val: 0.8206 acc_val: 0.8033 time: 0.3749s\n",
      "Epoch: 0032 loss_train: 0.0482 acc_train: 1.0000 loss_val: 0.9086 acc_val: 0.7767 time: 0.3801s\n",
      "Epoch: 0033 loss_train: 0.0529 acc_train: 1.0000 loss_val: 0.8481 acc_val: 0.8033 time: 0.3819s\n",
      "Epoch: 0034 loss_train: 0.0559 acc_train: 1.0000 loss_val: 0.8189 acc_val: 0.7867 time: 0.3790s\n",
      "Epoch: 0035 loss_train: 0.0504 acc_train: 1.0000 loss_val: 0.7780 acc_val: 0.8167 time: 0.3790s\n",
      "Epoch: 0036 loss_train: 0.0484 acc_train: 1.0000 loss_val: 0.7921 acc_val: 0.8033 time: 0.3840s\n",
      "Epoch: 0037 loss_train: 0.0540 acc_train: 1.0000 loss_val: 0.8113 acc_val: 0.7867 time: 0.3798s\n",
      "Epoch: 0038 loss_train: 0.0595 acc_train: 1.0000 loss_val: 0.7813 acc_val: 0.8000 time: 0.3845s\n",
      "Epoch: 0039 loss_train: 0.0707 acc_train: 1.0000 loss_val: 0.9445 acc_val: 0.7633 time: 0.3827s\n",
      "Epoch: 0040 loss_train: 0.1066 acc_train: 0.9929 loss_val: 1.0739 acc_val: 0.6900 time: 0.3837s\n",
      "Epoch: 0041 loss_train: 0.2391 acc_train: 0.9143 loss_val: 1.3450 acc_val: 0.6267 time: 0.3936s\n",
      "Epoch: 0042 loss_train: 0.3590 acc_train: 0.8714 loss_val: 0.7191 acc_val: 0.8100 time: 0.3965s\n",
      "Epoch: 0043 loss_train: 0.0707 acc_train: 0.9929 loss_val: 1.1978 acc_val: 0.6800 time: 0.4372s\n",
      "Epoch: 0044 loss_train: 0.2625 acc_train: 0.9000 loss_val: 0.7521 acc_val: 0.8233 time: 0.4366s\n",
      "Epoch: 0045 loss_train: 0.0654 acc_train: 0.9929 loss_val: 0.8792 acc_val: 0.7700 time: 0.3918s\n",
      "Epoch: 0046 loss_train: 0.0658 acc_train: 0.9929 loss_val: 1.1393 acc_val: 0.6933 time: 0.3885s\n",
      "Epoch: 0047 loss_train: 0.1472 acc_train: 0.9571 loss_val: 0.9518 acc_val: 0.7500 time: 0.3935s\n",
      "Epoch: 0048 loss_train: 0.0752 acc_train: 1.0000 loss_val: 0.7375 acc_val: 0.8067 time: 0.3997s\n",
      "Epoch: 0049 loss_train: 0.0391 acc_train: 1.0000 loss_val: 0.6916 acc_val: 0.8300 time: 0.3953s\n",
      "Epoch: 0050 loss_train: 0.0410 acc_train: 1.0000 loss_val: 0.7984 acc_val: 0.8167 time: 0.3902s\n",
      "Epoch: 0051 loss_train: 0.0573 acc_train: 1.0000 loss_val: 0.8582 acc_val: 0.7900 time: 0.3844s\n",
      "Epoch: 0052 loss_train: 0.0649 acc_train: 0.9929 loss_val: 0.7490 acc_val: 0.8200 time: 0.3966s\n",
      "Epoch: 0053 loss_train: 0.0401 acc_train: 1.0000 loss_val: 0.7060 acc_val: 0.8067 time: 0.3897s\n",
      "Epoch: 0054 loss_train: 0.0288 acc_train: 1.0000 loss_val: 0.7480 acc_val: 0.8033 time: 0.3958s\n",
      "Epoch: 0055 loss_train: 0.0251 acc_train: 1.0000 loss_val: 0.8346 acc_val: 0.7800 time: 0.3893s\n",
      "Epoch: 0056 loss_train: 0.0280 acc_train: 1.0000 loss_val: 0.9100 acc_val: 0.7600 time: 0.3955s\n",
      "Epoch: 0057 loss_train: 0.0351 acc_train: 1.0000 loss_val: 0.9113 acc_val: 0.7567 time: 0.3886s\n",
      "Epoch: 0058 loss_train: 0.0340 acc_train: 1.0000 loss_val: 0.8604 acc_val: 0.7733 time: 0.3963s\n",
      "Epoch: 0059 loss_train: 0.0303 acc_train: 1.0000 loss_val: 0.7981 acc_val: 0.7800 time: 0.3939s\n",
      "Epoch: 0060 loss_train: 0.0268 acc_train: 1.0000 loss_val: 0.7562 acc_val: 0.8033 time: 0.3944s\n",
      "Epoch: 0061 loss_train: 0.0247 acc_train: 1.0000 loss_val: 0.7558 acc_val: 0.7967 time: 0.3897s\n",
      "Epoch: 0062 loss_train: 0.0279 acc_train: 1.0000 loss_val: 0.7520 acc_val: 0.8000 time: 0.3886s\n",
      "Epoch: 0063 loss_train: 0.0318 acc_train: 1.0000 loss_val: 0.7215 acc_val: 0.8067 time: 0.3933s\n",
      "Epoch: 0064 loss_train: 0.0329 acc_train: 1.0000 loss_val: 0.7084 acc_val: 0.7900 time: 0.3904s\n",
      "Epoch: 0065 loss_train: 0.0339 acc_train: 1.0000 loss_val: 0.7263 acc_val: 0.8067 time: 0.3900s\n",
      "Epoch: 0066 loss_train: 0.0334 acc_train: 1.0000 loss_val: 0.7651 acc_val: 0.7867 time: 0.3959s\n",
      "Epoch: 0067 loss_train: 0.0377 acc_train: 1.0000 loss_val: 0.7546 acc_val: 0.7867 time: 0.3980s\n",
      "Epoch: 0068 loss_train: 0.0396 acc_train: 1.0000 loss_val: 0.7186 acc_val: 0.7833 time: 0.4047s\n",
      "Epoch: 0069 loss_train: 0.0404 acc_train: 1.0000 loss_val: 0.6962 acc_val: 0.7933 time: 0.3990s\n",
      "Epoch: 0070 loss_train: 0.0409 acc_train: 1.0000 loss_val: 0.6976 acc_val: 0.8033 time: 0.4297s\n",
      "Epoch: 0071 loss_train: 0.0430 acc_train: 1.0000 loss_val: 0.6897 acc_val: 0.8133 time: 0.4012s\n",
      "Epoch: 0072 loss_train: 0.0436 acc_train: 1.0000 loss_val: 0.6745 acc_val: 0.8033 time: 0.3984s\n",
      "Epoch: 0073 loss_train: 0.0432 acc_train: 1.0000 loss_val: 0.6821 acc_val: 0.8033 time: 0.3961s\n",
      "Epoch: 0074 loss_train: 0.0434 acc_train: 1.0000 loss_val: 0.6992 acc_val: 0.8000 time: 0.3974s\n",
      "Epoch: 0075 loss_train: 0.0434 acc_train: 1.0000 loss_val: 0.6934 acc_val: 0.8000 time: 0.3979s\n",
      "Epoch: 0076 loss_train: 0.0422 acc_train: 1.0000 loss_val: 0.6788 acc_val: 0.8000 time: 0.3986s\n",
      "Epoch: 0077 loss_train: 0.0418 acc_train: 1.0000 loss_val: 0.6813 acc_val: 0.7967 time: 0.4186s\n",
      "Epoch: 0078 loss_train: 0.0406 acc_train: 1.0000 loss_val: 0.6930 acc_val: 0.8000 time: 0.4093s\n",
      "Epoch: 0079 loss_train: 0.0395 acc_train: 1.0000 loss_val: 0.6885 acc_val: 0.8033 time: 0.4298s\n",
      "Epoch: 0080 loss_train: 0.0382 acc_train: 1.0000 loss_val: 0.6824 acc_val: 0.8000 time: 0.3973s\n",
      "Epoch: 0081 loss_train: 0.0374 acc_train: 1.0000 loss_val: 0.6860 acc_val: 0.8033 time: 0.4037s\n",
      "Epoch: 0082 loss_train: 0.0361 acc_train: 1.0000 loss_val: 0.6902 acc_val: 0.8067 time: 0.4018s\n",
      "Epoch: 0083 loss_train: 0.0356 acc_train: 1.0000 loss_val: 0.6827 acc_val: 0.8033 time: 0.3948s\n",
      "Epoch: 0084 loss_train: 0.0346 acc_train: 1.0000 loss_val: 0.6840 acc_val: 0.8067 time: 0.3925s\n",
      "Epoch: 0085 loss_train: 0.0341 acc_train: 1.0000 loss_val: 0.6946 acc_val: 0.8033 time: 0.4196s\n",
      "Epoch: 0086 loss_train: 0.0337 acc_train: 1.0000 loss_val: 0.6921 acc_val: 0.8033 time: 0.3977s\n",
      "Epoch: 0087 loss_train: 0.0333 acc_train: 1.0000 loss_val: 0.6822 acc_val: 0.8033 time: 0.4025s\n",
      "Epoch: 0088 loss_train: 0.0330 acc_train: 1.0000 loss_val: 0.6844 acc_val: 0.8067 time: 0.6530s\n",
      "Epoch: 0089 loss_train: 0.0327 acc_train: 1.0000 loss_val: 0.6907 acc_val: 0.8067 time: 0.5216s\n",
      "Epoch: 0090 loss_train: 0.0326 acc_train: 1.0000 loss_val: 0.6858 acc_val: 0.7967 time: 0.4494s\n",
      "Epoch: 0091 loss_train: 0.0324 acc_train: 1.0000 loss_val: 0.6847 acc_val: 0.7967 time: 0.4501s\n",
      "Epoch: 0092 loss_train: 0.0323 acc_train: 1.0000 loss_val: 0.6910 acc_val: 0.8067 time: 0.4189s\n",
      "Epoch: 0093 loss_train: 0.0323 acc_train: 1.0000 loss_val: 0.6868 acc_val: 0.8000 time: 0.4147s\n",
      "Epoch: 0094 loss_train: 0.0322 acc_train: 1.0000 loss_val: 0.6877 acc_val: 0.8067 time: 0.4394s\n",
      "Epoch: 0095 loss_train: 0.0320 acc_train: 1.0000 loss_val: 0.6929 acc_val: 0.8067 time: 0.4349s\n",
      "Epoch: 0096 loss_train: 0.0319 acc_train: 1.0000 loss_val: 0.6836 acc_val: 0.8067 time: 0.4909s\n",
      "Epoch: 0097 loss_train: 0.0317 acc_train: 1.0000 loss_val: 0.6929 acc_val: 0.8033 time: 0.4757s\n",
      "Epoch: 0098 loss_train: 0.0314 acc_train: 1.0000 loss_val: 0.6904 acc_val: 0.8100 time: 0.4176s\n",
      "Epoch: 0099 loss_train: 0.0311 acc_train: 1.0000 loss_val: 0.6905 acc_val: 0.8033 time: 0.3913s\n",
      "Epoch: 0100 loss_train: 0.0309 acc_train: 1.0000 loss_val: 0.6943 acc_val: 0.8033 time: 0.3986s\n",
      "Epoch: 0101 loss_train: 0.0307 acc_train: 1.0000 loss_val: 0.6933 acc_val: 0.8033 time: 0.4185s\n",
      "Epoch: 0102 loss_train: 0.0312 acc_train: 1.0000 loss_val: 0.7171 acc_val: 0.7933 time: 0.4085s\n",
      "Epoch: 0103 loss_train: 0.0349 acc_train: 1.0000 loss_val: 0.7366 acc_val: 0.7867 time: 0.4099s\n",
      "Epoch: 0104 loss_train: 0.0470 acc_train: 1.0000 loss_val: 0.8377 acc_val: 0.7667 time: 0.3997s\n",
      "Epoch: 0105 loss_train: 0.0796 acc_train: 0.9929 loss_val: 1.1245 acc_val: 0.6833 time: 0.3991s\n",
      "Epoch: 0106 loss_train: 0.2061 acc_train: 0.9571 loss_val: 1.9971 acc_val: 0.5700 time: 0.4011s\n",
      "Epoch: 0107 loss_train: 1.0698 acc_train: 0.6357 loss_val: 1.6434 acc_val: 0.5533 time: 0.4268s\n",
      "Epoch: 0108 loss_train: 0.4714 acc_train: 0.8357 loss_val: 1.5030 acc_val: 0.6133 time: 0.4071s\n",
      "Epoch: 0109 loss_train: 0.3189 acc_train: 0.9214 loss_val: 0.6858 acc_val: 0.8167 time: 0.4021s\n",
      "Epoch: 0110 loss_train: 0.0463 acc_train: 1.0000 loss_val: 0.8553 acc_val: 0.7833 time: 0.4054s\n",
      "Epoch: 0111 loss_train: 0.1557 acc_train: 0.9643 loss_val: 1.0044 acc_val: 0.7567 time: 0.4002s\n",
      "Epoch: 0112 loss_train: 0.2379 acc_train: 0.9429 loss_val: 0.9305 acc_val: 0.7600 time: 0.4037s\n",
      "Epoch: 0113 loss_train: 0.1861 acc_train: 0.9571 loss_val: 0.7704 acc_val: 0.7900 time: 0.4012s\n",
      "Epoch: 0114 loss_train: 0.1070 acc_train: 0.9857 loss_val: 0.6689 acc_val: 0.7967 time: 0.3968s\n",
      "Epoch: 0115 loss_train: 0.0613 acc_train: 0.9929 loss_val: 0.6822 acc_val: 0.8133 time: 0.4032s\n",
      "Epoch: 0116 loss_train: 0.0598 acc_train: 0.9857 loss_val: 0.7447 acc_val: 0.8033 time: 0.4027s\n",
      "Epoch: 0117 loss_train: 0.0668 acc_train: 0.9786 loss_val: 0.7760 acc_val: 0.7933 time: 0.4008s\n",
      "Epoch: 0118 loss_train: 0.0604 acc_train: 0.9857 loss_val: 0.7617 acc_val: 0.7833 time: 0.4299s\n",
      "Epoch: 0119 loss_train: 0.0399 acc_train: 0.9929 loss_val: 0.7683 acc_val: 0.7900 time: 0.3955s\n",
      "Epoch: 0120 loss_train: 0.0278 acc_train: 1.0000 loss_val: 0.7984 acc_val: 0.7767 time: 0.3942s\n",
      "Epoch: 0121 loss_train: 0.0253 acc_train: 1.0000 loss_val: 0.8122 acc_val: 0.7800 time: 0.3932s\n",
      "Epoch: 0122 loss_train: 0.0239 acc_train: 1.0000 loss_val: 0.8022 acc_val: 0.7900 time: 0.3975s\n",
      "Epoch: 0123 loss_train: 0.0212 acc_train: 1.0000 loss_val: 0.7853 acc_val: 0.8067 time: 0.3964s\n",
      "Epoch: 0124 loss_train: 0.0188 acc_train: 1.0000 loss_val: 0.7705 acc_val: 0.8200 time: 0.4200s\n",
      "Epoch: 0125 loss_train: 0.0171 acc_train: 1.0000 loss_val: 0.7585 acc_val: 0.8267 time: 0.4549s\n",
      "Epoch: 0126 loss_train: 0.0160 acc_train: 1.0000 loss_val: 0.7479 acc_val: 0.8233 time: 0.3979s\n",
      "Epoch: 0127 loss_train: 0.0149 acc_train: 1.0000 loss_val: 0.7410 acc_val: 0.8267 time: 0.3991s\n",
      "Epoch: 0128 loss_train: 0.0136 acc_train: 1.0000 loss_val: 0.7461 acc_val: 0.8167 time: 0.4013s\n",
      "Epoch: 0129 loss_train: 0.0128 acc_train: 1.0000 loss_val: 0.7648 acc_val: 0.8033 time: 0.4049s\n",
      "Epoch: 0130 loss_train: 0.0135 acc_train: 1.0000 loss_val: 0.7813 acc_val: 0.8067 time: 0.4950s\n",
      "Epoch: 0131 loss_train: 0.0147 acc_train: 1.0000 loss_val: 0.7772 acc_val: 0.7967 time: 0.3925s\n",
      "Epoch: 0132 loss_train: 0.0150 acc_train: 1.0000 loss_val: 0.7632 acc_val: 0.8033 time: 0.3999s\n",
      "Epoch: 0133 loss_train: 0.0153 acc_train: 1.0000 loss_val: 0.7540 acc_val: 0.8200 time: 0.3932s\n",
      "Epoch: 0134 loss_train: 0.0167 acc_train: 1.0000 loss_val: 0.7540 acc_val: 0.8200 time: 0.3916s\n",
      "Epoch: 0135 loss_train: 0.0182 acc_train: 1.0000 loss_val: 0.7583 acc_val: 0.8067 time: 0.4008s\n",
      "Epoch: 0136 loss_train: 0.0196 acc_train: 1.0000 loss_val: 0.7520 acc_val: 0.8067 time: 0.4055s\n",
      "Epoch: 0137 loss_train: 0.0209 acc_train: 1.0000 loss_val: 0.7385 acc_val: 0.8100 time: 0.3923s\n",
      "Epoch: 0138 loss_train: 0.0220 acc_train: 1.0000 loss_val: 0.7345 acc_val: 0.8000 time: 0.3958s\n",
      "Epoch: 0139 loss_train: 0.0240 acc_train: 1.0000 loss_val: 0.7250 acc_val: 0.8000 time: 0.4060s\n",
      "Epoch: 0140 loss_train: 0.0254 acc_train: 1.0000 loss_val: 0.7203 acc_val: 0.8000 time: 0.4055s\n",
      "Epoch: 0141 loss_train: 0.0269 acc_train: 1.0000 loss_val: 0.7226 acc_val: 0.8033 time: 0.3947s\n",
      "Epoch: 0142 loss_train: 0.0289 acc_train: 1.0000 loss_val: 0.7105 acc_val: 0.8000 time: 0.3931s\n",
      "Epoch: 0143 loss_train: 0.0306 acc_train: 1.0000 loss_val: 0.7306 acc_val: 0.7933 time: 0.4222s\n",
      "Epoch: 0144 loss_train: 0.0327 acc_train: 1.0000 loss_val: 0.7018 acc_val: 0.8167 time: 0.4043s\n",
      "Epoch: 0145 loss_train: 0.0355 acc_train: 1.0000 loss_val: 0.7283 acc_val: 0.7933 time: 0.3996s\n",
      "Epoch: 0146 loss_train: 0.0360 acc_train: 1.0000 loss_val: 0.6924 acc_val: 0.8067 time: 0.3943s\n",
      "Epoch: 0147 loss_train: 0.0350 acc_train: 1.0000 loss_val: 0.6873 acc_val: 0.8167 time: 0.4016s\n",
      "Epoch: 0148 loss_train: 0.0357 acc_train: 1.0000 loss_val: 0.7142 acc_val: 0.7967 time: 0.3883s\n",
      "Epoch: 0149 loss_train: 0.0365 acc_train: 1.0000 loss_val: 0.6901 acc_val: 0.8033 time: 0.3929s\n",
      "Epoch: 0150 loss_train: 0.0351 acc_train: 1.0000 loss_val: 0.6825 acc_val: 0.8167 time: 0.3976s\n",
      "Epoch: 0151 loss_train: 0.0352 acc_train: 1.0000 loss_val: 0.7058 acc_val: 0.8033 time: 0.4184s\n",
      "Epoch: 0152 loss_train: 0.0349 acc_train: 1.0000 loss_val: 0.6971 acc_val: 0.8033 time: 0.4137s\n",
      "Epoch: 0153 loss_train: 0.0334 acc_train: 1.0000 loss_val: 0.6871 acc_val: 0.8100 time: 0.3925s\n",
      "Epoch: 0154 loss_train: 0.0338 acc_train: 1.0000 loss_val: 0.6994 acc_val: 0.8000 time: 0.3959s\n",
      "Epoch: 0155 loss_train: 0.0321 acc_train: 1.0000 loss_val: 0.7038 acc_val: 0.8100 time: 0.4003s\n",
      "Epoch: 0156 loss_train: 0.0320 acc_train: 1.0000 loss_val: 0.6876 acc_val: 0.8133 time: 0.3999s\n",
      "Epoch: 0157 loss_train: 0.0310 acc_train: 1.0000 loss_val: 0.6964 acc_val: 0.8100 time: 0.4031s\n",
      "Epoch: 0158 loss_train: 0.0304 acc_train: 1.0000 loss_val: 0.7080 acc_val: 0.8033 time: 0.3905s\n",
      "Epoch: 0159 loss_train: 0.0298 acc_train: 1.0000 loss_val: 0.6985 acc_val: 0.8167 time: 0.4010s\n",
      "Epoch: 0160 loss_train: 0.0292 acc_train: 1.0000 loss_val: 0.6970 acc_val: 0.8100 time: 0.3970s\n",
      "Epoch: 0161 loss_train: 0.0287 acc_train: 1.0000 loss_val: 0.7051 acc_val: 0.8000 time: 0.3953s\n",
      "Epoch: 0162 loss_train: 0.0282 acc_train: 1.0000 loss_val: 0.7050 acc_val: 0.8033 time: 0.3898s\n",
      "Epoch: 0163 loss_train: 0.0280 acc_train: 1.0000 loss_val: 0.7040 acc_val: 0.8067 time: 0.3903s\n",
      "Epoch: 0164 loss_train: 0.0275 acc_train: 1.0000 loss_val: 0.7031 acc_val: 0.8067 time: 0.3942s\n",
      "Epoch: 0165 loss_train: 0.0272 acc_train: 1.0000 loss_val: 0.7033 acc_val: 0.8067 time: 0.4018s\n",
      "Epoch: 0166 loss_train: 0.0271 acc_train: 1.0000 loss_val: 0.7084 acc_val: 0.8067 time: 0.4088s\n",
      "Epoch: 0167 loss_train: 0.0268 acc_train: 1.0000 loss_val: 0.7048 acc_val: 0.8067 time: 0.5382s\n",
      "Epoch: 0168 loss_train: 0.0266 acc_train: 1.0000 loss_val: 0.7046 acc_val: 0.8067 time: 0.7085s\n",
      "Epoch: 0169 loss_train: 0.0266 acc_train: 1.0000 loss_val: 0.7079 acc_val: 0.8033 time: 0.7264s\n",
      "Epoch: 0170 loss_train: 0.0264 acc_train: 1.0000 loss_val: 0.7040 acc_val: 0.8067 time: 0.3968s\n",
      "Epoch: 0171 loss_train: 0.0264 acc_train: 1.0000 loss_val: 0.7117 acc_val: 0.8033 time: 0.4003s\n",
      "Epoch: 0172 loss_train: 0.0264 acc_train: 1.0000 loss_val: 0.7030 acc_val: 0.8133 time: 0.3951s\n",
      "Epoch: 0173 loss_train: 0.0263 acc_train: 1.0000 loss_val: 0.7093 acc_val: 0.8033 time: 0.3984s\n",
      "Epoch: 0174 loss_train: 0.0263 acc_train: 1.0000 loss_val: 0.7084 acc_val: 0.8067 time: 0.4054s\n",
      "Epoch: 0175 loss_train: 0.0263 acc_train: 1.0000 loss_val: 0.7069 acc_val: 0.8067 time: 0.3959s\n",
      "Epoch: 0176 loss_train: 0.0263 acc_train: 1.0000 loss_val: 0.7069 acc_val: 0.8067 time: 0.4020s\n",
      "Epoch: 0177 loss_train: 0.0262 acc_train: 1.0000 loss_val: 0.7134 acc_val: 0.8033 time: 0.4044s\n",
      "Epoch: 0178 loss_train: 0.0263 acc_train: 1.0000 loss_val: 0.7007 acc_val: 0.8200 time: 0.4240s\n",
      "Epoch: 0179 loss_train: 0.0265 acc_train: 1.0000 loss_val: 0.7382 acc_val: 0.7933 time: 0.3926s\n",
      "Epoch: 0180 loss_train: 0.0280 acc_train: 1.0000 loss_val: 0.7030 acc_val: 0.8267 time: 0.3938s\n",
      "Epoch: 0181 loss_train: 0.0328 acc_train: 1.0000 loss_val: 0.8236 acc_val: 0.7833 time: 0.4012s\n",
      "Epoch: 0182 loss_train: 0.0406 acc_train: 1.0000 loss_val: 0.7158 acc_val: 0.8000 time: 0.4057s\n",
      "Epoch: 0183 loss_train: 0.0411 acc_train: 1.0000 loss_val: 0.7416 acc_val: 0.7933 time: 0.4125s\n",
      "Epoch: 0184 loss_train: 0.0278 acc_train: 1.0000 loss_val: 0.7903 acc_val: 0.7767 time: 0.4027s\n",
      "Epoch: 0185 loss_train: 0.0312 acc_train: 1.0000 loss_val: 0.7071 acc_val: 0.8100 time: 0.3966s\n",
      "Epoch: 0186 loss_train: 0.0277 acc_train: 1.0000 loss_val: 0.7061 acc_val: 0.8233 time: 0.4803s\n",
      "Epoch: 0187 loss_train: 0.0270 acc_train: 1.0000 loss_val: 0.7543 acc_val: 0.7867 time: 0.3922s\n",
      "Epoch: 0188 loss_train: 0.0246 acc_train: 1.0000 loss_val: 0.7810 acc_val: 0.7833 time: 0.3977s\n",
      "Epoch: 0189 loss_train: 0.0260 acc_train: 1.0000 loss_val: 0.7198 acc_val: 0.8100 time: 0.4377s\n",
      "Epoch: 0190 loss_train: 0.0229 acc_train: 1.0000 loss_val: 0.7177 acc_val: 0.8233 time: 0.4245s\n",
      "Epoch: 0191 loss_train: 0.0260 acc_train: 1.0000 loss_val: 0.7361 acc_val: 0.8000 time: 0.4145s\n",
      "Epoch: 0192 loss_train: 0.0221 acc_train: 1.0000 loss_val: 0.7778 acc_val: 0.7833 time: 0.4387s\n",
      "Epoch: 0193 loss_train: 0.0258 acc_train: 1.0000 loss_val: 0.7259 acc_val: 0.8033 time: 0.3849s\n",
      "Epoch: 0194 loss_train: 0.0224 acc_train: 1.0000 loss_val: 0.7112 acc_val: 0.8200 time: 0.3918s\n",
      "Epoch: 0195 loss_train: 0.0253 acc_train: 1.0000 loss_val: 0.7212 acc_val: 0.8067 time: 0.4059s\n",
      "Epoch: 0196 loss_train: 0.0233 acc_train: 1.0000 loss_val: 0.7536 acc_val: 0.7833 time: 0.3859s\n",
      "Epoch: 0197 loss_train: 0.0250 acc_train: 1.0000 loss_val: 0.7291 acc_val: 0.8033 time: 0.3826s\n",
      "Epoch: 0198 loss_train: 0.0244 acc_train: 1.0000 loss_val: 0.7042 acc_val: 0.8133 time: 0.3929s\n",
      "Epoch: 0199 loss_train: 0.0251 acc_train: 1.0000 loss_val: 0.7151 acc_val: 0.8100 time: 0.3920s\n",
      "Epoch: 0200 loss_train: 0.0252 acc_train: 1.0000 loss_val: 0.7368 acc_val: 0.7967 time: 0.3982s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 81.4714s\n",
      "Test set results: loss= 0.7120 accuracy= 0.7780\n",
      "inference time:  0.11055469512939453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([tensor(1.9463, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.8292, grad_fn=<NllLossBackward0>),\n",
       "  tensor(2.1051, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.7740, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.8328, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.8273, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.7722, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.6709, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.5764, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.4373, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.3436, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.2215, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.1095, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9965, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8795, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7624, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6655, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.5517, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.4700, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.4049, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.3456, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.3004, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.2577, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.2099, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.1664, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.1231, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0953, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0791, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0708, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0609, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0509, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0482, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0529, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0559, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0504, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0484, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0540, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0595, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0707, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.1066, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.2391, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.3590, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0707, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.2625, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0654, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0658, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.1472, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0752, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0391, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0410, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0573, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0649, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0401, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0288, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0251, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0280, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0351, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0340, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0303, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0268, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0247, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0279, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0318, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0329, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0339, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0334, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0377, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0396, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0404, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0409, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0430, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0436, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0432, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0434, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0434, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0422, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0418, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0406, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0395, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0382, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0374, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0361, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0356, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0346, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0341, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0337, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0333, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0330, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0327, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0326, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0324, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0323, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0323, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0322, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0320, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0319, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0317, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0314, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0311, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0309, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0307, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0312, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0349, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0470, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0796, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.2061, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.0698, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.4714, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.3189, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0463, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.1557, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.2379, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.1861, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.1070, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0613, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0598, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0668, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0604, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0399, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0278, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0253, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0239, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0212, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0188, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0171, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0160, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0149, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0136, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0128, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0135, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0147, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0150, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0153, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0167, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0182, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0196, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0209, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0220, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0240, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0254, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0269, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0289, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0306, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0327, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0355, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0360, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0350, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0357, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0365, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0351, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0352, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0349, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0334, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0338, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0321, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0320, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0310, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0304, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0298, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0292, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0287, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0282, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0280, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0275, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0272, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0271, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0268, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0266, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0266, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0264, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0264, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0264, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0263, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0263, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0263, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0263, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0262, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0263, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0265, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0280, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0328, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0406, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0411, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0278, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0312, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0277, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0270, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0246, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0260, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0229, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0260, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0221, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0258, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0224, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0253, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0233, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0250, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0244, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0251, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0252, grad_fn=<NllLossBackward0>)],\n",
       " [tensor(0.2000, dtype=torch.float64),\n",
       "  tensor(0.2929, dtype=torch.float64),\n",
       "  tensor(0.2929, dtype=torch.float64),\n",
       "  tensor(0.2929, dtype=torch.float64),\n",
       "  tensor(0.2929, dtype=torch.float64),\n",
       "  tensor(0.2929, dtype=torch.float64),\n",
       "  tensor(0.2929, dtype=torch.float64),\n",
       "  tensor(0.2929, dtype=torch.float64),\n",
       "  tensor(0.2929, dtype=torch.float64),\n",
       "  tensor(0.3000, dtype=torch.float64),\n",
       "  tensor(0.4500, dtype=torch.float64),\n",
       "  tensor(0.5143, dtype=torch.float64),\n",
       "  tensor(0.5286, dtype=torch.float64),\n",
       "  tensor(0.5571, dtype=torch.float64),\n",
       "  tensor(0.6500, dtype=torch.float64),\n",
       "  tensor(0.7786, dtype=torch.float64),\n",
       "  tensor(0.7500, dtype=torch.float64),\n",
       "  tensor(0.8571, dtype=torch.float64),\n",
       "  tensor(0.8357, dtype=torch.float64),\n",
       "  tensor(0.8357, dtype=torch.float64),\n",
       "  tensor(0.8857, dtype=torch.float64),\n",
       "  tensor(0.9071, dtype=torch.float64),\n",
       "  tensor(0.9429, dtype=torch.float64),\n",
       "  tensor(0.9857, dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(0.9143, dtype=torch.float64),\n",
       "  tensor(0.8714, dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(0.9000, dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(0.9571, dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(0.9571, dtype=torch.float64),\n",
       "  tensor(0.6357, dtype=torch.float64),\n",
       "  tensor(0.8357, dtype=torch.float64),\n",
       "  tensor(0.9214, dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(0.9643, dtype=torch.float64),\n",
       "  tensor(0.9429, dtype=torch.float64),\n",
       "  tensor(0.9571, dtype=torch.float64),\n",
       "  tensor(0.9857, dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(0.9857, dtype=torch.float64),\n",
       "  tensor(0.9786, dtype=torch.float64),\n",
       "  tensor(0.9857, dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64)],\n",
       " [tensor(1.8221, grad_fn=<NllLossBackward0>),\n",
       "  tensor(2.0807, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.7790, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.8437, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.8414, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.7934, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.7071, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.6272, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.4873, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.4148, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.3150, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.2526, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.2066, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.1245, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.0451, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.0192, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9745, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9455, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9399, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8533, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8290, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9119, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8450, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8731, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8606, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8042, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8830, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8111, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9120, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8228, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8206, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9086, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8481, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8189, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7780, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7921, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8113, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7813, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9445, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.0739, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.3450, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7191, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.1978, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7521, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8792, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.1393, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9518, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7375, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6916, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7984, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8582, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7490, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7060, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7480, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8346, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9100, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9113, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8604, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7981, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7562, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7558, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7520, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7215, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7084, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7263, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7651, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7546, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7186, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6962, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6976, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6897, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6745, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6821, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6992, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6934, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6788, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6813, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6930, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6885, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6824, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6860, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6902, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6827, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6840, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6946, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6921, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6822, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6844, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6907, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6858, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6847, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6910, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6868, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6877, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6929, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6836, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6929, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6904, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6905, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6943, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6933, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7171, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7366, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8377, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.1245, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.9971, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.6434, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.5030, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6858, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8553, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.0044, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9305, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7704, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6689, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6822, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7447, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7760, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7617, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7683, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7984, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8122, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8022, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7853, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7705, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7585, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7479, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7410, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7461, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7648, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7813, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7772, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7632, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7540, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7540, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7583, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7520, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7385, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7345, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7250, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7203, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7226, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7105, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7306, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7018, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7283, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6924, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6873, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7142, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6901, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6825, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7058, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6971, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6871, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6994, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7038, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6876, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6964, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7080, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6985, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6970, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7051, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7050, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7040, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7031, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7033, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7084, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7048, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7046, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7079, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7040, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7117, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7030, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7093, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7084, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7069, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7069, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7134, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7007, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7382, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7030, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8236, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7158, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7416, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7903, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7071, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7061, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7543, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7810, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7198, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7177, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7361, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7778, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7259, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7112, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7212, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7536, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7291, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7042, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7151, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7368, grad_fn=<NllLossBackward0>)],\n",
       " [tensor(0.3500, dtype=torch.float64),\n",
       "  tensor(0.3500, dtype=torch.float64),\n",
       "  tensor(0.3500, dtype=torch.float64),\n",
       "  tensor(0.3500, dtype=torch.float64),\n",
       "  tensor(0.3500, dtype=torch.float64),\n",
       "  tensor(0.3500, dtype=torch.float64),\n",
       "  tensor(0.3500, dtype=torch.float64),\n",
       "  tensor(0.3500, dtype=torch.float64),\n",
       "  tensor(0.3533, dtype=torch.float64),\n",
       "  tensor(0.4933, dtype=torch.float64),\n",
       "  tensor(0.5467, dtype=torch.float64),\n",
       "  tensor(0.5000, dtype=torch.float64),\n",
       "  tensor(0.4933, dtype=torch.float64),\n",
       "  tensor(0.5533, dtype=torch.float64),\n",
       "  tensor(0.6933, dtype=torch.float64),\n",
       "  tensor(0.6233, dtype=torch.float64),\n",
       "  tensor(0.6900, dtype=torch.float64),\n",
       "  tensor(0.6567, dtype=torch.float64),\n",
       "  tensor(0.7167, dtype=torch.float64),\n",
       "  tensor(0.7300, dtype=torch.float64),\n",
       "  tensor(0.7433, dtype=torch.float64),\n",
       "  tensor(0.7567, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7700, dtype=torch.float64),\n",
       "  tensor(0.7700, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.7733, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.7767, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.7867, dtype=torch.float64),\n",
       "  tensor(0.8167, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.7867, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.7633, dtype=torch.float64),\n",
       "  tensor(0.6900, dtype=torch.float64),\n",
       "  tensor(0.6267, dtype=torch.float64),\n",
       "  tensor(0.8100, dtype=torch.float64),\n",
       "  tensor(0.6800, dtype=torch.float64),\n",
       "  tensor(0.8233, dtype=torch.float64),\n",
       "  tensor(0.7700, dtype=torch.float64),\n",
       "  tensor(0.6933, dtype=torch.float64),\n",
       "  tensor(0.7500, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8300, dtype=torch.float64),\n",
       "  tensor(0.8167, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.8200, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.7800, dtype=torch.float64),\n",
       "  tensor(0.7600, dtype=torch.float64),\n",
       "  tensor(0.7567, dtype=torch.float64),\n",
       "  tensor(0.7733, dtype=torch.float64),\n",
       "  tensor(0.7800, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.7867, dtype=torch.float64),\n",
       "  tensor(0.7867, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8133, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8100, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7867, dtype=torch.float64),\n",
       "  tensor(0.7667, dtype=torch.float64),\n",
       "  tensor(0.6833, dtype=torch.float64),\n",
       "  tensor(0.5700, dtype=torch.float64),\n",
       "  tensor(0.5533, dtype=torch.float64),\n",
       "  tensor(0.6133, dtype=torch.float64),\n",
       "  tensor(0.8167, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.7567, dtype=torch.float64),\n",
       "  tensor(0.7600, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.8133, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7767, dtype=torch.float64),\n",
       "  tensor(0.7800, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8200, dtype=torch.float64),\n",
       "  tensor(0.8267, dtype=torch.float64),\n",
       "  tensor(0.8233, dtype=torch.float64),\n",
       "  tensor(0.8267, dtype=torch.float64),\n",
       "  tensor(0.8167, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8200, dtype=torch.float64),\n",
       "  tensor(0.8200, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8100, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.8167, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8167, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8167, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8100, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.8100, dtype=torch.float64),\n",
       "  tensor(0.8133, dtype=torch.float64),\n",
       "  tensor(0.8100, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8167, dtype=torch.float64),\n",
       "  tensor(0.8100, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8133, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8200, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.8267, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7767, dtype=torch.float64),\n",
       "  tensor(0.8100, dtype=torch.float64),\n",
       "  tensor(0.8233, dtype=torch.float64),\n",
       "  tensor(0.7867, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.8100, dtype=torch.float64),\n",
       "  tensor(0.8233, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8200, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8133, dtype=torch.float64),\n",
       "  tensor(0.8100, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = ite_GCN(nfeat=features.shape[1],\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=0,\n",
    "            train_nite= 2,\n",
    "            eval_nite= 0,\n",
    "            allow_grad=True,\n",
    "            smooth_fac=smooth_fac)\n",
    "run_experiment(num_epochs, model2, lr, weight_decay, features, adj, idx_train, idx_val, idx_test, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 1.7943 accuracy= 0.1620\n",
      "inference time:  0.1115729808807373\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 0.7120 accuracy= 0.7780\n",
      "inference time:  0.1319718360900879\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 8.1743 accuracy= 0.3420\n",
      "inference time:  0.1900501251220703\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 27.2977 accuracy= 0.3540\n",
      "inference time:  0.2713141441345215\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 204.8581 accuracy= 0.2110\n",
      "inference time:  0.4239051342010498\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 722.1061 accuracy= 0.2390\n",
      "inference time:  0.39115381240844727\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 3141.8953 accuracy= 0.1750\n",
      "inference time:  0.45572519302368164\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 11322.1367 accuracy= 0.2060\n",
      "inference time:  0.5789189338684082\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 44796.0039 accuracy= 0.1680\n",
      "inference time:  0.5935399532318115\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 171245.7031 accuracy= 0.2810\n",
      "inference time:  0.6135060787200928\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 704483.2500 accuracy= 0.2860\n",
      "inference time:  0.6539671421051025\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 2887993.7500 accuracy= 0.2930\n",
      "inference time:  0.850844144821167\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 12310760.0000 accuracy= 0.2870\n",
      "inference time:  0.8096110820770264\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 52552016.0000 accuracy= 0.2930\n",
      "inference time:  1.0008769035339355\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 226961440.0000 accuracy= 0.2930\n",
      "inference time:  0.9477770328521729\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 981502208.0000 accuracy= 0.3010\n",
      "inference time:  1.1328151226043701\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 4266723584.0000 accuracy= 0.2940\n",
      "inference time:  1.065114974975586\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 18556422144.0000 accuracy= 0.3010\n",
      "inference time:  1.2627463340759277\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 80865419264.0000 accuracy= 0.3000\n",
      "inference time:  1.4481170177459717\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 352760954880.0000 accuracy= 0.2990\n",
      "inference time:  1.384653091430664\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 1540183949312.0000 accuracy= 0.2910\n",
      "inference time:  1.3647632598876953\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 6730026057728.0000 accuracy= 0.2750\n",
      "inference time:  1.443354845046997\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 29446335627264.0000 accuracy= 0.2680\n",
      "inference time:  1.5772221088409424\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 128836729569280.0000 accuracy= 0.2590\n",
      "inference time:  1.6410658359527588\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 563716135321600.0000 accuracy= 0.2510\n",
      "inference time:  1.8095498085021973\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 2467533068173312.0000 accuracy= 0.2440\n",
      "inference time:  1.760725975036621\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 10807344602546176.0000 accuracy= 0.2280\n",
      "inference time:  2.0200438499450684\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 47326884584751104.0000 accuracy= 0.2110\n",
      "inference time:  1.8033149242401123\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "Test set results: loss= 207333670699139072.0000 accuracy= 0.1960\n",
      "inference time:  1.9140820503234863\n"
     ]
    }
   ],
   "source": [
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "for i in range(1, 30):\n",
    "    model = ite_GCN(nfeat=features.shape[1],\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=0,\n",
    "            train_nite= 3,\n",
    "            eval_nite= i,\n",
    "            allow_grad=True,\n",
    "            smooth_fac=smooth_fac)\n",
    "    model.load_state_dict(model2.state_dict().copy())\n",
    "    loss_test, acc_test = test(model, features, adj, idx_test, labels)\n",
    "    test_losses.append(loss_test.item())\n",
    "    test_accuracies.append(acc_test.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.7942862510681152,\n",
       " 0.711990475654602,\n",
       " 8.17428970336914,\n",
       " 27.297683715820312,\n",
       " 204.85812377929688,\n",
       " 722.1061401367188,\n",
       " 3141.895263671875,\n",
       " 11322.13671875,\n",
       " 44796.00390625,\n",
       " 171245.703125,\n",
       " 704483.25,\n",
       " 2887993.75,\n",
       " 12310760.0,\n",
       " 52552016.0,\n",
       " 226961440.0,\n",
       " 981502208.0,\n",
       " 4266723584.0,\n",
       " 18556422144.0,\n",
       " 80865419264.0,\n",
       " 352760954880.0,\n",
       " 1540183949312.0,\n",
       " 6730026057728.0,\n",
       " 29446335627264.0,\n",
       " 128836729569280.0,\n",
       " 563716135321600.0,\n",
       " 2467533068173312.0,\n",
       " 1.0807344602546176e+16,\n",
       " 4.73268845847511e+16,\n",
       " 2.0733367069913907e+17]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.162,\n",
       " 0.778,\n",
       " 0.342,\n",
       " 0.354,\n",
       " 0.211,\n",
       " 0.239,\n",
       " 0.175,\n",
       " 0.206,\n",
       " 0.168,\n",
       " 0.281,\n",
       " 0.286,\n",
       " 0.293,\n",
       " 0.287,\n",
       " 0.293,\n",
       " 0.293,\n",
       " 0.301,\n",
       " 0.294,\n",
       " 0.301,\n",
       " 0.3,\n",
       " 0.299,\n",
       " 0.291,\n",
       " 0.275,\n",
       " 0.268,\n",
       " 0.259,\n",
       " 0.251,\n",
       " 0.244,\n",
       " 0.228,\n",
       " 0.211,\n",
       " 0.196]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1380afe20>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(test_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x138128820>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2, 2)\n",
    "fig.tight_layout(pad=5.0)\n",
    "ax[0, 0].plot(a, 'b') #row=0, col=0\n",
    "ax[0, 0].title.set_text(\"Training loss\")\n",
    "ax[0, 1].plot(a, 'b') #row=0, col=1\n",
    "ax[0, 1].title.set_text(\"Training accuracy\")\n",
    "ax[1, 0].plot(a, 'b') #row=1, col=0\n",
    "ax[1, 0].title.set_text(\"Validation loss\")\n",
    "ax[1, 1].plot(a, 'b') #row=1, col=1\n",
    "ax[1, 1].title.set_text(\"Validation accuracy\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iterENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
