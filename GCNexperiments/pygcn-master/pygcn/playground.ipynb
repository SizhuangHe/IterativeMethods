{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils import load_data, test, train, accuracy\n",
    "from models import GCN_2, GCN_3\n",
    "from layers import GraphConvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n"
     ]
    }
   ],
   "source": [
    "adj, features, labels, idx_train, idx_val, idx_test = load_data(path=\"../data/cora/\", dataset=\"cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 16\n",
    "dropout = 0.5\n",
    "lr = 0.01\n",
    "weight_decay = 5e-4\n",
    "num_epochs = 200\n",
    "smooth_fac = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ite_GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nclass, dropout, train_nite, eval_nite=0, allow_grad=True, smooth_fac=0):\n",
    "        '''     \n",
    "        - This model is a 1-layer GCN with nite iterations, followed by a linear layer and a log_softmax\n",
    "            - GC layer:     nfeat to nfeat\n",
    "            - linear layer: nfeat to nclass, (to cast hidden representations of nodes to a dimension of nclass)\n",
    "        - Activation: ReLu\n",
    "        - Input:\n",
    "            - nfeat:        the number of features of each node\n",
    "            - nclass:       the number of target classes (we are doing a node classification task here)\n",
    "            - dropout:      dropout rate\n",
    "            - train_nite:   the number of iterations during training\n",
    "            - eval_nite:    the number of iterations during evaluation, \n",
    "                            if not specified (or invalid), intialize to the same as train_nite\n",
    "            - allow_grad:   (bool) defaulted to True. \n",
    "                            whether or nor allow gradients to flow through all GC iterations, \n",
    "                            if False, gradients will only flow to the last iteration\n",
    "            - smooth_fac:   a number in [0,1], smoothing factor, controls how much of the OLD iteration result is\n",
    "                            counted in the skip connection in each iteration\n",
    "                            for example, smooth_fac = x means y_{i+1} = x * y_i + (1-x) * y_{i+1}\n",
    "                            Invalid inputs will be treated as 0.\n",
    "        - Output:\n",
    "            - A probability vector of length nclass, by log_softmax\n",
    "        '''\n",
    "        super(ite_GCN, self).__init__()\n",
    "\n",
    "        self.gc = GraphConvolution(nfeat, nfeat)\n",
    "        self.linear_no_bias = nn.Linear(nfeat, nclass, bias=False)\n",
    "        self.dropout = dropout\n",
    "        self.train_nite = train_nite\n",
    "        self.allow_grad = allow_grad\n",
    "        self.smooth_fac = smooth_fac\n",
    "        self.eval_nite = eval_nite\n",
    "        \n",
    "        if (smooth_fac > 1) or (smooth_fac < 0):\n",
    "            print(\"Invalid smoothing factor. Treat as 0.\")\n",
    "            self.smooth_fac = 0\n",
    "        if (eval_nite <= 0):\n",
    "            print(\"Unspecified or invalid number of iterations for inference. Treat as the same as training iterations.\")\n",
    "            self.eval_nite = self.train_nite\n",
    "        \n",
    "        print(\"Initialize a 1-layer GCN with \", self.train_nite, \"iterations\")\n",
    "        print(\"Gradient flows to all iterations: \", allow_grad)\n",
    "\n",
    "    def run_one_layer(self, x, adj):\n",
    "        x_old = x\n",
    "        x_new = self.gc(x, adj)\n",
    "        x = F.relu(self.smooth_fac * x_old + (1 - self.smooth_fac) * x_new)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        if self.training:\n",
    "            for i in range(self.train_nite):\n",
    "                if not self.allow_grad:\n",
    "                    # print(\"no no no! new new\")\n",
    "                    x = x.detach()\n",
    "                    x = self.run_one_layer(x, adj)\n",
    "                    # x.requires_grad_()\n",
    "                    # self.gc.weight.requires_grad_()\n",
    "                    # self.gc.weight.retain_grad()\n",
    "                    # print(self.gc.weight.requires_grad)\n",
    "                    # for name, param in self.named_parameters():\n",
    "                    #         print(name, param.grad)\n",
    "                else:\n",
    "                    # print(\"yea yea yea\")\n",
    "                    x = self.run_one_layer(x, adj)\n",
    "                    # for name, param in self.named_parameters():\n",
    "                    #         print(name, param.grad)\n",
    "        else:\n",
    "            for i in range(self.eval_nite):\n",
    "                x = self.run_one_layer(x, adj)\n",
    "\n",
    "        x = self.linear_no_bias(x)\n",
    "        # self.gc.weight.requires_grad_()\n",
    "        # print(\"???\")\n",
    "        # for name, param in self.named_parameters():\n",
    "        #     if param.grad is not None:\n",
    "        #         print(name, param.grad.abs().sum())\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(num_epochs, model, lr, weight_decay, features, adj, idx_train, idx_val, idx_test, labels):\n",
    "    print(\"runrunrun!\")\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=lr, weight_decay=weight_decay)\n",
    "    t_total = time.time()\n",
    "    loss_TRAIN = []\n",
    "    acc_TRAIN = []\n",
    "    loss_VAL = []\n",
    "    acc_VAL = []\n",
    "    for epoch in range(num_epochs):\n",
    "        t = time.time()\n",
    "    \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(features, adj)\n",
    "        \n",
    "        loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "        loss_TRAIN.append(loss_train)\n",
    "        acc_train = accuracy(output[idx_train], labels[idx_train])\n",
    "        acc_TRAIN.append(acc_train)\n",
    "\n",
    "        # t3 = time.time()\n",
    "        loss_train.backward()\n",
    "        # t4 = time.time()\n",
    "        # print(\"backward: \", t4-t3)\n",
    "        # print(\"before step: \", model.gc.weight)\n",
    "        optimizer.step()\n",
    "        # print(\"after step: \", model.gc.weight)\n",
    "\n",
    "        \n",
    "        # Evaluate validation set performance separately,\n",
    "        # deactivates dropout during validation run.\n",
    "        model.eval()\n",
    "        # t1 = time.time()\n",
    "        output = model(features, adj)\n",
    "        # print(\"eval output: \", output)\n",
    "        # t2 = time.time()\n",
    "        # print(\"forward time: \", t2-t1)\n",
    "\n",
    "        loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
    "        loss_VAL.append(loss_val)\n",
    "        acc_val = accuracy(output[idx_val], labels[idx_val])\n",
    "        acc_VAL.append(acc_val)\n",
    "        print('Epoch: {:04d}'.format(epoch+1),\n",
    "            'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "            'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "            'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "            'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "            'time: {:.4f}s'.format(time.time() - t))\n",
    "        \n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "    # Testing\n",
    "    test(model, features, adj, idx_test, labels)\n",
    "    return loss_TRAIN, acc_TRAIN, loss_VAL, acc_VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unspecified or invalid number of iterations for inference. Treat as the same as training iterations.\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n"
     ]
    }
   ],
   "source": [
    "model3 = ite_GCN(nfeat=features.shape[1],\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=dropout,\n",
    "            train_nite = 3,\n",
    "            allow_grad=True,\n",
    "            smooth_fac=0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# totally messed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runrunrun!\n",
      "before step:  Parameter containing:\n",
      "tensor([[-1.4470e-02, -1.2860e-02,  2.6237e-02,  ...,  1.6917e-02,\n",
      "         -2.5723e-02,  1.6576e-02],\n",
      "        [ 1.3976e-02, -7.6831e-03, -2.3939e-02,  ...,  2.5840e-02,\n",
      "         -6.5183e-03, -1.8812e-02],\n",
      "        [ 2.1743e-02,  1.9856e-02,  5.1084e-03,  ..., -1.7527e-02,\n",
      "          1.6048e-02, -2.1865e-02],\n",
      "        ...,\n",
      "        [ 8.4447e-03,  2.2534e-02,  1.0558e-02,  ...,  1.5942e-02,\n",
      "          2.5936e-02, -1.3098e-02],\n",
      "        [ 7.3724e-03,  1.6492e-02, -2.6382e-02,  ..., -1.3280e-02,\n",
      "         -2.0492e-03, -1.6572e-02],\n",
      "        [ 9.4801e-05, -2.1704e-02,  2.3851e-03,  ..., -1.8516e-02,\n",
      "         -1.3804e-02,  1.6619e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-0.0045, -0.0029,  0.0162,  ...,  0.0069, -0.0157,  0.0266],\n",
      "        [ 0.0040,  0.0023, -0.0139,  ...,  0.0158,  0.0034, -0.0088],\n",
      "        [ 0.0317,  0.0099, -0.0049,  ..., -0.0075,  0.0260, -0.0119],\n",
      "        ...,\n",
      "        [-0.0015,  0.0125,  0.0006,  ...,  0.0060,  0.0159, -0.0031],\n",
      "        [ 0.0174,  0.0065, -0.0364,  ..., -0.0033,  0.0079, -0.0066],\n",
      "        [ 0.0101, -0.0117, -0.0076,  ..., -0.0085, -0.0038,  0.0266]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-2.6510, -1.4312, -2.0578,  ..., -1.0082, -2.4667, -2.8943],\n",
      "        [-2.6515, -1.4317, -2.0570,  ..., -1.0081, -2.4669, -2.8943],\n",
      "        [-2.6483, -1.4324, -2.0551,  ..., -1.0105, -2.4645, -2.8903],\n",
      "        ...,\n",
      "        [-2.6532, -1.4307, -2.0580,  ..., -1.0067, -2.4687, -2.8968],\n",
      "        [-2.6378, -1.4355, -2.0520,  ..., -1.0175, -2.4560, -2.8779],\n",
      "        [-2.6475, -1.4326, -2.0559,  ..., -1.0108, -2.4637, -2.8892]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0001 loss_train: 1.9467 acc_train: 0.1357 loss_val: 1.8217 acc_val: 0.3500 time: 0.8498s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-0.0045, -0.0029,  0.0162,  ...,  0.0069, -0.0157,  0.0266],\n",
      "        [ 0.0040,  0.0023, -0.0139,  ...,  0.0158,  0.0034, -0.0088],\n",
      "        [ 0.0317,  0.0099, -0.0049,  ..., -0.0075,  0.0260, -0.0119],\n",
      "        ...,\n",
      "        [-0.0015,  0.0125,  0.0006,  ...,  0.0060,  0.0159, -0.0031],\n",
      "        [ 0.0174,  0.0065, -0.0364,  ..., -0.0033,  0.0079, -0.0066],\n",
      "        [ 0.0101, -0.0117, -0.0076,  ..., -0.0085, -0.0038,  0.0266]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-0.0108,  0.0053,  0.0085,  ..., -0.0021, -0.0216,  0.0208],\n",
      "        [-0.0055,  0.0052, -0.0138,  ...,  0.0063, -0.0028, -0.0084],\n",
      "        [ 0.0287,  0.0006, -0.0131,  ...,  0.0015,  0.0292, -0.0094],\n",
      "        ...,\n",
      "        [-0.0107,  0.0031, -0.0092,  ..., -0.0029,  0.0062, -0.0047],\n",
      "        [ 0.0105, -0.0025, -0.0449,  ...,  0.0050,  0.0020, -0.0117],\n",
      "        [ 0.0034, -0.0023, -0.0084,  ...,  0.0007, -0.0106,  0.0198]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-1.9470, -1.9089, -1.8724,  ..., -1.8509, -1.9075, -2.0358],\n",
      "        [-1.9487, -1.9089, -1.8795,  ..., -1.8548, -1.9129, -2.0289],\n",
      "        [-1.9488, -1.9094, -1.8796,  ..., -1.8559, -1.9135, -2.0277],\n",
      "        ...,\n",
      "        [-1.9481, -1.9091, -1.8791,  ..., -1.8554, -1.9125, -2.0288],\n",
      "        [-1.9489, -1.9091, -1.8812,  ..., -1.8562, -1.9140, -2.0269],\n",
      "        [-1.9479, -1.9089, -1.8750,  ..., -1.8521, -1.9098, -2.0329]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0002 loss_train: 1.8485 acc_train: 0.2929 loss_val: 1.9134 acc_val: 0.3500 time: 0.8285s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-0.0108,  0.0053,  0.0085,  ..., -0.0021, -0.0216,  0.0208],\n",
      "        [-0.0055,  0.0052, -0.0138,  ...,  0.0063, -0.0028, -0.0084],\n",
      "        [ 0.0287,  0.0006, -0.0131,  ...,  0.0015,  0.0292, -0.0094],\n",
      "        ...,\n",
      "        [-0.0107,  0.0031, -0.0092,  ..., -0.0029,  0.0062, -0.0047],\n",
      "        [ 0.0105, -0.0025, -0.0449,  ...,  0.0050,  0.0020, -0.0117],\n",
      "        [ 0.0034, -0.0023, -0.0084,  ...,  0.0007, -0.0106,  0.0198]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-1.0496e-02,  8.7369e-03,  1.8904e-03,  ..., -8.1968e-03,\n",
      "         -2.3404e-02,  1.9581e-02],\n",
      "        [-1.1417e-02,  3.7906e-03, -1.0694e-02,  ..., -2.2973e-03,\n",
      "         -8.4591e-03, -6.2296e-03],\n",
      "        [ 2.5423e-02, -6.7838e-03, -1.8886e-02,  ...,  8.0252e-03,\n",
      "          3.1266e-02, -7.3951e-03],\n",
      "        ...,\n",
      "        [-1.4243e-02, -4.9407e-03, -1.3504e-02,  ..., -8.6279e-03,\n",
      "         -1.9172e-03, -4.2662e-03],\n",
      "        [ 9.6859e-03, -8.4180e-03, -4.8043e-02,  ...,  9.3116e-03,\n",
      "         -5.0015e-05, -1.0729e-02],\n",
      "        [ 1.4616e-03,  5.5213e-03, -8.1976e-03,  ...,  7.6351e-03,\n",
      "         -1.3313e-02,  1.7960e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-2.0293, -1.8221, -1.8281,  ..., -1.6674, -1.9220, -2.1579],\n",
      "        [-2.0077, -1.8432, -1.8475,  ..., -1.7212, -1.9236, -2.1119],\n",
      "        [-2.0097, -1.8417, -1.8448,  ..., -1.7173, -1.9236, -2.1152],\n",
      "        ...,\n",
      "        [-2.0100, -1.8402, -1.8454,  ..., -1.7151, -1.9236, -2.1170],\n",
      "        [-2.0070, -1.8439, -1.8481,  ..., -1.7232, -1.9236, -2.1102],\n",
      "        [-2.0212, -1.8300, -1.8347,  ..., -1.6871, -1.9225, -2.1405]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0003 loss_train: 1.9110 acc_train: 0.2714 loss_val: 1.8648 acc_val: 0.3500 time: 0.7413s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-1.0496e-02,  8.7369e-03,  1.8904e-03,  ..., -8.1968e-03,\n",
      "         -2.3404e-02,  1.9581e-02],\n",
      "        [-1.1417e-02,  3.7906e-03, -1.0694e-02,  ..., -2.2973e-03,\n",
      "         -8.4591e-03, -6.2296e-03],\n",
      "        [ 2.5423e-02, -6.7838e-03, -1.8886e-02,  ...,  8.0252e-03,\n",
      "          3.1266e-02, -7.3951e-03],\n",
      "        ...,\n",
      "        [-1.4243e-02, -4.9407e-03, -1.3504e-02,  ..., -8.6279e-03,\n",
      "         -1.9172e-03, -4.2662e-03],\n",
      "        [ 9.6859e-03, -8.4180e-03, -4.8043e-02,  ...,  9.3116e-03,\n",
      "         -5.0015e-05, -1.0729e-02],\n",
      "        [ 1.4616e-03,  5.5213e-03, -8.1976e-03,  ...,  7.6351e-03,\n",
      "         -1.3313e-02,  1.7960e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-0.0076,  0.0081, -0.0036,  ..., -0.0148, -0.0215,  0.0201],\n",
      "        [-0.0142,  0.0004, -0.0064,  ..., -0.0085, -0.0093, -0.0036],\n",
      "        [ 0.0224, -0.0108, -0.0230,  ...,  0.0098,  0.0324, -0.0056],\n",
      "        ...,\n",
      "        [-0.0096, -0.0103, -0.0136,  ..., -0.0160,  0.0019,  0.0013],\n",
      "        [ 0.0105, -0.0104, -0.0479,  ...,  0.0038,  0.0011, -0.0091],\n",
      "        [ 0.0012,  0.0105, -0.0073,  ...,  0.0031, -0.0131,  0.0177]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-2.5110, -1.5338, -1.8036,  ..., -1.0822, -2.1789, -2.8763],\n",
      "        [-2.2971, -1.6033, -1.7901,  ..., -1.2818, -2.0609, -2.5612],\n",
      "        [-2.3309, -1.5897, -1.7882,  ..., -1.2464, -2.0785, -2.6110],\n",
      "        ...,\n",
      "        [-2.3226, -1.5914, -1.7907,  ..., -1.2541, -2.0749, -2.5995],\n",
      "        [-2.3035, -1.6003, -1.7903,  ..., -1.2749, -2.0643, -2.5703],\n",
      "        [-2.4338, -1.5541, -1.7947,  ..., -1.1466, -2.1349, -2.7638]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0004 loss_train: 1.8648 acc_train: 0.2929 loss_val: 1.7727 acc_val: 0.3500 time: 0.7032s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-0.0076,  0.0081, -0.0036,  ..., -0.0148, -0.0215,  0.0201],\n",
      "        [-0.0142,  0.0004, -0.0064,  ..., -0.0085, -0.0093, -0.0036],\n",
      "        [ 0.0224, -0.0108, -0.0230,  ...,  0.0098,  0.0324, -0.0056],\n",
      "        ...,\n",
      "        [-0.0096, -0.0103, -0.0136,  ..., -0.0160,  0.0019,  0.0013],\n",
      "        [ 0.0105, -0.0104, -0.0479,  ...,  0.0038,  0.0011, -0.0091],\n",
      "        [ 0.0012,  0.0105, -0.0073,  ...,  0.0031, -0.0131,  0.0177]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-0.0064,  0.0053, -0.0080,  ..., -0.0196, -0.0200,  0.0206],\n",
      "        [-0.0169,  0.0013, -0.0018,  ..., -0.0125, -0.0137, -0.0057],\n",
      "        [ 0.0183, -0.0116, -0.0258,  ...,  0.0088,  0.0318, -0.0045],\n",
      "        ...,\n",
      "        [-0.0056, -0.0125, -0.0112,  ..., -0.0192,  0.0044,  0.0054],\n",
      "        [ 0.0091, -0.0093, -0.0457,  ..., -0.0010,  0.0012, -0.0076],\n",
      "        [ 0.0012,  0.0123, -0.0059,  ..., -0.0009, -0.0126,  0.0180]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-3.5722, -1.4002, -2.5539,  ..., -0.5455, -3.0478, -4.1639],\n",
      "        [-2.6464, -1.4259, -2.0652,  ..., -0.9426, -2.3506, -2.9873],\n",
      "        [-2.8245, -1.3985, -2.1454,  ..., -0.8351, -2.4796, -3.2182],\n",
      "        ...,\n",
      "        [-2.7560, -1.4053, -2.1183,  ..., -0.8732, -2.4309, -3.1302],\n",
      "        [-2.7069, -1.4139, -2.0938,  ..., -0.9033, -2.3946, -3.0657],\n",
      "        [-3.2304, -1.3820, -2.3609,  ..., -0.6533, -2.7844, -3.7356]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0005 loss_train: 1.7736 acc_train: 0.2929 loss_val: 1.8160 acc_val: 0.3500 time: 0.7440s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-0.0064,  0.0053, -0.0080,  ..., -0.0196, -0.0200,  0.0206],\n",
      "        [-0.0169,  0.0013, -0.0018,  ..., -0.0125, -0.0137, -0.0057],\n",
      "        [ 0.0183, -0.0116, -0.0258,  ...,  0.0088,  0.0318, -0.0045],\n",
      "        ...,\n",
      "        [-0.0056, -0.0125, -0.0112,  ..., -0.0192,  0.0044,  0.0054],\n",
      "        [ 0.0091, -0.0093, -0.0457,  ..., -0.0010,  0.0012, -0.0076],\n",
      "        [ 0.0012,  0.0123, -0.0059,  ..., -0.0009, -0.0126,  0.0180]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-0.0098,  0.0015, -0.0114,  ..., -0.0227, -0.0208,  0.0177],\n",
      "        [-0.0226,  0.0063,  0.0024,  ..., -0.0138, -0.0201, -0.0111],\n",
      "        [ 0.0121, -0.0101, -0.0274,  ...,  0.0062,  0.0281, -0.0070],\n",
      "        ...,\n",
      "        [-0.0044, -0.0122, -0.0075,  ..., -0.0192,  0.0044,  0.0057],\n",
      "        [ 0.0043, -0.0063, -0.0421,  ..., -0.0052, -0.0014, -0.0106],\n",
      "        [-0.0026,  0.0116, -0.0043,  ..., -0.0042, -0.0148,  0.0153]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-2.3870, -1.4390, -1.9402,  ..., -1.1986, -2.1227, -2.6967],\n",
      "        [-2.0537, -1.7251, -1.8912,  ..., -1.6339, -1.9615, -2.1734],\n",
      "        [-2.1047, -1.6611, -1.8867,  ..., -1.5416, -1.9810, -2.2586],\n",
      "        ...,\n",
      "        [-2.0853, -1.6814, -1.8900,  ..., -1.5732, -1.9738, -2.2282],\n",
      "        [-2.0760, -1.6945, -1.8898,  ..., -1.5910, -1.9699, -2.2113],\n",
      "        [-2.2360, -1.5358, -1.9031,  ..., -1.3540, -2.0415, -2.4687]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0006 loss_train: 1.8498 acc_train: 0.2929 loss_val: 1.7484 acc_val: 0.3500 time: 0.7046s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-0.0098,  0.0015, -0.0114,  ..., -0.0227, -0.0208,  0.0177],\n",
      "        [-0.0226,  0.0063,  0.0024,  ..., -0.0138, -0.0201, -0.0111],\n",
      "        [ 0.0121, -0.0101, -0.0274,  ...,  0.0062,  0.0281, -0.0070],\n",
      "        ...,\n",
      "        [-0.0044, -0.0122, -0.0075,  ..., -0.0192,  0.0044,  0.0057],\n",
      "        [ 0.0043, -0.0063, -0.0421,  ..., -0.0052, -0.0014, -0.0106],\n",
      "        [-0.0026,  0.0116, -0.0043,  ..., -0.0042, -0.0148,  0.0153]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-0.0110, -0.0006, -0.0137,  ..., -0.0244, -0.0198,  0.0160],\n",
      "        [-0.0279,  0.0079,  0.0057,  ..., -0.0129, -0.0264, -0.0166],\n",
      "        [ 0.0064, -0.0071, -0.0281,  ...,  0.0028,  0.0238, -0.0094],\n",
      "        ...,\n",
      "        [-0.0040, -0.0101, -0.0031,  ..., -0.0171,  0.0041,  0.0052],\n",
      "        [ 0.0009, -0.0011, -0.0376,  ..., -0.0087, -0.0021, -0.0121],\n",
      "        [-0.0039,  0.0109, -0.0025,  ..., -0.0070, -0.0150,  0.0142]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-2.2730, -1.4634, -1.9132,  ..., -1.3607, -2.0434, -2.5279],\n",
      "        [-1.9752, -1.8591, -1.9193,  ..., -1.8337, -1.9434, -2.0241],\n",
      "        [-2.0058, -1.7947, -1.9050,  ..., -1.7574, -1.9472, -2.0840],\n",
      "        ...,\n",
      "        [-1.9935, -1.8165, -1.9119,  ..., -1.7840, -1.9456, -2.0620],\n",
      "        [-1.9893, -1.8269, -1.9129,  ..., -1.7958, -1.9447, -2.0527],\n",
      "        [-2.1153, -1.6234, -1.8936,  ..., -1.5531, -1.9771, -2.2772]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0007 loss_train: 1.7352 acc_train: 0.2857 loss_val: 1.7831 acc_val: 0.3500 time: 0.6843s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-0.0110, -0.0006, -0.0137,  ..., -0.0244, -0.0198,  0.0160],\n",
      "        [-0.0279,  0.0079,  0.0057,  ..., -0.0129, -0.0264, -0.0166],\n",
      "        [ 0.0064, -0.0071, -0.0281,  ...,  0.0028,  0.0238, -0.0094],\n",
      "        ...,\n",
      "        [-0.0040, -0.0101, -0.0031,  ..., -0.0171,  0.0041,  0.0052],\n",
      "        [ 0.0009, -0.0011, -0.0376,  ..., -0.0087, -0.0021, -0.0121],\n",
      "        [-0.0039,  0.0109, -0.0025,  ..., -0.0070, -0.0150,  0.0142]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-0.0109, -0.0057, -0.0149,  ..., -0.0247, -0.0179,  0.0157],\n",
      "        [-0.0296,  0.0122,  0.0078,  ..., -0.0106, -0.0322, -0.0196],\n",
      "        [ 0.0013, -0.0034, -0.0280,  ..., -0.0007,  0.0198, -0.0110],\n",
      "        ...,\n",
      "        [-0.0039, -0.0068,  0.0012,  ..., -0.0135,  0.0038,  0.0039],\n",
      "        [-0.0008, -0.0054, -0.0324,  ..., -0.0115, -0.0018, -0.0116],\n",
      "        [-0.0032,  0.0061, -0.0008,  ..., -0.0090, -0.0140,  0.0147]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-2.6136, -1.2011, -2.0778,  ..., -1.1584, -2.2419, -2.9624],\n",
      "        [-1.9785, -1.8567, -1.9256,  ..., -1.8391, -1.9467, -2.0193],\n",
      "        [-2.0314, -1.7478, -1.9107,  ..., -1.7263, -1.9561, -2.1126],\n",
      "        ...,\n",
      "        [-2.0063, -1.7929, -1.9186,  ..., -1.7731, -1.9514, -2.0715],\n",
      "        [-2.0011, -1.8050, -1.9186,  ..., -1.7853, -1.9501, -2.0615],\n",
      "        [-2.2625, -1.4450, -1.9446,  ..., -1.4111, -2.0470, -2.4715]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0008 loss_train: 1.7607 acc_train: 0.2643 loss_val: 1.7156 acc_val: 0.3500 time: 0.7516s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-0.0109, -0.0057, -0.0149,  ..., -0.0247, -0.0179,  0.0157],\n",
      "        [-0.0296,  0.0122,  0.0078,  ..., -0.0106, -0.0322, -0.0196],\n",
      "        [ 0.0013, -0.0034, -0.0280,  ..., -0.0007,  0.0198, -0.0110],\n",
      "        ...,\n",
      "        [-0.0039, -0.0068,  0.0012,  ..., -0.0135,  0.0038,  0.0039],\n",
      "        [-0.0008, -0.0054, -0.0324,  ..., -0.0115, -0.0018, -0.0116],\n",
      "        [-0.0032,  0.0061, -0.0008,  ..., -0.0090, -0.0140,  0.0147]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-0.0096, -0.0068, -0.0153,  ..., -0.0240, -0.0154,  0.0163],\n",
      "        [-0.0294,  0.0183,  0.0085,  ..., -0.0073, -0.0364, -0.0206],\n",
      "        [-0.0029,  0.0004, -0.0272,  ..., -0.0036,  0.0158, -0.0118],\n",
      "        ...,\n",
      "        [-0.0033, -0.0031,  0.0048,  ..., -0.0092,  0.0030,  0.0024],\n",
      "        [-0.0009, -0.0050, -0.0269,  ..., -0.0137, -0.0007, -0.0098],\n",
      "        [-0.0013,  0.0085,  0.0008,  ..., -0.0104, -0.0125,  0.0160]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-4.2418, -0.8152, -3.1335,  ..., -0.7822, -3.4477, -4.8658],\n",
      "        [-2.0676, -1.6909, -1.9211,  ..., -1.6744, -1.9742, -2.1520],\n",
      "        [-2.2750, -1.4370, -1.9645,  ..., -1.4192, -2.0691, -2.4430],\n",
      "        ...,\n",
      "        [-2.1497, -1.5713, -1.9397,  ..., -1.5539, -2.0104, -2.2711],\n",
      "        [-2.1400, -1.5859, -1.9336,  ..., -1.5683, -2.0044, -2.2569],\n",
      "        [-3.1182, -0.9968, -2.4128,  ..., -0.9686, -2.6210, -3.5106]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0009 loss_train: 1.6747 acc_train: 0.2500 loss_val: 1.6032 acc_val: 0.3500 time: 0.7765s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-0.0096, -0.0068, -0.0153,  ..., -0.0240, -0.0154,  0.0163],\n",
      "        [-0.0294,  0.0183,  0.0085,  ..., -0.0073, -0.0364, -0.0206],\n",
      "        [-0.0029,  0.0004, -0.0272,  ..., -0.0036,  0.0158, -0.0118],\n",
      "        ...,\n",
      "        [-0.0033, -0.0031,  0.0048,  ..., -0.0092,  0.0030,  0.0024],\n",
      "        [-0.0009, -0.0050, -0.0269,  ..., -0.0137, -0.0007, -0.0098],\n",
      "        [-0.0013,  0.0085,  0.0008,  ..., -0.0104, -0.0125,  0.0160]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-0.0075, -0.0044, -0.0148,  ..., -0.0224, -0.0139,  0.0179],\n",
      "        [-0.0286,  0.0253,  0.0079,  ..., -0.0036, -0.0415, -0.0215],\n",
      "        [-0.0066,  0.0037, -0.0258,  ..., -0.0056,  0.0112, -0.0126],\n",
      "        ...,\n",
      "        [-0.0026,  0.0007,  0.0073,  ..., -0.0044,  0.0015, -0.0012],\n",
      "        [-0.0006, -0.0024, -0.0212,  ..., -0.0152, -0.0017, -0.0070],\n",
      "        [ 0.0014,  0.0132,  0.0022,  ..., -0.0111, -0.0126,  0.0184]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-6.5201, -1.3932, -4.4900,  ..., -0.3116, -5.1252, -7.3205],\n",
      "        [-1.9624, -1.9243, -1.9443,  ..., -1.8901, -1.9520, -1.9707],\n",
      "        [-2.1871, -1.6234, -1.9241,  ..., -1.4782, -2.0223, -2.2908],\n",
      "        ...,\n",
      "        [-2.0269, -1.8124, -1.9284,  ..., -1.7317, -1.9674, -2.0720],\n",
      "        [-2.0172, -1.8281, -1.9265,  ..., -1.7533, -1.9637, -2.0582],\n",
      "        [-4.0274, -1.1857, -2.8758,  ..., -0.5704, -3.2465, -4.4811]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0010 loss_train: 1.5641 acc_train: 0.2071 loss_val: 1.4721 acc_val: 0.3500 time: 0.7058s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-0.0075, -0.0044, -0.0148,  ..., -0.0224, -0.0139,  0.0179],\n",
      "        [-0.0286,  0.0253,  0.0079,  ..., -0.0036, -0.0415, -0.0215],\n",
      "        [-0.0066,  0.0037, -0.0258,  ..., -0.0056,  0.0112, -0.0126],\n",
      "        ...,\n",
      "        [-0.0026,  0.0007,  0.0073,  ..., -0.0044,  0.0015, -0.0012],\n",
      "        [-0.0006, -0.0024, -0.0212,  ..., -0.0152, -0.0017, -0.0070],\n",
      "        [ 0.0014,  0.0132,  0.0022,  ..., -0.0111, -0.0126,  0.0184]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-0.0058, -0.0035, -0.0136,  ..., -0.0200, -0.0121,  0.0191],\n",
      "        [-0.0268,  0.0333,  0.0064,  ...,  0.0002, -0.0455, -0.0226],\n",
      "        [-0.0105,  0.0061, -0.0240,  ..., -0.0064,  0.0058, -0.0141],\n",
      "        ...,\n",
      "        [-0.0021,  0.0040,  0.0085,  ...,  0.0002, -0.0007, -0.0063],\n",
      "        [-0.0008, -0.0012, -0.0154,  ..., -0.0162, -0.0023, -0.0048],\n",
      "        [ 0.0033,  0.0143,  0.0032,  ..., -0.0112, -0.0114,  0.0201]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-7.7313, -1.4315, -4.7764,  ..., -0.2893, -5.7599, -8.4708],\n",
      "        [-1.9489, -1.9487, -1.9371,  ..., -1.9203, -1.9570, -1.9586],\n",
      "        [-1.9490, -1.9465, -1.9394,  ..., -1.9243, -1.9552, -1.9565],\n",
      "        ...,\n",
      "        [-1.9486, -1.9480, -1.9384,  ..., -1.9233, -1.9556, -1.9572],\n",
      "        [-1.9485, -1.9479, -1.9386,  ..., -1.9237, -1.9556, -1.9569],\n",
      "        [-3.7001, -1.1793, -2.4990,  ..., -0.6872, -2.9057, -3.9998]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0011 loss_train: 1.4492 acc_train: 0.2929 loss_val: 1.4646 acc_val: 0.3500 time: 0.8159s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-0.0058, -0.0035, -0.0136,  ..., -0.0200, -0.0121,  0.0191],\n",
      "        [-0.0268,  0.0333,  0.0064,  ...,  0.0002, -0.0455, -0.0226],\n",
      "        [-0.0105,  0.0061, -0.0240,  ..., -0.0064,  0.0058, -0.0141],\n",
      "        ...,\n",
      "        [-0.0021,  0.0040,  0.0085,  ...,  0.0002, -0.0007, -0.0063],\n",
      "        [-0.0008, -0.0012, -0.0154,  ..., -0.0162, -0.0023, -0.0048],\n",
      "        [ 0.0033,  0.0143,  0.0032,  ..., -0.0112, -0.0114,  0.0201]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-0.0041, -0.0038, -0.0119,  ..., -0.0172, -0.0099,  0.0205],\n",
      "        [-0.0240,  0.0388,  0.0043,  ...,  0.0035, -0.0446, -0.0207],\n",
      "        [-0.0140,  0.0071, -0.0218,  ..., -0.0060,  0.0011, -0.0149],\n",
      "        ...,\n",
      "        [-0.0016,  0.0063,  0.0083,  ...,  0.0043, -0.0026, -0.0105],\n",
      "        [-0.0012, -0.0017, -0.0097,  ..., -0.0167, -0.0017, -0.0027],\n",
      "        [ 0.0047,  0.0140,  0.0040,  ..., -0.0108, -0.0095,  0.0217]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-10.3813,  -0.9928,  -6.0197,  ...,  -0.4678,  -7.4146, -11.1810],\n",
      "        [ -1.9393,  -1.9642,  -1.9209,  ...,  -1.9242,  -1.9517,  -1.9638],\n",
      "        [ -1.9404,  -1.9608,  -1.9256,  ...,  -1.9295,  -1.9505,  -1.9598],\n",
      "        ...,\n",
      "        [ -1.9401,  -1.9623,  -1.9237,  ...,  -1.9271,  -1.9510,  -1.9615],\n",
      "        [ -1.9399,  -1.9621,  -1.9241,  ...,  -1.9275,  -1.9509,  -1.9613],\n",
      "        [ -4.1771,  -0.9590,  -2.6649,  ...,  -0.7522,  -3.1565,  -4.4533]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0012 loss_train: 1.4165 acc_train: 0.2929 loss_val: 1.4900 acc_val: 0.4267 time: 0.8070s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-0.0041, -0.0038, -0.0119,  ..., -0.0172, -0.0099,  0.0205],\n",
      "        [-0.0240,  0.0388,  0.0043,  ...,  0.0035, -0.0446, -0.0207],\n",
      "        [-0.0140,  0.0071, -0.0218,  ..., -0.0060,  0.0011, -0.0149],\n",
      "        ...,\n",
      "        [-0.0016,  0.0063,  0.0083,  ...,  0.0043, -0.0026, -0.0105],\n",
      "        [-0.0012, -0.0017, -0.0097,  ..., -0.0167, -0.0017, -0.0027],\n",
      "        [ 0.0047,  0.0140,  0.0040,  ..., -0.0108, -0.0095,  0.0217]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-0.0023, -0.0024, -0.0098,  ..., -0.0140, -0.0085,  0.0226],\n",
      "        [-0.0201,  0.0416,  0.0018,  ...,  0.0061, -0.0417, -0.0166],\n",
      "        [-0.0168,  0.0071, -0.0193,  ..., -0.0046, -0.0029, -0.0147],\n",
      "        ...,\n",
      "        [-0.0010,  0.0076,  0.0071,  ...,  0.0076, -0.0042, -0.0139],\n",
      "        [-0.0017, -0.0018, -0.0044,  ..., -0.0167, -0.0011, -0.0008],\n",
      "        [ 0.0065,  0.0144,  0.0043,  ..., -0.0099, -0.0085,  0.0242]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-15.2770,  -0.8929,  -8.4815,  ...,  -0.5271, -10.5156, -16.2265],\n",
      "        [ -1.9216,  -1.9956,  -1.8931,  ...,  -1.9480,  -1.9336,  -1.9627],\n",
      "        [ -1.9266,  -1.9847,  -1.9039,  ...,  -1.9486,  -1.9364,  -1.9588],\n",
      "        ...,\n",
      "        [ -1.9242,  -1.9899,  -1.8991,  ...,  -1.9481,  -1.9351,  -1.9605],\n",
      "        [ -1.9242,  -1.9895,  -1.8996,  ...,  -1.9483,  -1.9352,  -1.9603],\n",
      "        [ -6.0951,  -0.8064,  -3.5687,  ...,  -0.6779,  -4.3334,  -6.4524]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0013 loss_train: 1.4086 acc_train: 0.3643 loss_val: 1.4669 acc_val: 0.4267 time: 0.7205s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-0.0023, -0.0024, -0.0098,  ..., -0.0140, -0.0085,  0.0226],\n",
      "        [-0.0201,  0.0416,  0.0018,  ...,  0.0061, -0.0417, -0.0166],\n",
      "        [-0.0168,  0.0071, -0.0193,  ..., -0.0046, -0.0029, -0.0147],\n",
      "        ...,\n",
      "        [-0.0010,  0.0076,  0.0071,  ...,  0.0076, -0.0042, -0.0139],\n",
      "        [-0.0017, -0.0018, -0.0044,  ..., -0.0167, -0.0011, -0.0008],\n",
      "        [ 0.0065,  0.0144,  0.0043,  ..., -0.0099, -0.0085,  0.0242]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-0.0001, -0.0006, -0.0075,  ..., -0.0106, -0.0084,  0.0243],\n",
      "        [-0.0151,  0.0426, -0.0007,  ...,  0.0078, -0.0399, -0.0106],\n",
      "        [-0.0191,  0.0060, -0.0166,  ..., -0.0026, -0.0065, -0.0137],\n",
      "        ...,\n",
      "        [-0.0007,  0.0077,  0.0050,  ...,  0.0099, -0.0055, -0.0161],\n",
      "        [-0.0018, -0.0022,  0.0007,  ..., -0.0163, -0.0009,  0.0009],\n",
      "        [ 0.0093,  0.0162,  0.0043,  ..., -0.0086, -0.0089,  0.0261]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-20.6841,  -2.4744, -10.8884,  ...,  -0.0880, -13.6113, -21.5925],\n",
      "        [ -1.8923,  -2.0511,  -1.8520,  ...,  -1.9889,  -1.8994,  -1.9591],\n",
      "        [ -1.9055,  -2.0246,  -1.8719,  ...,  -1.9789,  -1.9101,  -1.9563],\n",
      "        ...,\n",
      "        [ -1.8988,  -2.0376,  -1.8627,  ...,  -1.9839,  -1.9051,  -1.9573],\n",
      "        [ -1.8984,  -2.0378,  -1.8629,  ...,  -1.9843,  -1.9050,  -1.9571],\n",
      "        [ -8.3509,  -1.2783,  -4.4809,  ...,  -0.3483,  -5.5733,  -8.7133]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0014 loss_train: 1.4039 acc_train: 0.3714 loss_val: 1.4288 acc_val: 0.4267 time: 0.6953s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-0.0001, -0.0006, -0.0075,  ..., -0.0106, -0.0084,  0.0243],\n",
      "        [-0.0151,  0.0426, -0.0007,  ...,  0.0078, -0.0399, -0.0106],\n",
      "        [-0.0191,  0.0060, -0.0166,  ..., -0.0026, -0.0065, -0.0137],\n",
      "        ...,\n",
      "        [-0.0007,  0.0077,  0.0050,  ...,  0.0099, -0.0055, -0.0161],\n",
      "        [-0.0018, -0.0022,  0.0007,  ..., -0.0163, -0.0009,  0.0009],\n",
      "        [ 0.0093,  0.0162,  0.0043,  ..., -0.0086, -0.0089,  0.0261]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-0.0003, -0.0034, -0.0050,  ..., -0.0071, -0.0082,  0.0225],\n",
      "        [-0.0129,  0.0401, -0.0028,  ...,  0.0083, -0.0362, -0.0086],\n",
      "        [-0.0213,  0.0045, -0.0137,  ..., -0.0004, -0.0101, -0.0129],\n",
      "        ...,\n",
      "        [-0.0005,  0.0069,  0.0026,  ...,  0.0109, -0.0064, -0.0182],\n",
      "        [-0.0029, -0.0050,  0.0052,  ..., -0.0154, -0.0005,  0.0003],\n",
      "        [ 0.0082,  0.0123,  0.0040,  ..., -0.0070, -0.0083,  0.0232]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-19.2861,  -0.5647,  -9.0942,  ...,  -0.8408, -11.8415, -19.8586],\n",
      "        [ -1.8323,  -2.1554,  -1.7816,  ...,  -2.0809,  -1.8437,  -1.9499],\n",
      "        [ -1.8541,  -2.1102,  -1.8126,  ...,  -2.0534,  -1.8637,  -1.9479],\n",
      "        ...,\n",
      "        [ -1.8436,  -2.1313,  -1.7984,  ...,  -2.0660,  -1.8543,  -1.9487],\n",
      "        [ -1.8422,  -2.1336,  -1.7972,  ...,  -2.0676,  -1.8534,  -1.9486],\n",
      "        [ -7.0517,  -0.6770,  -3.5008,  ...,  -0.8019,  -4.4814,  -7.2531]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0015 loss_train: 1.4190 acc_train: 0.4071 loss_val: 1.4980 acc_val: 0.2633 time: 0.6765s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-0.0003, -0.0034, -0.0050,  ..., -0.0071, -0.0082,  0.0225],\n",
      "        [-0.0129,  0.0401, -0.0028,  ...,  0.0083, -0.0362, -0.0086],\n",
      "        [-0.0213,  0.0045, -0.0137,  ..., -0.0004, -0.0101, -0.0129],\n",
      "        ...,\n",
      "        [-0.0005,  0.0069,  0.0026,  ...,  0.0109, -0.0064, -0.0182],\n",
      "        [-0.0029, -0.0050,  0.0052,  ..., -0.0154, -0.0005,  0.0003],\n",
      "        [ 0.0082,  0.0123,  0.0040,  ..., -0.0070, -0.0083,  0.0232]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 2.4292e-04, -4.9002e-03, -3.1725e-03,  ..., -3.6127e-03,\n",
      "         -8.7370e-03,  2.1232e-02],\n",
      "        [-1.0069e-02,  3.6929e-02, -4.8155e-03,  ...,  7.8565e-03,\n",
      "         -3.2383e-02, -6.1795e-03],\n",
      "        [-2.3038e-02,  2.5207e-03, -1.0826e-02,  ...,  1.6661e-03,\n",
      "         -1.3310e-02, -1.1302e-02],\n",
      "        ...,\n",
      "        [-4.2894e-04,  5.2112e-03, -2.0422e-05,  ...,  1.0847e-02,\n",
      "         -6.9596e-03, -1.9254e-02],\n",
      "        [-3.4432e-03, -6.4894e-03,  8.2495e-03,  ..., -1.4266e-02,\n",
      "         -5.1529e-04,  6.4588e-05],\n",
      "        [ 8.5437e-03,  1.0767e-02,  7.8850e-04,  ..., -5.3004e-03,\n",
      "         -9.2975e-03,  2.1344e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-19.0248,  -1.1811,  -8.1326,  ...,  -0.3671, -11.1820, -19.3195],\n",
      "        [ -1.7521,  -2.3314,  -1.6877,  ...,  -2.2303,  -1.7659,  -1.9326],\n",
      "        [ -1.7842,  -2.2564,  -1.7278,  ...,  -2.1756,  -1.7941,  -1.9324],\n",
      "        ...,\n",
      "        [ -1.7695,  -2.2894,  -1.7109,  ...,  -2.1993,  -1.7817,  -1.9320],\n",
      "        [ -1.7646,  -2.2998,  -1.7055,  ...,  -2.2073,  -1.7779,  -1.9318],\n",
      "        [ -6.6889,  -0.9127,  -2.9960,  ...,  -0.6374,  -4.0697,  -6.7960]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0016 loss_train: 1.3614 acc_train: 0.4357 loss_val: 1.4526 acc_val: 0.4100 time: 0.6744s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 2.4292e-04, -4.9002e-03, -3.1725e-03,  ..., -3.6127e-03,\n",
      "         -8.7370e-03,  2.1232e-02],\n",
      "        [-1.0069e-02,  3.6929e-02, -4.8155e-03,  ...,  7.8565e-03,\n",
      "         -3.2383e-02, -6.1795e-03],\n",
      "        [-2.3038e-02,  2.5207e-03, -1.0826e-02,  ...,  1.6661e-03,\n",
      "         -1.3310e-02, -1.1302e-02],\n",
      "        ...,\n",
      "        [-4.2894e-04,  5.2112e-03, -2.0422e-05,  ...,  1.0847e-02,\n",
      "         -6.9596e-03, -1.9254e-02],\n",
      "        [-3.4432e-03, -6.4894e-03,  8.2495e-03,  ..., -1.4266e-02,\n",
      "         -5.1529e-04,  6.4588e-05],\n",
      "        [ 8.5437e-03,  1.0767e-02,  7.8850e-04,  ..., -5.3004e-03,\n",
      "         -9.2975e-03,  2.1344e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.1634e-03, -5.2685e-03, -1.3914e-03,  ..., -3.4553e-04,\n",
      "         -9.3244e-03,  2.0336e-02],\n",
      "        [-6.9834e-03,  3.3010e-02, -5.9624e-03,  ...,  6.5732e-03,\n",
      "         -2.8043e-02, -2.7744e-03],\n",
      "        [-2.4073e-02,  9.5166e-04, -7.9426e-03,  ...,  3.2666e-03,\n",
      "         -1.6008e-02, -8.2110e-03],\n",
      "        ...,\n",
      "        [-2.3701e-04,  3.0629e-03, -2.3617e-03,  ...,  9.7989e-03,\n",
      "         -7.1599e-03, -1.9586e-02],\n",
      "        [-3.7896e-03, -7.3074e-03,  1.0778e-02,  ..., -1.2837e-02,\n",
      "         -5.4047e-04, -4.4053e-05],\n",
      "        [ 9.2969e-03,  1.0778e-02, -2.2004e-03,  ..., -3.4616e-03,\n",
      "         -1.0120e-02,  2.0489e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-23.1432,  -3.2130,  -9.6187,  ...,  -0.0411, -13.5353, -23.2313],\n",
      "        [ -1.6799,  -2.5732,  -1.5588,  ...,  -2.4327,  -1.6729,  -1.9391],\n",
      "        [ -1.7445,  -2.4278,  -1.5942,  ...,  -2.3110,  -1.7049,  -1.9532],\n",
      "        ...,\n",
      "        [ -1.7060,  -2.4984,  -1.5873,  ...,  -2.3733,  -1.6935,  -1.9385],\n",
      "        [ -1.6909,  -2.5366,  -1.5750,  ...,  -2.4045,  -1.6836,  -1.9372],\n",
      "        [ -9.6043,  -1.5863,  -3.9087,  ...,  -0.2595,  -5.6065,  -9.6534]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0017 loss_train: 1.3047 acc_train: 0.4071 loss_val: 1.3887 acc_val: 0.4233 time: 0.6852s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.1634e-03, -5.2685e-03, -1.3914e-03,  ..., -3.4553e-04,\n",
      "         -9.3244e-03,  2.0336e-02],\n",
      "        [-6.9834e-03,  3.3010e-02, -5.9624e-03,  ...,  6.5732e-03,\n",
      "         -2.8043e-02, -2.7744e-03],\n",
      "        [-2.4073e-02,  9.5166e-04, -7.9426e-03,  ...,  3.2666e-03,\n",
      "         -1.6008e-02, -8.2110e-03],\n",
      "        ...,\n",
      "        [-2.3701e-04,  3.0629e-03, -2.3617e-03,  ...,  9.7989e-03,\n",
      "         -7.1599e-03, -1.9586e-02],\n",
      "        [-3.7896e-03, -7.3074e-03,  1.0778e-02,  ..., -1.2837e-02,\n",
      "         -5.4047e-04, -4.4053e-05],\n",
      "        [ 9.2969e-03,  1.0778e-02, -2.2004e-03,  ..., -3.4616e-03,\n",
      "         -1.0120e-02,  2.0489e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0017, -0.0059,  0.0003,  ...,  0.0026, -0.0096,  0.0192],\n",
      "        [-0.0047,  0.0284, -0.0062,  ...,  0.0047, -0.0232,  0.0018],\n",
      "        [-0.0251,  0.0001, -0.0051,  ...,  0.0042, -0.0186, -0.0059],\n",
      "        ...,\n",
      "        [-0.0002,  0.0007, -0.0042,  ...,  0.0080, -0.0071, -0.0194],\n",
      "        [-0.0042, -0.0082,  0.0127,  ..., -0.0112, -0.0004, -0.0004],\n",
      "        [ 0.0095,  0.0100, -0.0048,  ..., -0.0016, -0.0101,  0.0189]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-22.5310,  -2.4057,  -8.8699,  ...,  -0.0947, -12.5921, -22.3622],\n",
      "        [ -1.5810,  -3.0582,  -1.3702,  ...,  -2.8846,  -1.5317,  -1.9913],\n",
      "        [ -1.6907,  -2.8011,  -1.3666,  ...,  -2.6646,  -1.5419,  -2.0333],\n",
      "        ...,\n",
      "        [ -1.6131,  -2.9300,  -1.3978,  ...,  -2.7769,  -1.5503,  -1.9866],\n",
      "        [ -1.5823,  -3.0358,  -1.3802,  ...,  -2.8656,  -1.5371,  -1.9863],\n",
      "        [ -9.8379,  -1.2943,  -3.6834,  ...,  -0.3622,  -5.4056,  -9.8078]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0018 loss_train: 1.2483 acc_train: 0.4214 loss_val: 1.3728 acc_val: 0.4133 time: 0.8886s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0017, -0.0059,  0.0003,  ...,  0.0026, -0.0096,  0.0192],\n",
      "        [-0.0047,  0.0284, -0.0062,  ...,  0.0047, -0.0232,  0.0018],\n",
      "        [-0.0251,  0.0001, -0.0051,  ...,  0.0042, -0.0186, -0.0059],\n",
      "        ...,\n",
      "        [-0.0002,  0.0007, -0.0042,  ...,  0.0080, -0.0071, -0.0194],\n",
      "        [-0.0042, -0.0082,  0.0127,  ..., -0.0112, -0.0004, -0.0004],\n",
      "        [ 0.0095,  0.0100, -0.0048,  ..., -0.0016, -0.0101,  0.0189]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0024, -0.0061,  0.0018,  ...,  0.0055, -0.0101,  0.0184],\n",
      "        [-0.0020,  0.0232, -0.0056,  ...,  0.0026, -0.0185,  0.0068],\n",
      "        [-0.0257, -0.0006, -0.0025,  ...,  0.0043, -0.0207, -0.0045],\n",
      "        ...,\n",
      "        [-0.0001, -0.0015, -0.0052,  ...,  0.0056, -0.0067, -0.0192],\n",
      "        [-0.0045, -0.0087,  0.0141,  ..., -0.0093, -0.0004, -0.0006],\n",
      "        [ 0.0101,  0.0094, -0.0068,  ...,  0.0006, -0.0096,  0.0175]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-23.5308,  -1.4223,  -9.0985,  ...,  -0.2761, -12.7703, -23.1041],\n",
      "        [ -1.5020,  -3.6713,  -1.2175,  ...,  -3.5561,  -1.4297,  -2.0781],\n",
      "        [ -1.7965,  -3.0679,  -1.0843,  ...,  -3.1086,  -1.3897,  -2.2765],\n",
      "        ...,\n",
      "        [ -1.5496,  -3.4470,  -1.2291,  ...,  -3.3706,  -1.4350,  -2.0798],\n",
      "        [ -1.4769,  -3.7271,  -1.2322,  ...,  -3.5972,  -1.4326,  -2.0679],\n",
      "        [-11.4148,  -0.8516,  -4.1180,  ...,  -0.5896,  -6.0312, -11.3102]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0019 loss_train: 1.1967 acc_train: 0.4357 loss_val: 1.4138 acc_val: 0.4600 time: 0.6949s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0024, -0.0061,  0.0018,  ...,  0.0055, -0.0101,  0.0184],\n",
      "        [-0.0020,  0.0232, -0.0056,  ...,  0.0026, -0.0185,  0.0068],\n",
      "        [-0.0257, -0.0006, -0.0025,  ...,  0.0043, -0.0207, -0.0045],\n",
      "        ...,\n",
      "        [-0.0001, -0.0015, -0.0052,  ...,  0.0056, -0.0067, -0.0192],\n",
      "        [-0.0045, -0.0087,  0.0141,  ..., -0.0093, -0.0004, -0.0006],\n",
      "        [ 0.0101,  0.0094, -0.0068,  ...,  0.0006, -0.0096,  0.0175]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 3.3671e-03, -5.8751e-03,  3.1014e-03,  ...,  8.4219e-03,\n",
      "         -1.0587e-02,  1.7821e-02],\n",
      "        [ 9.6822e-04,  1.7898e-02, -4.3958e-03,  ...,  5.4070e-04,\n",
      "         -1.3749e-02,  1.2112e-02],\n",
      "        [-2.5629e-02, -3.8576e-04,  4.3117e-05,  ...,  3.6496e-03,\n",
      "         -2.2339e-02, -4.0911e-03],\n",
      "        ...,\n",
      "        [ 1.0184e-04, -3.3561e-03, -5.5017e-03,  ...,  2.9035e-03,\n",
      "         -6.1178e-03, -1.8926e-02],\n",
      "        [-4.4405e-03, -8.6088e-03,  1.4837e-02,  ..., -6.4300e-03,\n",
      "         -4.6685e-04, -5.1656e-04],\n",
      "        [ 1.1727e-02,  9.4814e-03, -8.3040e-03,  ...,  5.2673e-03,\n",
      "         -9.4074e-03,  1.7326e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-32.3024,  -3.1371, -13.4659,  ...,  -0.0444, -18.0657, -31.1143],\n",
      "        [ -1.6442,  -3.6233,  -1.1002,  ...,  -3.6630,  -1.3497,  -2.2032],\n",
      "        [ -2.9172,  -2.0530,  -0.8679,  ...,  -2.1978,  -1.4736,  -3.2239],\n",
      "        ...,\n",
      "        [ -1.7753,  -3.2085,  -1.0840,  ...,  -3.3114,  -1.3484,  -2.2677],\n",
      "        [ -1.4365,  -4.0394,  -1.2289,  ...,  -4.0144,  -1.3787,  -2.0794],\n",
      "        [-18.4761,  -1.6961,  -7.3210,  ...,  -0.2035, -10.1270, -17.8684]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0020 loss_train: 1.1434 acc_train: 0.5286 loss_val: 1.5240 acc_val: 0.4367 time: 0.7022s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 3.3671e-03, -5.8751e-03,  3.1014e-03,  ...,  8.4219e-03,\n",
      "         -1.0587e-02,  1.7821e-02],\n",
      "        [ 9.6822e-04,  1.7898e-02, -4.3958e-03,  ...,  5.4070e-04,\n",
      "         -1.3749e-02,  1.2112e-02],\n",
      "        [-2.5629e-02, -3.8576e-04,  4.3117e-05,  ...,  3.6496e-03,\n",
      "         -2.2339e-02, -4.0911e-03],\n",
      "        ...,\n",
      "        [ 1.0184e-04, -3.3561e-03, -5.5017e-03,  ...,  2.9035e-03,\n",
      "         -6.1178e-03, -1.8926e-02],\n",
      "        [-4.4405e-03, -8.6088e-03,  1.4837e-02,  ..., -6.4300e-03,\n",
      "         -4.6685e-04, -5.1656e-04],\n",
      "        [ 1.1727e-02,  9.4814e-03, -8.3040e-03,  ...,  5.2673e-03,\n",
      "         -9.4074e-03,  1.7326e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 4.3507e-03, -5.3725e-03,  4.1133e-03,  ...,  1.1668e-02,\n",
      "         -1.1206e-02,  1.6907e-02],\n",
      "        [ 3.7134e-03,  1.1767e-02, -2.6975e-03,  ..., -1.2842e-03,\n",
      "         -9.1193e-03,  9.7818e-03],\n",
      "        [-2.5511e-02, -9.7609e-05,  2.3139e-03,  ...,  2.4742e-03,\n",
      "         -2.3614e-02, -8.5269e-03],\n",
      "        ...,\n",
      "        [ 4.7835e-04, -4.4341e-03, -4.9989e-03,  ...,  2.2906e-05,\n",
      "         -5.6405e-03, -2.2972e-02],\n",
      "        [-4.3515e-03, -8.5275e-03,  1.5044e-02,  ..., -4.7228e-03,\n",
      "         -5.0941e-04, -2.1698e-03],\n",
      "        [ 1.2931e-02,  9.3251e-03, -9.1259e-03,  ...,  9.9844e-03,\n",
      "         -9.8341e-03,  1.6514e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-18.6055,  -1.6005,  -6.7937,  ...,  -0.2269,  -9.5458, -17.4748],\n",
      "        [ -0.9856,  -5.6514,  -1.5945,  ...,  -5.5115,  -1.5145,  -1.9381],\n",
      "        [ -1.0111,  -5.5223,  -1.5720,  ...,  -5.4086,  -1.5049,  -1.9361],\n",
      "        ...,\n",
      "        [ -1.0136,  -5.4178,  -1.5900,  ...,  -5.2885,  -1.5141,  -1.9166],\n",
      "        [ -0.9467,  -5.9481,  -1.6075,  ...,  -5.7919,  -1.5182,  -1.9691],\n",
      "        [ -6.1139,  -1.0501,  -1.6448,  ...,  -0.9589,  -2.6891,  -5.9560]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0021 loss_train: 1.2013 acc_train: 0.4714 loss_val: 2.0508 acc_val: 0.2567 time: 0.6767s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 4.3507e-03, -5.3725e-03,  4.1133e-03,  ...,  1.1668e-02,\n",
      "         -1.1206e-02,  1.6907e-02],\n",
      "        [ 3.7134e-03,  1.1767e-02, -2.6975e-03,  ..., -1.2842e-03,\n",
      "         -9.1193e-03,  9.7818e-03],\n",
      "        [-2.5511e-02, -9.7609e-05,  2.3139e-03,  ...,  2.4742e-03,\n",
      "         -2.3614e-02, -8.5269e-03],\n",
      "        ...,\n",
      "        [ 4.7835e-04, -4.4341e-03, -4.9989e-03,  ...,  2.2906e-05,\n",
      "         -5.6405e-03, -2.2972e-02],\n",
      "        [-4.3515e-03, -8.5275e-03,  1.5044e-02,  ..., -4.7228e-03,\n",
      "         -5.0941e-04, -2.1698e-03],\n",
      "        [ 1.2931e-02,  9.3251e-03, -9.1259e-03,  ...,  9.9844e-03,\n",
      "         -9.8341e-03,  1.6514e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0068, -0.0044,  0.0048,  ...,  0.0151, -0.0118,  0.0181],\n",
      "        [ 0.0068,  0.0057, -0.0008,  ..., -0.0028, -0.0046,  0.0097],\n",
      "        [-0.0234,  0.0002,  0.0043,  ...,  0.0010, -0.0245, -0.0090],\n",
      "        ...,\n",
      "        [ 0.0013, -0.0048, -0.0039,  ..., -0.0026, -0.0050, -0.0256],\n",
      "        [-0.0039, -0.0081,  0.0147,  ..., -0.0026, -0.0006, -0.0020],\n",
      "        [ 0.0152,  0.0098, -0.0093,  ...,  0.0160, -0.0102,  0.0175]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-3.1520e+01, -4.0373e+00, -1.2735e+01,  ..., -1.7806e-02,\n",
      "         -1.7326e+01, -2.8751e+01],\n",
      "        [-1.1275e+00, -4.6866e+00, -1.6737e+00,  ..., -4.6806e+00,\n",
      "         -1.6091e+00, -1.7162e+00],\n",
      "        [-1.2082e+00, -4.4166e+00, -1.5966e+00,  ..., -4.4911e+00,\n",
      "         -1.5585e+00, -1.7436e+00],\n",
      "        ...,\n",
      "        [-1.1583e+00, -4.4774e+00, -1.6722e+00,  ..., -4.4814e+00,\n",
      "         -1.6077e+00, -1.7135e+00],\n",
      "        [-1.0693e+00, -5.0230e+00, -1.6926e+00,  ..., -5.0051e+00,\n",
      "         -1.6153e+00, -1.7277e+00],\n",
      "        [-1.6244e+01, -1.8780e+00, -6.2392e+00,  ..., -1.6844e-01,\n",
      "         -8.7162e+00, -1.4852e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0022 loss_train: 1.6985 acc_train: 0.3143 loss_val: 1.3521 acc_val: 0.4633 time: 0.6773s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0068, -0.0044,  0.0048,  ...,  0.0151, -0.0118,  0.0181],\n",
      "        [ 0.0068,  0.0057, -0.0008,  ..., -0.0028, -0.0046,  0.0097],\n",
      "        [-0.0234,  0.0002,  0.0043,  ...,  0.0010, -0.0245, -0.0090],\n",
      "        ...,\n",
      "        [ 0.0013, -0.0048, -0.0039,  ..., -0.0026, -0.0050, -0.0256],\n",
      "        [-0.0039, -0.0081,  0.0147,  ..., -0.0026, -0.0006, -0.0020],\n",
      "        [ 0.0152,  0.0098, -0.0093,  ...,  0.0160, -0.0102,  0.0175]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0093, -0.0034,  0.0052,  ...,  0.0182, -0.0123,  0.0184],\n",
      "        [ 0.0094,  0.0002,  0.0010,  ..., -0.0038, -0.0004,  0.0116],\n",
      "        [-0.0215,  0.0004,  0.0060,  ..., -0.0005, -0.0250, -0.0093],\n",
      "        ...,\n",
      "        [ 0.0020, -0.0045, -0.0023,  ..., -0.0047, -0.0043, -0.0272],\n",
      "        [-0.0036, -0.0079,  0.0140,  ..., -0.0012, -0.0005, -0.0017],\n",
      "        [ 0.0176,  0.0102, -0.0089,  ...,  0.0213, -0.0106,  0.0186]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-4.5823e+01, -6.6911e+00, -1.8808e+01,  ..., -1.2427e-03,\n",
      "         -2.5769e+01, -4.0918e+01],\n",
      "        [-1.4227e+00, -3.6198e+00, -1.5819e+00,  ..., -3.8308e+00,\n",
      "         -1.6072e+00, -1.6995e+00],\n",
      "        [-2.3069e+00, -2.0996e+00, -1.1935e+00,  ..., -2.5890e+00,\n",
      "         -1.4928e+00, -2.2913e+00],\n",
      "        ...,\n",
      "        [-1.5117e+00, -3.2572e+00, -1.5548e+00,  ..., -3.5362e+00,\n",
      "         -1.5887e+00, -1.7520e+00],\n",
      "        [-1.2788e+00, -4.1549e+00, -1.6635e+00,  ..., -4.2922e+00,\n",
      "         -1.6538e+00, -1.6488e+00],\n",
      "        [-2.8169e+01, -3.8053e+00, -1.1265e+01,  ..., -2.2518e-02,\n",
      "         -1.5659e+01, -2.5179e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0023 loss_train: 1.0063 acc_train: 0.5786 loss_val: 1.6067 acc_val: 0.4367 time: 0.6788s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0093, -0.0034,  0.0052,  ...,  0.0182, -0.0123,  0.0184],\n",
      "        [ 0.0094,  0.0002,  0.0010,  ..., -0.0038, -0.0004,  0.0116],\n",
      "        [-0.0215,  0.0004,  0.0060,  ..., -0.0005, -0.0250, -0.0093],\n",
      "        ...,\n",
      "        [ 0.0020, -0.0045, -0.0023,  ..., -0.0047, -0.0043, -0.0272],\n",
      "        [-0.0036, -0.0079,  0.0140,  ..., -0.0012, -0.0005, -0.0017],\n",
      "        [ 0.0176,  0.0102, -0.0089,  ...,  0.0213, -0.0106,  0.0186]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0092, -0.0033,  0.0053,  ...,  0.0188, -0.0123,  0.0174],\n",
      "        [ 0.0104, -0.0049,  0.0026,  ..., -0.0043,  0.0034,  0.0108],\n",
      "        [-0.0216,  0.0009,  0.0074,  ..., -0.0018, -0.0252, -0.0123],\n",
      "        ...,\n",
      "        [ 0.0017, -0.0035, -0.0006,  ..., -0.0062, -0.0035, -0.0323],\n",
      "        [-0.0046, -0.0087,  0.0128,  ..., -0.0011,  0.0005, -0.0040],\n",
      "        [ 0.0180,  0.0103, -0.0080,  ...,  0.0240, -0.0113,  0.0183]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-40.2248,  -1.6060, -14.6364,  ...,  -0.2240, -21.0539, -35.0627],\n",
      "        [ -1.3988,  -3.7440,  -1.6719,  ...,  -4.0138,  -1.7008,  -1.6208],\n",
      "        [ -1.7571,  -2.8412,  -1.3987,  ...,  -3.4813,  -1.5573,  -1.8584],\n",
      "        ...,\n",
      "        [ -1.4430,  -3.5043,  -1.6653,  ...,  -3.8178,  -1.6824,  -1.6490],\n",
      "        [ -1.3009,  -4.2075,  -1.7171,  ...,  -4.4515,  -1.7329,  -1.5830],\n",
      "        [-24.2565,  -0.8595,  -8.7794,  ...,  -0.5508, -12.6617, -21.2134]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0024 loss_train: 1.2069 acc_train: 0.4500 loss_val: 1.4466 acc_val: 0.4500 time: 0.6855s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0092, -0.0033,  0.0053,  ...,  0.0188, -0.0123,  0.0174],\n",
      "        [ 0.0104, -0.0049,  0.0026,  ..., -0.0043,  0.0034,  0.0108],\n",
      "        [-0.0216,  0.0009,  0.0074,  ..., -0.0018, -0.0252, -0.0123],\n",
      "        ...,\n",
      "        [ 0.0017, -0.0035, -0.0006,  ..., -0.0062, -0.0035, -0.0323],\n",
      "        [-0.0046, -0.0087,  0.0128,  ..., -0.0011,  0.0005, -0.0040],\n",
      "        [ 0.0180,  0.0103, -0.0080,  ...,  0.0240, -0.0113,  0.0183]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0099, -0.0025,  0.0051,  ...,  0.0194, -0.0133,  0.0173],\n",
      "        [ 0.0110, -0.0093,  0.0036,  ..., -0.0043,  0.0069,  0.0104],\n",
      "        [-0.0215,  0.0011,  0.0085,  ..., -0.0027, -0.0251, -0.0155],\n",
      "        ...,\n",
      "        [ 0.0017, -0.0018,  0.0010,  ..., -0.0069, -0.0031, -0.0358],\n",
      "        [-0.0053, -0.0092,  0.0113,  ..., -0.0008,  0.0006, -0.0057],\n",
      "        [ 0.0200,  0.0108, -0.0067,  ...,  0.0266, -0.0131,  0.0199]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-37.7519,  -2.8855, -11.8948,  ...,  -0.0575, -18.9289, -32.0650],\n",
      "        [ -1.3758,  -4.0702,  -1.7083,  ...,  -4.3009,  -1.7841,  -1.5556],\n",
      "        [ -1.4535,  -3.9294,  -1.6110,  ...,  -4.2489,  -1.7324,  -1.5945],\n",
      "        ...,\n",
      "        [ -1.3847,  -3.9677,  -1.7169,  ...,  -4.1996,  -1.7796,  -1.5625],\n",
      "        [ -1.3098,  -4.5027,  -1.7316,  ...,  -4.7582,  -1.8060,  -1.5282],\n",
      "        [-21.4216,  -1.4577,  -6.5232,  ...,  -0.2669, -10.5984, -18.2179]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0025 loss_train: 1.0554 acc_train: 0.5857 loss_val: 1.2971 acc_val: 0.5300 time: 0.6836s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0099, -0.0025,  0.0051,  ...,  0.0194, -0.0133,  0.0173],\n",
      "        [ 0.0110, -0.0093,  0.0036,  ..., -0.0043,  0.0069,  0.0104],\n",
      "        [-0.0215,  0.0011,  0.0085,  ..., -0.0027, -0.0251, -0.0155],\n",
      "        ...,\n",
      "        [ 0.0017, -0.0018,  0.0010,  ..., -0.0069, -0.0031, -0.0358],\n",
      "        [-0.0053, -0.0092,  0.0113,  ..., -0.0008,  0.0006, -0.0057],\n",
      "        [ 0.0200,  0.0108, -0.0067,  ...,  0.0266, -0.0131,  0.0199]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.1083e-02, -1.6649e-03,  4.6072e-03,  ...,  2.0194e-02,\n",
      "         -1.4774e-02,  1.7468e-02],\n",
      "        [ 1.1087e-02, -1.3069e-02,  4.0583e-03,  ..., -3.6909e-03,\n",
      "          9.7374e-03,  1.2108e-02],\n",
      "        [-2.1333e-02,  1.1246e-03,  9.2912e-03,  ..., -2.9838e-03,\n",
      "         -2.4669e-02, -1.7929e-02],\n",
      "        ...,\n",
      "        [ 2.0203e-03,  9.6618e-05,  2.4076e-03,  ..., -6.7673e-03,\n",
      "         -3.0320e-03, -3.8130e-02],\n",
      "        [-5.8242e-03, -9.3890e-03,  9.5715e-03,  ..., -3.9013e-04,\n",
      "          6.1221e-04, -6.8542e-03],\n",
      "        [ 2.2702e-02,  1.1339e-02, -5.1017e-03,  ...,  2.9778e-02,\n",
      "         -1.5371e-02,  2.2412e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.9517e+01, -6.7335e+00, -1.0757e+01,  ..., -1.2125e-03,\n",
      "         -1.9612e+01, -3.2919e+01],\n",
      "        [-1.4250e+00, -4.2336e+00, -1.6374e+00,  ..., -4.4416e+00,\n",
      "         -1.7859e+00, -1.5585e+00],\n",
      "        [-1.4906e+00, -4.2880e+00, -1.5167e+00,  ..., -4.4976e+00,\n",
      "         -1.7605e+00, -1.5876e+00],\n",
      "        ...,\n",
      "        [-1.4147e+00, -4.1935e+00, -1.6632e+00,  ..., -4.4076e+00,\n",
      "         -1.7897e+00, -1.5562e+00],\n",
      "        [-1.3572e+00, -4.7171e+00, -1.6637e+00,  ..., -4.9635e+00,\n",
      "         -1.8143e+00, -1.5295e+00],\n",
      "        [-2.1951e+01, -3.7313e+00, -5.4957e+00,  ..., -2.8491e-02,\n",
      "         -1.0685e+01, -1.8257e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0026 loss_train: 0.9383 acc_train: 0.6714 loss_val: 1.2810 acc_val: 0.5667 time: 0.7034s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.1083e-02, -1.6649e-03,  4.6072e-03,  ...,  2.0194e-02,\n",
      "         -1.4774e-02,  1.7468e-02],\n",
      "        [ 1.1087e-02, -1.3069e-02,  4.0583e-03,  ..., -3.6909e-03,\n",
      "          9.7374e-03,  1.2108e-02],\n",
      "        [-2.1333e-02,  1.1246e-03,  9.2912e-03,  ..., -2.9838e-03,\n",
      "         -2.4669e-02, -1.7929e-02],\n",
      "        ...,\n",
      "        [ 2.0203e-03,  9.6618e-05,  2.4076e-03,  ..., -6.7673e-03,\n",
      "         -3.0320e-03, -3.8130e-02],\n",
      "        [-5.8242e-03, -9.3890e-03,  9.5715e-03,  ..., -3.9013e-04,\n",
      "          6.1221e-04, -6.8542e-03],\n",
      "        [ 2.2702e-02,  1.1339e-02, -5.1017e-03,  ...,  2.9778e-02,\n",
      "         -1.5371e-02,  2.2412e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0120, -0.0008,  0.0039,  ...,  0.0202, -0.0161,  0.0176],\n",
      "        [ 0.0103, -0.0162,  0.0039,  ..., -0.0027,  0.0120,  0.0148],\n",
      "        [-0.0213,  0.0009,  0.0097,  ..., -0.0027, -0.0240, -0.0203],\n",
      "        ...,\n",
      "        [ 0.0021,  0.0019,  0.0033,  ..., -0.0060, -0.0028, -0.0397],\n",
      "        [-0.0064, -0.0095,  0.0077,  ..., -0.0003,  0.0007, -0.0081],\n",
      "        [ 0.0252,  0.0117, -0.0033,  ...,  0.0317, -0.0176,  0.0246]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-4.0781e+01, -8.9431e+00, -9.2502e+00,  ..., -2.2671e-04,\n",
      "         -1.9794e+01, -3.3376e+01],\n",
      "        [-1.5093e+00, -4.3893e+00, -1.4803e+00,  ..., -4.5987e+00,\n",
      "         -1.7462e+00, -1.6048e+00],\n",
      "        [-1.6557e+00, -4.5217e+00, -1.2577e+00,  ..., -4.6797e+00,\n",
      "         -1.7117e+00, -1.6770e+00],\n",
      "        ...,\n",
      "        [-1.4752e+00, -4.3937e+00, -1.5356e+00,  ..., -4.6228e+00,\n",
      "         -1.7527e+00, -1.5907e+00],\n",
      "        [-1.4361e+00, -4.9398e+00, -1.5057e+00,  ..., -5.1998e+00,\n",
      "         -1.7717e+00, -1.5747e+00],\n",
      "        [-2.2672e+01, -5.1965e+00, -4.5260e+00,  ..., -1.6516e-02,\n",
      "         -1.0809e+01, -1.8502e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0027 loss_train: 0.9081 acc_train: 0.6571 loss_val: 1.3199 acc_val: 0.5533 time: 0.8397s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0120, -0.0008,  0.0039,  ...,  0.0202, -0.0161,  0.0176],\n",
      "        [ 0.0103, -0.0162,  0.0039,  ..., -0.0027,  0.0120,  0.0148],\n",
      "        [-0.0213,  0.0009,  0.0097,  ..., -0.0027, -0.0240, -0.0203],\n",
      "        ...,\n",
      "        [ 0.0021,  0.0019,  0.0033,  ..., -0.0060, -0.0028, -0.0397],\n",
      "        [-0.0064, -0.0095,  0.0077,  ..., -0.0003,  0.0007, -0.0081],\n",
      "        [ 0.0252,  0.0117, -0.0033,  ...,  0.0317, -0.0176,  0.0246]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.2910e-02,  6.4349e-05,  3.0932e-03,  ...,  1.9198e-02,\n",
      "         -1.7226e-02,  1.7407e-02],\n",
      "        [ 9.2808e-03, -1.8690e-02,  3.2396e-03,  ..., -1.5082e-03,\n",
      "          1.3756e-02,  1.8413e-02],\n",
      "        [-2.1026e-02,  6.2745e-04,  9.8737e-03,  ..., -1.9999e-03,\n",
      "         -2.3093e-02, -2.2181e-02],\n",
      "        ...,\n",
      "        [ 1.9916e-03,  3.3156e-03,  3.6419e-03,  ..., -4.7390e-03,\n",
      "         -2.5117e-03, -4.0755e-02],\n",
      "        [-6.9284e-03, -9.4514e-03,  5.6535e-03,  ..., -5.8133e-04,\n",
      "          8.6415e-04, -9.3843e-03],\n",
      "        [ 2.7411e-02,  1.2008e-02, -1.4808e-03,  ...,  3.2069e-02,\n",
      "         -1.9492e-02,  2.6553e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.2918e+01, -9.7264e+00, -8.8084e+00,  ..., -2.0919e-04,\n",
      "         -2.0240e+01, -3.4679e+01],\n",
      "        [-1.6479e+00, -4.4583e+00, -1.2787e+00,  ..., -4.7025e+00,\n",
      "         -1.6405e+00, -1.7228e+00],\n",
      "        [-2.1112e+00, -4.6000e+00, -8.3772e-01,  ..., -4.7501e+00,\n",
      "         -1.6171e+00, -2.0152e+00],\n",
      "        ...,\n",
      "        [-1.5732e+00, -4.4960e+00, -1.3749e+00,  ..., -4.7846e+00,\n",
      "         -1.6530e+00, -1.6846e+00],\n",
      "        [-1.5506e+00, -5.0786e+00, -1.3184e+00,  ..., -5.4048e+00,\n",
      "         -1.6592e+00, -1.6888e+00],\n",
      "        [-2.4558e+01, -5.9231e+00, -4.2952e+00,  ..., -1.6457e-02,\n",
      "         -1.1376e+01, -1.9788e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0028 loss_train: 0.8723 acc_train: 0.6143 loss_val: 1.3036 acc_val: 0.5100 time: 0.6765s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.2910e-02,  6.4349e-05,  3.0932e-03,  ...,  1.9198e-02,\n",
      "         -1.7226e-02,  1.7407e-02],\n",
      "        [ 9.2808e-03, -1.8690e-02,  3.2396e-03,  ..., -1.5082e-03,\n",
      "          1.3756e-02,  1.8413e-02],\n",
      "        [-2.1026e-02,  6.2745e-04,  9.8737e-03,  ..., -1.9999e-03,\n",
      "         -2.3093e-02, -2.2181e-02],\n",
      "        ...,\n",
      "        [ 1.9916e-03,  3.3156e-03,  3.6419e-03,  ..., -4.7390e-03,\n",
      "         -2.5117e-03, -4.0755e-02],\n",
      "        [-6.9284e-03, -9.4514e-03,  5.6535e-03,  ..., -5.8133e-04,\n",
      "          8.6415e-04, -9.3843e-03],\n",
      "        [ 2.7411e-02,  1.2008e-02, -1.4808e-03,  ...,  3.2069e-02,\n",
      "         -1.9492e-02,  2.6553e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0137,  0.0011,  0.0022,  ...,  0.0176, -0.0181,  0.0170],\n",
      "        [ 0.0080, -0.0205,  0.0022,  ..., -0.0002,  0.0149,  0.0225],\n",
      "        [-0.0205,  0.0002,  0.0097,  ..., -0.0010, -0.0220, -0.0240],\n",
      "        ...,\n",
      "        [ 0.0017,  0.0042,  0.0034,  ..., -0.0031, -0.0021, -0.0411],\n",
      "        [-0.0074, -0.0093,  0.0036,  ..., -0.0009,  0.0011, -0.0108],\n",
      "        [ 0.0294,  0.0129,  0.0003,  ...,  0.0313, -0.0210,  0.0281]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-4.4535e+01, -8.3590e+00, -9.4983e+00,  ..., -3.0930e-04,\n",
      "         -2.0085e+01, -3.5692e+01],\n",
      "        [-1.7309e+00, -4.3498e+00, -1.2448e+00,  ..., -4.7781e+00,\n",
      "         -1.4630e+00, -1.8461e+00],\n",
      "        [-2.9798e+00, -4.2007e+00, -5.2891e-01,  ..., -4.6930e+00,\n",
      "         -1.5105e+00, -2.7450e+00],\n",
      "        ...,\n",
      "        [-1.6137e+00, -4.4303e+00, -1.3805e+00,  ..., -4.9091e+00,\n",
      "         -1.4789e+00, -1.7841e+00],\n",
      "        [-1.5679e+00, -5.0824e+00, -1.3491e+00,  ..., -5.6012e+00,\n",
      "         -1.4724e+00, -1.7875e+00],\n",
      "        [-2.6191e+01, -5.2117e+00, -4.7813e+00,  ..., -1.3944e-02,\n",
      "         -1.1558e+01, -2.0959e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0029 loss_train: 0.8358 acc_train: 0.6286 loss_val: 1.2400 acc_val: 0.5200 time: 0.7679s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0137,  0.0011,  0.0022,  ...,  0.0176, -0.0181,  0.0170],\n",
      "        [ 0.0080, -0.0205,  0.0022,  ..., -0.0002,  0.0149,  0.0225],\n",
      "        [-0.0205,  0.0002,  0.0097,  ..., -0.0010, -0.0220, -0.0240],\n",
      "        ...,\n",
      "        [ 0.0017,  0.0042,  0.0034,  ..., -0.0031, -0.0021, -0.0411],\n",
      "        [-0.0074, -0.0093,  0.0036,  ..., -0.0009,  0.0011, -0.0108],\n",
      "        [ 0.0294,  0.0129,  0.0003,  ...,  0.0313, -0.0210,  0.0281]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0144,  0.0022,  0.0012,  ...,  0.0153, -0.0189,  0.0166],\n",
      "        [ 0.0066, -0.0216,  0.0009,  ...,  0.0010,  0.0154,  0.0267],\n",
      "        [-0.0197, -0.0002,  0.0093,  ...,  0.0001, -0.0207, -0.0257],\n",
      "        ...,\n",
      "        [ 0.0013,  0.0045,  0.0027,  ..., -0.0013, -0.0017, -0.0412],\n",
      "        [-0.0079, -0.0091,  0.0017,  ..., -0.0011,  0.0013, -0.0122],\n",
      "        [ 0.0313,  0.0133,  0.0019,  ...,  0.0296, -0.0223,  0.0295]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-4.5797e+01, -6.4936e+00, -1.0735e+01,  ..., -1.5360e-03,\n",
      "         -1.9715e+01, -3.6466e+01],\n",
      "        [-1.7438e+00, -4.0580e+00, -1.4018e+00,  ..., -4.8705e+00,\n",
      "         -1.2443e+00, -1.9322e+00],\n",
      "        [-4.0079e+00, -3.3114e+00, -4.9082e-01,  ..., -4.4831e+00,\n",
      "         -1.3170e+00, -3.5812e+00],\n",
      "        ...,\n",
      "        [-1.5987e+00, -4.2213e+00, -1.5681e+00,  ..., -5.0483e+00,\n",
      "         -1.2740e+00, -1.8459e+00],\n",
      "        [-1.4575e+00, -5.0387e+00, -1.6434e+00,  ..., -5.8720e+00,\n",
      "         -1.2908e+00, -1.8019e+00],\n",
      "        [-2.7369e+01, -3.9869e+00, -5.6583e+00,  ..., -2.2302e-02,\n",
      "         -1.1469e+01, -2.1768e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0030 loss_train: 0.7369 acc_train: 0.6357 loss_val: 1.2504 acc_val: 0.5500 time: 0.7496s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0144,  0.0022,  0.0012,  ...,  0.0153, -0.0189,  0.0166],\n",
      "        [ 0.0066, -0.0216,  0.0009,  ...,  0.0010,  0.0154,  0.0267],\n",
      "        [-0.0197, -0.0002,  0.0093,  ...,  0.0001, -0.0207, -0.0257],\n",
      "        ...,\n",
      "        [ 0.0013,  0.0045,  0.0027,  ..., -0.0013, -0.0017, -0.0412],\n",
      "        [-0.0079, -0.0091,  0.0017,  ..., -0.0011,  0.0013, -0.0122],\n",
      "        [ 0.0313,  0.0133,  0.0019,  ...,  0.0296, -0.0223,  0.0295]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0150,  0.0031,  0.0002,  ...,  0.0130, -0.0196,  0.0163],\n",
      "        [ 0.0051, -0.0220, -0.0004,  ...,  0.0020,  0.0153,  0.0322],\n",
      "        [-0.0187, -0.0005,  0.0087,  ...,  0.0011, -0.0193, -0.0270],\n",
      "        ...,\n",
      "        [ 0.0008,  0.0041,  0.0017,  ...,  0.0006, -0.0012, -0.0407],\n",
      "        [-0.0083, -0.0088, -0.0002,  ..., -0.0012,  0.0015, -0.0133],\n",
      "        [ 0.0333,  0.0132,  0.0032,  ...,  0.0285, -0.0239,  0.0313]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-4.9096e+01, -8.9515e+00, -1.2433e+01,  ..., -1.3351e-04,\n",
      "         -2.1899e+01, -3.8861e+01],\n",
      "        [-1.4288e+00, -4.4368e+00, -1.8105e+00,  ..., -5.1781e+00,\n",
      "         -1.3241e+00, -1.7293e+00],\n",
      "        [-4.3719e+00, -3.5735e+00, -4.1630e-01,  ..., -4.3814e+00,\n",
      "         -1.4062e+00, -3.7727e+00],\n",
      "        ...,\n",
      "        [-1.3042e+00, -4.6402e+00, -2.0177e+00,  ..., -5.4169e+00,\n",
      "         -1.3803e+00, -1.6693e+00],\n",
      "        [-1.1526e+00, -5.5322e+00, -2.1818e+00,  ..., -6.3459e+00,\n",
      "         -1.4380e+00, -1.6299e+00],\n",
      "        [-2.9737e+01, -5.8809e+00, -6.8208e+00,  ..., -3.8927e-03,\n",
      "         -1.3126e+01, -2.3514e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0031 loss_train: 0.7204 acc_train: 0.6929 loss_val: 1.1680 acc_val: 0.6400 time: 0.6887s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0150,  0.0031,  0.0002,  ...,  0.0130, -0.0196,  0.0163],\n",
      "        [ 0.0051, -0.0220, -0.0004,  ...,  0.0020,  0.0153,  0.0322],\n",
      "        [-0.0187, -0.0005,  0.0087,  ...,  0.0011, -0.0193, -0.0270],\n",
      "        ...,\n",
      "        [ 0.0008,  0.0041,  0.0017,  ...,  0.0006, -0.0012, -0.0407],\n",
      "        [-0.0083, -0.0088, -0.0002,  ..., -0.0012,  0.0015, -0.0133],\n",
      "        [ 0.0333,  0.0132,  0.0032,  ...,  0.0285, -0.0239,  0.0313]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0156,  0.0036, -0.0006,  ...,  0.0105, -0.0202,  0.0161],\n",
      "        [ 0.0035, -0.0219, -0.0015,  ...,  0.0026,  0.0148,  0.0372],\n",
      "        [-0.0176, -0.0007,  0.0079,  ...,  0.0018, -0.0177, -0.0282],\n",
      "        ...,\n",
      "        [ 0.0003,  0.0031,  0.0005,  ...,  0.0022, -0.0007, -0.0397],\n",
      "        [-0.0086, -0.0084, -0.0019,  ..., -0.0013,  0.0016, -0.0144],\n",
      "        [ 0.0353,  0.0130,  0.0042,  ...,  0.0267, -0.0254,  0.0331]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-5.2366e+01, -1.3340e+01, -1.2374e+01,  ..., -5.8412e-06,\n",
      "         -2.4748e+01, -4.1141e+01],\n",
      "        [-1.0859e+00, -5.2760e+00, -2.2847e+00,  ..., -5.7811e+00,\n",
      "         -1.6294e+00, -1.5142e+00],\n",
      "        [-4.9623e+00, -5.0125e+00, -1.8558e-01,  ..., -4.6596e+00,\n",
      "         -2.1059e+00, -4.1594e+00],\n",
      "        ...,\n",
      "        [-9.9085e-01, -5.4612e+00, -2.5615e+00,  ..., -6.0739e+00,\n",
      "         -1.6985e+00, -1.4969e+00],\n",
      "        [-8.6389e-01, -6.4482e+00, -2.8241e+00,  ..., -7.1518e+00,\n",
      "         -1.7844e+00, -1.4842e+00],\n",
      "        [-3.1639e+01, -8.9735e+00, -6.7071e+00,  ..., -1.3501e-03,\n",
      "         -1.5053e+01, -2.4794e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0032 loss_train: 0.6123 acc_train: 0.8071 loss_val: 1.1293 acc_val: 0.6433 time: 0.7330s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0156,  0.0036, -0.0006,  ...,  0.0105, -0.0202,  0.0161],\n",
      "        [ 0.0035, -0.0219, -0.0015,  ...,  0.0026,  0.0148,  0.0372],\n",
      "        [-0.0176, -0.0007,  0.0079,  ...,  0.0018, -0.0177, -0.0282],\n",
      "        ...,\n",
      "        [ 0.0003,  0.0031,  0.0005,  ...,  0.0022, -0.0007, -0.0397],\n",
      "        [-0.0086, -0.0084, -0.0019,  ..., -0.0013,  0.0016, -0.0144],\n",
      "        [ 0.0353,  0.0130,  0.0042,  ...,  0.0267, -0.0254,  0.0331]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0161,  0.0038, -0.0013,  ...,  0.0078, -0.0206,  0.0159],\n",
      "        [ 0.0020, -0.0212, -0.0023,  ...,  0.0028,  0.0138,  0.0420],\n",
      "        [-0.0164, -0.0008,  0.0069,  ...,  0.0021, -0.0161, -0.0293],\n",
      "        ...,\n",
      "        [-0.0003,  0.0018, -0.0006,  ...,  0.0034, -0.0002, -0.0383],\n",
      "        [-0.0088, -0.0079, -0.0034,  ..., -0.0014,  0.0017, -0.0155],\n",
      "        [ 0.0371,  0.0123,  0.0049,  ...,  0.0241, -0.0266,  0.0346]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-5.5515e+01, -1.6047e+01, -1.0512e+01,  ..., -2.7299e-05,\n",
      "         -2.6639e+01, -4.2965e+01],\n",
      "        [-1.0465e+00, -5.7713e+00, -2.3690e+00,  ..., -6.2147e+00,\n",
      "         -1.6996e+00, -1.4415e+00],\n",
      "        [-7.9857e+00, -6.8654e+00, -3.0402e-02,  ..., -5.3466e+00,\n",
      "         -3.8361e+00, -6.4493e+00],\n",
      "        ...,\n",
      "        [-8.8687e-01, -6.0748e+00, -2.8877e+00,  ..., -6.6581e+00,\n",
      "         -1.8503e+00, -1.4284e+00],\n",
      "        [-7.4359e-01, -7.2654e+00, -3.3124e+00,  ..., -7.9754e+00,\n",
      "         -2.0110e+00, -1.4250e+00],\n",
      "        [-3.3549e+01, -1.0720e+01, -5.3733e+00,  ..., -4.6717e-03,\n",
      "         -1.6248e+01, -2.5841e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0033 loss_train: 0.5805 acc_train: 0.7714 loss_val: 1.2000 acc_val: 0.6400 time: 0.7463s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0161,  0.0038, -0.0013,  ...,  0.0078, -0.0206,  0.0159],\n",
      "        [ 0.0020, -0.0212, -0.0023,  ...,  0.0028,  0.0138,  0.0420],\n",
      "        [-0.0164, -0.0008,  0.0069,  ...,  0.0021, -0.0161, -0.0293],\n",
      "        ...,\n",
      "        [-0.0003,  0.0018, -0.0006,  ...,  0.0034, -0.0002, -0.0383],\n",
      "        [-0.0088, -0.0079, -0.0034,  ..., -0.0014,  0.0017, -0.0155],\n",
      "        [ 0.0371,  0.0123,  0.0049,  ...,  0.0241, -0.0266,  0.0346]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0165,  0.0046, -0.0017,  ...,  0.0053, -0.0210,  0.0156],\n",
      "        [ 0.0007, -0.0201, -0.0027,  ...,  0.0027,  0.0124,  0.0462],\n",
      "        [-0.0151, -0.0007,  0.0058,  ...,  0.0019, -0.0144, -0.0307],\n",
      "        ...,\n",
      "        [-0.0008,  0.0004, -0.0016,  ...,  0.0042,  0.0002, -0.0371],\n",
      "        [-0.0090, -0.0073, -0.0046,  ..., -0.0014,  0.0019, -0.0169],\n",
      "        [ 0.0387,  0.0127,  0.0058,  ...,  0.0215, -0.0275,  0.0356]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-5.7264e+01, -1.5593e+01, -1.0905e+01,  ..., -1.8596e-05,\n",
      "         -2.6571e+01, -4.3772e+01],\n",
      "        [-9.8829e-01, -5.8385e+00, -3.2264e+00,  ..., -6.8493e+00,\n",
      "         -1.4797e+00, -1.5213e+00],\n",
      "        [-9.1305e+00, -6.6564e+00, -3.3695e-02,  ..., -5.4821e+00,\n",
      "         -3.6363e+00, -7.1042e+00],\n",
      "        ...,\n",
      "        [-8.3079e-01, -6.3859e+00, -3.6543e+00,  ..., -7.3458e+00,\n",
      "         -1.7514e+00, -1.4659e+00],\n",
      "        [-6.5370e-01, -7.9599e+00, -4.3567e+00,  ..., -9.0295e+00,\n",
      "         -2.0638e+00, -1.4602e+00],\n",
      "        [-3.3975e+01, -9.8207e+00, -5.6096e+00,  ..., -3.7240e-03,\n",
      "         -1.5727e+01, -2.5823e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0034 loss_train: 0.5113 acc_train: 0.8071 loss_val: 1.1707 acc_val: 0.6500 time: 0.7531s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0165,  0.0046, -0.0017,  ...,  0.0053, -0.0210,  0.0156],\n",
      "        [ 0.0007, -0.0201, -0.0027,  ...,  0.0027,  0.0124,  0.0462],\n",
      "        [-0.0151, -0.0007,  0.0058,  ...,  0.0019, -0.0144, -0.0307],\n",
      "        ...,\n",
      "        [-0.0008,  0.0004, -0.0016,  ...,  0.0042,  0.0002, -0.0371],\n",
      "        [-0.0090, -0.0073, -0.0046,  ..., -0.0014,  0.0019, -0.0169],\n",
      "        [ 0.0387,  0.0127,  0.0058,  ...,  0.0215, -0.0275,  0.0356]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0168,  0.0058, -0.0013,  ...,  0.0031, -0.0211,  0.0153],\n",
      "        [-0.0004, -0.0185, -0.0026,  ...,  0.0022,  0.0107,  0.0503],\n",
      "        [-0.0137, -0.0005,  0.0047,  ...,  0.0014, -0.0127, -0.0316],\n",
      "        ...,\n",
      "        [-0.0012, -0.0010, -0.0022,  ...,  0.0045,  0.0006, -0.0354],\n",
      "        [-0.0091, -0.0068, -0.0055,  ..., -0.0013,  0.0019, -0.0181],\n",
      "        [ 0.0405,  0.0145,  0.0080,  ...,  0.0195, -0.0282,  0.0368]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-6.3731e+01, -1.7135e+01, -1.3652e+01,  ..., -1.1921e-06,\n",
      "         -2.9366e+01, -4.8016e+01],\n",
      "        [-1.6420e+00, -4.9339e+00, -3.2714e+00,  ..., -6.6484e+00,\n",
      "         -7.5624e-01, -1.8708e+00],\n",
      "        [-1.3030e+01, -6.5272e+00, -2.3199e-02,  ..., -4.5962e+00,\n",
      "         -4.4864e+00, -9.5100e+00],\n",
      "        ...,\n",
      "        [-1.1459e+00, -5.8601e+00, -3.8384e+00,  ..., -7.3055e+00,\n",
      "         -1.2158e+00, -1.5617e+00],\n",
      "        [-7.5014e-01, -8.1665e+00, -5.0363e+00,  ..., -9.5557e+00,\n",
      "         -1.8976e+00, -1.3960e+00],\n",
      "        [-3.8450e+01, -1.0345e+01, -7.5584e+00,  ..., -5.5393e-04,\n",
      "         -1.7392e+01, -2.8825e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0035 loss_train: 0.4251 acc_train: 0.8286 loss_val: 1.2406 acc_val: 0.6833 time: 0.8515s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0168,  0.0058, -0.0013,  ...,  0.0031, -0.0211,  0.0153],\n",
      "        [-0.0004, -0.0185, -0.0026,  ...,  0.0022,  0.0107,  0.0503],\n",
      "        [-0.0137, -0.0005,  0.0047,  ...,  0.0014, -0.0127, -0.0316],\n",
      "        ...,\n",
      "        [-0.0012, -0.0010, -0.0022,  ...,  0.0045,  0.0006, -0.0354],\n",
      "        [-0.0091, -0.0068, -0.0055,  ..., -0.0013,  0.0019, -0.0181],\n",
      "        [ 0.0405,  0.0145,  0.0080,  ...,  0.0195, -0.0282,  0.0368]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0171,  0.0068, -0.0008,  ...,  0.0013, -0.0212,  0.0151],\n",
      "        [-0.0015, -0.0166, -0.0022,  ...,  0.0014,  0.0088,  0.0538],\n",
      "        [-0.0122, -0.0003,  0.0035,  ...,  0.0007, -0.0110, -0.0314],\n",
      "        ...,\n",
      "        [-0.0015, -0.0021, -0.0025,  ...,  0.0043,  0.0009, -0.0334],\n",
      "        [-0.0092, -0.0062, -0.0062,  ..., -0.0013,  0.0020, -0.0192],\n",
      "        [ 0.0422,  0.0157,  0.0069,  ...,  0.0175, -0.0287,  0.0382]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-6.8111e+01, -2.1389e+01, -1.5554e+01,  ..., -1.1921e-07,\n",
      "         -3.3794e+01, -5.0095e+01],\n",
      "        [-1.1466e+00, -6.3585e+00, -3.9964e+00,  ..., -7.4534e+00,\n",
      "         -1.6169e+00, -1.2999e+00],\n",
      "        [-1.5743e+01, -9.2643e+00, -1.3677e-02,  ..., -4.3681e+00,\n",
      "         -7.1525e+00, -1.0584e+01],\n",
      "        ...,\n",
      "        [-8.5549e-01, -7.5654e+00, -4.7782e+00,  ..., -8.3876e+00,\n",
      "         -2.3807e+00, -1.1696e+00],\n",
      "        [-6.5865e-01, -9.9506e+00, -6.2048e+00,  ..., -1.0982e+01,\n",
      "         -3.0802e+00, -1.1626e+00],\n",
      "        [-4.0741e+01, -1.3122e+01, -8.7687e+00,  ..., -1.5758e-04,\n",
      "         -2.0164e+01, -2.9737e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0036 loss_train: 0.4168 acc_train: 0.8357 loss_val: 1.1370 acc_val: 0.7033 time: 0.7827s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0171,  0.0068, -0.0008,  ...,  0.0013, -0.0212,  0.0151],\n",
      "        [-0.0015, -0.0166, -0.0022,  ...,  0.0014,  0.0088,  0.0538],\n",
      "        [-0.0122, -0.0003,  0.0035,  ...,  0.0007, -0.0110, -0.0314],\n",
      "        ...,\n",
      "        [-0.0015, -0.0021, -0.0025,  ...,  0.0043,  0.0009, -0.0334],\n",
      "        [-0.0092, -0.0062, -0.0062,  ..., -0.0013,  0.0020, -0.0192],\n",
      "        [ 0.0422,  0.0157,  0.0069,  ...,  0.0175, -0.0287,  0.0382]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.7310e-02,  7.4794e-03, -3.2185e-04,  ..., -4.9249e-04,\n",
      "         -2.1233e-02,  1.4880e-02],\n",
      "        [-2.3226e-03, -1.4447e-02, -1.4532e-03,  ...,  5.7438e-04,\n",
      "          6.7581e-03,  5.5483e-02],\n",
      "        [-1.0728e-02,  1.0144e-05,  2.2866e-03,  ..., -1.2231e-04,\n",
      "         -9.2187e-03, -3.1926e-02],\n",
      "        ...,\n",
      "        [-1.6554e-03, -2.7829e-03, -2.2742e-03,  ...,  3.6152e-03,\n",
      "          1.2018e-03, -3.1138e-02],\n",
      "        [-9.1785e-03, -5.5402e-03, -6.5088e-03,  ..., -1.1570e-03,\n",
      "          2.1055e-03, -2.0488e-02],\n",
      "        [ 4.3124e-02,  1.5683e-02,  1.8656e-03,  ...,  1.3770e-02,\n",
      "         -2.9135e-02,  3.9269e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-6.8564e+01, -2.2812e+01, -1.4354e+01,  ..., -5.9605e-07,\n",
      "         -3.4859e+01, -4.8845e+01],\n",
      "        [-9.3004e-01, -8.1134e+00, -5.1933e+00,  ..., -8.9473e+00,\n",
      "         -2.6919e+00, -1.0861e+00],\n",
      "        [-1.6535e+01, -1.1737e+01, -3.1077e-03,  ..., -5.8438e+00,\n",
      "         -8.7801e+00, -1.0194e+01],\n",
      "        ...,\n",
      "        [-8.0606e-01, -9.2588e+00, -5.8468e+00,  ..., -9.8716e+00,\n",
      "         -3.4280e+00, -1.0084e+00],\n",
      "        [-6.2221e-01, -1.2007e+01, -7.7186e+00,  ..., -1.2971e+01,\n",
      "         -4.2800e+00, -1.0827e+00],\n",
      "        [-3.9672e+01, -1.3578e+01, -7.7602e+00,  ..., -4.2775e-04,\n",
      "         -2.0136e+01, -2.7914e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0037 loss_train: 0.3431 acc_train: 0.8714 loss_val: 1.1997 acc_val: 0.6767 time: 0.7464s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.7310e-02,  7.4794e-03, -3.2185e-04,  ..., -4.9249e-04,\n",
      "         -2.1233e-02,  1.4880e-02],\n",
      "        [-2.3226e-03, -1.4447e-02, -1.4532e-03,  ...,  5.7438e-04,\n",
      "          6.7581e-03,  5.5483e-02],\n",
      "        [-1.0728e-02,  1.0144e-05,  2.2866e-03,  ..., -1.2231e-04,\n",
      "         -9.2187e-03, -3.1926e-02],\n",
      "        ...,\n",
      "        [-1.6554e-03, -2.7829e-03, -2.2742e-03,  ...,  3.6152e-03,\n",
      "          1.2018e-03, -3.1138e-02],\n",
      "        [-9.1785e-03, -5.5402e-03, -6.5088e-03,  ..., -1.1570e-03,\n",
      "          2.1055e-03, -2.0488e-02],\n",
      "        [ 4.3124e-02,  1.5683e-02,  1.8656e-03,  ...,  1.3770e-02,\n",
      "         -2.9135e-02,  3.9269e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0175,  0.0082,  0.0002,  ..., -0.0021, -0.0211,  0.0145],\n",
      "        [-0.0030, -0.0121, -0.0006,  ..., -0.0003,  0.0047,  0.0569],\n",
      "        [-0.0092,  0.0003,  0.0011,  ..., -0.0008, -0.0075, -0.0332],\n",
      "        ...,\n",
      "        [-0.0017, -0.0030, -0.0017,  ...,  0.0027,  0.0014, -0.0294],\n",
      "        [-0.0092, -0.0049, -0.0066,  ..., -0.0010,  0.0022, -0.0216],\n",
      "        [ 0.0439,  0.0162, -0.0027,  ...,  0.0082, -0.0294,  0.0401]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-7.1370e+01, -2.1689e+01, -1.2810e+01,  ..., -2.7418e-06,\n",
      "         -3.4523e+01, -4.9713e+01],\n",
      "        [-1.4446e+00, -6.9896e+00, -4.8946e+00,  ..., -8.7711e+00,\n",
      "         -1.4992e+00, -1.5982e+00],\n",
      "        [-2.0357e+01, -1.2801e+01, -6.8474e-04,  ..., -7.3644e+00,\n",
      "         -1.0028e+01, -1.2625e+01],\n",
      "        ...,\n",
      "        [-8.7282e-01, -9.2493e+00, -6.0900e+00,  ..., -1.0250e+01,\n",
      "         -3.1126e+00, -1.2045e+00],\n",
      "        [-5.2123e-01, -1.2852e+01, -8.7799e+00,  ..., -1.4222e+01,\n",
      "         -4.4872e+00, -1.3875e+00],\n",
      "        [-4.1192e+01, -1.2009e+01, -6.8117e+00,  ..., -1.1076e-03,\n",
      "         -1.9174e+01, -2.8428e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0038 loss_train: 0.3534 acc_train: 0.8571 loss_val: 1.2897 acc_val: 0.6867 time: 0.7921s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0175,  0.0082,  0.0002,  ..., -0.0021, -0.0211,  0.0145],\n",
      "        [-0.0030, -0.0121, -0.0006,  ..., -0.0003,  0.0047,  0.0569],\n",
      "        [-0.0092,  0.0003,  0.0011,  ..., -0.0008, -0.0075, -0.0332],\n",
      "        ...,\n",
      "        [-0.0017, -0.0030, -0.0017,  ...,  0.0027,  0.0014, -0.0294],\n",
      "        [-0.0092, -0.0049, -0.0066,  ..., -0.0010,  0.0022, -0.0216],\n",
      "        [ 0.0439,  0.0162, -0.0027,  ...,  0.0082, -0.0294,  0.0401]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.7723e-02,  9.4460e-03,  7.1955e-04,  ..., -3.3149e-03,\n",
      "         -2.0973e-02,  1.4067e-02],\n",
      "        [-3.4840e-03, -9.6349e-03,  3.4683e-04,  ..., -1.0467e-03,\n",
      "          2.5923e-03,  5.8265e-02],\n",
      "        [-7.6222e-03,  4.6115e-04,  4.8087e-05,  ..., -1.3213e-03,\n",
      "         -5.8622e-03, -3.4955e-02],\n",
      "        ...,\n",
      "        [-1.6070e-03, -2.7336e-03, -9.9325e-04,  ...,  1.2384e-03,\n",
      "          1.4763e-03, -2.8642e-02],\n",
      "        [-9.0382e-03, -4.2491e-03, -6.3825e-03,  ..., -8.7073e-04,\n",
      "          2.2174e-03, -2.2280e-02],\n",
      "        [ 4.5308e-02,  1.7444e-02, -6.8036e-03,  ...,  3.0333e-03,\n",
      "         -2.9446e-02,  4.0849e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-7.8374e+01, -2.2092e+01, -1.6491e+01,  ..., -1.1921e-07,\n",
      "         -3.7418e+01, -5.4230e+01],\n",
      "        [-2.7171e+00, -5.5424e+00, -4.9165e+00,  ..., -8.2686e+00,\n",
      "         -5.6043e-01, -2.9559e+00],\n",
      "        [-2.4264e+01, -1.1723e+01, -2.6881e-03,  ..., -5.9333e+00,\n",
      "         -1.0542e+01, -1.4856e+01],\n",
      "        ...,\n",
      "        [-1.2448e+00, -7.9330e+00, -5.7180e+00,  ..., -9.5082e+00,\n",
      "         -2.0729e+00, -1.6628e+00],\n",
      "        [-4.4123e-01, -1.2917e+01, -9.6267e+00,  ..., -1.4718e+01,\n",
      "         -4.3153e+00, -1.8884e+00],\n",
      "        [-4.6567e+01, -1.1657e+01, -9.7794e+00,  ..., -6.5325e-05,\n",
      "         -2.0877e+01, -3.2304e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0039 loss_train: 0.2777 acc_train: 0.9071 loss_val: 1.4391 acc_val: 0.6833 time: 0.8148s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.7723e-02,  9.4460e-03,  7.1955e-04,  ..., -3.3149e-03,\n",
      "         -2.0973e-02,  1.4067e-02],\n",
      "        [-3.4840e-03, -9.6349e-03,  3.4683e-04,  ..., -1.0467e-03,\n",
      "          2.5923e-03,  5.8265e-02],\n",
      "        [-7.6222e-03,  4.6115e-04,  4.8087e-05,  ..., -1.3213e-03,\n",
      "         -5.8622e-03, -3.4955e-02],\n",
      "        ...,\n",
      "        [-1.6070e-03, -2.7336e-03, -9.9325e-04,  ...,  1.2384e-03,\n",
      "          1.4763e-03, -2.8642e-02],\n",
      "        [-9.0382e-03, -4.2491e-03, -6.3825e-03,  ..., -8.7073e-04,\n",
      "          2.2174e-03, -2.2280e-02],\n",
      "        [ 4.5308e-02,  1.7444e-02, -6.8036e-03,  ...,  3.0333e-03,\n",
      "         -2.9446e-02,  4.0849e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0179,  0.0101,  0.0011,  ..., -0.0041, -0.0208,  0.0136],\n",
      "        [-0.0038, -0.0071,  0.0011,  ..., -0.0016,  0.0006,  0.0588],\n",
      "        [-0.0061,  0.0005, -0.0009,  ..., -0.0015, -0.0043, -0.0366],\n",
      "        ...,\n",
      "        [-0.0006, -0.0021, -0.0001,  ..., -0.0002,  0.0015, -0.0274],\n",
      "        [-0.0089, -0.0036, -0.0059,  ..., -0.0007,  0.0023, -0.0227],\n",
      "        [ 0.0463,  0.0177, -0.0102,  ..., -0.0015, -0.0294,  0.0416]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-8.2329e+01, -2.6452e+01, -1.8951e+01,  ...,  0.0000e+00,\n",
      "         -4.3225e+01, -5.5299e+01],\n",
      "        [-1.3241e+00, -7.4355e+00, -5.2823e+00,  ..., -8.8693e+00,\n",
      "         -2.0919e+00, -1.6354e+00],\n",
      "        [-2.5603e+01, -1.4404e+01, -4.2507e-03,  ..., -5.4634e+00,\n",
      "         -1.3744e+01, -1.4114e+01],\n",
      "        ...,\n",
      "        [-9.1906e-01, -1.0325e+01, -6.3852e+00,  ..., -1.0561e+01,\n",
      "         -4.3047e+00, -9.7160e-01],\n",
      "        [-2.1274e-01, -1.5796e+01, -1.1725e+01,  ..., -1.7058e+01,\n",
      "         -6.7148e+00, -2.1009e+00],\n",
      "        [-4.8807e+01, -1.4830e+01, -1.1612e+01,  ..., -9.4175e-06,\n",
      "         -2.4914e+01, -3.2846e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0040 loss_train: 0.2758 acc_train: 0.8857 loss_val: 1.2171 acc_val: 0.7300 time: 0.8083s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0179,  0.0101,  0.0011,  ..., -0.0041, -0.0208,  0.0136],\n",
      "        [-0.0038, -0.0071,  0.0011,  ..., -0.0016,  0.0006,  0.0588],\n",
      "        [-0.0061,  0.0005, -0.0009,  ..., -0.0015, -0.0043, -0.0366],\n",
      "        ...,\n",
      "        [-0.0006, -0.0021, -0.0001,  ..., -0.0002,  0.0015, -0.0274],\n",
      "        [-0.0089, -0.0036, -0.0059,  ..., -0.0007,  0.0023, -0.0227],\n",
      "        [ 0.0463,  0.0177, -0.0102,  ..., -0.0015, -0.0294,  0.0416]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0177,  0.0105,  0.0014,  ..., -0.0046, -0.0205,  0.0134],\n",
      "        [-0.0039, -0.0047,  0.0016,  ..., -0.0018, -0.0012,  0.0595],\n",
      "        [-0.0046,  0.0005, -0.0018,  ..., -0.0013, -0.0028, -0.0379],\n",
      "        ...,\n",
      "        [ 0.0004, -0.0012,  0.0007,  ..., -0.0015,  0.0014, -0.0259],\n",
      "        [-0.0087, -0.0030, -0.0053,  ..., -0.0005,  0.0023, -0.0228],\n",
      "        [ 0.0468,  0.0176, -0.0128,  ..., -0.0056, -0.0292,  0.0424]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-8.8982e+01, -3.0336e+01, -1.8032e+01,  ...,  0.0000e+00,\n",
      "         -4.8296e+01, -5.6992e+01],\n",
      "        [-2.3512e+00, -8.0987e+00, -3.0638e+00,  ..., -8.0571e+00,\n",
      "         -2.9972e+00, -6.6498e-01],\n",
      "        [-3.3352e+01, -1.9030e+01, -1.3620e-03,  ..., -6.5995e+00,\n",
      "         -1.9466e+01, -1.7288e+01],\n",
      "        ...,\n",
      "        [-2.9449e+00, -1.1125e+01, -3.7100e+00,  ..., -9.4400e+00,\n",
      "         -5.5867e+00, -1.7433e-01],\n",
      "        [-3.0796e-01, -1.7198e+01, -1.1854e+01,  ..., -1.7953e+01,\n",
      "         -7.8701e+00, -1.5238e+00],\n",
      "        [-5.4215e+01, -1.8080e+01, -1.1236e+01,  ..., -1.3232e-05,\n",
      "         -2.9077e+01, -3.4614e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0041 loss_train: 0.2220 acc_train: 0.9357 loss_val: 1.3954 acc_val: 0.7200 time: 0.8837s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0177,  0.0105,  0.0014,  ..., -0.0046, -0.0205,  0.0134],\n",
      "        [-0.0039, -0.0047,  0.0016,  ..., -0.0018, -0.0012,  0.0595],\n",
      "        [-0.0046,  0.0005, -0.0018,  ..., -0.0013, -0.0028, -0.0379],\n",
      "        ...,\n",
      "        [ 0.0004, -0.0012,  0.0007,  ..., -0.0015,  0.0014, -0.0259],\n",
      "        [-0.0087, -0.0030, -0.0053,  ..., -0.0005,  0.0023, -0.0228],\n",
      "        [ 0.0468,  0.0176, -0.0128,  ..., -0.0056, -0.0292,  0.0424]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0173,  0.0104,  0.0016,  ..., -0.0049, -0.0201,  0.0124],\n",
      "        [-0.0041, -0.0023,  0.0018,  ..., -0.0018, -0.0028,  0.0567],\n",
      "        [-0.0032,  0.0004, -0.0025,  ..., -0.0009, -0.0014, -0.0422],\n",
      "        ...,\n",
      "        [ 0.0009, -0.0002,  0.0013,  ..., -0.0018,  0.0013, -0.0274],\n",
      "        [-0.0086, -0.0024, -0.0045,  ..., -0.0004,  0.0023, -0.0242],\n",
      "        [ 0.0460,  0.0163, -0.0147,  ..., -0.0092, -0.0287,  0.0407]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-7.8975e+01, -2.1546e+01, -1.6388e+01,  ..., -1.1921e-07,\n",
      "         -3.6998e+01, -5.0642e+01],\n",
      "        [-1.3305e+00, -8.3810e+00, -7.1570e+00,  ..., -1.1069e+01,\n",
      "         -1.6587e+00, -2.8207e+00],\n",
      "        [-2.4084e+01, -1.4631e+01, -2.6318e-04,  ..., -8.3256e+00,\n",
      "         -1.1551e+01, -1.1511e+01],\n",
      "        ...,\n",
      "        [-1.0222e+00, -1.2327e+01, -7.3282e+00,  ..., -1.2486e+01,\n",
      "         -5.1128e+00, -7.6771e-01],\n",
      "        [-5.4132e-02, -2.0430e+01, -1.5924e+01,  ..., -2.2113e+01,\n",
      "         -9.1116e+00, -3.3343e+00],\n",
      "        [-4.3496e+01, -9.5450e+00, -9.7624e+00,  ..., -1.2910e-04,\n",
      "         -1.8162e+01, -2.8498e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0042 loss_train: 0.2450 acc_train: 0.8929 loss_val: 1.5289 acc_val: 0.6800 time: 0.7085s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0173,  0.0104,  0.0016,  ..., -0.0049, -0.0201,  0.0124],\n",
      "        [-0.0041, -0.0023,  0.0018,  ..., -0.0018, -0.0028,  0.0567],\n",
      "        [-0.0032,  0.0004, -0.0025,  ..., -0.0009, -0.0014, -0.0422],\n",
      "        ...,\n",
      "        [ 0.0009, -0.0002,  0.0013,  ..., -0.0018,  0.0013, -0.0274],\n",
      "        [-0.0086, -0.0024, -0.0045,  ..., -0.0004,  0.0023, -0.0242],\n",
      "        [ 0.0460,  0.0163, -0.0147,  ..., -0.0092, -0.0287,  0.0407]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.7302e-02,  1.0579e-02,  1.6399e-03,  ..., -4.9561e-03,\n",
      "         -1.9744e-02,  1.1707e-02],\n",
      "        [-4.0394e-03, -7.5151e-05,  1.7379e-03,  ..., -1.5406e-03,\n",
      "         -4.1905e-03,  5.5894e-02],\n",
      "        [-1.5144e-03,  2.1831e-04, -3.1319e-03,  ..., -3.3971e-04,\n",
      "         -6.5649e-05, -4.4848e-02],\n",
      "        ...,\n",
      "        [ 1.3382e-03,  7.9505e-04,  1.6170e-03,  ..., -1.9768e-03,\n",
      "          1.1328e-03, -2.8287e-02],\n",
      "        [-8.3430e-03, -1.7829e-03, -3.6132e-03,  ..., -1.8250e-04,\n",
      "          2.3434e-03, -2.4919e-02],\n",
      "        [ 4.6519e-02,  1.5204e-02, -1.5649e-02,  ..., -1.2084e-02,\n",
      "         -2.8369e-02,  4.0549e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-8.7669e+01, -1.9706e+01, -2.1700e+01,  ...,  0.0000e+00,\n",
      "         -3.8086e+01, -5.7860e+01],\n",
      "        [-6.0296e+00, -4.9664e+00, -7.2643e+00,  ..., -9.6475e+00,\n",
      "         -1.4320e-01, -7.2172e+00],\n",
      "        [-3.0626e+01, -1.0294e+01, -8.5208e-03,  ..., -4.7776e+00,\n",
      "         -1.0291e+01, -1.5891e+01],\n",
      "        ...,\n",
      "        [-2.8325e+00, -8.0399e+00, -4.3504e+00,  ..., -8.6532e+00,\n",
      "         -2.2749e+00, -1.1290e+00],\n",
      "        [-7.9478e-02, -1.8192e+01, -1.5184e+01,  ..., -2.0451e+01,\n",
      "         -7.4202e+00, -3.4427e+00],\n",
      "        [-5.1362e+01, -7.7490e+00, -1.4179e+01,  ..., -4.3204e-04,\n",
      "         -1.9200e+01, -3.5632e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0043 loss_train: 0.1950 acc_train: 0.9357 loss_val: 2.0662 acc_val: 0.6567 time: 0.7089s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.7302e-02,  1.0579e-02,  1.6399e-03,  ..., -4.9561e-03,\n",
      "         -1.9744e-02,  1.1707e-02],\n",
      "        [-4.0394e-03, -7.5151e-05,  1.7379e-03,  ..., -1.5406e-03,\n",
      "         -4.1905e-03,  5.5894e-02],\n",
      "        [-1.5144e-03,  2.1831e-04, -3.1319e-03,  ..., -3.3971e-04,\n",
      "         -6.5649e-05, -4.4848e-02],\n",
      "        ...,\n",
      "        [ 1.3382e-03,  7.9505e-04,  1.6170e-03,  ..., -1.9768e-03,\n",
      "          1.1328e-03, -2.8287e-02],\n",
      "        [-8.3430e-03, -1.7829e-03, -3.6132e-03,  ..., -1.8250e-04,\n",
      "          2.3434e-03, -2.4919e-02],\n",
      "        [ 4.6519e-02,  1.5204e-02, -1.5649e-02,  ..., -1.2084e-02,\n",
      "         -2.8369e-02,  4.0549e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.7721e-02,  1.0778e-02,  1.5817e-03,  ..., -4.7519e-03,\n",
      "         -1.9771e-02,  1.2167e-02],\n",
      "        [-6.1832e-03,  1.9467e-03,  1.3553e-03,  ..., -1.0580e-03,\n",
      "         -5.2717e-03,  5.5992e-02],\n",
      "        [-3.9271e-04,  6.7557e-06, -3.5635e-03,  ...,  2.5534e-04,\n",
      "          1.1177e-03, -4.6701e-02],\n",
      "        ...,\n",
      "        [ 2.4515e-03,  1.5288e-03,  1.6622e-03,  ..., -1.9144e-03,\n",
      "          9.1372e-04, -2.7891e-02],\n",
      "        [-8.1310e-03, -1.2228e-03, -2.6370e-03,  ..., -2.0604e-05,\n",
      "          2.3400e-03, -2.5582e-02],\n",
      "        [ 4.7065e-02,  1.3160e-02, -1.5841e-02,  ..., -1.4321e-02,\n",
      "         -2.8884e-02,  4.2594e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-9.2906e+01, -3.3643e+01, -1.8945e+01,  ...,  0.0000e+00,\n",
      "         -4.9494e+01, -5.3521e+01],\n",
      "        [-2.5708e+00, -9.7615e+00, -5.0249e+00,  ..., -1.0009e+01,\n",
      "         -3.4307e+00, -8.4315e-01],\n",
      "        [-3.5863e+01, -2.2175e+01, -3.8295e-04,  ..., -7.8706e+00,\n",
      "         -2.0202e+01, -1.3798e+01],\n",
      "        ...,\n",
      "        [-7.5591e+00, -1.5569e+01, -4.3765e+00,  ..., -1.1017e+01,\n",
      "         -9.3678e+00, -1.8662e-02],\n",
      "        [-1.5876e-01, -2.2074e+01, -1.6316e+01,  ..., -2.2748e+01,\n",
      "         -1.0704e+01, -2.0214e+00],\n",
      "        [-5.4834e+01, -1.9339e+01, -1.2274e+01,  ..., -4.6492e-06,\n",
      "         -2.8785e+01, -3.1766e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0044 loss_train: 0.3527 acc_train: 0.8714 loss_val: 1.4217 acc_val: 0.7233 time: 0.7423s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.7721e-02,  1.0778e-02,  1.5817e-03,  ..., -4.7519e-03,\n",
      "         -1.9771e-02,  1.2167e-02],\n",
      "        [-6.1832e-03,  1.9467e-03,  1.3553e-03,  ..., -1.0580e-03,\n",
      "         -5.2717e-03,  5.5992e-02],\n",
      "        [-3.9271e-04,  6.7557e-06, -3.5635e-03,  ...,  2.5534e-04,\n",
      "          1.1177e-03, -4.6701e-02],\n",
      "        ...,\n",
      "        [ 2.4515e-03,  1.5288e-03,  1.6622e-03,  ..., -1.9144e-03,\n",
      "          9.1372e-04, -2.7891e-02],\n",
      "        [-8.1310e-03, -1.2228e-03, -2.6370e-03,  ..., -2.0604e-05,\n",
      "          2.3400e-03, -2.5582e-02],\n",
      "        [ 4.7065e-02,  1.3160e-02, -1.5841e-02,  ..., -1.4321e-02,\n",
      "         -2.8884e-02,  4.2594e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0179,  0.0108,  0.0014,  ..., -0.0043, -0.0195,  0.0127],\n",
      "        [-0.0080,  0.0037,  0.0008,  ..., -0.0005, -0.0061,  0.0531],\n",
      "        [ 0.0005, -0.0002, -0.0038,  ...,  0.0007,  0.0022, -0.0493],\n",
      "        ...,\n",
      "        [ 0.0032,  0.0020,  0.0014,  ..., -0.0012,  0.0007, -0.0291],\n",
      "        [-0.0079, -0.0007, -0.0016,  ...,  0.0001,  0.0023, -0.0268],\n",
      "        [ 0.0462,  0.0112, -0.0153,  ..., -0.0159, -0.0287,  0.0437]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-9.2403e+01, -3.6463e+01, -1.2678e+01,  ..., -3.0994e-06,\n",
      "         -4.9420e+01, -4.9271e+01],\n",
      "        [-2.8446e+00, -1.1698e+01, -4.7160e+00,  ..., -1.1233e+01,\n",
      "         -4.5657e+00, -4.7948e-01],\n",
      "        [-3.9150e+01, -2.7603e+01, -4.7684e-06,  ..., -1.2334e+01,\n",
      "         -2.3439e+01, -1.4809e+01],\n",
      "        ...,\n",
      "        [-1.0130e+01, -1.7595e+01, -2.8089e+00,  ..., -1.1487e+01,\n",
      "         -1.0770e+01, -6.3885e-02],\n",
      "        [-1.3433e-01, -2.3682e+01, -1.6702e+01,  ..., -2.4137e+01,\n",
      "         -1.1476e+01, -2.1643e+00],\n",
      "        [-5.3965e+01, -2.1573e+01, -7.9393e+00,  ..., -3.5649e-04,\n",
      "         -2.8882e+01, -2.8303e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0045 loss_train: 0.1850 acc_train: 0.9214 loss_val: 1.9354 acc_val: 0.6267 time: 0.9060s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0179,  0.0108,  0.0014,  ..., -0.0043, -0.0195,  0.0127],\n",
      "        [-0.0080,  0.0037,  0.0008,  ..., -0.0005, -0.0061,  0.0531],\n",
      "        [ 0.0005, -0.0002, -0.0038,  ...,  0.0007,  0.0022, -0.0493],\n",
      "        ...,\n",
      "        [ 0.0032,  0.0020,  0.0014,  ..., -0.0012,  0.0007, -0.0291],\n",
      "        [-0.0079, -0.0007, -0.0016,  ...,  0.0001,  0.0023, -0.0268],\n",
      "        [ 0.0462,  0.0112, -0.0153,  ..., -0.0159, -0.0287,  0.0437]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0182,  0.0139,  0.0012,  ..., -0.0038, -0.0191,  0.0125],\n",
      "        [-0.0093,  0.0052,  0.0001,  ...,  0.0001, -0.0065,  0.0464],\n",
      "        [ 0.0022, -0.0003, -0.0040,  ...,  0.0010,  0.0031, -0.0534],\n",
      "        ...,\n",
      "        [ 0.0036,  0.0020,  0.0010,  ...,  0.0006,  0.0004, -0.0323],\n",
      "        [-0.0076, -0.0002, -0.0007,  ...,  0.0003,  0.0023, -0.0284],\n",
      "        [ 0.0455,  0.0123, -0.0141,  ..., -0.0167, -0.0275,  0.0427]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-8.8444e+01, -2.9395e+01, -1.4619e+01,  ..., -4.7684e-07,\n",
      "         -4.1622e+01, -5.2168e+01],\n",
      "        [-2.4800e+00, -8.3121e+00, -6.5702e+00,  ..., -1.1247e+01,\n",
      "         -1.1698e+00, -5.1049e+00],\n",
      "        [-3.4908e+01, -2.1486e+01, -7.7486e-06,  ..., -1.1799e+01,\n",
      "         -1.6319e+01, -1.6517e+01],\n",
      "        ...,\n",
      "        [-6.7681e+00, -1.3602e+01, -2.0091e+00,  ..., -9.9473e+00,\n",
      "         -6.4520e+00, -1.8775e-01],\n",
      "        [-9.5262e-03, -2.4095e+01, -1.8809e+01,  ..., -2.5547e+01,\n",
      "         -1.1290e+01, -5.2799e+00],\n",
      "        [-5.0989e+01, -1.5439e+01, -9.5513e+00,  ..., -7.1285e-05,\n",
      "         -2.2672e+01, -3.1227e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0046 loss_train: 0.2870 acc_train: 0.8929 loss_val: 1.5557 acc_val: 0.7267 time: 0.9003s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0182,  0.0139,  0.0012,  ..., -0.0038, -0.0191,  0.0125],\n",
      "        [-0.0093,  0.0052,  0.0001,  ...,  0.0001, -0.0065,  0.0464],\n",
      "        [ 0.0022, -0.0003, -0.0040,  ...,  0.0010,  0.0031, -0.0534],\n",
      "        ...,\n",
      "        [ 0.0036,  0.0020,  0.0010,  ...,  0.0006,  0.0004, -0.0323],\n",
      "        [-0.0076, -0.0002, -0.0007,  ...,  0.0003,  0.0023, -0.0284],\n",
      "        [ 0.0455,  0.0123, -0.0141,  ..., -0.0167, -0.0275,  0.0427]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0186,  0.0167,  0.0009,  ..., -0.0031, -0.0185,  0.0126],\n",
      "        [-0.0075,  0.0065, -0.0005,  ...,  0.0007, -0.0067,  0.0411],\n",
      "        [ 0.0036, -0.0004, -0.0039,  ...,  0.0011,  0.0039, -0.0565],\n",
      "        ...,\n",
      "        [ 0.0037,  0.0017,  0.0004,  ...,  0.0021,  0.0002, -0.0348],\n",
      "        [-0.0073,  0.0002,  0.0003,  ...,  0.0004,  0.0024, -0.0292],\n",
      "        [ 0.0451,  0.0136, -0.0124,  ..., -0.0169, -0.0263,  0.0418]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-8.9605e+01, -2.5361e+01, -2.1340e+01,  ...,  0.0000e+00,\n",
      "         -3.9121e+01, -5.8661e+01],\n",
      "        [-5.7959e+00, -6.0944e+00, -7.7773e+00,  ..., -1.0898e+01,\n",
      "         -1.5177e-01, -1.0299e+01],\n",
      "        [-3.2474e+01, -1.4042e+01, -4.0642e-04,  ..., -7.9180e+00,\n",
      "         -1.0101e+01, -1.8533e+01],\n",
      "        ...,\n",
      "        [-5.1904e+00, -9.0586e+00, -1.1864e+00,  ..., -7.1604e+00,\n",
      "         -2.6871e+00, -1.2380e+00],\n",
      "        [-9.7269e-03, -2.2409e+01, -1.8422e+01,  ..., -2.4446e+01,\n",
      "         -9.8563e+00, -6.7491e+00],\n",
      "        [-5.2374e+01, -1.1881e+01, -1.4282e+01,  ..., -7.5102e-06,\n",
      "         -2.0631e+01, -3.6939e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0047 loss_train: 0.1187 acc_train: 0.9643 loss_val: 1.9582 acc_val: 0.6733 time: 0.8484s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0186,  0.0167,  0.0009,  ..., -0.0031, -0.0185,  0.0126],\n",
      "        [-0.0075,  0.0065, -0.0005,  ...,  0.0007, -0.0067,  0.0411],\n",
      "        [ 0.0036, -0.0004, -0.0039,  ...,  0.0011,  0.0039, -0.0565],\n",
      "        ...,\n",
      "        [ 0.0037,  0.0017,  0.0004,  ...,  0.0021,  0.0002, -0.0348],\n",
      "        [-0.0073,  0.0002,  0.0003,  ...,  0.0004,  0.0024, -0.0292],\n",
      "        [ 0.0451,  0.0136, -0.0124,  ..., -0.0169, -0.0263,  0.0418]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.8765e-02,  1.8114e-02,  5.5210e-04,  ..., -2.2781e-03,\n",
      "         -1.7882e-02,  1.2978e-02],\n",
      "        [-5.4847e-03,  7.3892e-03, -9.5798e-04,  ...,  1.0589e-03,\n",
      "         -6.6029e-03,  3.6002e-02],\n",
      "        [ 4.6476e-03, -3.6659e-04, -3.7899e-03,  ...,  8.4651e-04,\n",
      "          4.5783e-03, -5.8317e-02],\n",
      "        ...,\n",
      "        [ 1.2877e-03,  1.2134e-03, -2.2776e-04,  ...,  3.2124e-03,\n",
      "         -8.6665e-05, -3.7139e-02],\n",
      "        [-7.1043e-03,  6.4601e-04,  1.0795e-03,  ...,  4.5432e-04,\n",
      "          2.4276e-03, -2.9736e-02],\n",
      "        [ 4.3820e-02,  1.4152e-02, -1.0268e-02,  ..., -1.6512e-02,\n",
      "         -2.5357e-02,  4.1489e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-8.5342e+01, -2.4899e+01, -2.3076e+01,  ...,  0.0000e+00,\n",
      "         -3.9611e+01, -5.6013e+01],\n",
      "        [-2.5398e+00, -7.1274e+00, -7.9381e+00,  ..., -1.1159e+01,\n",
      "         -8.9199e-01, -7.9623e+00],\n",
      "        [-2.7467e+01, -1.3140e+01, -7.2465e-04,  ..., -7.4076e+00,\n",
      "         -9.1177e+00, -1.4999e+01],\n",
      "        ...,\n",
      "        [-3.4913e+00, -1.0521e+01, -3.2545e+00,  ..., -8.4288e+00,\n",
      "         -4.1506e+00, -4.3024e-01],\n",
      "        [-4.5588e-03, -2.4193e+01, -1.9910e+01,  ..., -2.5935e+01,\n",
      "         -1.1628e+01, -7.4656e+00],\n",
      "        [-4.8249e+01, -1.1632e+01, -1.5102e+01,  ..., -9.1791e-06,\n",
      "         -2.0818e+01, -3.4302e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0048 loss_train: 0.2588 acc_train: 0.8929 loss_val: 1.6721 acc_val: 0.6967 time: 0.6997s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.8765e-02,  1.8114e-02,  5.5210e-04,  ..., -2.2781e-03,\n",
      "         -1.7882e-02,  1.2978e-02],\n",
      "        [-5.4847e-03,  7.3892e-03, -9.5798e-04,  ...,  1.0589e-03,\n",
      "         -6.6029e-03,  3.6002e-02],\n",
      "        [ 4.6476e-03, -3.6659e-04, -3.7899e-03,  ...,  8.4651e-04,\n",
      "          4.5783e-03, -5.8317e-02],\n",
      "        ...,\n",
      "        [ 1.2877e-03,  1.2134e-03, -2.2776e-04,  ...,  3.2124e-03,\n",
      "         -8.6665e-05, -3.7139e-02],\n",
      "        [-7.1043e-03,  6.4601e-04,  1.0795e-03,  ...,  4.5432e-04,\n",
      "          2.4276e-03, -2.9736e-02],\n",
      "        [ 4.3820e-02,  1.4152e-02, -1.0268e-02,  ..., -1.6512e-02,\n",
      "         -2.5357e-02,  4.1489e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0186,  0.0189,  0.0002,  ..., -0.0015, -0.0175,  0.0138],\n",
      "        [-0.0051,  0.0080, -0.0012,  ...,  0.0012, -0.0062,  0.0321],\n",
      "        [ 0.0052, -0.0003, -0.0035,  ...,  0.0005,  0.0051, -0.0583],\n",
      "        ...,\n",
      "        [-0.0008,  0.0005, -0.0007,  ...,  0.0039, -0.0003, -0.0383],\n",
      "        [-0.0069,  0.0010,  0.0018,  ...,  0.0005,  0.0025, -0.0294],\n",
      "        [ 0.0420,  0.0143, -0.0079,  ..., -0.0156, -0.0247,  0.0420]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-8.6386e+01, -2.7051e+01, -2.2330e+01,  ...,  0.0000e+00,\n",
      "         -4.2726e+01, -5.3573e+01],\n",
      "        [-1.5781e+00, -8.1938e+00, -7.7709e+00,  ..., -1.1438e+01,\n",
      "         -2.1132e+00, -6.5177e+00],\n",
      "        [-3.1268e+01, -1.5889e+01, -4.8888e-04,  ..., -7.6298e+00,\n",
      "         -1.3024e+01, -1.4914e+01],\n",
      "        ...,\n",
      "        [-6.1861e+00, -1.1696e+01, -2.7135e+00,  ..., -7.6640e+00,\n",
      "         -6.0980e+00, -1.1975e-01],\n",
      "        [-5.4848e-03, -2.4317e+01, -1.9614e+01,  ..., -2.5773e+01,\n",
      "         -1.2237e+01, -7.0462e+00],\n",
      "        [-4.9013e+01, -1.3855e+01, -1.4652e+01,  ..., -1.4305e-06,\n",
      "         -2.3509e+01, -3.2391e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0049 loss_train: 0.1680 acc_train: 0.9429 loss_val: 1.4064 acc_val: 0.7400 time: 0.7256s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0186,  0.0189,  0.0002,  ..., -0.0015, -0.0175,  0.0138],\n",
      "        [-0.0051,  0.0080, -0.0012,  ...,  0.0012, -0.0062,  0.0321],\n",
      "        [ 0.0052, -0.0003, -0.0035,  ...,  0.0005,  0.0051, -0.0583],\n",
      "        ...,\n",
      "        [-0.0008,  0.0005, -0.0007,  ...,  0.0039, -0.0003, -0.0383],\n",
      "        [-0.0069,  0.0010,  0.0018,  ...,  0.0005,  0.0025, -0.0294],\n",
      "        [ 0.0420,  0.0143, -0.0079,  ..., -0.0156, -0.0247,  0.0420]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.7960e-02,  1.9299e-02, -1.1266e-04,  ..., -6.3037e-04,\n",
      "         -1.7010e-02,  1.4993e-02],\n",
      "        [-6.5028e-03,  8.3294e-03, -1.2559e-03,  ...,  1.2181e-03,\n",
      "         -5.6727e-03,  2.8123e-02],\n",
      "        [ 5.2166e-03, -1.3147e-04, -3.1580e-03,  ...,  2.1374e-05,\n",
      "          5.5263e-03, -5.7787e-02],\n",
      "        ...,\n",
      "        [-1.8541e-03, -1.8622e-04, -1.0586e-03,  ...,  4.0399e-03,\n",
      "         -4.7941e-04, -3.8494e-02],\n",
      "        [-6.8109e-03,  1.2851e-03,  2.3380e-03,  ...,  5.5721e-04,\n",
      "          2.8914e-03, -2.8904e-02],\n",
      "        [ 3.9626e-02,  1.4074e-02, -5.3148e-03,  ..., -1.4164e-02,\n",
      "         -2.4118e-02,  4.3065e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-9.1782e+01, -2.9137e+01, -1.9569e+01,  ...,  0.0000e+00,\n",
      "         -4.5522e+01, -5.3750e+01],\n",
      "        [-2.9721e+00, -6.9991e+00, -5.6007e+00,  ..., -9.9740e+00,\n",
      "         -1.7283e+00, -6.2929e+00],\n",
      "        [-4.2205e+01, -1.9793e+01, -2.7975e-04,  ..., -8.1817e+00,\n",
      "         -1.9064e+01, -1.9517e+01],\n",
      "        ...,\n",
      "        [-1.2896e+01, -1.2265e+01, -2.5748e-01,  ..., -5.1329e+00,\n",
      "         -8.3035e+00, -1.5153e+00],\n",
      "        [-1.2454e-02, -2.2485e+01, -1.7515e+01,  ..., -2.3731e+01,\n",
      "         -1.1298e+01, -6.0685e+00],\n",
      "        [-5.4208e+01, -1.6285e+01, -1.3178e+01,  ..., -2.0266e-06,\n",
      "         -2.6520e+01, -3.3190e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0050 loss_train: 0.1522 acc_train: 0.9429 loss_val: 1.4785 acc_val: 0.7333 time: 0.6789s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.7960e-02,  1.9299e-02, -1.1266e-04,  ..., -6.3037e-04,\n",
      "         -1.7010e-02,  1.4993e-02],\n",
      "        [-6.5028e-03,  8.3294e-03, -1.2559e-03,  ...,  1.2181e-03,\n",
      "         -5.6727e-03,  2.8123e-02],\n",
      "        [ 5.2166e-03, -1.3147e-04, -3.1580e-03,  ...,  2.1374e-05,\n",
      "          5.5263e-03, -5.7787e-02],\n",
      "        ...,\n",
      "        [-1.8541e-03, -1.8622e-04, -1.0586e-03,  ...,  4.0399e-03,\n",
      "         -4.7941e-04, -3.8494e-02],\n",
      "        [-6.8109e-03,  1.2851e-03,  2.3380e-03,  ...,  5.5721e-04,\n",
      "          2.8914e-03, -2.8904e-02],\n",
      "        [ 3.9626e-02,  1.4074e-02, -5.3148e-03,  ..., -1.4164e-02,\n",
      "         -2.4118e-02,  4.3065e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.7005e-02,  1.8563e-02, -3.9935e-04,  ...,  1.4774e-04,\n",
      "         -1.6532e-02,  1.5305e-02],\n",
      "        [-8.4996e-03,  8.3700e-03, -1.0631e-03,  ...,  1.0055e-03,\n",
      "         -4.9215e-03,  2.4056e-02],\n",
      "        [ 4.4026e-03,  2.3966e-05, -2.7170e-03,  ..., -3.9104e-04,\n",
      "          5.8129e-03, -5.8683e-02],\n",
      "        ...,\n",
      "        [-2.4468e-03, -8.0228e-04, -1.1650e-03,  ...,  3.7100e-03,\n",
      "         -6.1569e-04, -3.8815e-02],\n",
      "        [-6.6461e-03,  1.5161e-03,  2.7406e-03,  ...,  5.7340e-04,\n",
      "          3.2971e-03, -2.9332e-02],\n",
      "        [ 3.6536e-02,  1.2800e-02, -2.7492e-03,  ..., -1.2391e-02,\n",
      "         -2.3439e-02,  4.2500e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-8.2230e+01, -2.5588e+01, -1.5539e+01,  ..., -1.1921e-07,\n",
      "         -3.9585e+01, -4.4510e+01],\n",
      "        [-1.3968e+00, -9.5332e+00, -7.1341e+00,  ..., -1.1935e+01,\n",
      "         -3.0792e+00, -4.9825e+00],\n",
      "        [-3.6211e+01, -2.0110e+01, -3.2067e-05,  ..., -1.0380e+01,\n",
      "         -1.6832e+01, -1.3920e+01],\n",
      "        ...,\n",
      "        [-9.0849e+00, -1.4497e+01, -3.8532e+00,  ..., -9.4964e+00,\n",
      "         -8.6409e+00, -2.5706e-02],\n",
      "        [-1.0739e-02, -2.4066e+01, -1.8588e+01,  ..., -2.5222e+01,\n",
      "         -1.2109e+01, -5.9973e+00],\n",
      "        [-4.5075e+01, -1.3273e+01, -9.7661e+00,  ..., -5.9126e-05,\n",
      "         -2.1276e+01, -2.5534e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0051 loss_train: 0.1524 acc_train: 0.9429 loss_val: 1.3631 acc_val: 0.7367 time: 0.7253s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.7005e-02,  1.8563e-02, -3.9935e-04,  ...,  1.4774e-04,\n",
      "         -1.6532e-02,  1.5305e-02],\n",
      "        [-8.4996e-03,  8.3700e-03, -1.0631e-03,  ...,  1.0055e-03,\n",
      "         -4.9215e-03,  2.4056e-02],\n",
      "        [ 4.4026e-03,  2.3966e-05, -2.7170e-03,  ..., -3.9104e-04,\n",
      "          5.8129e-03, -5.8683e-02],\n",
      "        ...,\n",
      "        [-2.4468e-03, -8.0228e-04, -1.1650e-03,  ...,  3.7100e-03,\n",
      "         -6.1569e-04, -3.8815e-02],\n",
      "        [-6.6461e-03,  1.5161e-03,  2.7406e-03,  ...,  5.7340e-04,\n",
      "          3.2971e-03, -2.9332e-02],\n",
      "        [ 3.6536e-02,  1.2800e-02, -2.7492e-03,  ..., -1.2391e-02,\n",
      "         -2.3439e-02,  4.2500e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0162,  0.0181, -0.0006,  ...,  0.0008, -0.0159,  0.0156],\n",
      "        [-0.0097,  0.0082, -0.0007,  ...,  0.0007, -0.0040,  0.0204],\n",
      "        [ 0.0039,  0.0002, -0.0022,  ..., -0.0007,  0.0060, -0.0589],\n",
      "        ...,\n",
      "        [-0.0026, -0.0012, -0.0010,  ...,  0.0030, -0.0007, -0.0380],\n",
      "        [-0.0063,  0.0017,  0.0030,  ...,  0.0006,  0.0041, -0.0293],\n",
      "        [ 0.0340,  0.0121, -0.0003,  ..., -0.0103, -0.0226,  0.0420]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-7.8699e+01, -2.3440e+01, -1.3819e+01,  ..., -9.5367e-07,\n",
      "         -3.5886e+01, -4.0439e+01],\n",
      "        [-1.6413e+00, -9.4845e+00, -6.7634e+00,  ..., -1.1893e+01,\n",
      "         -2.6849e+00, -4.8214e+00],\n",
      "        [-3.5203e+01, -1.9929e+01, -2.5749e-05,  ..., -1.0879e+01,\n",
      "         -1.5573e+01, -1.1908e+01],\n",
      "        ...,\n",
      "        [-8.4584e+00, -1.5771e+01, -5.8477e+00,  ..., -1.1450e+01,\n",
      "         -9.1356e+00, -6.1046e-03],\n",
      "        [-1.3680e-02, -2.4027e+01, -1.8323e+01,  ..., -2.5098e+01,\n",
      "         -1.1719e+01, -5.5446e+00],\n",
      "        [-4.1833e+01, -1.1581e+01, -8.2930e+00,  ..., -2.5960e-04,\n",
      "         -1.8416e+01, -2.2619e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0052 loss_train: 0.1029 acc_train: 0.9714 loss_val: 1.3985 acc_val: 0.7333 time: 0.7599s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0162,  0.0181, -0.0006,  ...,  0.0008, -0.0159,  0.0156],\n",
      "        [-0.0097,  0.0082, -0.0007,  ...,  0.0007, -0.0040,  0.0204],\n",
      "        [ 0.0039,  0.0002, -0.0022,  ..., -0.0007,  0.0060, -0.0589],\n",
      "        ...,\n",
      "        [-0.0026, -0.0012, -0.0010,  ...,  0.0030, -0.0007, -0.0380],\n",
      "        [-0.0063,  0.0017,  0.0030,  ...,  0.0006,  0.0041, -0.0293],\n",
      "        [ 0.0340,  0.0121, -0.0003,  ..., -0.0103, -0.0226,  0.0420]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0156,  0.0175, -0.0008,  ...,  0.0014, -0.0152,  0.0160],\n",
      "        [-0.0102,  0.0077, -0.0002,  ...,  0.0002, -0.0031,  0.0177],\n",
      "        [ 0.0034,  0.0003, -0.0017,  ..., -0.0008,  0.0060, -0.0585],\n",
      "        ...,\n",
      "        [-0.0025, -0.0014, -0.0008,  ...,  0.0020, -0.0007, -0.0363],\n",
      "        [-0.0059,  0.0019,  0.0031,  ...,  0.0005,  0.0049, -0.0291],\n",
      "        [ 0.0326,  0.0114,  0.0020,  ..., -0.0081, -0.0210,  0.0420]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-8.0472e+01, -2.2786e+01, -1.4813e+01,  ..., -3.5763e-07,\n",
      "         -3.4911e+01, -4.0773e+01],\n",
      "        [-3.4889e+00, -7.7615e+00, -5.2020e+00,  ..., -1.0585e+01,\n",
      "         -1.2718e+00, -5.7804e+00],\n",
      "        [-3.8354e+01, -1.9292e+01, -5.3524e-05,  ..., -9.8978e+00,\n",
      "         -1.5328e+01, -1.2720e+01],\n",
      "        ...,\n",
      "        [-9.0977e+00, -1.5887e+01, -6.3231e+00,  ..., -1.1469e+01,\n",
      "         -9.2314e+00, -3.6476e-03],\n",
      "        [-2.7032e-02, -2.2585e+01, -1.6916e+01,  ..., -2.3629e+01,\n",
      "         -1.0398e+01, -4.7837e+00],\n",
      "        [-4.3709e+01, -1.1173e+01, -8.9060e+00,  ..., -1.4960e-04,\n",
      "         -1.8027e+01, -2.3652e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0053 loss_train: 0.0920 acc_train: 0.9714 loss_val: 1.4657 acc_val: 0.7567 time: 0.8065s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0156,  0.0175, -0.0008,  ...,  0.0014, -0.0152,  0.0160],\n",
      "        [-0.0102,  0.0077, -0.0002,  ...,  0.0002, -0.0031,  0.0177],\n",
      "        [ 0.0034,  0.0003, -0.0017,  ..., -0.0008,  0.0060, -0.0585],\n",
      "        ...,\n",
      "        [-0.0025, -0.0014, -0.0008,  ...,  0.0020, -0.0007, -0.0363],\n",
      "        [-0.0059,  0.0019,  0.0031,  ...,  0.0005,  0.0049, -0.0291],\n",
      "        [ 0.0326,  0.0114,  0.0020,  ..., -0.0081, -0.0210,  0.0420]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0150,  0.0167, -0.0009,  ...,  0.0019, -0.0145,  0.0162],\n",
      "        [-0.0101,  0.0071,  0.0002,  ..., -0.0002, -0.0021,  0.0151],\n",
      "        [ 0.0031,  0.0003, -0.0012,  ..., -0.0007,  0.0060, -0.0583],\n",
      "        ...,\n",
      "        [-0.0021, -0.0013, -0.0003,  ...,  0.0008, -0.0007, -0.0349],\n",
      "        [-0.0055,  0.0021,  0.0030,  ...,  0.0005,  0.0055, -0.0291],\n",
      "        [ 0.0317,  0.0108,  0.0039,  ..., -0.0058, -0.0194,  0.0419]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-8.0543e+01, -2.2963e+01, -1.6820e+01,  ...,  0.0000e+00,\n",
      "         -3.4640e+01, -4.0375e+01],\n",
      "        [-3.7013e+00, -7.7011e+00, -5.0486e+00,  ..., -1.0370e+01,\n",
      "         -1.0076e+00, -5.7424e+00],\n",
      "        [-3.8114e+01, -1.8356e+01, -2.5150e-04,  ..., -8.3383e+00,\n",
      "         -1.4371e+01, -1.1360e+01],\n",
      "        ...,\n",
      "        [-8.8108e+00, -1.6266e+01, -7.4047e+00,  ..., -1.1871e+01,\n",
      "         -9.4300e+00, -2.1159e-03],\n",
      "        [-3.1206e-02, -2.2360e+01, -1.6641e+01,  ..., -2.3231e+01,\n",
      "         -1.0050e+01, -4.4797e+00],\n",
      "        [-4.3859e+01, -1.1437e+01, -1.0178e+01,  ..., -4.8755e-05,\n",
      "         -1.8059e+01, -2.3503e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0054 loss_train: 0.0960 acc_train: 0.9714 loss_val: 1.4413 acc_val: 0.7567 time: 0.8135s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0150,  0.0167, -0.0009,  ...,  0.0019, -0.0145,  0.0162],\n",
      "        [-0.0101,  0.0071,  0.0002,  ..., -0.0002, -0.0021,  0.0151],\n",
      "        [ 0.0031,  0.0003, -0.0012,  ..., -0.0007,  0.0060, -0.0583],\n",
      "        ...,\n",
      "        [-0.0021, -0.0013, -0.0003,  ...,  0.0008, -0.0007, -0.0349],\n",
      "        [-0.0055,  0.0021,  0.0030,  ...,  0.0005,  0.0055, -0.0291],\n",
      "        [ 0.0317,  0.0108,  0.0039,  ..., -0.0058, -0.0194,  0.0419]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.4343e-02,  1.5947e-02,  1.3434e-03,  ...,  2.2290e-03,\n",
      "         -1.3779e-02,  1.6658e-02],\n",
      "        [-9.5422e-03,  6.2488e-03,  5.8908e-04,  ..., -5.4211e-04,\n",
      "         -1.0599e-03,  1.3157e-02],\n",
      "        [ 2.8333e-03,  2.4505e-04, -6.1709e-04,  ..., -4.4217e-04,\n",
      "          5.8617e-03, -5.7548e-02],\n",
      "        ...,\n",
      "        [-1.4884e-03, -9.9739e-04,  9.2005e-05,  ..., -3.5426e-04,\n",
      "         -7.0189e-04, -3.3274e-02],\n",
      "        [-5.0665e-03,  2.4203e-03,  3.3335e-03,  ...,  4.4152e-04,\n",
      "          5.3933e-03, -2.9202e-02],\n",
      "        [ 3.0461e-02,  1.0474e-02,  7.8646e-03,  ..., -3.4735e-03,\n",
      "         -1.7716e-02,  4.2098e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-8.0179e+01, -2.3418e+01, -1.9054e+01,  ...,  0.0000e+00,\n",
      "         -3.4995e+01, -4.0812e+01],\n",
      "        [-2.7319e+00, -8.4409e+00, -5.4953e+00,  ..., -1.0646e+01,\n",
      "         -1.4160e+00, -4.9697e+00],\n",
      "        [-3.7351e+01, -1.7358e+01, -1.3282e-03,  ..., -6.6460e+00,\n",
      "         -1.3734e+01, -1.0518e+01],\n",
      "        ...,\n",
      "        [-7.9772e+00, -1.6163e+01, -7.9441e+00,  ..., -1.1900e+01,\n",
      "         -9.3160e+00, -2.4100e-03],\n",
      "        [-2.6430e-02, -2.2716e+01, -1.6867e+01,  ..., -2.3365e+01,\n",
      "         -1.0333e+01, -4.5783e+00],\n",
      "        [-4.3417e+01, -1.1928e+01, -1.1590e+01,  ..., -1.5855e-05,\n",
      "         -1.8474e+01, -2.3462e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0055 loss_train: 0.1097 acc_train: 0.9429 loss_val: 1.3405 acc_val: 0.7700 time: 0.6984s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.4343e-02,  1.5947e-02,  1.3434e-03,  ...,  2.2290e-03,\n",
      "         -1.3779e-02,  1.6658e-02],\n",
      "        [-9.5422e-03,  6.2488e-03,  5.8908e-04,  ..., -5.4211e-04,\n",
      "         -1.0599e-03,  1.3157e-02],\n",
      "        [ 2.8333e-03,  2.4505e-04, -6.1709e-04,  ..., -4.4217e-04,\n",
      "          5.8617e-03, -5.7548e-02],\n",
      "        ...,\n",
      "        [-1.4884e-03, -9.9739e-04,  9.2005e-05,  ..., -3.5426e-04,\n",
      "         -7.0189e-04, -3.3274e-02],\n",
      "        [-5.0665e-03,  2.4203e-03,  3.3335e-03,  ...,  4.4152e-04,\n",
      "          5.3933e-03, -2.9202e-02],\n",
      "        [ 3.0461e-02,  1.0474e-02,  7.8646e-03,  ..., -3.4735e-03,\n",
      "         -1.7716e-02,  4.2098e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0136,  0.0151,  0.0044,  ...,  0.0024, -0.0130,  0.0169],\n",
      "        [-0.0087,  0.0053,  0.0008,  ..., -0.0008, -0.0001,  0.0113],\n",
      "        [ 0.0024,  0.0002, -0.0001,  ..., -0.0001,  0.0056, -0.0566],\n",
      "        ...,\n",
      "        [-0.0008, -0.0005,  0.0005,  ..., -0.0013, -0.0006, -0.0310],\n",
      "        [-0.0047,  0.0028,  0.0031,  ...,  0.0004,  0.0051, -0.0293],\n",
      "        [ 0.0287,  0.0101,  0.0141,  ..., -0.0012, -0.0163,  0.0423]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-7.7901e+01, -2.1372e+01, -1.7636e+01,  ...,  0.0000e+00,\n",
      "         -3.2432e+01, -4.1083e+01],\n",
      "        [-2.3639e+00, -9.4449e+00, -6.0595e+00,  ..., -1.1505e+01,\n",
      "         -1.9166e+00, -4.8958e+00],\n",
      "        [-3.7143e+01, -1.7217e+01, -5.3356e-04,  ..., -7.5574e+00,\n",
      "         -1.3229e+01, -1.1579e+01],\n",
      "        ...,\n",
      "        [-6.7140e+00, -1.5958e+01, -7.9223e+00,  ..., -1.2363e+01,\n",
      "         -8.8050e+00, -5.9461e-03],\n",
      "        [-2.4441e-02, -2.3308e+01, -1.7137e+01,  ..., -2.3960e+01,\n",
      "         -1.0661e+01, -4.9016e+00],\n",
      "        [-4.1596e+01, -1.0574e+01, -1.0645e+01,  ..., -4.9351e-05,\n",
      "         -1.6732e+01, -2.3416e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0056 loss_train: 0.0906 acc_train: 0.9714 loss_val: 1.3396 acc_val: 0.7600 time: 0.6345s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0136,  0.0151,  0.0044,  ...,  0.0024, -0.0130,  0.0169],\n",
      "        [-0.0087,  0.0053,  0.0008,  ..., -0.0008, -0.0001,  0.0113],\n",
      "        [ 0.0024,  0.0002, -0.0001,  ..., -0.0001,  0.0056, -0.0566],\n",
      "        ...,\n",
      "        [-0.0008, -0.0005,  0.0005,  ..., -0.0013, -0.0006, -0.0310],\n",
      "        [-0.0047,  0.0028,  0.0031,  ...,  0.0004,  0.0051, -0.0293],\n",
      "        [ 0.0287,  0.0101,  0.0141,  ..., -0.0012, -0.0163,  0.0423]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.2970e-02,  1.4198e-02,  7.1646e-03,  ...,  2.4437e-03,\n",
      "         -1.2273e-02,  1.7237e-02],\n",
      "        [-7.4321e-03,  4.3047e-03,  8.8313e-04,  ..., -8.5555e-04,\n",
      "          7.6572e-04,  9.6281e-03],\n",
      "        [ 1.6892e-03,  5.0008e-04,  3.6410e-04,  ...,  2.1041e-04,\n",
      "          5.3462e-03, -5.5602e-02],\n",
      "        ...,\n",
      "        [-7.3751e-05, -2.5784e-05,  7.2444e-04,  ..., -2.0742e-03,\n",
      "         -5.1362e-04, -2.8114e-02],\n",
      "        [-4.2756e-03,  3.1396e-03,  1.6763e-03,  ...,  2.9695e-04,\n",
      "          4.5162e-03, -2.9447e-02],\n",
      "        [ 2.7087e-02,  9.9931e-03,  2.2977e-02,  ...,  8.3122e-04,\n",
      "         -1.4748e-02,  4.2698e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-7.6126e+01, -1.9121e+01, -1.6156e+01,  ..., -1.1921e-07,\n",
      "         -3.0505e+01, -4.2076e+01],\n",
      "        [-2.0522e+00, -1.0349e+01, -6.5969e+00,  ..., -1.2362e+01,\n",
      "         -2.4552e+00, -4.9841e+00],\n",
      "        [-3.7165e+01, -1.7027e+01, -1.7486e-04,  ..., -8.6751e+00,\n",
      "         -1.2986e+01, -1.3214e+01],\n",
      "        ...,\n",
      "        [-5.4021e+00, -1.5604e+01, -7.6603e+00,  ..., -1.2647e+01,\n",
      "         -8.2247e+00, -1.6820e-02],\n",
      "        [-1.9435e-02, -2.4020e+01, -1.7527e+01,  ..., -2.4733e+01,\n",
      "         -1.1162e+01, -5.4225e+00],\n",
      "        [-4.0270e+01, -9.1451e+00, -9.7161e+00,  ..., -1.6736e-04,\n",
      "         -1.5437e+01, -2.3885e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0057 loss_train: 0.0748 acc_train: 0.9786 loss_val: 1.3454 acc_val: 0.7667 time: 0.7103s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.2970e-02,  1.4198e-02,  7.1646e-03,  ...,  2.4437e-03,\n",
      "         -1.2273e-02,  1.7237e-02],\n",
      "        [-7.4321e-03,  4.3047e-03,  8.8313e-04,  ..., -8.5555e-04,\n",
      "          7.6572e-04,  9.6281e-03],\n",
      "        [ 1.6892e-03,  5.0008e-04,  3.6410e-04,  ...,  2.1041e-04,\n",
      "          5.3462e-03, -5.5602e-02],\n",
      "        ...,\n",
      "        [-7.3751e-05, -2.5784e-05,  7.2444e-04,  ..., -2.0742e-03,\n",
      "         -5.1362e-04, -2.8114e-02],\n",
      "        [-4.2756e-03,  3.1396e-03,  1.6763e-03,  ...,  2.9695e-04,\n",
      "          4.5162e-03, -2.9447e-02],\n",
      "        [ 2.7087e-02,  9.9931e-03,  2.2977e-02,  ...,  8.3122e-04,\n",
      "         -1.4748e-02,  4.2698e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0124,  0.0132,  0.0086,  ...,  0.0023, -0.0115,  0.0178],\n",
      "        [-0.0058,  0.0032,  0.0008,  ..., -0.0008,  0.0015,  0.0086],\n",
      "        [ 0.0013,  0.0052,  0.0012,  ...,  0.0005,  0.0051, -0.0544],\n",
      "        ...,\n",
      "        [ 0.0006,  0.0004,  0.0008,  ..., -0.0025, -0.0004, -0.0249],\n",
      "        [-0.0038,  0.0036,  0.0005,  ...,  0.0002,  0.0043, -0.0293],\n",
      "        [ 0.0257,  0.0110,  0.0309,  ...,  0.0027, -0.0132,  0.0432]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-7.6484e+01, -1.7917e+01, -1.6018e+01,  ..., -1.1921e-07,\n",
      "         -3.0583e+01, -4.4165e+01],\n",
      "        [-1.8221e+00, -1.0847e+01, -6.8162e+00,  ..., -1.2839e+01,\n",
      "         -2.8331e+00, -5.1435e+00],\n",
      "        [-3.8030e+01, -1.6676e+01, -1.3446e-04,  ..., -8.9292e+00,\n",
      "         -1.3298e+01, -1.5009e+01],\n",
      "        ...,\n",
      "        [-4.4983e+00, -1.5159e+01, -7.2328e+00,  ..., -1.2533e+01,\n",
      "         -7.8056e+00, -3.4252e-02],\n",
      "        [-1.2786e-02, -2.4612e+01, -1.7863e+01,  ..., -2.5362e+01,\n",
      "         -1.1751e+01, -6.0513e+00],\n",
      "        [-4.0980e+01, -8.6420e+00, -9.8758e+00,  ..., -2.2802e-04,\n",
      "         -1.5796e+01, -2.5400e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0058 loss_train: 0.0567 acc_train: 0.9929 loss_val: 1.3259 acc_val: 0.7667 time: 0.8428s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0124,  0.0132,  0.0086,  ...,  0.0023, -0.0115,  0.0178],\n",
      "        [-0.0058,  0.0032,  0.0008,  ..., -0.0008,  0.0015,  0.0086],\n",
      "        [ 0.0013,  0.0052,  0.0012,  ...,  0.0005,  0.0051, -0.0544],\n",
      "        ...,\n",
      "        [ 0.0006,  0.0004,  0.0008,  ..., -0.0025, -0.0004, -0.0249],\n",
      "        [-0.0038,  0.0036,  0.0005,  ...,  0.0002,  0.0043, -0.0293],\n",
      "        [ 0.0257,  0.0110,  0.0309,  ...,  0.0027, -0.0132,  0.0432]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0120,  0.0121,  0.0089,  ...,  0.0021, -0.0108,  0.0186],\n",
      "        [-0.0042,  0.0022,  0.0005,  ..., -0.0006,  0.0021,  0.0076],\n",
      "        [ 0.0009,  0.0065,  0.0001,  ...,  0.0006,  0.0053, -0.0536],\n",
      "        ...,\n",
      "        [ 0.0012,  0.0008,  0.0007,  ..., -0.0025, -0.0002, -0.0216],\n",
      "        [-0.0034,  0.0040, -0.0019,  ...,  0.0001,  0.0043, -0.0293],\n",
      "        [ 0.0246,  0.0117,  0.0377,  ...,  0.0043, -0.0120,  0.0438]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-7.6833e+01, -1.7601e+01, -1.6537e+01,  ..., -1.1921e-07,\n",
      "         -3.1160e+01, -4.5645e+01],\n",
      "        [-1.4748e+00, -1.1662e+01, -7.3480e+00,  ..., -1.3587e+01,\n",
      "         -3.3411e+00, -5.3216e+00],\n",
      "        [-3.7668e+01, -1.6321e+01, -1.2349e-04,  ..., -9.0183e+00,\n",
      "         -1.3099e+01, -1.5714e+01],\n",
      "        ...,\n",
      "        [-3.4990e+00, -1.5089e+01, -7.2204e+00,  ..., -1.2733e+01,\n",
      "         -7.5695e+00, -7.0622e-02],\n",
      "        [-6.8871e-03, -2.5761e+01, -1.8742e+01,  ..., -2.6491e+01,\n",
      "         -1.2654e+01, -6.8483e+00],\n",
      "        [-4.1361e+01, -8.6089e+00, -1.0355e+01,  ..., -2.1443e-04,\n",
      "         -1.6354e+01, -2.6328e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0059 loss_train: 0.0632 acc_train: 0.9929 loss_val: 1.2845 acc_val: 0.7667 time: 0.6336s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0120,  0.0121,  0.0089,  ...,  0.0021, -0.0108,  0.0186],\n",
      "        [-0.0042,  0.0022,  0.0005,  ..., -0.0006,  0.0021,  0.0076],\n",
      "        [ 0.0009,  0.0065,  0.0001,  ...,  0.0006,  0.0053, -0.0536],\n",
      "        ...,\n",
      "        [ 0.0012,  0.0008,  0.0007,  ..., -0.0025, -0.0002, -0.0216],\n",
      "        [-0.0034,  0.0040, -0.0019,  ...,  0.0001,  0.0043, -0.0293],\n",
      "        [ 0.0246,  0.0117,  0.0377,  ...,  0.0043, -0.0120,  0.0438]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.1522e-02,  1.0971e-02,  8.7535e-03,  ...,  1.8273e-03,\n",
      "         -1.0093e-02,  1.9539e-02],\n",
      "        [-2.2587e-03,  1.1419e-03,  2.0440e-04,  ..., -3.1959e-04,\n",
      "          2.6154e-03,  6.8283e-03],\n",
      "        [ 6.7686e-04,  1.1189e-02, -2.3299e-03,  ...,  5.2484e-04,\n",
      "          2.8555e-03, -5.3056e-02],\n",
      "        ...,\n",
      "        [ 1.7743e-03,  9.5904e-04,  5.3033e-04,  ..., -2.2690e-03,\n",
      "         -1.0696e-04, -1.8265e-02],\n",
      "        [-2.9502e-03,  4.3903e-03, -4.2800e-03,  ...,  5.6762e-05,\n",
      "          4.1457e-03, -2.9212e-02],\n",
      "        [ 2.3566e-02,  1.2519e-02,  3.8887e-02,  ...,  5.5294e-03,\n",
      "         -1.0969e-02,  4.4380e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-7.8896e+01, -1.7899e+01, -1.7526e+01,  ...,  0.0000e+00,\n",
      "         -3.2233e+01, -4.7378e+01],\n",
      "        [-2.1482e+00, -1.1854e+01, -7.3367e+00,  ..., -1.3824e+01,\n",
      "         -3.3395e+00, -5.7536e+00],\n",
      "        [-3.8684e+01, -1.6060e+01, -1.6521e-04,  ..., -8.7231e+00,\n",
      "         -1.3066e+01, -1.6349e+01],\n",
      "        ...,\n",
      "        [-3.7151e+00, -1.5212e+01, -7.1625e+00,  ..., -1.2774e+01,\n",
      "         -7.6291e+00, -6.9994e-02],\n",
      "        [-7.5536e-03, -2.6157e+01, -1.8972e+01,  ..., -2.6825e+01,\n",
      "         -1.2860e+01, -6.9050e+00],\n",
      "        [-4.3400e+01, -9.0936e+00, -1.1269e+01,  ..., -1.2516e-04,\n",
      "         -1.7488e+01, -2.7834e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0060 loss_train: 0.0584 acc_train: 0.9929 loss_val: 1.2888 acc_val: 0.7767 time: 0.7236s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.1522e-02,  1.0971e-02,  8.7535e-03,  ...,  1.8273e-03,\n",
      "         -1.0093e-02,  1.9539e-02],\n",
      "        [-2.2587e-03,  1.1419e-03,  2.0440e-04,  ..., -3.1959e-04,\n",
      "          2.6154e-03,  6.8283e-03],\n",
      "        [ 6.7686e-04,  1.1189e-02, -2.3299e-03,  ...,  5.2484e-04,\n",
      "          2.8555e-03, -5.3056e-02],\n",
      "        ...,\n",
      "        [ 1.7743e-03,  9.5904e-04,  5.3033e-04,  ..., -2.2690e-03,\n",
      "         -1.0696e-04, -1.8265e-02],\n",
      "        [-2.9502e-03,  4.3903e-03, -4.2800e-03,  ...,  5.6762e-05,\n",
      "          4.1457e-03, -2.9212e-02],\n",
      "        [ 2.3566e-02,  1.2519e-02,  3.8887e-02,  ...,  5.5294e-03,\n",
      "         -1.0969e-02,  4.4380e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.1099e-02,  9.9084e-03,  7.9816e-03,  ...,  1.4493e-03,\n",
      "         -9.4113e-03,  2.0280e-02],\n",
      "        [-2.4358e-04,  1.6185e-04, -1.2774e-04,  ..., -1.4992e-05,\n",
      "          2.9263e-03,  6.5491e-03],\n",
      "        [ 5.3523e-04,  1.9102e-02, -4.1920e-03,  ...,  3.5821e-04,\n",
      "          1.2638e-03, -5.2513e-02],\n",
      "        ...,\n",
      "        [ 2.9752e-03,  9.3440e-04,  2.3430e-04,  ..., -1.7356e-03,\n",
      "          2.6638e-05, -1.4969e-02],\n",
      "        [-2.4872e-03,  4.8546e-03, -6.1397e-03,  ..., -1.6953e-05,\n",
      "          4.1476e-03, -2.9140e-02],\n",
      "        [ 2.2713e-02,  1.3414e-02,  3.9267e-02,  ...,  6.4682e-03,\n",
      "         -1.0153e-02,  4.4850e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-7.9878e+01, -1.7678e+01, -1.7639e+01,  ...,  0.0000e+00,\n",
      "         -3.2165e+01, -4.8087e+01],\n",
      "        [-3.3008e+00, -1.1915e+01, -7.1160e+00,  ..., -1.3987e+01,\n",
      "         -3.1738e+00, -6.3703e+00],\n",
      "        [-3.9678e+01, -1.6123e+01, -1.3386e-04,  ..., -8.9389e+00,\n",
      "         -1.2892e+01, -1.6837e+01],\n",
      "        ...,\n",
      "        [-4.3080e+00, -1.5515e+01, -7.0857e+00,  ..., -1.2903e+01,\n",
      "         -7.7964e+00, -5.5405e-02],\n",
      "        [-8.5682e-03, -2.6578e+01, -1.9158e+01,  ..., -2.7190e+01,\n",
      "         -1.2977e+01, -6.8265e+00],\n",
      "        [-4.4685e+01, -9.2800e+00, -1.1656e+01,  ..., -1.0192e-04,\n",
      "         -1.7933e+01, -2.8634e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0061 loss_train: 0.0622 acc_train: 0.9857 loss_val: 1.3215 acc_val: 0.7733 time: 0.6554s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.1099e-02,  9.9084e-03,  7.9816e-03,  ...,  1.4493e-03,\n",
      "         -9.4113e-03,  2.0280e-02],\n",
      "        [-2.4358e-04,  1.6185e-04, -1.2774e-04,  ..., -1.4992e-05,\n",
      "          2.9263e-03,  6.5491e-03],\n",
      "        [ 5.3523e-04,  1.9102e-02, -4.1920e-03,  ...,  3.5821e-04,\n",
      "          1.2638e-03, -5.2513e-02],\n",
      "        ...,\n",
      "        [ 2.9752e-03,  9.3440e-04,  2.3430e-04,  ..., -1.7356e-03,\n",
      "          2.6638e-05, -1.4969e-02],\n",
      "        [-2.4872e-03,  4.8546e-03, -6.1397e-03,  ..., -1.6953e-05,\n",
      "          4.1476e-03, -2.9140e-02],\n",
      "        [ 2.2713e-02,  1.3414e-02,  3.9267e-02,  ...,  6.4682e-03,\n",
      "         -1.0153e-02,  4.4850e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.0641e-02,  8.8759e-03,  8.1755e-03,  ...,  1.0271e-03,\n",
      "         -8.7213e-03,  2.0886e-02],\n",
      "        [ 1.5400e-03, -7.3272e-04, -3.6250e-04,  ...,  2.6398e-04,\n",
      "          3.0708e-03,  6.3968e-03],\n",
      "        [ 3.0995e-04,  2.4150e-02, -5.2937e-03,  ...,  1.1708e-04,\n",
      "         -6.4467e-04, -5.2304e-02],\n",
      "        ...,\n",
      "        [ 5.0091e-03,  7.3758e-04, -8.0735e-05,  ..., -1.0298e-03,\n",
      "          1.4628e-04, -1.1352e-02],\n",
      "        [-2.1045e-03,  5.2475e-03, -7.9237e-03,  ..., -8.3184e-05,\n",
      "          4.0708e-03, -2.9061e-02],\n",
      "        [ 2.1842e-02,  1.4191e-02,  3.9021e-02,  ...,  7.0689e-03,\n",
      "         -9.3538e-03,  4.5071e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-7.9466e+01, -1.7124e+01, -1.7355e+01,  ..., -1.1921e-07,\n",
      "         -3.1267e+01, -4.7479e+01],\n",
      "        [-4.1527e+00, -1.2461e+01, -7.2863e+00,  ..., -1.4555e+01,\n",
      "         -3.2605e+00, -6.7276e+00],\n",
      "        [-3.9441e+01, -1.6271e+01, -9.2025e-05,  ..., -9.3484e+00,\n",
      "         -1.2309e+01, -1.6162e+01],\n",
      "        ...,\n",
      "        [-4.8788e+00, -1.6392e+01, -7.5711e+00,  ..., -1.3582e+01,\n",
      "         -8.3188e+00, -3.7864e-02],\n",
      "        [-8.0225e-03, -2.7519e+01, -1.9804e+01,  ..., -2.8046e+01,\n",
      "         -1.3412e+01, -6.7445e+00],\n",
      "        [-4.4669e+01, -9.2058e+00, -1.1642e+01,  ..., -1.0919e-04,\n",
      "         -1.7690e+01, -2.8273e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0062 loss_train: 0.0415 acc_train: 1.0000 loss_val: 1.3347 acc_val: 0.7633 time: 0.8522s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.0641e-02,  8.8759e-03,  8.1755e-03,  ...,  1.0271e-03,\n",
      "         -8.7213e-03,  2.0886e-02],\n",
      "        [ 1.5400e-03, -7.3272e-04, -3.6250e-04,  ...,  2.6398e-04,\n",
      "          3.0708e-03,  6.3968e-03],\n",
      "        [ 3.0995e-04,  2.4150e-02, -5.2937e-03,  ...,  1.1708e-04,\n",
      "         -6.4467e-04, -5.2304e-02],\n",
      "        ...,\n",
      "        [ 5.0091e-03,  7.3758e-04, -8.0735e-05,  ..., -1.0298e-03,\n",
      "          1.4628e-04, -1.1352e-02],\n",
      "        [-2.1045e-03,  5.2475e-03, -7.9237e-03,  ..., -8.3184e-05,\n",
      "          4.0708e-03, -2.9061e-02],\n",
      "        [ 2.1842e-02,  1.4191e-02,  3.9021e-02,  ...,  7.0689e-03,\n",
      "         -9.3538e-03,  4.5071e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.0204e-02,  7.8359e-03,  8.0263e-03,  ...,  5.8760e-04,\n",
      "         -8.0251e-03,  2.1415e-02],\n",
      "        [ 2.9240e-03, -1.5197e-03, -5.1564e-04,  ...,  4.7140e-04,\n",
      "          3.0658e-03,  6.4254e-03],\n",
      "        [-1.8267e-05,  2.5599e-02, -5.5139e-03,  ..., -1.3134e-04,\n",
      "         -2.2545e-03, -5.1929e-02],\n",
      "        ...,\n",
      "        [ 7.4238e-03,  4.2024e-04, -3.4943e-04,  ..., -2.5254e-04,\n",
      "          2.4604e-04, -7.6593e-03],\n",
      "        [-1.7685e-03,  5.5024e-03, -9.2611e-03,  ..., -1.4001e-04,\n",
      "          4.1676e-03, -2.8889e-02],\n",
      "        [ 2.1057e-02,  1.4714e-02,  3.7629e-02,  ...,  7.3374e-03,\n",
      "         -8.6060e-03,  4.5264e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-7.8960e+01, -1.6401e+01, -1.6373e+01,  ..., -1.1921e-07,\n",
      "         -2.9928e+01, -4.6604e+01],\n",
      "        [-4.9755e+00, -1.3216e+01, -7.4580e+00,  ..., -1.5309e+01,\n",
      "         -3.4047e+00, -6.9836e+00],\n",
      "        [-3.9472e+01, -1.6735e+01, -4.6014e-05,  ..., -1.0156e+01,\n",
      "         -1.1877e+01, -1.5700e+01],\n",
      "        ...,\n",
      "        [-5.5600e+00, -1.7347e+01, -7.9553e+00,  ..., -1.4358e+01,\n",
      "         -8.8338e+00, -2.5577e-02],\n",
      "        [-7.9865e-03, -2.8453e+01, -2.0307e+01,  ..., -2.8919e+01,\n",
      "         -1.3754e+01, -6.5916e+00],\n",
      "        [-4.4565e+01, -8.9730e+00, -1.1132e+01,  ..., -1.4149e-04,\n",
      "         -1.7083e+01, -2.7721e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0063 loss_train: 0.0363 acc_train: 0.9929 loss_val: 1.3827 acc_val: 0.7600 time: 0.8708s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.0204e-02,  7.8359e-03,  8.0263e-03,  ...,  5.8760e-04,\n",
      "         -8.0251e-03,  2.1415e-02],\n",
      "        [ 2.9240e-03, -1.5197e-03, -5.1564e-04,  ...,  4.7140e-04,\n",
      "          3.0658e-03,  6.4254e-03],\n",
      "        [-1.8267e-05,  2.5599e-02, -5.5139e-03,  ..., -1.3134e-04,\n",
      "         -2.2545e-03, -5.1929e-02],\n",
      "        ...,\n",
      "        [ 7.4238e-03,  4.2024e-04, -3.4943e-04,  ..., -2.5254e-04,\n",
      "          2.4604e-04, -7.6593e-03],\n",
      "        [-1.7685e-03,  5.5024e-03, -9.2611e-03,  ..., -1.4001e-04,\n",
      "          4.1676e-03, -2.8889e-02],\n",
      "        [ 2.1057e-02,  1.4714e-02,  3.7629e-02,  ...,  7.3374e-03,\n",
      "         -8.6060e-03,  4.5264e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 9.8136e-03,  6.1777e-03,  7.8221e-03,  ...,  1.5624e-04,\n",
      "         -7.3004e-03,  2.1831e-02],\n",
      "        [ 4.8172e-03, -2.1826e-03, -5.7477e-04,  ...,  5.7734e-04,\n",
      "          2.9315e-03,  6.6599e-03],\n",
      "        [-2.9667e-04,  2.0351e-02, -5.6136e-03,  ..., -3.2318e-04,\n",
      "         -3.3288e-03, -5.1169e-02],\n",
      "        ...,\n",
      "        [ 1.0019e-02,  5.5288e-05, -5.2283e-04,  ...,  4.7119e-04,\n",
      "          3.1956e-04, -4.0921e-03],\n",
      "        [-1.5116e-03,  5.6564e-03, -1.0543e-02,  ..., -1.8602e-04,\n",
      "          4.4034e-03, -2.8779e-02],\n",
      "        [ 2.0402e-02,  1.5141e-02,  3.5498e-02,  ...,  7.2921e-03,\n",
      "         -7.7915e-03,  4.5574e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-7.7465e+01, -1.5454e+01, -1.5715e+01,  ..., -3.5763e-07,\n",
      "         -2.8748e+01, -4.5241e+01],\n",
      "        [-4.9241e+00, -1.4117e+01, -7.9171e+00,  ..., -1.6144e+01,\n",
      "         -3.7199e+00, -6.7281e+00],\n",
      "        [-3.8210e+01, -1.6788e+01, -3.9100e-05,  ..., -1.0575e+01,\n",
      "         -1.1277e+01, -1.4393e+01],\n",
      "        ...,\n",
      "        [-5.7716e+00, -1.8496e+01, -8.8031e+00,  ..., -1.5393e+01,\n",
      "         -9.5461e+00, -1.6444e-02],\n",
      "        [-5.0281e-03, -2.9868e+01, -2.1389e+01,  ..., -3.0252e+01,\n",
      "         -1.4573e+01, -6.6870e+00],\n",
      "        [-4.3461e+01, -8.5399e+00, -1.0717e+01,  ..., -2.1777e-04,\n",
      "         -1.6417e+01, -2.6588e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0064 loss_train: 0.0365 acc_train: 0.9857 loss_val: 1.3919 acc_val: 0.7633 time: 0.7999s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 9.8136e-03,  6.1777e-03,  7.8221e-03,  ...,  1.5624e-04,\n",
      "         -7.3004e-03,  2.1831e-02],\n",
      "        [ 4.8172e-03, -2.1826e-03, -5.7477e-04,  ...,  5.7734e-04,\n",
      "          2.9315e-03,  6.6599e-03],\n",
      "        [-2.9667e-04,  2.0351e-02, -5.6136e-03,  ..., -3.2318e-04,\n",
      "         -3.3288e-03, -5.1169e-02],\n",
      "        ...,\n",
      "        [ 1.0019e-02,  5.5288e-05, -5.2283e-04,  ...,  4.7119e-04,\n",
      "          3.1956e-04, -4.0921e-03],\n",
      "        [-1.5116e-03,  5.6564e-03, -1.0543e-02,  ..., -1.8602e-04,\n",
      "          4.4034e-03, -2.8779e-02],\n",
      "        [ 2.0402e-02,  1.5141e-02,  3.5498e-02,  ...,  7.2921e-03,\n",
      "         -7.7915e-03,  4.5574e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0094,  0.0048,  0.0070,  ..., -0.0002, -0.0066,  0.0223],\n",
      "        [ 0.0066, -0.0027, -0.0001,  ...,  0.0006,  0.0026,  0.0070],\n",
      "        [ 0.0002,  0.0159, -0.0047,  ..., -0.0004, -0.0042, -0.0503],\n",
      "        ...,\n",
      "        [ 0.0123, -0.0003, -0.0006,  ...,  0.0011,  0.0004, -0.0008],\n",
      "        [-0.0012,  0.0060, -0.0126,  ..., -0.0002,  0.0052, -0.0285],\n",
      "        [ 0.0198,  0.0157,  0.0320,  ...,  0.0070, -0.0070,  0.0459]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-7.8371e+01, -1.6073e+01, -1.6451e+01,  ..., -1.1921e-07,\n",
      "         -2.9814e+01, -4.5169e+01],\n",
      "        [-4.7746e+00, -1.4456e+01, -7.9293e+00,  ..., -1.6309e+01,\n",
      "         -3.7970e+00, -6.1842e+00],\n",
      "        [-3.8278e+01, -1.6649e+01, -5.4358e-05,  ..., -1.0109e+01,\n",
      "         -1.1311e+01, -1.3705e+01],\n",
      "        ...,\n",
      "        [-6.3500e+00, -1.9163e+01, -9.2469e+00,  ..., -1.5764e+01,\n",
      "         -1.0165e+01, -8.1939e-03],\n",
      "        [-3.3586e-03, -3.0654e+01, -2.2037e+01,  ..., -3.0937e+01,\n",
      "         -1.5114e+01, -6.6852e+00],\n",
      "        [-4.4455e+01, -9.2178e+00, -1.1349e+01,  ..., -1.1110e-04,\n",
      "         -1.7458e+01, -2.6638e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0065 loss_train: 0.0400 acc_train: 1.0000 loss_val: 1.3463 acc_val: 0.7733 time: 0.7832s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0094,  0.0048,  0.0070,  ..., -0.0002, -0.0066,  0.0223],\n",
      "        [ 0.0066, -0.0027, -0.0001,  ...,  0.0006,  0.0026,  0.0070],\n",
      "        [ 0.0002,  0.0159, -0.0047,  ..., -0.0004, -0.0042, -0.0503],\n",
      "        ...,\n",
      "        [ 0.0123, -0.0003, -0.0006,  ...,  0.0011,  0.0004, -0.0008],\n",
      "        [-0.0012,  0.0060, -0.0126,  ..., -0.0002,  0.0052, -0.0285],\n",
      "        [ 0.0198,  0.0157,  0.0320,  ...,  0.0070, -0.0070,  0.0459]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 0.0091,  0.0032,  0.0055,  ..., -0.0006, -0.0058,  0.0226],\n",
      "        [ 0.0084, -0.0031,  0.0003,  ...,  0.0005,  0.0022,  0.0080],\n",
      "        [ 0.0011,  0.0090, -0.0042,  ..., -0.0004, -0.0031, -0.0489],\n",
      "        ...,\n",
      "        [ 0.0139, -0.0005, -0.0005,  ...,  0.0015,  0.0004,  0.0033],\n",
      "        [-0.0009,  0.0058, -0.0143,  ..., -0.0002,  0.0063, -0.0281],\n",
      "        [ 0.0194,  0.0155,  0.0255,  ...,  0.0064, -0.0056,  0.0463]],\n",
      "       requires_grad=True)\n",
      "eval output:  tensor([[-7.9994e+01, -1.5858e+01, -1.7717e+01,  ..., -1.1921e-07,\n",
      "         -3.0635e+01, -4.6408e+01],\n",
      "        [-5.6533e+00, -1.3832e+01, -7.3999e+00,  ..., -1.5805e+01,\n",
      "         -3.2797e+00, -6.3558e+00],\n",
      "        [-3.9704e+01, -1.5639e+01, -1.4101e-04,  ..., -8.9705e+00,\n",
      "         -1.1257e+01, -1.4216e+01],\n",
      "        ...,\n",
      "        [-7.2075e+00, -1.8914e+01, -8.9884e+00,  ..., -1.5296e+01,\n",
      "         -1.0226e+01, -4.8600e-03],\n",
      "        [-3.6270e-03, -3.0343e+01, -2.1812e+01,  ..., -3.0628e+01,\n",
      "         -1.4919e+01, -6.3899e+00],\n",
      "        [-4.6511e+01, -9.3314e+00, -1.2452e+01,  ..., -9.2502e-05,\n",
      "         -1.8463e+01, -2.8097e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0066 loss_train: 0.0346 acc_train: 0.9929 loss_val: 1.3863 acc_val: 0.7767 time: 0.7800s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 0.0091,  0.0032,  0.0055,  ..., -0.0006, -0.0058,  0.0226],\n",
      "        [ 0.0084, -0.0031,  0.0003,  ...,  0.0005,  0.0022,  0.0080],\n",
      "        [ 0.0011,  0.0090, -0.0042,  ..., -0.0004, -0.0031, -0.0489],\n",
      "        ...,\n",
      "        [ 0.0139, -0.0005, -0.0005,  ...,  0.0015,  0.0004,  0.0033],\n",
      "        [-0.0009,  0.0058, -0.0143,  ..., -0.0002,  0.0063, -0.0281],\n",
      "        [ 0.0194,  0.0155,  0.0255,  ...,  0.0064, -0.0056,  0.0463]],\n",
      "       requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 8.4686e-03,  1.6025e-03,  4.3133e-03,  ..., -8.7582e-04,\n",
      "         -5.0893e-03,  2.2624e-02],\n",
      "        [ 8.4482e-03, -3.3363e-03,  7.6242e-05,  ...,  2.8631e-04,\n",
      "          1.7515e-03,  8.7642e-03],\n",
      "        [ 6.5803e-04, -4.6364e-05, -3.9807e-03,  ..., -2.6505e-04,\n",
      "         -1.2085e-03, -4.7657e-02],\n",
      "        ...,\n",
      "        [ 1.5115e-02, -6.6845e-04, -3.3520e-04,  ...,  1.6252e-03,\n",
      "          3.8278e-04,  6.4099e-03],\n",
      "        [-9.4388e-04,  5.4447e-03, -1.7565e-02,  ..., -2.5294e-04,\n",
      "          7.5119e-03, -2.7911e-02],\n",
      "        [ 1.8511e-02,  1.4839e-02,  1.8801e-02,  ...,  5.6049e-03,\n",
      "         -4.4175e-03,  4.6482e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-7.7580e+01, -1.3211e+01, -1.5842e+01,  ..., -1.9073e-06,\n",
      "         -2.7434e+01, -4.5457e+01],\n",
      "        [-6.1925e+00, -1.3936e+01, -7.4303e+00,  ..., -1.6353e+01,\n",
      "         -2.9874e+00, -6.8875e+00],\n",
      "        [-3.9372e+01, -1.5361e+01, -8.0821e-05,  ..., -9.8776e+00,\n",
      "         -1.0468e+01, -1.4492e+01],\n",
      "        ...,\n",
      "        [-7.0627e+00, -1.9105e+01, -9.0040e+00,  ..., -1.5757e+01,\n",
      "         -1.0118e+01, -5.5423e-03],\n",
      "        [-2.6527e-03, -3.1089e+01, -2.2356e+01,  ..., -3.1579e+01,\n",
      "         -1.5242e+01, -6.6624e+00],\n",
      "        [-4.4906e+01, -7.4723e+00, -1.1172e+01,  ..., -5.8300e-04,\n",
      "         -1.6176e+01, -2.7624e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0067 loss_train: 0.0383 acc_train: 1.0000 loss_val: 1.5231 acc_val: 0.7567 time: 0.6260s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 8.4686e-03,  1.6025e-03,  4.3133e-03,  ..., -8.7582e-04,\n",
      "         -5.0893e-03,  2.2624e-02],\n",
      "        [ 8.4482e-03, -3.3363e-03,  7.6242e-05,  ...,  2.8631e-04,\n",
      "          1.7515e-03,  8.7642e-03],\n",
      "        [ 6.5803e-04, -4.6364e-05, -3.9807e-03,  ..., -2.6505e-04,\n",
      "         -1.2085e-03, -4.7657e-02],\n",
      "        ...,\n",
      "        [ 1.5115e-02, -6.6845e-04, -3.3520e-04,  ...,  1.6252e-03,\n",
      "          3.8278e-04,  6.4099e-03],\n",
      "        [-9.4388e-04,  5.4447e-03, -1.7565e-02,  ..., -2.5294e-04,\n",
      "          7.5119e-03, -2.7911e-02],\n",
      "        [ 1.8511e-02,  1.4839e-02,  1.8801e-02,  ...,  5.6049e-03,\n",
      "         -4.4175e-03,  4.6482e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 8.2534e-03,  7.2145e-04,  1.9641e-03,  ..., -1.0823e-03,\n",
      "         -4.7489e-03,  2.2698e-02],\n",
      "        [ 8.3906e-03, -3.3948e-03, -1.0517e-04,  ...,  7.2108e-05,\n",
      "          1.1610e-03,  9.5265e-03],\n",
      "        [ 8.7815e-04, -5.4818e-03, -2.4192e-03,  ..., -8.2728e-05,\n",
      "         -2.4130e-04, -4.6306e-02],\n",
      "        ...,\n",
      "        [ 1.5339e-02, -6.5211e-04, -1.1335e-04,  ...,  1.5575e-03,\n",
      "          3.5405e-04,  5.7851e-03],\n",
      "        [-5.8763e-04,  5.7746e-03, -1.8463e-02,  ..., -2.5200e-04,\n",
      "          8.3177e-03, -2.7569e-02],\n",
      "        [ 1.7912e-02,  1.4546e-02,  1.2367e-02,  ...,  4.6709e-03,\n",
      "         -3.8739e-03,  4.6837e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-7.7378e+01, -1.4145e+01, -1.5679e+01,  ..., -8.3446e-07,\n",
      "         -2.7883e+01, -4.4347e+01],\n",
      "        [-6.3856e+00, -1.4607e+01, -7.4610e+00,  ..., -1.6788e+01,\n",
      "         -3.4021e+00, -6.5864e+00],\n",
      "        [-3.9303e+01, -1.5904e+01, -6.4133e-05,  ..., -1.0070e+01,\n",
      "         -1.0796e+01, -1.3928e+01],\n",
      "        ...,\n",
      "        [-7.3140e+00, -1.9813e+01, -9.3039e+00,  ..., -1.6266e+01,\n",
      "         -1.0659e+01, -4.2258e-03],\n",
      "        [-2.3693e-03, -3.1857e+01, -2.2743e+01,  ..., -3.2247e+01,\n",
      "         -1.5800e+01, -6.6782e+00],\n",
      "        [-4.4760e+01, -8.2271e+00, -1.1034e+01,  ..., -2.8368e-04,\n",
      "         -1.6556e+01, -2.6692e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0068 loss_train: 0.0371 acc_train: 0.9929 loss_val: 1.4904 acc_val: 0.7633 time: 0.6233s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 8.2534e-03,  7.2145e-04,  1.9641e-03,  ..., -1.0823e-03,\n",
      "         -4.7489e-03,  2.2698e-02],\n",
      "        [ 8.3906e-03, -3.3948e-03, -1.0517e-04,  ...,  7.2108e-05,\n",
      "          1.1610e-03,  9.5265e-03],\n",
      "        [ 8.7815e-04, -5.4818e-03, -2.4192e-03,  ..., -8.2728e-05,\n",
      "         -2.4130e-04, -4.6306e-02],\n",
      "        ...,\n",
      "        [ 1.5339e-02, -6.5211e-04, -1.1335e-04,  ...,  1.5575e-03,\n",
      "          3.5405e-04,  5.7851e-03],\n",
      "        [-5.8763e-04,  5.7746e-03, -1.8463e-02,  ..., -2.5200e-04,\n",
      "          8.3177e-03, -2.7569e-02],\n",
      "        [ 1.7912e-02,  1.4546e-02,  1.2367e-02,  ...,  4.6709e-03,\n",
      "         -3.8739e-03,  4.6837e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 7.7940e-03, -1.1397e-05,  1.5474e-03,  ..., -1.2071e-03,\n",
      "         -4.4499e-03,  2.2091e-02],\n",
      "        [ 8.0670e-03, -3.3226e-03, -1.6543e-04,  ..., -1.3518e-04,\n",
      "          5.5745e-04,  1.0315e-02],\n",
      "        [ 8.4471e-04, -1.0727e-02,  1.2517e-03,  ...,  1.0451e-04,\n",
      "         -6.9691e-04, -4.5046e-02],\n",
      "        ...,\n",
      "        [ 1.4575e-02, -5.0883e-04,  1.1118e-04,  ...,  1.2891e-03,\n",
      "          3.0561e-04,  4.6275e-03],\n",
      "        [-4.1215e-04,  5.8462e-03, -1.7060e-02,  ..., -2.4078e-04,\n",
      "          9.0233e-03, -2.7053e-02],\n",
      "        [ 1.7313e-02,  1.4161e-02,  5.9234e-03,  ...,  3.6337e-03,\n",
      "         -3.6447e-03,  4.7363e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-7.8164e+01, -1.5612e+01, -1.5212e+01,  ..., -3.5763e-07,\n",
      "         -2.9053e+01, -4.3231e+01],\n",
      "        [-7.0832e+00, -1.5561e+01, -7.2848e+00,  ..., -1.7293e+01,\n",
      "         -4.2178e+00, -6.2216e+00],\n",
      "        [-4.0547e+01, -1.7017e+01, -3.7073e-05,  ..., -1.0420e+01,\n",
      "         -1.2010e+01, -1.3859e+01],\n",
      "        ...,\n",
      "        [-8.1654e+00, -2.0528e+01, -9.2256e+00,  ..., -1.6623e+01,\n",
      "         -1.1362e+01, -3.1721e-03],\n",
      "        [-4.0695e-03, -3.2013e+01, -2.2195e+01,  ..., -3.2187e+01,\n",
      "         -1.5984e+01, -6.1099e+00],\n",
      "        [-4.5421e+01, -9.3359e+00, -1.0657e+01,  ..., -1.1169e-04,\n",
      "         -1.7410e+01, -2.5815e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0069 loss_train: 0.0247 acc_train: 1.0000 loss_val: 1.4946 acc_val: 0.7733 time: 0.6370s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 7.7940e-03, -1.1397e-05,  1.5474e-03,  ..., -1.2071e-03,\n",
      "         -4.4499e-03,  2.2091e-02],\n",
      "        [ 8.0670e-03, -3.3226e-03, -1.6543e-04,  ..., -1.3518e-04,\n",
      "          5.5745e-04,  1.0315e-02],\n",
      "        [ 8.4471e-04, -1.0727e-02,  1.2517e-03,  ...,  1.0451e-04,\n",
      "         -6.9691e-04, -4.5046e-02],\n",
      "        ...,\n",
      "        [ 1.4575e-02, -5.0883e-04,  1.1118e-04,  ...,  1.2891e-03,\n",
      "          3.0561e-04,  4.6275e-03],\n",
      "        [-4.1215e-04,  5.8462e-03, -1.7060e-02,  ..., -2.4078e-04,\n",
      "          9.0233e-03, -2.7053e-02],\n",
      "        [ 1.7313e-02,  1.4161e-02,  5.9234e-03,  ...,  3.6337e-03,\n",
      "         -3.6447e-03,  4.7363e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 7.3141e-03, -6.8861e-04,  1.6972e-03,  ..., -1.2501e-03,\n",
      "         -4.0115e-03,  2.1307e-02],\n",
      "        [ 7.6398e-03, -3.1402e-03, -2.1684e-04,  ..., -2.9844e-04,\n",
      "         -1.0537e-05,  1.1062e-02],\n",
      "        [ 8.7982e-04, -1.4533e-02,  5.0108e-03,  ...,  2.4636e-04,\n",
      "         -8.0025e-04, -4.3707e-02],\n",
      "        ...,\n",
      "        [ 1.3330e-02, -2.7795e-04,  2.9133e-04,  ...,  8.7060e-04,\n",
      "          2.4231e-04,  3.1614e-03],\n",
      "        [-2.7238e-04,  5.6852e-03, -1.5833e-02,  ..., -2.2063e-04,\n",
      "          9.7927e-03, -2.6599e-02],\n",
      "        [ 1.6719e-02,  1.3757e-02,  1.4909e-04,  ...,  2.5442e-03,\n",
      "         -3.3413e-03,  4.7927e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-7.8765e+01, -1.6335e+01, -1.5106e+01,  ..., -3.5763e-07,\n",
      "         -2.9879e+01, -4.2893e+01],\n",
      "        [-7.7411e+00, -1.5618e+01, -6.6729e+00,  ..., -1.7084e+01,\n",
      "         -4.4254e+00, -6.1078e+00],\n",
      "        [-4.2109e+01, -1.7409e+01, -4.0530e-05,  ..., -1.0185e+01,\n",
      "         -1.3024e+01, -1.4458e+01],\n",
      "        ...,\n",
      "        [-8.6769e+00, -2.0578e+01, -8.8339e+00,  ..., -1.6407e+01,\n",
      "         -1.1623e+01, -2.6437e-03],\n",
      "        [-5.4625e-03, -3.1762e+01, -2.1521e+01,  ..., -3.1783e+01,\n",
      "         -1.5985e+01, -5.7772e+00],\n",
      "        [-4.6140e+01, -9.9247e+00, -1.0626e+01,  ..., -7.3192e-05,\n",
      "         -1.8089e+01, -2.5732e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0070 loss_train: 0.0222 acc_train: 1.0000 loss_val: 1.5243 acc_val: 0.7700 time: 0.6095s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 7.3141e-03, -6.8861e-04,  1.6972e-03,  ..., -1.2501e-03,\n",
      "         -4.0115e-03,  2.1307e-02],\n",
      "        [ 7.6398e-03, -3.1402e-03, -2.1684e-04,  ..., -2.9844e-04,\n",
      "         -1.0537e-05,  1.1062e-02],\n",
      "        [ 8.7982e-04, -1.4533e-02,  5.0108e-03,  ...,  2.4636e-04,\n",
      "         -8.0025e-04, -4.3707e-02],\n",
      "        ...,\n",
      "        [ 1.3330e-02, -2.7795e-04,  2.9133e-04,  ...,  8.7060e-04,\n",
      "          2.4231e-04,  3.1614e-03],\n",
      "        [-2.7238e-04,  5.6852e-03, -1.5833e-02,  ..., -2.2063e-04,\n",
      "          9.7927e-03, -2.6599e-02],\n",
      "        [ 1.6719e-02,  1.3757e-02,  1.4909e-04,  ...,  2.5442e-03,\n",
      "         -3.3413e-03,  4.7927e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 6.7406e-03, -1.1290e-03,  4.8145e-03,  ..., -1.2160e-03,\n",
      "         -3.1720e-03,  1.9531e-02],\n",
      "        [ 6.8256e-03, -2.8642e-03, -2.1753e-04,  ..., -3.9158e-04,\n",
      "         -5.2423e-04,  1.1598e-02],\n",
      "        [ 7.0967e-04, -1.6117e-02,  7.0102e-03,  ...,  3.0870e-04,\n",
      "         -4.7444e-04, -4.2679e-02],\n",
      "        ...,\n",
      "        [ 1.5231e-02, -1.3090e-05,  4.0022e-04,  ...,  3.3864e-04,\n",
      "          1.7288e-04, -2.2589e-05],\n",
      "        [-2.6451e-04,  5.3265e-03, -1.6534e-02,  ..., -1.9315e-04,\n",
      "          1.0649e-02, -2.6410e-02],\n",
      "        [ 1.5983e-02,  1.2864e-02, -5.1331e-03,  ...,  1.4512e-03,\n",
      "         -2.5560e-03,  4.8051e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-7.5022e+01, -1.5179e+01, -1.4885e+01,  ..., -5.9605e-07,\n",
      "         -2.8612e+01, -4.1495e+01],\n",
      "        [-5.9256e+00, -1.6259e+01, -7.5676e+00,  ..., -1.7871e+01,\n",
      "         -4.8724e+00, -5.9115e+00],\n",
      "        [-3.9200e+01, -1.6749e+01, -4.9471e-05,  ..., -1.0048e+01,\n",
      "         -1.2296e+01, -1.3425e+01],\n",
      "        ...,\n",
      "        [-6.6689e+00, -2.0725e+01, -9.5490e+00,  ..., -1.6934e+01,\n",
      "         -1.1624e+01, -4.2714e-03],\n",
      "        [-1.2348e-03, -3.3371e+01, -2.3359e+01,  ..., -3.3573e+01,\n",
      "         -1.7451e+01, -7.2919e+00],\n",
      "        [-4.2764e+01, -8.9606e+00, -1.0376e+01,  ..., -1.5949e-04,\n",
      "         -1.6859e+01, -2.4432e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0071 loss_train: 0.0287 acc_train: 1.0000 loss_val: 1.4370 acc_val: 0.7733 time: 0.6086s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 6.7406e-03, -1.1290e-03,  4.8145e-03,  ..., -1.2160e-03,\n",
      "         -3.1720e-03,  1.9531e-02],\n",
      "        [ 6.8256e-03, -2.8642e-03, -2.1753e-04,  ..., -3.9158e-04,\n",
      "         -5.2423e-04,  1.1598e-02],\n",
      "        [ 7.0967e-04, -1.6117e-02,  7.0102e-03,  ...,  3.0870e-04,\n",
      "         -4.7444e-04, -4.2679e-02],\n",
      "        ...,\n",
      "        [ 1.5231e-02, -1.3090e-05,  4.0022e-04,  ...,  3.3864e-04,\n",
      "          1.7288e-04, -2.2589e-05],\n",
      "        [-2.6451e-04,  5.3265e-03, -1.6534e-02,  ..., -1.9315e-04,\n",
      "          1.0649e-02, -2.6410e-02],\n",
      "        [ 1.5983e-02,  1.2864e-02, -5.1331e-03,  ...,  1.4512e-03,\n",
      "         -2.5560e-03,  4.8051e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 6.1751e-03, -1.4724e-03,  5.0440e-03,  ..., -1.1134e-03,\n",
      "         -2.4492e-03,  1.8041e-02],\n",
      "        [ 5.8418e-03, -2.5120e-03, -1.8508e-04,  ..., -4.0350e-04,\n",
      "         -9.6459e-04,  1.2124e-02],\n",
      "        [ 4.3226e-04, -1.6337e-02,  6.8931e-03,  ...,  2.8161e-04,\n",
      "         -1.2112e-03, -4.1474e-02],\n",
      "        ...,\n",
      "        [ 1.6516e-02,  2.2964e-04,  4.1340e-04,  ..., -1.9022e-04,\n",
      "          9.8818e-05, -1.3627e-03],\n",
      "        [-3.8592e-04,  4.7611e-03, -1.7429e-02,  ..., -1.6011e-04,\n",
      "          1.0960e-02, -2.5934e-02],\n",
      "        [ 1.5450e-02,  1.2170e-02, -1.2421e-02,  ...,  4.0000e-04,\n",
      "         -2.0836e-03,  4.8241e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-7.6868e+01, -1.4081e+01, -1.5113e+01,  ..., -1.0729e-06,\n",
      "         -2.8193e+01, -4.3589e+01],\n",
      "        [-8.5804e+00, -1.4256e+01, -6.0216e+00,  ..., -1.6449e+01,\n",
      "         -3.5295e+00, -7.5326e+00],\n",
      "        [-4.2578e+01, -1.5599e+01, -1.0907e-04,  ..., -9.1621e+00,\n",
      "         -1.2470e+01, -1.6112e+01],\n",
      "        ...,\n",
      "        [-7.4975e+00, -1.8933e+01, -7.8541e+00,  ..., -1.5173e+01,\n",
      "         -1.0507e+01, -6.2051e-03],\n",
      "        [-2.5910e-03, -3.1431e+01, -2.1651e+01,  ..., -3.1826e+01,\n",
      "         -1.6132e+01, -6.8914e+00],\n",
      "        [-4.5557e+01, -8.2452e+00, -1.0908e+01,  ..., -2.8082e-04,\n",
      "         -1.6979e+01, -2.7132e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0072 loss_train: 0.0404 acc_train: 0.9786 loss_val: 1.6344 acc_val: 0.7567 time: 0.6198s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 6.1751e-03, -1.4724e-03,  5.0440e-03,  ..., -1.1134e-03,\n",
      "         -2.4492e-03,  1.8041e-02],\n",
      "        [ 5.8418e-03, -2.5120e-03, -1.8508e-04,  ..., -4.0350e-04,\n",
      "         -9.6459e-04,  1.2124e-02],\n",
      "        [ 4.3226e-04, -1.6337e-02,  6.8931e-03,  ...,  2.8161e-04,\n",
      "         -1.2112e-03, -4.1474e-02],\n",
      "        ...,\n",
      "        [ 1.6516e-02,  2.2964e-04,  4.1340e-04,  ..., -1.9022e-04,\n",
      "          9.8818e-05, -1.3627e-03],\n",
      "        [-3.8592e-04,  4.7611e-03, -1.7429e-02,  ..., -1.6011e-04,\n",
      "          1.0960e-02, -2.5934e-02],\n",
      "        [ 1.5450e-02,  1.2170e-02, -1.2421e-02,  ...,  4.0000e-04,\n",
      "         -2.0836e-03,  4.8241e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 5.7650e-03, -1.4720e-03,  4.9399e-03,  ..., -9.5441e-04,\n",
      "         -1.9467e-03,  1.6796e-02],\n",
      "        [ 5.5913e-03, -2.1021e-03, -1.1704e-04,  ..., -3.3907e-04,\n",
      "         -1.3171e-03,  1.2494e-02],\n",
      "        [ 6.0470e-04, -1.4095e-02,  8.3724e-03,  ...,  1.8025e-04,\n",
      "         -1.8448e-03, -4.0434e-02],\n",
      "        ...,\n",
      "        [ 1.6591e-02,  4.0308e-04,  3.3640e-04,  ..., -6.4318e-04,\n",
      "          2.5279e-05, -2.7490e-03],\n",
      "        [-3.9981e-04,  4.8552e-03, -1.4810e-02,  ..., -1.2339e-04,\n",
      "          1.0984e-02, -2.5370e-02],\n",
      "        [ 1.5383e-02,  1.3161e-02, -1.9139e-02,  ..., -5.6962e-04,\n",
      "         -1.9691e-03,  4.8891e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-8.0060e+01, -1.6475e+01, -1.7635e+01,  ..., -1.1921e-07,\n",
      "         -3.1571e+01, -4.5092e+01],\n",
      "        [-1.0071e+01, -1.3292e+01, -5.1567e+00,  ..., -1.5270e+01,\n",
      "         -3.2428e+00, -7.9856e+00],\n",
      "        [-4.4334e+01, -1.4699e+01, -9.3345e-04,  ..., -6.9795e+00,\n",
      "         -1.3155e+01, -1.6740e+01],\n",
      "        ...,\n",
      "        [-8.3271e+00, -1.7839e+01, -6.9265e+00,  ..., -1.3677e+01,\n",
      "         -1.0182e+01, -7.1321e-03],\n",
      "        [-5.2831e-03, -3.0082e+01, -2.0443e+01,  ..., -3.0356e+01,\n",
      "         -1.5455e+01, -6.4139e+00],\n",
      "        [-4.8699e+01, -9.8564e+00, -1.2921e+01,  ..., -5.4835e-05,\n",
      "         -1.9544e+01, -2.9039e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0073 loss_train: 0.0309 acc_train: 0.9929 loss_val: 1.7107 acc_val: 0.7667 time: 0.6743s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 5.7650e-03, -1.4720e-03,  4.9399e-03,  ..., -9.5441e-04,\n",
      "         -1.9467e-03,  1.6796e-02],\n",
      "        [ 5.5913e-03, -2.1021e-03, -1.1704e-04,  ..., -3.3907e-04,\n",
      "         -1.3171e-03,  1.2494e-02],\n",
      "        [ 6.0470e-04, -1.4095e-02,  8.3724e-03,  ...,  1.8025e-04,\n",
      "         -1.8448e-03, -4.0434e-02],\n",
      "        ...,\n",
      "        [ 1.6591e-02,  4.0308e-04,  3.3640e-04,  ..., -6.4318e-04,\n",
      "          2.5279e-05, -2.7490e-03],\n",
      "        [-3.9981e-04,  4.8552e-03, -1.4810e-02,  ..., -1.2339e-04,\n",
      "          1.0984e-02, -2.5370e-02],\n",
      "        [ 1.5383e-02,  1.3161e-02, -1.9139e-02,  ..., -5.6962e-04,\n",
      "         -1.9691e-03,  4.8891e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 4.7963e-03, -2.9857e-03,  5.5303e-03,  ..., -7.5326e-04,\n",
      "         -1.7555e-03,  1.4450e-02],\n",
      "        [ 1.2411e-03, -1.6583e-03, -3.0778e-05,  ..., -2.1701e-04,\n",
      "         -1.5693e-03,  1.0740e-02],\n",
      "        [-2.4441e-03, -1.7676e-02,  1.1942e-02,  ...,  3.8882e-05,\n",
      "         -2.6706e-03, -4.1795e-02],\n",
      "        ...,\n",
      "        [ 1.4711e-02,  4.7797e-04,  1.9373e-04,  ..., -9.6382e-04,\n",
      "         -4.3022e-05, -4.5660e-03],\n",
      "        [-8.4124e-04,  3.0784e-03, -1.0920e-02,  ..., -8.4844e-05,\n",
      "          1.1167e-02, -2.5320e-02],\n",
      "        [ 1.3924e-02,  1.0514e-02, -2.0346e-02,  ..., -1.4243e-03,\n",
      "         -3.1169e-03,  4.8207e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-7.1911e+01, -1.3759e+01, -1.0698e+01,  ..., -2.3603e-05,\n",
      "         -2.5258e+01, -3.8286e+01],\n",
      "        [-9.2462e+00, -1.8193e+01, -8.0812e+00,  ..., -2.0272e+01,\n",
      "         -6.3497e+00, -8.4381e+00],\n",
      "        [-3.8864e+01, -1.8239e+01, -1.0610e-05,  ..., -1.3169e+01,\n",
      "         -1.2296e+01, -1.4449e+01],\n",
      "        ...,\n",
      "        [-6.0850e+00, -2.0486e+01, -8.3768e+00,  ..., -1.7327e+01,\n",
      "         -1.0987e+01, -3.3643e-02],\n",
      "        [-3.9163e-03, -3.3427e+01, -2.2560e+01,  ..., -3.4067e+01,\n",
      "         -1.7400e+01, -7.5337e+00],\n",
      "        [-4.0817e+01, -7.1719e+00, -7.3276e+00,  ..., -1.4272e-03,\n",
      "         -1.3632e+01, -2.3109e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0074 loss_train: 0.0692 acc_train: 0.9786 loss_val: 1.8652 acc_val: 0.7100 time: 0.6670s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 4.7963e-03, -2.9857e-03,  5.5303e-03,  ..., -7.5326e-04,\n",
      "         -1.7555e-03,  1.4450e-02],\n",
      "        [ 1.2411e-03, -1.6583e-03, -3.0778e-05,  ..., -2.1701e-04,\n",
      "         -1.5693e-03,  1.0740e-02],\n",
      "        [-2.4441e-03, -1.7676e-02,  1.1942e-02,  ...,  3.8882e-05,\n",
      "         -2.6706e-03, -4.1795e-02],\n",
      "        ...,\n",
      "        [ 1.4711e-02,  4.7797e-04,  1.9373e-04,  ..., -9.6382e-04,\n",
      "         -4.3022e-05, -4.5660e-03],\n",
      "        [-8.4124e-04,  3.0784e-03, -1.0920e-02,  ..., -8.4844e-05,\n",
      "          1.1167e-02, -2.5320e-02],\n",
      "        [ 1.3924e-02,  1.0514e-02, -2.0346e-02,  ..., -1.4243e-03,\n",
      "         -3.1169e-03,  4.8207e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 5.3641e-03, -3.7965e-03,  7.2881e-04,  ..., -5.2566e-04,\n",
      "         -1.0078e-03,  1.3000e-02],\n",
      "        [ 3.7197e-04, -1.1954e-03,  5.3913e-05,  ..., -6.5377e-05,\n",
      "         -1.7208e-03,  1.0216e-02],\n",
      "        [-2.6564e-03, -1.9777e-02,  1.1128e-02,  ..., -9.9976e-05,\n",
      "         -5.1437e-04, -4.2041e-02],\n",
      "        ...,\n",
      "        [ 1.4048e-02,  4.4759e-04,  2.2179e-05,  ..., -1.1188e-03,\n",
      "         -1.0209e-04, -4.1895e-03],\n",
      "        [-4.6676e-04,  2.4044e-03, -1.1821e-02,  ..., -4.6267e-05,\n",
      "          1.2139e-02, -2.4425e-02],\n",
      "        [ 1.6050e-02,  8.7861e-03, -2.7470e-02,  ..., -2.1382e-03,\n",
      "         -2.1189e-03,  4.8257e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-7.5649e+01, -1.8285e+01, -1.8092e+01,  ...,  0.0000e+00,\n",
      "         -3.2166e+01, -4.1452e+01],\n",
      "        [-7.9795e+00, -1.5686e+01, -7.2517e+00,  ..., -1.7371e+01,\n",
      "         -5.1142e+00, -7.5382e+00],\n",
      "        [-3.7474e+01, -1.5390e+01, -2.4340e-04,  ..., -8.3661e+00,\n",
      "         -1.1815e+01, -1.3208e+01],\n",
      "        ...,\n",
      "        [-5.6877e+00, -1.8569e+01, -8.3314e+00,  ..., -1.4894e+01,\n",
      "         -1.0533e+01, -1.5175e-02],\n",
      "        [-1.5566e-03, -3.2032e+01, -2.2642e+01,  ..., -3.2462e+01,\n",
      "         -1.7205e+01, -7.9465e+00],\n",
      "        [-4.4939e+01, -1.0606e+01, -1.3481e+01,  ..., -2.6106e-05,\n",
      "         -1.9502e+01, -2.6817e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0075 loss_train: 0.1208 acc_train: 0.9643 loss_val: 1.4452 acc_val: 0.7833 time: 0.6051s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 5.3641e-03, -3.7965e-03,  7.2881e-04,  ..., -5.2566e-04,\n",
      "         -1.0078e-03,  1.3000e-02],\n",
      "        [ 3.7197e-04, -1.1954e-03,  5.3913e-05,  ..., -6.5377e-05,\n",
      "         -1.7208e-03,  1.0216e-02],\n",
      "        [-2.6564e-03, -1.9777e-02,  1.1128e-02,  ..., -9.9976e-05,\n",
      "         -5.1437e-04, -4.2041e-02],\n",
      "        ...,\n",
      "        [ 1.4048e-02,  4.4759e-04,  2.2179e-05,  ..., -1.1188e-03,\n",
      "         -1.0209e-04, -4.1895e-03],\n",
      "        [-4.6676e-04,  2.4044e-03, -1.1821e-02,  ..., -4.6267e-05,\n",
      "          1.2139e-02, -2.4425e-02],\n",
      "        [ 1.6050e-02,  8.7861e-03, -2.7470e-02,  ..., -2.1382e-03,\n",
      "         -2.1189e-03,  4.8257e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 5.6611e-03, -4.5155e-03, -3.3090e-03,  ..., -2.8757e-04,\n",
      "         -1.4844e-04,  1.1389e-02],\n",
      "        [-8.9498e-04, -7.3202e-04,  1.1917e-04,  ...,  8.4475e-05,\n",
      "         -1.7731e-03,  9.6094e-03],\n",
      "        [-3.0246e-03, -2.0772e-02,  8.4553e-03,  ..., -1.9797e-04,\n",
      "          1.4663e-03, -4.2219e-02],\n",
      "        ...,\n",
      "        [ 1.3956e-02,  3.2743e-04, -1.3815e-04,  ..., -1.1054e-03,\n",
      "         -1.4886e-04, -3.1280e-03],\n",
      "        [-2.0268e-04,  1.4769e-03, -1.4716e-02,  ..., -9.3098e-06,\n",
      "          1.3073e-02, -2.4153e-02],\n",
      "        [ 1.7569e-02,  7.1205e-03, -3.3607e-02,  ..., -2.6935e-03,\n",
      "         -1.4120e-03,  4.7974e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-7.7101e+01, -2.0922e+01, -2.2915e+01,  ...,  0.0000e+00,\n",
      "         -3.6465e+01, -4.3148e+01],\n",
      "        [-6.3185e+00, -1.3489e+01, -6.6087e+00,  ..., -1.4998e+01,\n",
      "         -3.9031e+00, -6.5668e+00],\n",
      "        [-3.5343e+01, -1.2881e+01, -1.1953e-02,  ..., -4.4349e+00,\n",
      "         -1.1143e+01, -1.1732e+01],\n",
      "        ...,\n",
      "        [-5.1205e+00, -1.6836e+01, -8.2910e+00,  ..., -1.2768e+01,\n",
      "         -9.9477e+00, -1.1381e-02],\n",
      "        [-6.7640e-04, -3.0954e+01, -2.2752e+01,  ..., -3.1323e+01,\n",
      "         -1.6987e+01, -8.3083e+00],\n",
      "        [-4.6974e+01, -1.2522e+01, -1.7347e+01,  ..., -3.6955e-06,\n",
      "         -2.2995e+01, -2.9020e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0076 loss_train: 0.0251 acc_train: 1.0000 loss_val: 1.5136 acc_val: 0.7533 time: 0.6139s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 5.6611e-03, -4.5155e-03, -3.3090e-03,  ..., -2.8757e-04,\n",
      "         -1.4844e-04,  1.1389e-02],\n",
      "        [-8.9498e-04, -7.3202e-04,  1.1917e-04,  ...,  8.4475e-05,\n",
      "         -1.7731e-03,  9.6094e-03],\n",
      "        [-3.0246e-03, -2.0772e-02,  8.4553e-03,  ..., -1.9797e-04,\n",
      "          1.4663e-03, -4.2219e-02],\n",
      "        ...,\n",
      "        [ 1.3956e-02,  3.2743e-04, -1.3815e-04,  ..., -1.1054e-03,\n",
      "         -1.4886e-04, -3.1280e-03],\n",
      "        [-2.0268e-04,  1.4769e-03, -1.4716e-02,  ..., -9.3098e-06,\n",
      "          1.3073e-02, -2.4153e-02],\n",
      "        [ 1.7569e-02,  7.1205e-03, -3.3607e-02,  ..., -2.6935e-03,\n",
      "         -1.4120e-03,  4.7974e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 2.7144e-03, -5.7506e-03, -7.9585e-03,  ..., -5.4297e-05,\n",
      "          2.0188e-04,  6.5423e-03],\n",
      "        [-7.6730e-03, -2.8502e-04,  1.5273e-04,  ...,  2.0406e-04,\n",
      "         -1.7322e-03,  4.4959e-03],\n",
      "        [-7.3840e-03, -2.0733e-02,  6.5208e-03,  ..., -2.3126e-04,\n",
      "          2.1774e-03, -4.5550e-02],\n",
      "        ...,\n",
      "        [ 1.2315e-02,  1.5034e-04, -2.5286e-04,  ..., -9.5529e-04,\n",
      "         -1.8131e-04, -2.8119e-03],\n",
      "        [-1.6160e-03,  1.9999e-04, -1.6559e-02,  ...,  2.4582e-05,\n",
      "          1.3932e-02, -2.5741e-02],\n",
      "        [ 1.2933e-02,  5.5017e-03, -3.9011e-02,  ..., -3.0804e-03,\n",
      "         -3.5379e-03,  4.3571e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-5.8765e+01, -1.0685e+01, -1.1219e+01,  ..., -3.6358e-05,\n",
      "         -2.0979e+01, -3.3071e+01],\n",
      "        [-3.5988e+00, -1.8950e+01, -1.0831e+01,  ..., -2.1495e+01,\n",
      "         -6.7162e+00, -7.2813e+00],\n",
      "        [-2.2230e+01, -1.5690e+01, -2.3337e-02,  ..., -1.3264e+01,\n",
      "         -6.9254e+00, -6.9745e+00],\n",
      "        ...,\n",
      "        [-6.2400e-01, -2.0447e+01, -1.1290e+01,  ..., -1.8961e+01,\n",
      "         -1.0472e+01, -8.8007e-01],\n",
      "        [-1.9179e-04, -3.5856e+01, -2.6418e+01,  ..., -3.6997e+01,\n",
      "         -1.9532e+01, -1.0277e+01],\n",
      "        [-2.9934e+01, -3.6511e+00, -8.2030e+00,  ..., -2.6684e-02,\n",
      "         -9.2527e+00, -2.0458e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0077 loss_train: 0.1964 acc_train: 0.9143 loss_val: 1.8979 acc_val: 0.6733 time: 0.6566s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 2.7144e-03, -5.7506e-03, -7.9585e-03,  ..., -5.4297e-05,\n",
      "          2.0188e-04,  6.5423e-03],\n",
      "        [-7.6730e-03, -2.8502e-04,  1.5273e-04,  ...,  2.0406e-04,\n",
      "         -1.7322e-03,  4.4959e-03],\n",
      "        [-7.3840e-03, -2.0733e-02,  6.5208e-03,  ..., -2.3126e-04,\n",
      "          2.1774e-03, -4.5550e-02],\n",
      "        ...,\n",
      "        [ 1.2315e-02,  1.5034e-04, -2.5286e-04,  ..., -9.5529e-04,\n",
      "         -1.8131e-04, -2.8119e-03],\n",
      "        [-1.6160e-03,  1.9999e-04, -1.6559e-02,  ...,  2.4582e-05,\n",
      "          1.3932e-02, -2.5741e-02],\n",
      "        [ 1.2933e-02,  5.5017e-03, -3.9011e-02,  ..., -3.0804e-03,\n",
      "         -3.5379e-03,  4.3571e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.1839e-03, -6.7616e-03, -1.5064e-02,  ...,  1.6038e-04,\n",
      "         -6.2679e-04,  6.0483e-03],\n",
      "        [-1.4080e-02,  1.3061e-04,  1.5015e-04,  ...,  2.7304e-04,\n",
      "         -1.6085e-03,  3.9436e-03],\n",
      "        [-1.0894e-02, -1.9764e-02,  4.3057e-03,  ..., -1.9618e-04,\n",
      "          2.3104e-03, -4.4056e-02],\n",
      "        ...,\n",
      "        [ 9.9844e-03, -4.1630e-05, -3.0051e-04,  ..., -2.5570e-04,\n",
      "         -2.3395e-04,  5.9279e-04],\n",
      "        [-1.4019e-03, -9.5203e-04, -1.9084e-02,  ...,  5.4212e-05,\n",
      "          1.4143e-02, -2.4662e-02],\n",
      "        [ 1.1563e-02,  4.0077e-03, -4.8654e-02,  ..., -3.2971e-03,\n",
      "         -7.9741e-03,  4.4609e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-6.7403e+01, -1.6054e+01, -7.7576e+00,  ..., -4.2763e-04,\n",
      "         -2.7296e+01, -3.0640e+01],\n",
      "        [-1.0139e+01, -1.6136e+01, -4.1391e+00,  ..., -1.6800e+01,\n",
      "         -5.9024e+00, -5.1457e+00],\n",
      "        [-3.7413e+01, -2.1127e+01, -1.0967e-05,  ..., -1.5248e+01,\n",
      "         -1.4983e+01, -1.1732e+01],\n",
      "        ...,\n",
      "        [-8.6702e+00, -1.9418e+01, -6.6058e+00,  ..., -1.5609e+01,\n",
      "         -1.1344e+01, -1.0240e-02],\n",
      "        [-2.7814e-02, -2.9152e+01, -1.7663e+01,  ..., -2.9183e+01,\n",
      "         -1.4850e+01, -4.3377e+00],\n",
      "        [-3.9886e+01, -8.9544e+00, -6.6431e+00,  ..., -1.4333e-03,\n",
      "         -1.6088e+01, -2.0053e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0078 loss_train: 0.2307 acc_train: 0.9286 loss_val: 1.8469 acc_val: 0.7167 time: 0.6173s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.1839e-03, -6.7616e-03, -1.5064e-02,  ...,  1.6038e-04,\n",
      "         -6.2679e-04,  6.0483e-03],\n",
      "        [-1.4080e-02,  1.3061e-04,  1.5015e-04,  ...,  2.7304e-04,\n",
      "         -1.6085e-03,  3.9436e-03],\n",
      "        [-1.0894e-02, -1.9764e-02,  4.3057e-03,  ..., -1.9618e-04,\n",
      "          2.3104e-03, -4.4056e-02],\n",
      "        ...,\n",
      "        [ 9.9844e-03, -4.1630e-05, -3.0051e-04,  ..., -2.5570e-04,\n",
      "         -2.3395e-04,  5.9279e-04],\n",
      "        [-1.4019e-03, -9.5203e-04, -1.9084e-02,  ...,  5.4212e-05,\n",
      "          1.4143e-02, -2.4662e-02],\n",
      "        [ 1.1563e-02,  4.0077e-03, -4.8654e-02,  ..., -3.2971e-03,\n",
      "         -7.9741e-03,  4.4609e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 3.6458e-05, -7.5578e-03, -2.0311e-02,  ...,  3.4496e-04,\n",
      "         -1.1327e-03,  5.5002e-03],\n",
      "        [-1.8750e-02,  5.0225e-04,  1.1518e-04,  ...,  2.8252e-04,\n",
      "         -1.4153e-03,  3.5102e-03],\n",
      "        [-1.3312e-02, -1.7999e-02,  2.5932e-03,  ..., -1.0868e-04,\n",
      "          2.5574e-03, -4.2544e-02],\n",
      "        ...,\n",
      "        [ 7.7875e-03, -2.0675e-04, -2.7633e-04,  ...,  4.1471e-04,\n",
      "         -2.6521e-04,  2.9045e-03],\n",
      "        [-8.9671e-04, -1.9791e-03, -2.0751e-02,  ...,  7.8664e-05,\n",
      "          1.4800e-02, -2.3949e-02],\n",
      "        [ 1.0916e-02,  2.6246e-03, -5.6515e-02,  ..., -3.3493e-03,\n",
      "         -9.8650e-03,  4.5311e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-7.4170e+01, -2.0689e+01, -1.1221e+01,  ..., -1.3351e-05,\n",
      "         -3.4764e+01, -3.2357e+01],\n",
      "        [-1.3596e+01, -1.2250e+01, -2.6524e-01,  ..., -1.1541e+01,\n",
      "         -4.8130e+00, -4.4266e+00],\n",
      "        [-4.4351e+01, -2.1106e+01, -7.0333e-06,  ..., -1.2034e+01,\n",
      "         -1.8728e+01, -1.3791e+01],\n",
      "        ...,\n",
      "        [-1.3300e+01, -1.6506e+01, -3.5841e+00,  ..., -1.0800e+01,\n",
      "         -1.1225e+01, -2.8993e-02],\n",
      "        [-4.0582e-01, -2.3594e+01, -1.2359e+01,  ..., -2.2639e+01,\n",
      "         -1.1736e+01, -1.2518e+00],\n",
      "        [-4.7677e+01, -1.3267e+01, -9.9148e+00,  ..., -5.1139e-05,\n",
      "         -2.3211e+01, -2.2657e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0079 loss_train: 0.0836 acc_train: 0.9643 loss_val: 2.3660 acc_val: 0.6833 time: 0.6014s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 3.6458e-05, -7.5578e-03, -2.0311e-02,  ...,  3.4496e-04,\n",
      "         -1.1327e-03,  5.5002e-03],\n",
      "        [-1.8750e-02,  5.0225e-04,  1.1518e-04,  ...,  2.8252e-04,\n",
      "         -1.4153e-03,  3.5102e-03],\n",
      "        [-1.3312e-02, -1.7999e-02,  2.5932e-03,  ..., -1.0868e-04,\n",
      "          2.5574e-03, -4.2544e-02],\n",
      "        ...,\n",
      "        [ 7.7875e-03, -2.0675e-04, -2.7633e-04,  ...,  4.1471e-04,\n",
      "         -2.6521e-04,  2.9045e-03],\n",
      "        [-8.9671e-04, -1.9791e-03, -2.0751e-02,  ...,  7.8664e-05,\n",
      "          1.4800e-02, -2.3949e-02],\n",
      "        [ 1.0916e-02,  2.6246e-03, -5.6515e-02,  ..., -3.3493e-03,\n",
      "         -9.8650e-03,  4.5311e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-9.5127e-04, -8.1444e-03, -2.4034e-02,  ...,  4.9071e-04,\n",
      "         -1.3510e-03,  3.6664e-03],\n",
      "        [-2.2311e-02,  8.1992e-04,  5.8294e-05,  ...,  2.3588e-04,\n",
      "         -1.1686e-03, -2.2694e-03],\n",
      "        [-1.4824e-02, -1.5593e-02,  9.6297e-04,  ...,  1.6446e-06,\n",
      "          2.7404e-03, -4.8214e-02],\n",
      "        ...,\n",
      "        [ 1.0835e-02, -3.1240e-04, -1.9212e-04,  ...,  9.6568e-04,\n",
      "         -2.6289e-04, -4.7915e-03],\n",
      "        [-5.7217e-04, -2.8749e-03, -2.1394e-02,  ...,  9.7321e-05,\n",
      "          1.7046e-02, -2.7994e-02],\n",
      "        [ 1.0259e-02,  1.3523e-03, -6.2958e-02,  ..., -3.2493e-03,\n",
      "         -7.4977e-03,  4.1895e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-5.0145e+01, -1.3592e+01, -1.2668e+01,  ..., -4.4107e-06,\n",
      "         -2.3677e+01, -2.5647e+01],\n",
      "        [-2.6444e-01, -1.6949e+01, -1.0701e+01,  ..., -1.8813e+01,\n",
      "         -6.6292e+00, -5.0428e+00],\n",
      "        [-1.6885e+01, -1.4490e+01, -6.3346e-02,  ..., -1.0786e+01,\n",
      "         -7.1174e+00, -3.0801e+00],\n",
      "        ...,\n",
      "        [-6.4238e-01, -1.7325e+01, -9.8712e+00,  ..., -1.5756e+01,\n",
      "         -9.2515e+00, -7.8539e-01],\n",
      "        [-2.7414e-04, -3.0837e+01, -2.2816e+01,  ..., -3.1723e+01,\n",
      "         -1.6933e+01, -8.7708e+00],\n",
      "        [-2.6058e+01, -6.4076e+00, -9.4699e+00,  ..., -1.7310e-03,\n",
      "         -1.2633e+01, -1.5935e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0080 loss_train: 0.4021 acc_train: 0.8571 loss_val: 1.3833 acc_val: 0.7233 time: 0.5777s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-9.5127e-04, -8.1444e-03, -2.4034e-02,  ...,  4.9071e-04,\n",
      "         -1.3510e-03,  3.6664e-03],\n",
      "        [-2.2311e-02,  8.1992e-04,  5.8294e-05,  ...,  2.3588e-04,\n",
      "         -1.1686e-03, -2.2694e-03],\n",
      "        [-1.4824e-02, -1.5593e-02,  9.6297e-04,  ...,  1.6446e-06,\n",
      "          2.7404e-03, -4.8214e-02],\n",
      "        ...,\n",
      "        [ 1.0835e-02, -3.1240e-04, -1.9212e-04,  ...,  9.6568e-04,\n",
      "         -2.6289e-04, -4.7915e-03],\n",
      "        [-5.7217e-04, -2.8749e-03, -2.1394e-02,  ...,  9.7321e-05,\n",
      "          1.7046e-02, -2.7994e-02],\n",
      "        [ 1.0259e-02,  1.3523e-03, -6.2958e-02,  ..., -3.2493e-03,\n",
      "         -7.4977e-03,  4.1895e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-1.8280e-03, -8.5299e-03, -2.6195e-02,  ...,  5.9201e-04,\n",
      "         -1.6816e-03,  2.5095e-03],\n",
      "        [-2.4970e-02,  1.0765e-03, -6.0654e-06,  ...,  1.4724e-04,\n",
      "         -8.8541e-04, -5.2650e-03],\n",
      "        [-1.6085e-02, -1.2713e-02, -5.4323e-04,  ...,  1.0110e-04,\n",
      "          2.8623e-03, -5.0799e-02],\n",
      "        ...,\n",
      "        [ 1.2851e-02, -3.4128e-04, -7.2233e-05,  ...,  1.3237e-03,\n",
      "         -2.4281e-04, -1.1620e-02],\n",
      "        [-7.4114e-05, -3.6357e-03, -2.1196e-02,  ...,  1.0987e-04,\n",
      "          1.8404e-02, -3.0500e-02],\n",
      "        [ 9.7553e-03,  1.8966e-04, -6.8061e-02,  ..., -3.0149e-03,\n",
      "         -6.9550e-03,  4.0537e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.3295e+01, -9.7821e+00, -1.3284e+01,  ..., -5.8172e-05,\n",
      "         -1.8605e+01, -2.6084e+01],\n",
      "        [-7.0183e-01, -1.4098e+01, -1.0097e+01,  ..., -1.7192e+01,\n",
      "         -4.1057e+00, -6.9224e+00],\n",
      "        [-1.4077e+01, -1.0598e+01, -2.3533e-01,  ..., -9.6236e+00,\n",
      "         -3.1561e+00, -5.4690e+00],\n",
      "        ...,\n",
      "        [-7.1423e-02, -1.6478e+01, -1.1015e+01,  ..., -1.6218e+01,\n",
      "         -8.7366e+00, -3.0102e+00],\n",
      "        [-5.6191e-04, -2.8329e+01, -2.1265e+01,  ..., -2.9651e+01,\n",
      "         -1.4999e+01, -8.8276e+00],\n",
      "        [-2.1309e+01, -2.8946e+00, -9.3345e+00,  ..., -5.7253e-02,\n",
      "         -8.3532e+00, -1.6667e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0081 loss_train: 0.2901 acc_train: 0.9286 loss_val: 1.7645 acc_val: 0.6067 time: 0.6252s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-1.8280e-03, -8.5299e-03, -2.6195e-02,  ...,  5.9201e-04,\n",
      "         -1.6816e-03,  2.5095e-03],\n",
      "        [-2.4970e-02,  1.0765e-03, -6.0654e-06,  ...,  1.4724e-04,\n",
      "         -8.8541e-04, -5.2650e-03],\n",
      "        [-1.6085e-02, -1.2713e-02, -5.4323e-04,  ...,  1.0110e-04,\n",
      "          2.8623e-03, -5.0799e-02],\n",
      "        ...,\n",
      "        [ 1.2851e-02, -3.4128e-04, -7.2233e-05,  ...,  1.3237e-03,\n",
      "         -2.4281e-04, -1.1620e-02],\n",
      "        [-7.4114e-05, -3.6357e-03, -2.1196e-02,  ...,  1.0987e-04,\n",
      "          1.8404e-02, -3.0500e-02],\n",
      "        [ 9.7553e-03,  1.8966e-04, -6.8061e-02,  ..., -3.0149e-03,\n",
      "         -6.9550e-03,  4.0537e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-2.2684e-03, -8.7252e-03, -2.6852e-02,  ...,  6.4646e-04,\n",
      "         -2.4024e-03,  2.8869e-03],\n",
      "        [-2.6753e-02,  1.2677e-03, -6.3013e-05,  ...,  3.7814e-05,\n",
      "         -5.8344e-04, -3.3128e-03],\n",
      "        [-1.7036e-02, -9.5312e-03, -1.8907e-03,  ...,  1.6191e-04,\n",
      "          2.9264e-03, -5.0758e-02],\n",
      "        ...,\n",
      "        [ 1.3872e-02, -2.9400e-04,  5.2848e-05,  ...,  1.4534e-03,\n",
      "         -2.0790e-04, -1.7146e-02],\n",
      "        [ 2.3173e-03, -4.2603e-03, -2.0244e-02,  ...,  1.1630e-04,\n",
      "          1.6770e-02, -3.0652e-02],\n",
      "        [ 1.0298e-02, -8.6481e-04, -7.1889e-02,  ..., -2.6683e-03,\n",
      "         -1.1129e-02,  4.3506e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-5.2532e+01, -1.8859e+01, -1.5691e+01,  ..., -1.1921e-07,\n",
      "         -2.7816e+01, -2.5202e+01],\n",
      "        [-5.5813e+00, -9.6325e+00, -5.7480e+00,  ..., -1.2362e+01,\n",
      "         -1.9944e+00, -7.6476e+00],\n",
      "        [-2.8978e+01, -1.3332e+01, -1.1788e-03,  ..., -6.8570e+00,\n",
      "         -9.8860e+00, -9.6831e+00],\n",
      "        ...,\n",
      "        [-4.9554e+00, -1.2210e+01, -5.1448e+00,  ..., -9.1797e+00,\n",
      "         -7.3825e+00, -3.1030e-02],\n",
      "        [-1.4834e-02, -2.1671e+01, -1.5143e+01,  ..., -2.2469e+01,\n",
      "         -1.1046e+01, -5.5729e+00],\n",
      "        [-3.0220e+01, -1.0479e+01, -1.2110e+01,  ..., -3.3616e-05,\n",
      "         -1.6739e+01, -1.7091e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0082 loss_train: 0.4123 acc_train: 0.8000 loss_val: 1.2422 acc_val: 0.7767 time: 0.5678s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-2.2684e-03, -8.7252e-03, -2.6852e-02,  ...,  6.4646e-04,\n",
      "         -2.4024e-03,  2.8869e-03],\n",
      "        [-2.6753e-02,  1.2677e-03, -6.3013e-05,  ...,  3.7814e-05,\n",
      "         -5.8344e-04, -3.3128e-03],\n",
      "        [-1.7036e-02, -9.5312e-03, -1.8907e-03,  ...,  1.6191e-04,\n",
      "          2.9264e-03, -5.0758e-02],\n",
      "        ...,\n",
      "        [ 1.3872e-02, -2.9400e-04,  5.2848e-05,  ...,  1.4534e-03,\n",
      "         -2.0790e-04, -1.7146e-02],\n",
      "        [ 2.3173e-03, -4.2603e-03, -2.0244e-02,  ...,  1.1630e-04,\n",
      "          1.6770e-02, -3.0652e-02],\n",
      "        [ 1.0298e-02, -8.6481e-04, -7.1889e-02,  ..., -2.6683e-03,\n",
      "         -1.1129e-02,  4.3506e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-2.6790e-03, -8.7439e-03, -2.6133e-02,  ...,  6.5479e-04,\n",
      "         -3.0769e-03,  3.1727e-03],\n",
      "        [-2.7805e-02,  1.3920e-03, -1.0054e-04,  ..., -6.8822e-05,\n",
      "         -2.7979e-04, -1.6291e-03],\n",
      "        [-1.7832e-02, -6.2165e-03, -3.0523e-03,  ...,  1.6981e-04,\n",
      "          2.9369e-03, -5.0913e-02],\n",
      "        ...,\n",
      "        [ 1.4244e-02, -1.8752e-04,  1.5398e-04,  ...,  1.3561e-03,\n",
      "         -1.6187e-04, -2.2273e-02],\n",
      "        [ 4.3384e-03, -4.7499e-03, -1.8645e-02,  ...,  1.1686e-04,\n",
      "          1.4501e-02, -3.1022e-02],\n",
      "        [ 1.0704e-02, -1.8133e-03, -7.4522e-02,  ..., -2.2348e-03,\n",
      "         -1.5369e-02,  4.6103e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-5.7400e+01, -2.5742e+01, -1.5708e+01,  ..., -1.1921e-07,\n",
      "         -3.3851e+01, -2.1948e+01],\n",
      "        [-8.4845e+00, -8.7696e+00, -2.6048e+00,  ..., -9.7698e+00,\n",
      "         -2.4031e+00, -6.0294e+00],\n",
      "        [-3.7181e+01, -1.6556e+01, -9.6930e-03,  ..., -4.6454e+00,\n",
      "         -1.5145e+01, -1.0114e+01],\n",
      "        ...,\n",
      "        [-1.1845e+01, -1.2451e+01, -3.1060e+00,  ..., -5.8728e+00,\n",
      "         -9.3829e+00, -4.9432e-02],\n",
      "        [-2.1223e-01, -1.7567e+01, -1.0541e+01,  ..., -1.7564e+01,\n",
      "         -8.6893e+00, -2.5953e+00],\n",
      "        [-3.4901e+01, -1.6405e+01, -1.2403e+01,  ..., -4.6492e-06,\n",
      "         -2.2240e+01, -1.4683e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0083 loss_train: 0.1098 acc_train: 0.9643 loss_val: 1.5256 acc_val: 0.7567 time: 0.6084s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-2.6790e-03, -8.7439e-03, -2.6133e-02,  ...,  6.5479e-04,\n",
      "         -3.0769e-03,  3.1727e-03],\n",
      "        [-2.7805e-02,  1.3920e-03, -1.0054e-04,  ..., -6.8822e-05,\n",
      "         -2.7979e-04, -1.6291e-03],\n",
      "        [-1.7832e-02, -6.2165e-03, -3.0523e-03,  ...,  1.6981e-04,\n",
      "          2.9369e-03, -5.0913e-02],\n",
      "        ...,\n",
      "        [ 1.4244e-02, -1.8752e-04,  1.5398e-04,  ...,  1.3561e-03,\n",
      "         -1.6187e-04, -2.2273e-02],\n",
      "        [ 4.3384e-03, -4.7499e-03, -1.8645e-02,  ...,  1.1686e-04,\n",
      "          1.4501e-02, -3.1022e-02],\n",
      "        [ 1.0704e-02, -1.8133e-03, -7.4522e-02,  ..., -2.2348e-03,\n",
      "         -1.5369e-02,  4.6103e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-3.5467e-03, -8.6012e-03, -2.4222e-02,  ...,  6.2056e-04,\n",
      "         -3.5206e-03,  2.5441e-03],\n",
      "        [-2.7990e-02,  1.4506e-03, -1.1196e-04,  ..., -1.5160e-04,\n",
      "          9.7565e-06, -1.3859e-03],\n",
      "        [-1.8040e-02, -2.9299e-03, -4.0089e-03,  ...,  1.2720e-04,\n",
      "          2.8985e-03, -5.3734e-02],\n",
      "        ...,\n",
      "        [ 1.3616e-02, -5.0230e-05,  2.0996e-04,  ...,  1.0664e-03,\n",
      "         -1.0891e-04, -2.7401e-02],\n",
      "        [ 3.9361e-03, -5.1081e-03, -1.6517e-02,  ...,  1.1204e-04,\n",
      "          1.3110e-02, -3.4074e-02],\n",
      "        [ 9.6285e-03, -2.6584e-03, -7.6043e-02,  ..., -1.7415e-03,\n",
      "         -1.8292e-02,  4.6508e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-5.0759e+01, -2.3318e+01, -9.6836e+00,  ..., -6.2583e-05,\n",
      "         -2.8813e+01, -1.5406e+01],\n",
      "        [-9.1493e+00, -1.0474e+01, -2.4604e+00,  ..., -1.0969e+01,\n",
      "         -3.6528e+00, -5.3917e+00],\n",
      "        [-3.8692e+01, -1.9421e+01, -3.8521e-04,  ..., -7.9581e+00,\n",
      "         -1.6755e+01, -1.0252e+01],\n",
      "        ...,\n",
      "        [-1.3269e+01, -1.3676e+01, -2.6364e+00,  ..., -7.1959e+00,\n",
      "         -1.0073e+01, -7.5740e-02],\n",
      "        [-6.7992e-01, -1.7350e+01, -9.2128e+00,  ..., -1.7134e+01,\n",
      "         -8.3586e+00, -1.7354e+00],\n",
      "        [-2.9380e+01, -1.4489e+01, -7.9607e+00,  ..., -4.1822e-04,\n",
      "         -1.8323e+01, -9.5848e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0084 loss_train: 0.2624 acc_train: 0.9214 loss_val: 1.4366 acc_val: 0.7367 time: 0.6050s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-3.5467e-03, -8.6012e-03, -2.4222e-02,  ...,  6.2056e-04,\n",
      "         -3.5206e-03,  2.5441e-03],\n",
      "        [-2.7990e-02,  1.4506e-03, -1.1196e-04,  ..., -1.5160e-04,\n",
      "          9.7565e-06, -1.3859e-03],\n",
      "        [-1.8040e-02, -2.9299e-03, -4.0089e-03,  ...,  1.2720e-04,\n",
      "          2.8985e-03, -5.3734e-02],\n",
      "        ...,\n",
      "        [ 1.3616e-02, -5.0230e-05,  2.0996e-04,  ...,  1.0664e-03,\n",
      "         -1.0891e-04, -2.7401e-02],\n",
      "        [ 3.9361e-03, -5.1081e-03, -1.6517e-02,  ...,  1.1204e-04,\n",
      "          1.3110e-02, -3.4074e-02],\n",
      "        [ 9.6285e-03, -2.6584e-03, -7.6043e-02,  ..., -1.7415e-03,\n",
      "         -1.8292e-02,  4.6508e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-4.3506e-03, -8.3142e-03, -2.1334e-02,  ...,  5.4973e-04,\n",
      "         -3.8215e-03,  7.3255e-04],\n",
      "        [-2.7440e-02,  1.4471e-03, -9.7026e-05,  ..., -1.9598e-04,\n",
      "          2.7145e-04, -2.3389e-03],\n",
      "        [-1.7929e-02,  1.8165e-04, -4.7490e-03,  ...,  5.1091e-05,\n",
      "          2.8160e-03, -5.8141e-02],\n",
      "        ...,\n",
      "        [ 1.2404e-02,  8.5102e-05,  2.1179e-04,  ...,  8.9728e-04,\n",
      "         -5.3311e-05, -3.2668e-02],\n",
      "        [ 2.9278e-03, -5.3401e-03, -1.3985e-02,  ...,  1.0254e-04,\n",
      "          1.2026e-02, -3.8528e-02],\n",
      "        [ 8.3306e-03, -3.4034e-03, -7.6544e-02,  ..., -1.2158e-03,\n",
      "         -2.0121e-02,  4.5781e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.1948e+01, -1.8822e+01, -4.8416e+00,  ..., -7.9554e-03,\n",
      "         -2.2442e+01, -1.0441e+01],\n",
      "        [-7.6182e+00, -1.1832e+01, -4.0849e+00,  ..., -1.2899e+01,\n",
      "         -4.4073e+00, -5.7903e+00],\n",
      "        [-3.5606e+01, -1.9632e+01, -1.0120e-04,  ..., -1.0323e+01,\n",
      "         -1.5890e+01, -9.5975e+00],\n",
      "        ...,\n",
      "        [-1.1511e+01, -1.3985e+01, -3.0490e+00,  ..., -8.8152e+00,\n",
      "         -9.7283e+00, -5.0521e-02],\n",
      "        [-3.4884e-01, -1.8319e+01, -1.0312e+01,  ..., -1.8469e+01,\n",
      "         -8.9100e+00, -2.5660e+00],\n",
      "        [-2.1871e+01, -1.0775e+01, -4.4392e+00,  ..., -1.5145e-02,\n",
      "         -1.3097e+01, -5.7438e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0085 loss_train: 0.1853 acc_train: 0.9643 loss_val: 1.4149 acc_val: 0.6967 time: 0.7325s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-4.3506e-03, -8.3142e-03, -2.1334e-02,  ...,  5.4973e-04,\n",
      "         -3.8215e-03,  7.3255e-04],\n",
      "        [-2.7440e-02,  1.4471e-03, -9.7026e-05,  ..., -1.9598e-04,\n",
      "          2.7145e-04, -2.3389e-03],\n",
      "        [-1.7929e-02,  1.8165e-04, -4.7490e-03,  ...,  5.1091e-05,\n",
      "          2.8160e-03, -5.8141e-02],\n",
      "        ...,\n",
      "        [ 1.2404e-02,  8.5102e-05,  2.1179e-04,  ...,  8.9728e-04,\n",
      "         -5.3311e-05, -3.2668e-02],\n",
      "        [ 2.9278e-03, -5.3401e-03, -1.3985e-02,  ...,  1.0254e-04,\n",
      "          1.2026e-02, -3.8528e-02],\n",
      "        [ 8.3306e-03, -3.4034e-03, -7.6544e-02,  ..., -1.2158e-03,\n",
      "         -2.0121e-02,  4.5781e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-5.0123e-03, -7.9008e-03, -1.7704e-02,  ...,  4.5010e-04,\n",
      "         -4.0010e-03, -5.8484e-04],\n",
      "        [-2.6239e-02,  1.3872e-03, -6.1468e-05,  ..., -1.9641e-04,\n",
      "          4.9411e-04, -3.1906e-03],\n",
      "        [-1.7505e-02,  2.9907e-03, -5.2689e-03,  ..., -3.2978e-05,\n",
      "          2.6947e-03, -6.2152e-02],\n",
      "        ...,\n",
      "        [ 1.0580e-02,  1.8887e-04,  1.6386e-04,  ...,  6.3449e-04,\n",
      "          7.9676e-07, -3.7445e-02],\n",
      "        [ 1.9502e-03, -5.4532e-03, -1.1180e-02,  ...,  8.9216e-05,\n",
      "          1.1299e-02, -4.2007e-02],\n",
      "        [ 7.4254e-03, -4.0518e-03, -7.6117e-02,  ..., -6.8430e-04,\n",
      "         -2.1241e-02,  4.4770e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.7098e+01, -1.5648e+01, -4.8945e+00,  ..., -7.5498e-03,\n",
      "         -1.9537e+01, -1.0305e+01],\n",
      "        [-6.2844e+00, -1.0328e+01, -4.6263e+00,  ..., -1.2312e+01,\n",
      "         -3.2873e+00, -6.7520e+00],\n",
      "        [-3.2431e+01, -1.7239e+01, -1.6104e-04,  ..., -9.4119e+00,\n",
      "         -1.4012e+01, -9.4627e+00],\n",
      "        ...,\n",
      "        [-9.2725e+00, -1.2374e+01, -3.2198e+00,  ..., -8.0724e+00,\n",
      "         -8.5511e+00, -4.4627e-02],\n",
      "        [-1.1270e-01, -1.7943e+01, -1.1013e+01,  ..., -1.8352e+01,\n",
      "         -8.9040e+00, -3.5229e+00],\n",
      "        [-1.8276e+01, -8.1319e+00, -4.4004e+00,  ..., -1.5222e-02,\n",
      "         -1.0613e+01, -5.9855e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0086 loss_train: 0.2161 acc_train: 0.9357 loss_val: 1.2246 acc_val: 0.7500 time: 0.5753s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-5.0123e-03, -7.9008e-03, -1.7704e-02,  ...,  4.5010e-04,\n",
      "         -4.0010e-03, -5.8484e-04],\n",
      "        [-2.6239e-02,  1.3872e-03, -6.1468e-05,  ..., -1.9641e-04,\n",
      "          4.9411e-04, -3.1906e-03],\n",
      "        [-1.7505e-02,  2.9907e-03, -5.2689e-03,  ..., -3.2978e-05,\n",
      "          2.6947e-03, -6.2152e-02],\n",
      "        ...,\n",
      "        [ 1.0580e-02,  1.8887e-04,  1.6386e-04,  ...,  6.3449e-04,\n",
      "          7.9676e-07, -3.7445e-02],\n",
      "        [ 1.9502e-03, -5.4532e-03, -1.1180e-02,  ...,  8.9216e-05,\n",
      "          1.1299e-02, -4.2007e-02],\n",
      "        [ 7.4254e-03, -4.0518e-03, -7.6117e-02,  ..., -6.8430e-04,\n",
      "         -2.1241e-02,  4.4770e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-5.5236e-03, -7.3799e-03, -1.3575e-02,  ...,  3.3065e-04,\n",
      "         -4.0578e-03, -1.5352e-03],\n",
      "        [-2.4476e-02,  1.2782e-03, -1.5227e-05,  ..., -1.5671e-04,\n",
      "          6.6953e-04, -3.8172e-03],\n",
      "        [-1.6790e-02,  5.3935e-03, -5.5720e-03,  ..., -9.9251e-05,\n",
      "          2.5400e-03, -6.5605e-02],\n",
      "        ...,\n",
      "        [ 8.3064e-03,  2.4092e-04,  8.1885e-05,  ...,  3.0052e-04,\n",
      "          4.9731e-05, -4.1571e-02],\n",
      "        [ 1.0711e-03, -5.4559e-03, -8.2259e-03,  ...,  7.3012e-05,\n",
      "          1.0707e-02, -4.4960e-02],\n",
      "        [ 6.8724e-03, -4.6075e-03, -7.4859e-02,  ..., -1.7163e-04,\n",
      "         -2.1814e-02,  4.3732e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.4369e+01, -1.3092e+01, -6.7896e+00,  ..., -1.1333e-03,\n",
      "         -1.8251e+01, -1.2149e+01],\n",
      "        [-5.6416e+00, -8.0250e+00, -4.6055e+00,  ..., -1.0884e+01,\n",
      "         -1.7159e+00, -7.8149e+00],\n",
      "        [-2.9637e+01, -1.4118e+01, -6.8617e-04,  ..., -7.4078e+00,\n",
      "         -1.1919e+01, -9.5632e+00],\n",
      "        ...,\n",
      "        [-7.1421e+00, -1.0429e+01, -3.3380e+00,  ..., -6.8043e+00,\n",
      "         -7.2653e+00, -4.4276e-02],\n",
      "        [-5.8006e-02, -1.6962e+01, -1.0985e+01,  ..., -1.7488e+01,\n",
      "         -8.4726e+00, -4.0621e+00],\n",
      "        [-1.6970e+01, -5.8823e+00, -5.6068e+00,  ..., -6.8973e-03,\n",
      "         -9.3420e+00, -8.0363e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0087 loss_train: 0.0964 acc_train: 0.9929 loss_val: 1.2283 acc_val: 0.7500 time: 0.5729s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-5.5236e-03, -7.3799e-03, -1.3575e-02,  ...,  3.3065e-04,\n",
      "         -4.0578e-03, -1.5352e-03],\n",
      "        [-2.4476e-02,  1.2782e-03, -1.5227e-05,  ..., -1.5671e-04,\n",
      "          6.6953e-04, -3.8172e-03],\n",
      "        [-1.6790e-02,  5.3935e-03, -5.5720e-03,  ..., -9.9251e-05,\n",
      "          2.5400e-03, -6.5605e-02],\n",
      "        ...,\n",
      "        [ 8.3064e-03,  2.4092e-04,  8.1885e-05,  ...,  3.0052e-04,\n",
      "          4.9731e-05, -4.1571e-02],\n",
      "        [ 1.0711e-03, -5.4559e-03, -8.2259e-03,  ...,  7.3012e-05,\n",
      "          1.0707e-02, -4.4960e-02],\n",
      "        [ 6.8724e-03, -4.6075e-03, -7.4859e-02,  ..., -1.7163e-04,\n",
      "         -2.1814e-02,  4.3732e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-5.9394e-03, -6.7704e-03, -9.1869e-03,  ...,  2.0089e-04,\n",
      "         -4.0795e-03, -2.4006e-03],\n",
      "        [-2.2251e-02,  1.1287e-03,  3.0137e-05,  ..., -8.8588e-05,\n",
      "          7.9267e-04, -4.3231e-03],\n",
      "        [-1.5841e-02,  7.3139e-03, -5.6681e-03,  ..., -1.2945e-04,\n",
      "          2.3575e-03, -6.8706e-02],\n",
      "        ...,\n",
      "        [ 5.7575e-03,  2.3426e-04, -1.1735e-05,  ..., -1.0863e-04,\n",
      "          8.8851e-05, -4.5069e-02],\n",
      "        [ 2.8310e-04, -5.3580e-03, -5.2457e-03,  ...,  5.4935e-05,\n",
      "          1.0133e-02, -4.7560e-02],\n",
      "        [ 6.4974e-03, -5.0746e-03, -7.2864e-02,  ...,  3.0045e-04,\n",
      "         -2.2512e-02,  4.3102e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.2428e+01, -1.2343e+01, -8.3426e+00,  ..., -2.4649e-04,\n",
      "         -1.8464e+01, -1.2455e+01],\n",
      "        [-4.1825e+00, -7.3550e+00, -4.7540e+00,  ..., -1.0236e+01,\n",
      "         -1.3559e+00, -7.3724e+00],\n",
      "        [-2.6748e+01, -1.2105e+01, -3.4527e-03,  ..., -5.7349e+00,\n",
      "         -1.0627e+01, -8.6127e+00],\n",
      "        ...,\n",
      "        [-5.8676e+00, -9.6407e+00, -3.7326e+00,  ..., -6.2720e+00,\n",
      "         -6.7526e+00, -3.5982e-02],\n",
      "        [-3.1307e-02, -1.7079e+01, -1.1323e+01,  ..., -1.7445e+01,\n",
      "         -8.7716e+00, -4.3027e+00],\n",
      "        [-1.5935e+01, -5.1646e+00, -6.4035e+00,  ..., -7.7125e-03,\n",
      "         -9.2863e+00, -8.4334e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0088 loss_train: 0.0910 acc_train: 0.9786 loss_val: 1.2270 acc_val: 0.7367 time: 0.5599s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-5.9394e-03, -6.7704e-03, -9.1869e-03,  ...,  2.0089e-04,\n",
      "         -4.0795e-03, -2.4006e-03],\n",
      "        [-2.2251e-02,  1.1287e-03,  3.0137e-05,  ..., -8.8588e-05,\n",
      "          7.9267e-04, -4.3231e-03],\n",
      "        [-1.5841e-02,  7.3139e-03, -5.6681e-03,  ..., -1.2945e-04,\n",
      "          2.3575e-03, -6.8706e-02],\n",
      "        ...,\n",
      "        [ 5.7575e-03,  2.3426e-04, -1.1735e-05,  ..., -1.0863e-04,\n",
      "          8.8851e-05, -4.5069e-02],\n",
      "        [ 2.8310e-04, -5.3580e-03, -5.2457e-03,  ...,  5.4935e-05,\n",
      "          1.0133e-02, -4.7560e-02],\n",
      "        [ 6.4974e-03, -5.0746e-03, -7.2864e-02,  ...,  3.0045e-04,\n",
      "         -2.2512e-02,  4.3102e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-6.2720e-03, -6.0914e-03, -4.7703e-03,  ...,  7.0212e-05,\n",
      "         -4.0801e-03, -3.1710e-03],\n",
      "        [-1.9661e-02,  9.4835e-04,  6.4237e-05,  ..., -8.6241e-06,\n",
      "          8.6165e-04, -4.7290e-03],\n",
      "        [-1.4740e-02,  8.7045e-03, -5.5727e-03,  ..., -1.1769e-04,\n",
      "          2.1525e-03, -7.1436e-02],\n",
      "        ...,\n",
      "        [ 3.1078e-03,  1.7564e-04, -9.3692e-05,  ..., -4.6239e-04,\n",
      "          1.1788e-04, -4.7999e-02],\n",
      "        [-4.2860e-04, -5.1703e-03, -2.3510e-03,  ...,  3.5992e-05,\n",
      "          9.6824e-03, -4.9852e-02],\n",
      "        [ 6.1719e-03, -5.4578e-03, -7.0226e-02,  ...,  7.1387e-04,\n",
      "         -2.3260e-02,  4.2688e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.0675e+01, -1.2719e+01, -9.2531e+00,  ..., -1.0859e-04,\n",
      "         -1.9155e+01, -1.1531e+01],\n",
      "        [-1.9541e+00, -8.3529e+00, -5.1972e+00,  ..., -1.0589e+01,\n",
      "         -2.0400e+00, -5.8017e+00],\n",
      "        [-2.4029e+01, -1.1346e+01, -9.2147e-03,  ..., -4.8002e+00,\n",
      "         -1.0057e+01, -7.0345e+00],\n",
      "        ...,\n",
      "        [-5.2936e+00, -1.0037e+01, -4.4043e+00,  ..., -6.5815e+00,\n",
      "         -7.0122e+00, -2.3656e-02],\n",
      "        [-1.6590e-02, -1.8405e+01, -1.2264e+01,  ..., -1.8478e+01,\n",
      "         -9.7843e+00, -4.5856e+00],\n",
      "        [-1.4707e+01, -5.5727e+00, -6.6714e+00,  ..., -5.7684e-03,\n",
      "         -9.7334e+00, -7.3803e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0089 loss_train: 0.0931 acc_train: 0.9857 loss_val: 1.0739 acc_val: 0.7400 time: 0.6380s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-6.2720e-03, -6.0914e-03, -4.7703e-03,  ...,  7.0212e-05,\n",
      "         -4.0801e-03, -3.1710e-03],\n",
      "        [-1.9661e-02,  9.4835e-04,  6.4237e-05,  ..., -8.6241e-06,\n",
      "          8.6165e-04, -4.7290e-03],\n",
      "        [-1.4740e-02,  8.7045e-03, -5.5727e-03,  ..., -1.1769e-04,\n",
      "          2.1525e-03, -7.1436e-02],\n",
      "        ...,\n",
      "        [ 3.1078e-03,  1.7564e-04, -9.3692e-05,  ..., -4.6239e-04,\n",
      "          1.1788e-04, -4.7999e-02],\n",
      "        [-4.2860e-04, -5.1703e-03, -2.3510e-03,  ...,  3.5992e-05,\n",
      "          9.6824e-03, -4.9852e-02],\n",
      "        [ 6.1719e-03, -5.4578e-03, -7.0226e-02,  ...,  7.1387e-04,\n",
      "         -2.3260e-02,  4.2688e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-6.5095e-03, -5.3617e-03, -5.3925e-04,  ..., -5.2728e-05,\n",
      "         -4.0640e-03, -3.8112e-03],\n",
      "        [-1.6807e-02,  7.4696e-04,  8.0167e-05,  ...,  6.5554e-05,\n",
      "          8.7763e-04, -5.1128e-03],\n",
      "        [-1.3523e-02,  9.5476e-03, -5.3060e-03,  ..., -7.1294e-05,\n",
      "          1.9304e-03, -7.3713e-02],\n",
      "        ...,\n",
      "        [ 5.2307e-04,  8.2918e-05, -1.4543e-04,  ..., -7.1140e-04,\n",
      "          1.3564e-04, -5.0404e-02],\n",
      "        [-8.2889e-04, -4.9042e-03,  3.5817e-04,  ...,  1.7144e-05,\n",
      "          9.1122e-03, -5.1754e-02],\n",
      "        [ 5.9321e-03, -5.7616e-03, -6.7037e-02,  ...,  1.0548e-03,\n",
      "         -2.4033e-02,  4.2603e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.1330e+01, -1.4350e+01, -1.0073e+01,  ..., -5.8649e-05,\n",
      "         -2.1008e+01, -1.1050e+01],\n",
      "        [-1.5722e+00, -8.8956e+00, -5.3177e+00,  ..., -1.0920e+01,\n",
      "         -2.3559e+00, -5.6075e+00],\n",
      "        [-2.3890e+01, -1.1480e+01, -1.2915e-02,  ..., -4.4546e+00,\n",
      "         -1.0303e+01, -6.7624e+00],\n",
      "        ...,\n",
      "        [-5.5711e+00, -1.0384e+01, -4.5887e+00,  ..., -6.5574e+00,\n",
      "         -7.3528e+00, -1.8646e-02],\n",
      "        [-1.2660e-02, -1.9066e+01, -1.2607e+01,  ..., -1.8981e+01,\n",
      "         -1.0217e+01, -4.7900e+00],\n",
      "        [-1.5260e+01, -6.6481e+00, -7.1459e+00,  ..., -2.9540e-03,\n",
      "         -1.0980e+01, -7.0737e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0090 loss_train: 0.1033 acc_train: 0.9643 loss_val: 1.0166 acc_val: 0.7567 time: 0.6107s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-6.5095e-03, -5.3617e-03, -5.3925e-04,  ..., -5.2728e-05,\n",
      "         -4.0640e-03, -3.8112e-03],\n",
      "        [-1.6807e-02,  7.4696e-04,  8.0167e-05,  ...,  6.5554e-05,\n",
      "          8.7763e-04, -5.1128e-03],\n",
      "        [-1.3523e-02,  9.5476e-03, -5.3060e-03,  ..., -7.1294e-05,\n",
      "          1.9304e-03, -7.3713e-02],\n",
      "        ...,\n",
      "        [ 5.2307e-04,  8.2918e-05, -1.4543e-04,  ..., -7.1140e-04,\n",
      "          1.3564e-04, -5.0404e-02],\n",
      "        [-8.2889e-04, -4.9042e-03,  3.5817e-04,  ...,  1.7144e-05,\n",
      "          9.1122e-03, -5.1754e-02],\n",
      "        [ 5.9321e-03, -5.7616e-03, -6.7037e-02,  ...,  1.0548e-03,\n",
      "         -2.4033e-02,  4.2603e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-6.6874e-03, -4.5993e-03,  3.3173e-03,  ..., -1.6051e-04,\n",
      "         -4.0667e-03, -4.3517e-03],\n",
      "        [-1.3784e-02,  5.3449e-04,  7.5836e-05,  ...,  1.1900e-04,\n",
      "          8.4450e-04, -5.7700e-03],\n",
      "        [-1.2220e-02,  9.8531e-03, -4.8920e-03,  ..., -7.5150e-06,\n",
      "          1.6965e-03, -7.5711e-02],\n",
      "        ...,\n",
      "        [-1.8482e-03, -1.9848e-05, -1.5720e-04,  ..., -8.4832e-04,\n",
      "          1.4186e-04, -5.2299e-02],\n",
      "        [-1.1878e-03, -4.5716e-03,  2.7969e-03,  ..., -7.3085e-07,\n",
      "          8.7255e-03, -5.3407e-02],\n",
      "        [ 5.6744e-03, -5.9909e-03, -6.3385e-02,  ...,  1.3137e-03,\n",
      "         -2.4870e-02,  4.2582e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.2636e+01, -1.5533e+01, -1.0452e+01,  ..., -4.1722e-05,\n",
      "         -2.2375e+01, -1.1279e+01],\n",
      "        [-2.5146e+00, -8.7584e+00, -5.1220e+00,  ..., -1.1073e+01,\n",
      "         -2.0301e+00, -6.5649e+00],\n",
      "        [-2.4943e+01, -1.1977e+01, -7.7748e-03,  ..., -4.9308e+00,\n",
      "         -1.0650e+01, -7.6233e+00],\n",
      "        ...,\n",
      "        [-5.8710e+00, -1.0374e+01, -4.3676e+00,  ..., -6.3564e+00,\n",
      "         -7.3926e+00, -2.0252e-02],\n",
      "        [-1.1731e-02, -1.9199e+01, -1.2544e+01,  ..., -1.9113e+01,\n",
      "         -1.0176e+01, -4.9624e+00],\n",
      "        [-1.6313e+01, -7.2337e+00, -7.5143e+00,  ..., -1.7832e-03,\n",
      "         -1.1840e+01, -7.5874e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0091 loss_train: 0.1110 acc_train: 0.9571 loss_val: 1.0369 acc_val: 0.7567 time: 0.6221s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-6.6874e-03, -4.5993e-03,  3.3173e-03,  ..., -1.6051e-04,\n",
      "         -4.0667e-03, -4.3517e-03],\n",
      "        [-1.3784e-02,  5.3449e-04,  7.5836e-05,  ...,  1.1900e-04,\n",
      "          8.4450e-04, -5.7700e-03],\n",
      "        [-1.2220e-02,  9.8531e-03, -4.8920e-03,  ..., -7.5150e-06,\n",
      "          1.6965e-03, -7.5711e-02],\n",
      "        ...,\n",
      "        [-1.8482e-03, -1.9848e-05, -1.5720e-04,  ..., -8.4832e-04,\n",
      "          1.4186e-04, -5.2299e-02],\n",
      "        [-1.1878e-03, -4.5716e-03,  2.7969e-03,  ..., -7.3085e-07,\n",
      "          8.7255e-03, -5.3407e-02],\n",
      "        [ 5.6744e-03, -5.9909e-03, -6.3385e-02,  ...,  1.3137e-03,\n",
      "         -2.4870e-02,  4.2582e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-6.8160e-03, -3.8213e-03,  6.6429e-03,  ..., -2.4733e-04,\n",
      "         -4.0395e-03, -4.8073e-03],\n",
      "        [-1.0688e-02,  3.2045e-04,  5.4077e-05,  ...,  1.4238e-04,\n",
      "          7.6844e-04, -6.4891e-03],\n",
      "        [-1.0855e-02,  9.6558e-03, -4.3573e-03,  ...,  5.2522e-05,\n",
      "          1.4557e-03, -7.7431e-02],\n",
      "        ...,\n",
      "        [-3.8822e-03, -1.0833e-04, -1.2974e-04,  ..., -8.4007e-04,\n",
      "          1.3712e-04, -5.3747e-02],\n",
      "        [-1.5025e-03, -4.1845e-03,  4.8972e-03,  ..., -1.6876e-05,\n",
      "          8.4775e-03, -5.4879e-02],\n",
      "        [ 5.3508e-03, -6.1507e-03, -5.9353e-02,  ...,  1.4860e-03,\n",
      "         -2.5513e-02,  4.2491e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.3857e+01, -1.6453e+01, -1.0364e+01,  ..., -4.1365e-05,\n",
      "         -2.3322e+01, -1.1532e+01],\n",
      "        [-3.7037e+00, -8.9276e+00, -5.0949e+00,  ..., -1.1556e+01,\n",
      "         -1.8821e+00, -7.7254e+00],\n",
      "        [-2.6249e+01, -1.2825e+01, -2.8912e-03,  ..., -5.9129e+00,\n",
      "         -1.1103e+01, -8.7316e+00],\n",
      "        ...,\n",
      "        [-6.0768e+00, -1.0404e+01, -4.0734e+00,  ..., -6.3143e+00,\n",
      "         -7.3825e+00, -2.4372e-02],\n",
      "        [-1.2018e-02, -1.9315e+01, -1.2436e+01,  ..., -1.9287e+01,\n",
      "         -1.0064e+01, -5.1518e+00],\n",
      "        [-1.7168e+01, -7.5646e+00, -7.6209e+00,  ..., -1.3064e-03,\n",
      "         -1.2321e+01, -8.1380e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0092 loss_train: 0.0982 acc_train: 0.9786 loss_val: 1.0912 acc_val: 0.7667 time: 0.7573s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-6.8160e-03, -3.8213e-03,  6.6429e-03,  ..., -2.4733e-04,\n",
      "         -4.0395e-03, -4.8073e-03],\n",
      "        [-1.0688e-02,  3.2045e-04,  5.4077e-05,  ...,  1.4238e-04,\n",
      "          7.6844e-04, -6.4891e-03],\n",
      "        [-1.0855e-02,  9.6558e-03, -4.3573e-03,  ...,  5.2522e-05,\n",
      "          1.4557e-03, -7.7431e-02],\n",
      "        ...,\n",
      "        [-3.8822e-03, -1.0833e-04, -1.2974e-04,  ..., -8.4007e-04,\n",
      "          1.3712e-04, -5.3747e-02],\n",
      "        [-1.5025e-03, -4.1845e-03,  4.8972e-03,  ..., -1.6876e-05,\n",
      "          8.4775e-03, -5.4879e-02],\n",
      "        [ 5.3508e-03, -6.1507e-03, -5.9353e-02,  ...,  1.4860e-03,\n",
      "         -2.5513e-02,  4.2491e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-6.8980e-03, -3.0437e-03,  9.3195e-03,  ..., -3.0927e-04,\n",
      "         -3.9882e-03, -5.2100e-03],\n",
      "        [-7.6025e-03,  1.1362e-04,  2.1592e-05,  ...,  1.3345e-04,\n",
      "          6.5746e-04, -7.1226e-03],\n",
      "        [-9.4529e-03,  9.0114e-03, -3.7300e-03,  ...,  9.0630e-05,\n",
      "          1.2127e-03, -7.8901e-02],\n",
      "        ...,\n",
      "        [-5.4855e-03, -1.6353e-04, -7.3259e-05,  ..., -7.0292e-04,\n",
      "          1.2275e-04, -5.4776e-02],\n",
      "        [-1.7784e-03, -3.7550e-03,  6.6095e-03,  ..., -3.0678e-05,\n",
      "          8.3386e-03, -5.6119e-02],\n",
      "        [ 5.0429e-03, -6.2459e-03, -5.5024e-02,  ...,  1.5713e-03,\n",
      "         -2.6030e-02,  4.2378e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.4610e+01, -1.7279e+01, -9.8027e+00,  ..., -6.8185e-05,\n",
      "         -2.3901e+01, -1.1258e+01],\n",
      "        [-4.4400e+00, -9.8437e+00, -5.3110e+00,  ..., -1.2556e+01,\n",
      "         -2.2587e+00, -8.4499e+00],\n",
      "        [-2.7350e+01, -1.4070e+01, -7.7373e-04,  ..., -7.2726e+00,\n",
      "         -1.1709e+01, -9.6077e+00],\n",
      "        ...,\n",
      "        [-6.1939e+00, -1.0810e+01, -3.9068e+00,  ..., -6.7085e+00,\n",
      "         -7.5279e+00, -2.6822e-02],\n",
      "        [-1.2140e-02, -1.9905e+01, -1.2592e+01,  ..., -1.9913e+01,\n",
      "         -1.0252e+01, -5.4014e+00],\n",
      "        [-1.7495e+01, -7.9253e+00, -7.3639e+00,  ..., -1.3079e-03,\n",
      "         -1.2532e+01, -8.0852e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0093 loss_train: 0.0709 acc_train: 0.9786 loss_val: 1.1249 acc_val: 0.7633 time: 0.8109s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-6.8980e-03, -3.0437e-03,  9.3195e-03,  ..., -3.0927e-04,\n",
      "         -3.9882e-03, -5.2100e-03],\n",
      "        [-7.6025e-03,  1.1362e-04,  2.1592e-05,  ...,  1.3345e-04,\n",
      "          6.5746e-04, -7.1226e-03],\n",
      "        [-9.4529e-03,  9.0114e-03, -3.7300e-03,  ...,  9.0630e-05,\n",
      "          1.2127e-03, -7.8901e-02],\n",
      "        ...,\n",
      "        [-5.4855e-03, -1.6353e-04, -7.3259e-05,  ..., -7.0292e-04,\n",
      "          1.2275e-04, -5.4776e-02],\n",
      "        [-1.7784e-03, -3.7550e-03,  6.6095e-03,  ..., -3.0678e-05,\n",
      "          8.3386e-03, -5.6119e-02],\n",
      "        [ 5.0429e-03, -6.2459e-03, -5.5024e-02,  ...,  1.5713e-03,\n",
      "         -2.6030e-02,  4.2378e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-6.9340e-03, -2.2811e-03,  1.1272e-02,  ..., -3.4441e-04,\n",
      "         -3.9142e-03, -5.5534e-03],\n",
      "        [-4.6085e-03, -7.8231e-05, -1.2944e-05,  ...,  9.7010e-05,\n",
      "          5.2074e-04, -7.6408e-03],\n",
      "        [-8.0388e-03,  7.9919e-03, -3.0389e-03,  ...,  9.6959e-05,\n",
      "          9.7176e-04, -8.0127e-02],\n",
      "        ...,\n",
      "        [-6.5991e-03, -1.7572e-04, -4.1820e-06,  ..., -4.6807e-04,\n",
      "          1.0067e-04, -5.5424e-02],\n",
      "        [-2.0080e-03, -3.2948e-03,  7.9030e-03,  ..., -4.1688e-05,\n",
      "          8.2200e-03, -5.7100e-02],\n",
      "        [ 4.7890e-03, -6.2817e-03, -5.0473e-02,  ...,  1.5734e-03,\n",
      "         -2.6405e-02,  4.2245e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.5348e+01, -1.8090e+01, -9.2367e+00,  ..., -1.1575e-04,\n",
      "         -2.4455e+01, -1.0906e+01],\n",
      "        [-5.1525e+00, -1.0981e+01, -5.5916e+00,  ..., -1.3725e+01,\n",
      "         -2.7908e+00, -9.1438e+00],\n",
      "        [-2.8356e+01, -1.5431e+01, -2.1324e-04,  ..., -8.6617e+00,\n",
      "         -1.2374e+01, -1.0309e+01],\n",
      "        ...,\n",
      "        [-6.3511e+00, -1.1494e+01, -3.8802e+00,  ..., -7.3048e+00,\n",
      "         -7.8541e+00, -2.6339e-02],\n",
      "        [-1.1876e-02, -2.0767e+01, -1.2911e+01,  ..., -2.0791e+01,\n",
      "         -1.0624e+01, -5.7185e+00],\n",
      "        [-1.7851e+01, -8.3911e+00, -7.1265e+00,  ..., -1.3973e-03,\n",
      "         -1.2837e+01, -7.9205e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0094 loss_train: 0.0452 acc_train: 1.0000 loss_val: 1.1705 acc_val: 0.7533 time: 0.8052s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-6.9340e-03, -2.2811e-03,  1.1272e-02,  ..., -3.4441e-04,\n",
      "         -3.9142e-03, -5.5534e-03],\n",
      "        [-4.6085e-03, -7.8231e-05, -1.2944e-05,  ...,  9.7010e-05,\n",
      "          5.2074e-04, -7.6408e-03],\n",
      "        [-8.0388e-03,  7.9919e-03, -3.0389e-03,  ...,  9.6959e-05,\n",
      "          9.7176e-04, -8.0127e-02],\n",
      "        ...,\n",
      "        [-6.5991e-03, -1.7572e-04, -4.1820e-06,  ..., -4.6807e-04,\n",
      "          1.0067e-04, -5.5424e-02],\n",
      "        [-2.0080e-03, -3.2948e-03,  7.9030e-03,  ..., -4.1688e-05,\n",
      "          8.2200e-03, -5.7100e-02],\n",
      "        [ 4.7890e-03, -6.2817e-03, -5.0473e-02,  ...,  1.5734e-03,\n",
      "         -2.6405e-02,  4.2245e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-6.9291e-03, -1.5467e-03,  1.2469e-02,  ..., -3.5279e-04,\n",
      "         -3.8140e-03, -5.8457e-03],\n",
      "        [-1.7755e-03, -2.4862e-04, -4.1103e-05,  ...,  4.3309e-05,\n",
      "          3.6813e-04, -8.0778e-03],\n",
      "        [-6.6348e-03,  6.6807e-03, -2.3124e-03,  ...,  7.2393e-05,\n",
      "          7.3675e-04, -8.1106e-02],\n",
      "        ...,\n",
      "        [-7.1991e-03, -1.4593e-04,  5.9362e-05,  ..., -1.8141e-04,\n",
      "          7.3205e-05, -5.5711e-02],\n",
      "        [-2.2030e-03, -2.8154e-03,  8.7660e-03,  ..., -4.9628e-05,\n",
      "          8.1783e-03, -5.7863e-02],\n",
      "        [ 4.5488e-03, -6.2632e-03, -4.5770e-02,  ...,  1.4996e-03,\n",
      "         -2.6629e-02,  4.2093e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.6338e+01, -1.8965e+01, -8.8345e+00,  ..., -1.6867e-04,\n",
      "         -2.5174e+01, -1.0681e+01],\n",
      "        [-5.8884e+00, -1.1985e+01, -5.7716e+00,  ..., -1.4775e+01,\n",
      "         -3.2174e+00, -9.8195e+00],\n",
      "        [-2.9375e+01, -1.6756e+01, -7.1523e-05,  ..., -9.9135e+00,\n",
      "         -1.3034e+01, -1.0927e+01],\n",
      "        ...,\n",
      "        [-6.5980e+00, -1.2300e+01, -3.9026e+00,  ..., -7.9444e+00,\n",
      "         -8.2748e+00, -2.4770e-02],\n",
      "        [-1.1278e-02, -2.1637e+01, -1.3244e+01,  ..., -2.1666e+01,\n",
      "         -1.1004e+01, -6.0337e+00],\n",
      "        [-1.8450e+01, -8.9381e+00, -7.0213e+00,  ..., -1.4123e-03,\n",
      "         -1.3310e+01, -7.8605e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0095 loss_train: 0.0434 acc_train: 1.0000 loss_val: 1.2381 acc_val: 0.7533 time: 0.7871s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-6.9291e-03, -1.5467e-03,  1.2469e-02,  ..., -3.5279e-04,\n",
      "         -3.8140e-03, -5.8457e-03],\n",
      "        [-1.7755e-03, -2.4862e-04, -4.1103e-05,  ...,  4.3309e-05,\n",
      "          3.6813e-04, -8.0778e-03],\n",
      "        [-6.6348e-03,  6.6807e-03, -2.3124e-03,  ...,  7.2393e-05,\n",
      "          7.3675e-04, -8.1106e-02],\n",
      "        ...,\n",
      "        [-7.1991e-03, -1.4593e-04,  5.9362e-05,  ..., -1.8141e-04,\n",
      "          7.3205e-05, -5.5711e-02],\n",
      "        [-2.2030e-03, -2.8154e-03,  8.7660e-03,  ..., -4.9628e-05,\n",
      "          8.1783e-03, -5.7863e-02],\n",
      "        [ 4.5488e-03, -6.2632e-03, -4.5770e-02,  ...,  1.4996e-03,\n",
      "         -2.6629e-02,  4.2093e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-6.8850e-03, -8.5180e-04,  1.2920e-02,  ..., -3.3624e-04,\n",
      "         -3.6987e-03, -6.0670e-03],\n",
      "        [ 8.3605e-04, -3.9249e-04, -5.6699e-05,  ..., -1.4591e-05,\n",
      "          2.0950e-04, -8.3429e-03],\n",
      "        [-5.2610e-03,  5.1678e-03, -1.5777e-03,  ...,  2.7422e-05,\n",
      "          5.1117e-04, -8.1796e-02],\n",
      "        ...,\n",
      "        [-7.2958e-03, -8.4901e-05,  1.0215e-04,  ...,  1.0690e-04,\n",
      "          4.2878e-05, -5.5673e-02],\n",
      "        [-2.3678e-03, -2.3273e-03,  9.2042e-03,  ..., -5.4390e-05,\n",
      "          8.2379e-03, -5.8392e-02],\n",
      "        [ 4.3392e-03, -6.1954e-03, -4.0984e-02,  ...,  1.3604e-03,\n",
      "         -2.6704e-02,  4.1972e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.7441e+01, -2.0087e+01, -8.8617e+00,  ..., -1.7141e-04,\n",
      "         -2.6308e+01, -1.0426e+01],\n",
      "        [-5.7541e+00, -1.2988e+01, -5.8373e+00,  ..., -1.5553e+01,\n",
      "         -3.7593e+00, -9.6037e+00],\n",
      "        [-2.9976e+01, -1.7918e+01, -3.9457e-05,  ..., -1.0759e+01,\n",
      "         -1.3699e+01, -1.1051e+01],\n",
      "        ...,\n",
      "        [-6.9474e+00, -1.3319e+01, -4.1638e+00,  ..., -8.6400e+00,\n",
      "         -8.9275e+00, -1.8507e-02],\n",
      "        [-7.7678e-03, -2.2798e+01, -1.3848e+01,  ..., -2.2710e+01,\n",
      "         -1.1750e+01, -6.2688e+00],\n",
      "        [-1.9111e+01, -9.8400e+00, -7.1449e+00,  ..., -1.3639e-03,\n",
      "         -1.4193e+01, -7.5614e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0096 loss_train: 0.0656 acc_train: 0.9786 loss_val: 1.2436 acc_val: 0.7467 time: 0.8442s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-6.8850e-03, -8.5180e-04,  1.2920e-02,  ..., -3.3624e-04,\n",
      "         -3.6987e-03, -6.0670e-03],\n",
      "        [ 8.3605e-04, -3.9249e-04, -5.6699e-05,  ..., -1.4591e-05,\n",
      "          2.0950e-04, -8.3429e-03],\n",
      "        [-5.2610e-03,  5.1678e-03, -1.5777e-03,  ...,  2.7422e-05,\n",
      "          5.1117e-04, -8.1796e-02],\n",
      "        ...,\n",
      "        [-7.2958e-03, -8.4901e-05,  1.0215e-04,  ...,  1.0690e-04,\n",
      "          4.2878e-05, -5.5673e-02],\n",
      "        [-2.3678e-03, -2.3273e-03,  9.2042e-03,  ..., -5.4390e-05,\n",
      "          8.2379e-03, -5.8392e-02],\n",
      "        [ 4.3392e-03, -6.1954e-03, -4.0984e-02,  ...,  1.3604e-03,\n",
      "         -2.6704e-02,  4.1972e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-6.8020e-03, -2.0627e-04,  1.2673e-02,  ..., -2.9815e-04,\n",
      "         -3.5679e-03, -6.2234e-03],\n",
      "        [ 3.1764e-03, -5.0628e-04, -5.7101e-05,  ..., -6.3832e-05,\n",
      "          5.4206e-05, -8.4780e-03],\n",
      "        [-3.9355e-03,  3.5450e-03, -8.5975e-04,  ..., -2.1932e-05,\n",
      "          2.9803e-04, -8.2216e-02],\n",
      "        ...,\n",
      "        [-6.9295e-03, -9.7414e-06,  1.1541e-04,  ...,  3.5066e-04,\n",
      "          1.2213e-05, -5.5341e-02],\n",
      "        [-2.5064e-03, -1.8407e-03,  9.2393e-03,  ..., -5.6029e-05,\n",
      "          8.3814e-03, -5.8680e-02],\n",
      "        [ 4.1767e-03, -6.0832e-03, -3.6173e-02,  ...,  1.1683e-03,\n",
      "         -2.6656e-02,  4.1863e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.9430e+01, -2.1379e+01, -9.9148e+00,  ..., -6.3298e-05,\n",
      "         -2.8182e+01, -1.1186e+01],\n",
      "        [-6.1063e+00, -1.3075e+01, -5.5847e+00,  ..., -1.5622e+01,\n",
      "         -3.6948e+00, -9.7554e+00],\n",
      "        [-3.0992e+01, -1.8375e+01, -3.3616e-05,  ..., -1.0759e+01,\n",
      "         -1.4188e+01, -1.1421e+01],\n",
      "        ...,\n",
      "        [-7.5420e+00, -1.3822e+01, -4.2869e+00,  ..., -8.6894e+00,\n",
      "         -9.4070e+00, -1.5495e-02],\n",
      "        [-6.2654e-03, -2.3203e+01, -1.4036e+01,  ..., -2.3046e+01,\n",
      "         -1.2015e+01, -6.3526e+00],\n",
      "        [-2.0805e+01, -1.0846e+01, -8.0261e+00,  ..., -6.0326e-04,\n",
      "         -1.5720e+01, -8.2678e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0097 loss_train: 0.0521 acc_train: 0.9857 loss_val: 1.2216 acc_val: 0.7667 time: 0.8102s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-6.8020e-03, -2.0627e-04,  1.2673e-02,  ..., -2.9815e-04,\n",
      "         -3.5679e-03, -6.2234e-03],\n",
      "        [ 3.1764e-03, -5.0628e-04, -5.7101e-05,  ..., -6.3832e-05,\n",
      "          5.4206e-05, -8.4780e-03],\n",
      "        [-3.9355e-03,  3.5450e-03, -8.5975e-04,  ..., -2.1932e-05,\n",
      "          2.9803e-04, -8.2216e-02],\n",
      "        ...,\n",
      "        [-6.9295e-03, -9.7414e-06,  1.1541e-04,  ...,  3.5066e-04,\n",
      "          1.2213e-05, -5.5341e-02],\n",
      "        [-2.5064e-03, -1.8407e-03,  9.2393e-03,  ..., -5.6029e-05,\n",
      "          8.3814e-03, -5.8680e-02],\n",
      "        [ 4.1767e-03, -6.0832e-03, -3.6173e-02,  ...,  1.1683e-03,\n",
      "         -2.6656e-02,  4.1863e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-6.6858e-03,  3.8192e-04,  1.1807e-02,  ..., -2.4306e-04,\n",
      "         -3.4257e-03, -6.3452e-03],\n",
      "        [ 5.2074e-03, -5.8798e-04, -4.3584e-05,  ..., -9.4525e-05,\n",
      "         -8.9368e-05, -8.5507e-03],\n",
      "        [-2.6743e-03,  1.9015e-03, -1.8108e-04,  ..., -5.9625e-05,\n",
      "          9.9895e-05, -8.2418e-02],\n",
      "        ...,\n",
      "        [-6.1656e-03,  6.0565e-05,  9.8495e-05,  ...,  5.1477e-04,\n",
      "         -1.6457e-05, -5.4747e-02],\n",
      "        [-2.6207e-03, -1.3646e-03,  8.9069e-03,  ..., -5.4746e-05,\n",
      "          8.6339e-03, -5.8803e-02],\n",
      "        [ 4.0257e-03, -5.9315e-03, -3.1396e-02,  ...,  9.3738e-04,\n",
      "         -2.6359e-02,  4.1735e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.1886e+01, -2.2592e+01, -1.1501e+01,  ..., -1.3351e-05,\n",
      "         -3.0352e+01, -1.2654e+01],\n",
      "        [-6.8371e+00, -1.2259e+01, -4.9906e+00,  ..., -1.4999e+01,\n",
      "         -2.9631e+00, -1.0201e+01],\n",
      "        [-3.2321e+01, -1.8267e+01, -4.4226e-05,  ..., -1.0184e+01,\n",
      "         -1.4492e+01, -1.2082e+01],\n",
      "        ...,\n",
      "        [-8.2907e+00, -1.3799e+01, -4.2101e+00,  ..., -8.1303e+00,\n",
      "         -9.6489e+00, -1.6029e-02],\n",
      "        [-5.5241e-03, -2.2989e+01, -1.3898e+01,  ..., -2.2804e+01,\n",
      "         -1.1887e+01, -6.3211e+00],\n",
      "        [-2.3169e+01, -1.1776e+01, -9.3612e+00,  ..., -1.5186e-04,\n",
      "         -1.7570e+01, -9.7518e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0098 loss_train: 0.0573 acc_train: 0.9857 loss_val: 1.2251 acc_val: 0.7700 time: 0.8120s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-6.6858e-03,  3.8192e-04,  1.1807e-02,  ..., -2.4306e-04,\n",
      "         -3.4257e-03, -6.3452e-03],\n",
      "        [ 5.2074e-03, -5.8798e-04, -4.3584e-05,  ..., -9.4525e-05,\n",
      "         -8.9368e-05, -8.5507e-03],\n",
      "        [-2.6743e-03,  1.9015e-03, -1.8108e-04,  ..., -5.9625e-05,\n",
      "          9.9895e-05, -8.2418e-02],\n",
      "        ...,\n",
      "        [-6.1656e-03,  6.0565e-05,  9.8495e-05,  ...,  5.1477e-04,\n",
      "         -1.6457e-05, -5.4747e-02],\n",
      "        [-2.6207e-03, -1.3646e-03,  8.9069e-03,  ..., -5.4746e-05,\n",
      "          8.6339e-03, -5.8803e-02],\n",
      "        [ 4.0257e-03, -5.9315e-03, -3.1396e-02,  ...,  9.3738e-04,\n",
      "         -2.6359e-02,  4.1735e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-6.5437e-03,  9.0653e-04,  1.0423e-02,  ..., -1.7633e-04,\n",
      "         -3.2738e-03, -6.4348e-03],\n",
      "        [ 6.9022e-03, -6.3707e-04, -2.0703e-05,  ..., -1.0166e-04,\n",
      "         -2.1421e-04, -8.6262e-03],\n",
      "        [-1.4908e-03,  3.1998e-04,  4.3914e-04,  ..., -7.4695e-05,\n",
      "         -8.1159e-05, -8.2469e-02],\n",
      "        ...,\n",
      "        [-5.0882e-03,  1.0980e-04,  5.8380e-05,  ...,  7.5831e-04,\n",
      "         -4.1147e-05, -5.3931e-02],\n",
      "        [-2.7125e-03, -9.0708e-04,  8.2536e-03,  ..., -5.0870e-05,\n",
      "          8.8350e-03, -5.8842e-02],\n",
      "        [ 3.8806e-03, -5.7451e-03, -2.6703e-02,  ...,  6.8241e-04,\n",
      "         -2.5926e-02,  4.1511e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.3753e+01, -2.3465e+01, -1.2939e+01,  ..., -3.3379e-06,\n",
      "         -3.2122e+01, -1.3872e+01],\n",
      "        [-7.3043e+00, -1.1657e+01, -4.5683e+00,  ..., -1.4540e+01,\n",
      "         -2.3904e+00, -1.0509e+01],\n",
      "        [-3.3097e+01, -1.8012e+01, -7.3192e-05,  ..., -9.5847e+00,\n",
      "         -1.4634e+01, -1.2466e+01],\n",
      "        ...,\n",
      "        [-8.8005e+00, -1.3861e+01, -4.2803e+00,  ..., -7.7360e+00,\n",
      "         -9.9019e+00, -1.4842e-02],\n",
      "        [-4.5198e-03, -2.3054e+01, -1.3962e+01,  ..., -2.2810e+01,\n",
      "         -1.1960e+01, -6.3522e+00],\n",
      "        [-2.5012e+01, -1.2438e+01, -1.0543e+01,  ..., -4.7206e-05,\n",
      "         -1.9065e+01, -1.0990e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0099 loss_train: 0.0268 acc_train: 1.0000 loss_val: 1.2715 acc_val: 0.7800 time: 0.9129s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-6.5437e-03,  9.0653e-04,  1.0423e-02,  ..., -1.7633e-04,\n",
      "         -3.2738e-03, -6.4348e-03],\n",
      "        [ 6.9022e-03, -6.3707e-04, -2.0703e-05,  ..., -1.0166e-04,\n",
      "         -2.1421e-04, -8.6262e-03],\n",
      "        [-1.4908e-03,  3.1998e-04,  4.3914e-04,  ..., -7.4695e-05,\n",
      "         -8.1159e-05, -8.2469e-02],\n",
      "        ...,\n",
      "        [-5.0882e-03,  1.0980e-04,  5.8380e-05,  ...,  7.5831e-04,\n",
      "         -4.1147e-05, -5.3931e-02],\n",
      "        [-2.7125e-03, -9.0708e-04,  8.2536e-03,  ..., -5.0870e-05,\n",
      "          8.8350e-03, -5.8842e-02],\n",
      "        [ 3.8806e-03, -5.7451e-03, -2.6703e-02,  ...,  6.8241e-04,\n",
      "         -2.5926e-02,  4.1511e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-6.3956e-03,  1.3631e-03,  8.6394e-03,  ..., -1.0364e-04,\n",
      "         -3.1390e-03, -6.5521e-03],\n",
      "        [ 8.2453e-03, -6.5444e-04,  5.0853e-06,  ..., -8.5806e-05,\n",
      "         -3.1495e-04, -8.7699e-03],\n",
      "        [-3.9628e-04, -1.1269e-03,  9.8528e-04,  ..., -6.4360e-05,\n",
      "         -2.4352e-04, -8.2483e-02],\n",
      "        ...,\n",
      "        [-3.7932e-03,  1.2816e-04,  7.3041e-06,  ...,  8.5528e-04,\n",
      "         -6.0344e-05, -5.2902e-02],\n",
      "        [-2.7832e-03, -4.7535e-04,  7.3346e-03,  ..., -4.4825e-05,\n",
      "          8.9579e-03, -5.8854e-02],\n",
      "        [ 3.6575e-03, -5.5286e-03, -2.2139e-02,  ...,  4.1804e-04,\n",
      "         -2.5432e-02,  4.1134e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.3699e+01, -2.4174e+01, -1.3277e+01,  ..., -3.8147e-06,\n",
      "         -3.2926e+01, -1.3054e+01],\n",
      "        [-5.9187e+00, -1.2924e+01, -4.7741e+00,  ..., -1.5224e+01,\n",
      "         -3.3543e+00, -9.1321e+00],\n",
      "        [-3.2321e+01, -1.8538e+01, -6.9497e-05,  ..., -9.7440e+00,\n",
      "         -1.4948e+01, -1.1474e+01],\n",
      "        ...,\n",
      "        [-8.9489e+00, -1.5320e+01, -5.1811e+00,  ..., -8.8034e+00,\n",
      "         -1.0948e+01, -6.0564e-03],\n",
      "        [-2.6295e-03, -2.4579e+01, -1.4960e+01,  ..., -2.4085e+01,\n",
      "         -1.3120e+01, -6.5399e+00],\n",
      "        [-2.4719e+01, -1.3206e+01, -1.0651e+01,  ..., -7.3549e-05,\n",
      "         -1.9716e+01, -9.9424e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0100 loss_train: 0.0752 acc_train: 0.9643 loss_val: 1.1197 acc_val: 0.7933 time: 0.8315s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-6.3956e-03,  1.3631e-03,  8.6394e-03,  ..., -1.0364e-04,\n",
      "         -3.1390e-03, -6.5521e-03],\n",
      "        [ 8.2453e-03, -6.5444e-04,  5.0853e-06,  ..., -8.5806e-05,\n",
      "         -3.1495e-04, -8.7699e-03],\n",
      "        [-3.9628e-04, -1.1269e-03,  9.8528e-04,  ..., -6.4360e-05,\n",
      "         -2.4352e-04, -8.2483e-02],\n",
      "        ...,\n",
      "        [-3.7932e-03,  1.2816e-04,  7.3041e-06,  ...,  8.5528e-04,\n",
      "         -6.0344e-05, -5.2902e-02],\n",
      "        [-2.7832e-03, -4.7535e-04,  7.3346e-03,  ..., -4.4825e-05,\n",
      "          8.9579e-03, -5.8854e-02],\n",
      "        [ 3.6575e-03, -5.5286e-03, -2.2139e-02,  ...,  4.1804e-04,\n",
      "         -2.5432e-02,  4.1134e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-6.2336e-03,  1.7487e-03,  6.5837e-03,  ..., -3.0592e-05,\n",
      "         -3.0018e-03, -6.6394e-03],\n",
      "        [ 9.2320e-03, -6.4223e-04,  2.7160e-05,  ..., -5.2534e-05,\n",
      "         -3.8806e-04, -8.9049e-03],\n",
      "        [ 6.0025e-04, -2.3792e-03,  1.4455e-03,  ..., -3.4251e-05,\n",
      "         -3.8602e-04, -8.2384e-02],\n",
      "        ...,\n",
      "        [-2.3821e-03,  1.1403e-04, -4.0763e-05,  ...,  8.6405e-04,\n",
      "         -6.6099e-05, -5.1688e-02],\n",
      "        [-2.8347e-03, -7.5362e-05,  6.2102e-03,  ..., -3.7109e-05,\n",
      "          9.0361e-03, -5.8772e-02],\n",
      "        [ 3.4422e-03, -5.2864e-03, -1.7746e-02,  ...,  1.5810e-04,\n",
      "         -2.4866e-02,  4.0720e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.2806e+01, -2.4184e+01, -1.2803e+01,  ..., -9.5367e-06,\n",
      "         -3.2684e+01, -1.1893e+01],\n",
      "        [-4.7165e+00, -1.4432e+01, -5.1527e+00,  ..., -1.6231e+01,\n",
      "         -4.4326e+00, -8.0123e+00],\n",
      "        [-3.1398e+01, -1.9244e+01, -5.3047e-05,  ..., -1.0442e+01,\n",
      "         -1.5122e+01, -1.0663e+01],\n",
      "        ...,\n",
      "        [-8.7288e+00, -1.6743e+01, -5.9403e+00,  ..., -1.0141e+01,\n",
      "         -1.1776e+01, -2.9283e-03],\n",
      "        [-1.6560e-03, -2.6238e+01, -1.6008e+01,  ..., -2.5562e+01,\n",
      "         -1.4297e+01, -6.8402e+00],\n",
      "        [-2.3636e+01, -1.3331e+01, -1.0149e+01,  ..., -2.2611e-04,\n",
      "         -1.9411e+01, -8.5933e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0101 loss_train: 0.0357 acc_train: 0.9857 loss_val: 1.0829 acc_val: 0.7900 time: 1.1509s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-6.2336e-03,  1.7487e-03,  6.5837e-03,  ..., -3.0592e-05,\n",
      "         -3.0018e-03, -6.6394e-03],\n",
      "        [ 9.2320e-03, -6.4223e-04,  2.7160e-05,  ..., -5.2534e-05,\n",
      "         -3.8806e-04, -8.9049e-03],\n",
      "        [ 6.0025e-04, -2.3792e-03,  1.4455e-03,  ..., -3.4251e-05,\n",
      "         -3.8602e-04, -8.2384e-02],\n",
      "        ...,\n",
      "        [-2.3821e-03,  1.1403e-04, -4.0763e-05,  ...,  8.6405e-04,\n",
      "         -6.6099e-05, -5.1688e-02],\n",
      "        [-2.8347e-03, -7.5362e-05,  6.2102e-03,  ..., -3.7109e-05,\n",
      "          9.0361e-03, -5.8772e-02],\n",
      "        [ 3.4422e-03, -5.2864e-03, -1.7746e-02,  ...,  1.5810e-04,\n",
      "         -2.4866e-02,  4.0720e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-6.0517e-03,  2.0624e-03,  4.3853e-03,  ...,  3.7651e-05,\n",
      "         -2.8546e-03, -6.6787e-03],\n",
      "        [ 9.8676e-03, -6.0364e-04,  4.0387e-05,  ..., -1.0786e-05,\n",
      "         -4.3185e-04, -8.9789e-03],\n",
      "        [ 1.4921e-03, -3.3920e-03,  1.8120e-03,  ...,  4.0926e-06,\n",
      "         -5.0796e-04, -8.2066e-02],\n",
      "        ...,\n",
      "        [-9.5569e-04,  7.3766e-05, -7.3817e-05,  ...,  8.1669e-04,\n",
      "         -6.6201e-05, -5.0346e-02],\n",
      "        [-2.8685e-03,  2.8799e-04,  4.9439e-03,  ..., -2.8257e-05,\n",
      "          9.1900e-03, -5.8575e-02],\n",
      "        [ 3.2605e-03, -5.0228e-03, -1.3557e-02,  ..., -8.4942e-05,\n",
      "         -2.4212e-02,  4.0330e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.2485e+01, -2.3642e+01, -1.2492e+01,  ..., -1.0610e-05,\n",
      "         -3.2201e+01, -1.1892e+01],\n",
      "        [-5.0926e+00, -1.4906e+01, -5.2893e+00,  ..., -1.6757e+01,\n",
      "         -4.6644e+00, -8.3658e+00],\n",
      "        [-3.1392e+01, -1.9337e+01, -3.9457e-05,  ..., -1.0814e+01,\n",
      "         -1.5043e+01, -1.0883e+01],\n",
      "        ...,\n",
      "        [-8.4382e+00, -1.7107e+01, -6.0744e+00,  ..., -1.0645e+01,\n",
      "         -1.1881e+01, -2.6532e-03],\n",
      "        [-1.3965e-03, -2.6885e+01, -1.6403e+01,  ..., -2.6192e+01,\n",
      "         -1.4714e+01, -7.0376e+00],\n",
      "        [-2.3334e+01, -1.2882e+01, -9.9251e+00,  ..., -2.3184e-04,\n",
      "         -1.8974e+01, -8.6208e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0102 loss_train: 0.0446 acc_train: 0.9857 loss_val: 1.1203 acc_val: 0.7867 time: 0.8584s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-6.0517e-03,  2.0624e-03,  4.3853e-03,  ...,  3.7651e-05,\n",
      "         -2.8546e-03, -6.6787e-03],\n",
      "        [ 9.8676e-03, -6.0364e-04,  4.0387e-05,  ..., -1.0786e-05,\n",
      "         -4.3185e-04, -8.9789e-03],\n",
      "        [ 1.4921e-03, -3.3920e-03,  1.8120e-03,  ...,  4.0926e-06,\n",
      "         -5.0796e-04, -8.2066e-02],\n",
      "        ...,\n",
      "        [-9.5569e-04,  7.3766e-05, -7.3817e-05,  ...,  8.1669e-04,\n",
      "         -6.6201e-05, -5.0346e-02],\n",
      "        [-2.8685e-03,  2.8799e-04,  4.9439e-03,  ..., -2.8257e-05,\n",
      "          9.1900e-03, -5.8575e-02],\n",
      "        [ 3.2605e-03, -5.0228e-03, -1.3557e-02,  ..., -8.4942e-05,\n",
      "         -2.4212e-02,  4.0330e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-5.8601e-03,  2.3043e-03,  2.1696e-03,  ...,  9.6713e-05,\n",
      "         -2.7019e-03, -6.7172e-03],\n",
      "        [ 1.0167e-02, -5.4271e-04,  4.2276e-05,  ...,  2.9384e-05,\n",
      "         -4.4648e-04, -8.9910e-03],\n",
      "        [ 2.2748e-03, -4.1358e-03,  2.0806e-03,  ...,  3.7444e-05,\n",
      "         -6.0903e-04, -8.1635e-02],\n",
      "        ...,\n",
      "        [ 3.9567e-04,  1.9470e-05, -8.4737e-05,  ...,  6.4138e-04,\n",
      "         -6.0437e-05, -4.8857e-02],\n",
      "        [-2.8857e-03,  6.1094e-04,  3.5991e-03,  ..., -1.8819e-05,\n",
      "          9.4085e-03, -5.8259e-02],\n",
      "        [ 3.1016e-03, -4.7418e-03, -9.6039e-03,  ..., -3.0054e-04,\n",
      "         -2.3480e-02,  3.9953e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.2923e+01, -2.2659e+01, -1.2313e+01,  ..., -6.4373e-06,\n",
      "         -3.1503e+01, -1.3158e+01],\n",
      "        [-6.9463e+00, -1.4421e+01, -5.1497e+00,  ..., -1.6843e+01,\n",
      "         -4.0471e+00, -1.0097e+01],\n",
      "        [-3.2461e+01, -1.8866e+01, -2.2769e-05,  ..., -1.0945e+01,\n",
      "         -1.4673e+01, -1.2326e+01],\n",
      "        ...,\n",
      "        [-8.1299e+00, -1.6341e+01, -5.4647e+00,  ..., -1.0256e+01,\n",
      "         -1.1175e+01, -4.8115e-03],\n",
      "        [-1.6177e-03, -2.6523e+01, -1.6122e+01,  ..., -2.5982e+01,\n",
      "         -1.4338e+01, -7.1410e+00],\n",
      "        [-2.4043e+01, -1.1897e+01, -9.9936e+00,  ..., -9.0595e-05,\n",
      "         -1.8423e+01, -1.0173e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0103 loss_train: 0.0397 acc_train: 0.9929 loss_val: 1.2363 acc_val: 0.7700 time: 0.7669s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-5.8601e-03,  2.3043e-03,  2.1696e-03,  ...,  9.6713e-05,\n",
      "         -2.7019e-03, -6.7172e-03],\n",
      "        [ 1.0167e-02, -5.4271e-04,  4.2276e-05,  ...,  2.9384e-05,\n",
      "         -4.4648e-04, -8.9910e-03],\n",
      "        [ 2.2748e-03, -4.1358e-03,  2.0806e-03,  ...,  3.7444e-05,\n",
      "         -6.0903e-04, -8.1635e-02],\n",
      "        ...,\n",
      "        [ 3.9567e-04,  1.9470e-05, -8.4737e-05,  ...,  6.4138e-04,\n",
      "         -6.0437e-05, -4.8857e-02],\n",
      "        [-2.8857e-03,  6.1094e-04,  3.5991e-03,  ..., -1.8819e-05,\n",
      "          9.4085e-03, -5.8259e-02],\n",
      "        [ 3.1016e-03, -4.7418e-03, -9.6039e-03,  ..., -3.0054e-04,\n",
      "         -2.3480e-02,  3.9953e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-5.6554e-03,  2.4761e-03,  5.2494e-05,  ...,  1.4324e-04,\n",
      "         -2.5449e-03, -6.7208e-03],\n",
      "        [ 1.0152e-02, -4.6407e-04,  3.3383e-05,  ...,  5.9139e-05,\n",
      "         -4.3375e-04, -8.9608e-03],\n",
      "        [ 2.9459e-03, -4.5976e-03,  2.2511e-03,  ...,  5.5348e-05,\n",
      "         -6.8932e-04, -8.1050e-02],\n",
      "        ...,\n",
      "        [ 1.5925e-03, -3.4384e-05, -7.2714e-05,  ...,  3.7952e-04,\n",
      "         -4.9588e-05, -4.7244e-02],\n",
      "        [-2.8872e-03,  8.9082e-04,  2.2367e-03,  ..., -9.3227e-06,\n",
      "          9.5953e-03, -5.7839e-02],\n",
      "        [ 2.9998e-03, -4.4473e-03, -5.9109e-03,  ..., -4.8042e-04,\n",
      "         -2.2710e-02,  3.9607e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.3448e+01, -2.1703e+01, -1.2357e+01,  ..., -4.7684e-06,\n",
      "         -3.0865e+01, -1.4517e+01],\n",
      "        [-8.5941e+00, -1.3879e+01, -5.0588e+00,  ..., -1.6855e+01,\n",
      "         -3.3800e+00, -1.1686e+01],\n",
      "        [-3.3337e+01, -1.8264e+01, -2.0504e-05,  ..., -1.0914e+01,\n",
      "         -1.4201e+01, -1.3609e+01],\n",
      "        ...,\n",
      "        [-7.8780e+00, -1.5371e+01, -4.6909e+00,  ..., -9.6622e+00,\n",
      "         -1.0277e+01, -1.0257e-02],\n",
      "        [-2.1056e-03, -2.6111e+01, -1.5814e+01,  ..., -2.5743e+01,\n",
      "         -1.3911e+01, -7.2524e+00],\n",
      "        [-2.4886e+01, -1.0903e+01, -1.0195e+01,  ..., -6.3179e-05,\n",
      "         -1.7899e+01, -1.1814e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0104 loss_train: 0.0183 acc_train: 1.0000 loss_val: 1.4221 acc_val: 0.7567 time: 0.7160s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-5.6554e-03,  2.4761e-03,  5.2494e-05,  ...,  1.4324e-04,\n",
      "         -2.5449e-03, -6.7208e-03],\n",
      "        [ 1.0152e-02, -4.6407e-04,  3.3383e-05,  ...,  5.9139e-05,\n",
      "         -4.3375e-04, -8.9608e-03],\n",
      "        [ 2.9459e-03, -4.5976e-03,  2.2511e-03,  ...,  5.5348e-05,\n",
      "         -6.8932e-04, -8.1050e-02],\n",
      "        ...,\n",
      "        [ 1.5925e-03, -3.4384e-05, -7.2714e-05,  ...,  3.7952e-04,\n",
      "         -4.9588e-05, -4.7244e-02],\n",
      "        [-2.8872e-03,  8.9082e-04,  2.2367e-03,  ..., -9.3227e-06,\n",
      "          9.5953e-03, -5.7839e-02],\n",
      "        [ 2.9998e-03, -4.4473e-03, -5.9109e-03,  ..., -4.8042e-04,\n",
      "         -2.2710e-02,  3.9607e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-5.4437e-03,  2.5808e-03, -1.8653e-03,  ...,  1.7506e-04,\n",
      "         -2.3884e-03, -6.7009e-03],\n",
      "        [ 9.8521e-03, -3.7273e-04,  1.6926e-05,  ...,  7.2738e-05,\n",
      "         -3.9687e-04, -8.8875e-03],\n",
      "        [ 3.5049e-03, -4.7796e-03,  2.3263e-03,  ...,  5.3324e-05,\n",
      "         -7.4929e-04, -8.0392e-02],\n",
      "        ...,\n",
      "        [ 2.5721e-03, -7.4683e-05, -4.2952e-05,  ...,  7.9346e-05,\n",
      "         -3.5890e-05, -4.5509e-02],\n",
      "        [-2.8748e-03,  1.1260e-03,  9.1316e-04,  ..., -2.5588e-07,\n",
      "          9.4260e-03, -5.7298e-02],\n",
      "        [ 2.9062e-03, -4.1429e-03, -2.4980e-03,  ..., -6.1879e-04,\n",
      "         -2.1915e-02,  3.9286e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.3560e+01, -2.1319e+01, -1.2403e+01,  ..., -4.4107e-06,\n",
      "         -3.0571e+01, -1.4996e+01],\n",
      "        [-9.2353e+00, -1.4199e+01, -5.2644e+00,  ..., -1.7301e+01,\n",
      "         -3.5156e+00, -1.2300e+01],\n",
      "        [-3.3455e+01, -1.8095e+01, -2.0027e-05,  ..., -1.0932e+01,\n",
      "         -1.4012e+01, -1.3928e+01],\n",
      "        ...,\n",
      "        [-7.7302e+00, -1.5302e+01, -4.5025e+00,  ..., -9.7190e+00,\n",
      "         -1.0068e+01, -1.2536e-02],\n",
      "        [-2.4225e-03, -2.6289e+01, -1.5886e+01,  ..., -2.5966e+01,\n",
      "         -1.3973e+01, -7.3625e+00],\n",
      "        [-2.5139e+01, -1.0582e+01, -1.0223e+01,  ..., -6.6397e-05,\n",
      "         -1.7653e+01, -1.2286e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0105 loss_train: 0.0310 acc_train: 0.9929 loss_val: 1.4841 acc_val: 0.7533 time: 0.7288s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-5.4437e-03,  2.5808e-03, -1.8653e-03,  ...,  1.7506e-04,\n",
      "         -2.3884e-03, -6.7009e-03],\n",
      "        [ 9.8521e-03, -3.7273e-04,  1.6926e-05,  ...,  7.2738e-05,\n",
      "         -3.9687e-04, -8.8875e-03],\n",
      "        [ 3.5049e-03, -4.7796e-03,  2.3263e-03,  ...,  5.3324e-05,\n",
      "         -7.4929e-04, -8.0392e-02],\n",
      "        ...,\n",
      "        [ 2.5721e-03, -7.4683e-05, -4.2952e-05,  ...,  7.9346e-05,\n",
      "         -3.5890e-05, -4.5509e-02],\n",
      "        [-2.8748e-03,  1.1260e-03,  9.1316e-04,  ..., -2.5588e-07,\n",
      "          9.4260e-03, -5.7298e-02],\n",
      "        [ 2.9062e-03, -4.1429e-03, -2.4980e-03,  ..., -6.1879e-04,\n",
      "         -2.1915e-02,  3.9286e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-5.2203e-03,  2.6224e-03, -3.5017e-03,  ...,  1.9123e-04,\n",
      "         -2.2306e-03, -6.6651e-03],\n",
      "        [ 9.3021e-03, -2.7380e-04, -2.2468e-06,  ...,  6.8581e-05,\n",
      "         -3.4020e-04, -8.7434e-03],\n",
      "        [ 3.9530e-03, -4.6981e-03,  2.3124e-03,  ...,  3.3853e-05,\n",
      "         -7.8970e-04, -7.9641e-02],\n",
      "        ...,\n",
      "        [ 3.2909e-03, -9.2765e-05, -4.8200e-06,  ..., -2.0962e-04,\n",
      "         -2.0754e-05, -4.3683e-02],\n",
      "        [-2.8494e-03,  1.3159e-03, -3.2136e-04,  ...,  7.9582e-06,\n",
      "          9.0631e-03, -5.6669e-02],\n",
      "        [ 2.8183e-03, -3.8320e-03,  6.1979e-04,  ..., -7.1245e-04,\n",
      "         -2.1133e-02,  3.8975e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.3071e+01, -2.1265e+01, -1.2382e+01,  ..., -4.6492e-06,\n",
      "         -3.0380e+01, -1.4668e+01],\n",
      "        [-9.0514e+00, -1.5318e+01, -5.7669e+00,  ..., -1.8202e+01,\n",
      "         -4.3737e+00, -1.2158e+01],\n",
      "        [-3.2825e+01, -1.8260e+01, -1.9073e-05,  ..., -1.1036e+01,\n",
      "         -1.3982e+01, -1.3435e+01],\n",
      "        ...,\n",
      "        [-7.5407e+00, -1.6174e+01, -5.0397e+00,  ..., -1.0495e+01,\n",
      "         -1.0622e+01, -7.8387e-03],\n",
      "        [-2.0822e-03, -2.7157e+01, -1.6434e+01,  ..., -2.6749e+01,\n",
      "         -1.4615e+01, -7.5196e+00],\n",
      "        [-2.4656e+01, -1.0683e+01, -1.0059e+01,  ..., -7.3669e-05,\n",
      "         -1.7495e+01, -1.1744e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0106 loss_train: 0.0233 acc_train: 1.0000 loss_val: 1.4332 acc_val: 0.7467 time: 0.6683s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-5.2203e-03,  2.6224e-03, -3.5017e-03,  ...,  1.9123e-04,\n",
      "         -2.2306e-03, -6.6651e-03],\n",
      "        [ 9.3021e-03, -2.7380e-04, -2.2468e-06,  ...,  6.8581e-05,\n",
      "         -3.4020e-04, -8.7434e-03],\n",
      "        [ 3.9530e-03, -4.6981e-03,  2.3124e-03,  ...,  3.3853e-05,\n",
      "         -7.8970e-04, -7.9641e-02],\n",
      "        ...,\n",
      "        [ 3.2909e-03, -9.2765e-05, -4.8200e-06,  ..., -2.0962e-04,\n",
      "         -2.0754e-05, -4.3683e-02],\n",
      "        [-2.8494e-03,  1.3159e-03, -3.2136e-04,  ...,  7.9582e-06,\n",
      "          9.0631e-03, -5.6669e-02],\n",
      "        [ 2.8183e-03, -3.8320e-03,  6.1979e-04,  ..., -7.1245e-04,\n",
      "         -2.1133e-02,  3.8975e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-4.9879e-03,  2.6058e-03, -4.7963e-03,  ...,  1.9201e-04,\n",
      "         -2.0725e-03, -6.5988e-03],\n",
      "        [ 8.5401e-03, -1.7228e-04, -1.9015e-05,  ...,  4.9228e-05,\n",
      "         -2.6886e-04, -8.5108e-03],\n",
      "        [ 4.2931e-03, -4.3814e-03,  2.2180e-03,  ...,  4.9882e-06,\n",
      "         -8.1160e-04, -7.8784e-02],\n",
      "        ...,\n",
      "        [ 3.7261e-03, -8.6191e-05,  3.0932e-05,  ..., -4.3565e-04,\n",
      "         -5.4209e-06, -4.1791e-02],\n",
      "        [-2.8105e-03,  1.4609e-03, -1.4247e-03,  ...,  1.4976e-05,\n",
      "          8.6487e-03, -5.5942e-02],\n",
      "        [ 2.7425e-03, -3.5177e-03,  3.4321e-03,  ..., -7.6070e-04,\n",
      "         -2.0343e-02,  3.8674e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.2700e+01, -2.1438e+01, -1.2613e+01,  ..., -3.9339e-06,\n",
      "         -3.0512e+01, -1.4328e+01],\n",
      "        [-8.4927e+00, -1.6314e+01, -6.1476e+00,  ..., -1.8849e+01,\n",
      "         -5.2215e+00, -1.1602e+01],\n",
      "        [-3.2108e+01, -1.8392e+01, -2.3722e-05,  ..., -1.0876e+01,\n",
      "         -1.4075e+01, -1.2682e+01],\n",
      "        ...,\n",
      "        [-7.4865e+00, -1.7155e+01, -5.7244e+00,  ..., -1.1224e+01,\n",
      "         -1.1364e+01, -4.3581e-03],\n",
      "        [-1.5726e-03, -2.8037e+01, -1.7034e+01,  ..., -2.7479e+01,\n",
      "         -1.5351e+01, -7.6309e+00],\n",
      "        [-2.4262e+01, -1.1023e+01, -1.0064e+01,  ..., -7.3788e-05,\n",
      "         -1.7641e+01, -1.1113e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0107 loss_train: 0.0210 acc_train: 1.0000 loss_val: 1.3600 acc_val: 0.7600 time: 0.6303s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-4.9879e-03,  2.6058e-03, -4.7963e-03,  ...,  1.9201e-04,\n",
      "         -2.0725e-03, -6.5988e-03],\n",
      "        [ 8.5401e-03, -1.7228e-04, -1.9015e-05,  ...,  4.9228e-05,\n",
      "         -2.6886e-04, -8.5108e-03],\n",
      "        [ 4.2931e-03, -4.3814e-03,  2.2180e-03,  ...,  4.9882e-06,\n",
      "         -8.1160e-04, -7.8784e-02],\n",
      "        ...,\n",
      "        [ 3.7261e-03, -8.6191e-05,  3.0932e-05,  ..., -4.3565e-04,\n",
      "         -5.4209e-06, -4.1791e-02],\n",
      "        [-2.8105e-03,  1.4609e-03, -1.4247e-03,  ...,  1.4976e-05,\n",
      "          8.6487e-03, -5.5942e-02],\n",
      "        [ 2.7425e-03, -3.5177e-03,  3.4321e-03,  ..., -7.6070e-04,\n",
      "         -2.0343e-02,  3.8674e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-4.7549e-03,  2.5365e-03, -5.7119e-03,  ...,  1.7875e-04,\n",
      "         -1.9154e-03, -6.5108e-03],\n",
      "        [ 7.6070e-03, -7.2843e-05, -2.9317e-05,  ...,  2.0477e-05,\n",
      "         -1.8839e-04, -8.2382e-03],\n",
      "        [ 4.5297e-03, -3.8674e-03,  2.0537e-03,  ..., -2.2783e-05,\n",
      "         -8.1627e-04, -7.7853e-02],\n",
      "        ...,\n",
      "        [ 3.8754e-03, -5.8840e-05,  5.5112e-05,  ..., -5.6630e-04,\n",
      "          8.8773e-06, -3.9844e-02],\n",
      "        [-2.7622e-03,  1.5621e-03, -2.3636e-03,  ...,  2.0545e-05,\n",
      "          8.2394e-03, -5.5143e-02],\n",
      "        [ 2.6694e-03, -3.2029e-03,  5.9328e-03,  ..., -7.6522e-04,\n",
      "         -1.9537e-02,  3.8381e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.2897e+01, -2.1289e+01, -1.2826e+01,  ..., -3.0994e-06,\n",
      "         -3.0472e+01, -1.4775e+01],\n",
      "        [-8.7505e+00, -1.6676e+01, -6.2671e+00,  ..., -1.9142e+01,\n",
      "         -5.5137e+00, -1.1753e+01],\n",
      "        [-3.2150e+01, -1.8256e+01, -2.8848e-05,  ..., -1.0639e+01,\n",
      "         -1.4065e+01, -1.2725e+01],\n",
      "        ...,\n",
      "        [-7.5146e+00, -1.7305e+01, -5.7409e+00,  ..., -1.1287e+01,\n",
      "         -1.1459e+01, -4.3148e-03],\n",
      "        [-1.5951e-03, -2.8266e+01, -1.7156e+01,  ..., -2.7675e+01,\n",
      "         -1.5563e+01, -7.6742e+00],\n",
      "        [-2.4580e+01, -1.1006e+01, -1.0202e+01,  ..., -6.4729e-05,\n",
      "         -1.7691e+01, -1.1415e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0108 loss_train: 0.0253 acc_train: 0.9929 loss_val: 1.3669 acc_val: 0.7600 time: 0.7494s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-4.7549e-03,  2.5365e-03, -5.7119e-03,  ...,  1.7875e-04,\n",
      "         -1.9154e-03, -6.5108e-03],\n",
      "        [ 7.6070e-03, -7.2843e-05, -2.9317e-05,  ...,  2.0477e-05,\n",
      "         -1.8839e-04, -8.2382e-03],\n",
      "        [ 4.5297e-03, -3.8674e-03,  2.0537e-03,  ..., -2.2783e-05,\n",
      "         -8.1627e-04, -7.7853e-02],\n",
      "        ...,\n",
      "        [ 3.8754e-03, -5.8840e-05,  5.5112e-05,  ..., -5.6630e-04,\n",
      "          8.8773e-06, -3.9844e-02],\n",
      "        [-2.7622e-03,  1.5621e-03, -2.3636e-03,  ...,  2.0545e-05,\n",
      "          8.2394e-03, -5.5143e-02],\n",
      "        [ 2.6694e-03, -3.2029e-03,  5.9328e-03,  ..., -7.6522e-04,\n",
      "         -1.9537e-02,  3.8381e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-4.5075e-03,  2.4209e-03, -6.2348e-03,  ...,  1.5368e-04,\n",
      "         -1.7601e-03, -6.2611e-03],\n",
      "        [ 6.5449e-03,  2.0318e-05, -3.1099e-05,  ..., -1.0225e-05,\n",
      "         -1.0438e-04, -7.8620e-03],\n",
      "        [ 4.6682e-03, -3.2007e-03,  1.8317e-03,  ..., -4.0250e-05,\n",
      "         -8.0521e-04, -7.6820e-02],\n",
      "        ...,\n",
      "        [ 3.7551e-03, -1.9420e-05,  6.2381e-05,  ..., -5.8890e-04,\n",
      "          2.1317e-05, -3.7856e-02],\n",
      "        [-2.7050e-03,  1.6216e-03, -3.1189e-03,  ...,  2.4510e-05,\n",
      "          7.9750e-03, -5.4295e-02],\n",
      "        [ 2.6020e-03, -2.8904e-03,  8.1200e-03,  ..., -7.2978e-04,\n",
      "         -1.8723e-02,  3.8161e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.3781e+01, -2.1173e+01, -1.3332e+01,  ..., -1.7881e-06,\n",
      "         -3.0710e+01, -1.5813e+01],\n",
      "        [-9.3233e+00, -1.5998e+01, -5.8013e+00,  ..., -1.8542e+01,\n",
      "         -5.0453e+00, -1.1993e+01],\n",
      "        [-3.2957e+01, -1.7763e+01, -5.4477e-05,  ..., -9.8780e+00,\n",
      "         -1.4158e+01, -1.3200e+01],\n",
      "        ...,\n",
      "        [-7.8961e+00, -1.6827e+01, -5.3709e+00,  ..., -1.0615e+01,\n",
      "         -1.1246e+01, -5.5598e-03],\n",
      "        [-1.7729e-03, -2.7799e+01, -1.6838e+01,  ..., -2.7186e+01,\n",
      "         -1.5323e+01, -7.5412e+00],\n",
      "        [-2.5684e+01, -1.0984e+01, -1.0699e+01,  ..., -4.3510e-05,\n",
      "         -1.8054e+01, -1.2443e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0109 loss_train: 0.0312 acc_train: 0.9857 loss_val: 1.3918 acc_val: 0.7600 time: 0.6800s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-4.5075e-03,  2.4209e-03, -6.2348e-03,  ...,  1.5368e-04,\n",
      "         -1.7601e-03, -6.2611e-03],\n",
      "        [ 6.5449e-03,  2.0318e-05, -3.1099e-05,  ..., -1.0225e-05,\n",
      "         -1.0438e-04, -7.8620e-03],\n",
      "        [ 4.6682e-03, -3.2007e-03,  1.8317e-03,  ..., -4.0250e-05,\n",
      "         -8.0521e-04, -7.6820e-02],\n",
      "        ...,\n",
      "        [ 3.7551e-03, -1.9420e-05,  6.2381e-05,  ..., -5.8890e-04,\n",
      "          2.1317e-05, -3.7856e-02],\n",
      "        [-2.7050e-03,  1.6216e-03, -3.1189e-03,  ...,  2.4510e-05,\n",
      "          7.9750e-03, -5.4295e-02],\n",
      "        [ 2.6020e-03, -2.8904e-03,  8.1200e-03,  ..., -7.2978e-04,\n",
      "         -1.8723e-02,  3.8161e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-4.2577e-03,  2.2656e-03, -6.3704e-03,  ...,  1.1973e-04,\n",
      "         -1.6077e-03, -6.0109e-03],\n",
      "        [ 5.3957e-03,  1.0366e-04, -2.4678e-05,  ..., -3.5632e-05,\n",
      "         -2.2157e-05, -7.5063e-03],\n",
      "        [ 4.7154e-03, -2.4300e-03,  1.5651e-03,  ..., -4.2470e-05,\n",
      "         -7.8005e-04, -7.5746e-02],\n",
      "        ...,\n",
      "        [ 3.3978e-03,  2.1098e-05,  5.2351e-05,  ..., -5.0971e-04,\n",
      "          3.0840e-05, -3.5846e-02],\n",
      "        [-2.6381e-03,  1.6418e-03, -3.6780e-03,  ...,  2.6810e-05,\n",
      "          7.7402e-03, -5.3401e-02],\n",
      "        [ 2.5398e-03, -2.5823e-03,  1.0003e-02,  ..., -6.5984e-04,\n",
      "         -1.7923e-02,  3.7914e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.4628e+01, -2.0890e+01, -1.3738e+01,  ..., -1.0729e-06,\n",
      "         -3.0732e+01, -1.6897e+01],\n",
      "        [-1.0054e+01, -1.5114e+01, -5.2699e+00,  ..., -1.7831e+01,\n",
      "         -4.3580e+00, -1.2392e+01],\n",
      "        [-3.3768e+01, -1.7164e+01, -1.1086e-04,  ..., -9.1268e+00,\n",
      "         -1.4132e+01, -1.3755e+01],\n",
      "        ...,\n",
      "        [-8.2440e+00, -1.6073e+01, -4.8124e+00,  ..., -9.7460e+00,\n",
      "         -1.0782e+01, -9.0375e-03],\n",
      "        [-2.1293e-03, -2.7174e+01, -1.6400e+01,  ..., -2.6577e+01,\n",
      "         -1.4919e+01, -7.3867e+00],\n",
      "        [-2.6838e+01, -1.0790e+01, -1.1162e+01,  ..., -3.6001e-05,\n",
      "         -1.8248e+01, -1.3616e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0110 loss_train: 0.0129 acc_train: 1.0000 loss_val: 1.4676 acc_val: 0.7567 time: 0.6574s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-4.2577e-03,  2.2656e-03, -6.3704e-03,  ...,  1.1973e-04,\n",
      "         -1.6077e-03, -6.0109e-03],\n",
      "        [ 5.3957e-03,  1.0366e-04, -2.4678e-05,  ..., -3.5632e-05,\n",
      "         -2.2157e-05, -7.5063e-03],\n",
      "        [ 4.7154e-03, -2.4300e-03,  1.5651e-03,  ..., -4.2470e-05,\n",
      "         -7.8005e-04, -7.5746e-02],\n",
      "        ...,\n",
      "        [ 3.3978e-03,  2.1098e-05,  5.2351e-05,  ..., -5.0971e-04,\n",
      "          3.0840e-05, -3.5846e-02],\n",
      "        [-2.6381e-03,  1.6418e-03, -3.6780e-03,  ...,  2.6810e-05,\n",
      "          7.7402e-03, -5.3401e-02],\n",
      "        [ 2.5398e-03, -2.5823e-03,  1.0003e-02,  ..., -6.5984e-04,\n",
      "         -1.7923e-02,  3.7914e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-4.0080e-03,  2.0773e-03, -6.1467e-03,  ...,  8.0185e-05,\n",
      "         -1.4588e-03, -5.7653e-03],\n",
      "        [ 4.2001e-03,  1.7438e-04, -1.2469e-05,  ..., -5.0347e-05,\n",
      "          5.3534e-05, -7.1476e-03],\n",
      "        [ 4.6789e-03, -1.6051e-03,  1.2676e-03,  ..., -3.0085e-05,\n",
      "         -7.4254e-04, -7.4660e-02],\n",
      "        ...,\n",
      "        [ 2.8491e-03,  5.2423e-05,  2.9281e-05,  ..., -3.5055e-04,\n",
      "          3.6964e-05, -3.3823e-02],\n",
      "        [-2.5636e-03,  1.6260e-03, -4.0201e-03,  ...,  2.7477e-05,\n",
      "          7.6312e-03, -5.2480e-02],\n",
      "        [ 2.4910e-03, -2.2811e-03,  1.1596e-02,  ..., -5.6218e-04,\n",
      "         -1.7145e-02,  3.7650e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.4777e+01, -2.0495e+01, -1.3750e+01,  ..., -1.0729e-06,\n",
      "         -3.0141e+01, -1.7408e+01],\n",
      "        [-1.0442e+01, -1.4751e+01, -5.0208e+00,  ..., -1.7546e+01,\n",
      "         -3.9168e+00, -1.2648e+01],\n",
      "        [-3.4023e+01, -1.6872e+01, -1.5210e-04,  ..., -8.8043e+00,\n",
      "         -1.3848e+01, -1.4009e+01],\n",
      "        ...,\n",
      "        [-8.3120e+00, -1.5644e+01, -4.4581e+00,  ..., -9.3128e+00,\n",
      "         -1.0396e+01, -1.2649e-02],\n",
      "        [-2.1784e-03, -2.7070e+01, -1.6294e+01,  ..., -2.6455e+01,\n",
      "         -1.4801e+01, -7.3649e+00],\n",
      "        [-2.7298e+01, -1.0531e+01, -1.1255e+01,  ..., -4.0292e-05,\n",
      "         -1.7884e+01, -1.4214e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0111 loss_train: 0.0181 acc_train: 1.0000 loss_val: 1.5325 acc_val: 0.7633 time: 0.6276s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-4.0080e-03,  2.0773e-03, -6.1467e-03,  ...,  8.0185e-05,\n",
      "         -1.4588e-03, -5.7653e-03],\n",
      "        [ 4.2001e-03,  1.7438e-04, -1.2469e-05,  ..., -5.0347e-05,\n",
      "          5.3534e-05, -7.1476e-03],\n",
      "        [ 4.6789e-03, -1.6051e-03,  1.2676e-03,  ..., -3.0085e-05,\n",
      "         -7.4254e-04, -7.4660e-02],\n",
      "        ...,\n",
      "        [ 2.8491e-03,  5.2423e-05,  2.9281e-05,  ..., -3.5055e-04,\n",
      "          3.6964e-05, -3.3823e-02],\n",
      "        [-2.5636e-03,  1.6260e-03, -4.0201e-03,  ...,  2.7477e-05,\n",
      "          7.6312e-03, -5.2480e-02],\n",
      "        [ 2.4910e-03, -2.2811e-03,  1.1596e-02,  ..., -5.6218e-04,\n",
      "         -1.7145e-02,  3.7650e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-3.7600e-03,  1.8630e-03, -5.6119e-03,  ...,  3.8481e-05,\n",
      "         -1.3137e-03, -5.5482e-03],\n",
      "        [ 2.9968e-03,  2.3047e-04,  1.8226e-06,  ..., -5.1928e-05,\n",
      "          1.1874e-04, -6.8653e-03],\n",
      "        [ 4.5684e-03, -7.7410e-04,  9.5259e-04,  ..., -8.6415e-06,\n",
      "         -6.9451e-04, -7.3585e-02],\n",
      "        ...,\n",
      "        [ 2.1627e-03,  6.7477e-05,  5.5176e-07,  ..., -1.4614e-04,\n",
      "          3.9506e-05, -3.1801e-02],\n",
      "        [-2.4821e-03,  1.5778e-03, -4.1847e-03,  ...,  2.6625e-05,\n",
      "          7.4664e-03, -5.1536e-02],\n",
      "        [ 2.4351e-03, -1.9885e-03,  1.2893e-02,  ..., -4.4440e-04,\n",
      "         -1.6423e-02,  3.7344e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.3571e+01, -2.0308e+01, -1.3340e+01,  ..., -1.7881e-06,\n",
      "         -2.9349e+01, -1.6499e+01],\n",
      "        [-9.5240e+00, -1.5803e+01, -5.4122e+00,  ..., -1.8195e+01,\n",
      "         -4.6900e+00, -1.1865e+01],\n",
      "        [-3.2892e+01, -1.7251e+01, -1.2421e-04,  ..., -9.0233e+00,\n",
      "         -1.3745e+01, -1.3070e+01],\n",
      "        ...,\n",
      "        [-8.0053e+00, -1.6709e+01, -5.2678e+00,  ..., -1.0270e+01,\n",
      "         -1.1132e+01, -5.9762e-03],\n",
      "        [-1.4159e-03, -2.8066e+01, -1.7000e+01,  ..., -2.7251e+01,\n",
      "         -1.5568e+01, -7.4919e+00],\n",
      "        [-2.6295e+01, -1.0584e+01, -1.0850e+01,  ..., -4.6491e-05,\n",
      "         -1.7336e+01, -1.3230e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0112 loss_train: 0.0261 acc_train: 0.9929 loss_val: 1.4387 acc_val: 0.7600 time: 0.6345s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-3.7600e-03,  1.8630e-03, -5.6119e-03,  ...,  3.8481e-05,\n",
      "         -1.3137e-03, -5.5482e-03],\n",
      "        [ 2.9968e-03,  2.3047e-04,  1.8226e-06,  ..., -5.1928e-05,\n",
      "          1.1874e-04, -6.8653e-03],\n",
      "        [ 4.5684e-03, -7.7410e-04,  9.5259e-04,  ..., -8.6415e-06,\n",
      "         -6.9451e-04, -7.3585e-02],\n",
      "        ...,\n",
      "        [ 2.1627e-03,  6.7477e-05,  5.5176e-07,  ..., -1.4614e-04,\n",
      "          3.9506e-05, -3.1801e-02],\n",
      "        [-2.4821e-03,  1.5778e-03, -4.1847e-03,  ...,  2.6625e-05,\n",
      "          7.4664e-03, -5.1536e-02],\n",
      "        [ 2.4351e-03, -1.9885e-03,  1.2893e-02,  ..., -4.4440e-04,\n",
      "         -1.6423e-02,  3.7344e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-3.5134e-03,  1.6296e-03, -4.8235e-03,  ..., -2.0956e-06,\n",
      "         -1.1742e-03, -5.3187e-03],\n",
      "        [ 1.8210e-03,  2.7076e-04,  1.4268e-05,  ..., -4.1207e-05,\n",
      "          1.7049e-04, -6.7079e-03],\n",
      "        [ 4.3911e-03,  1.8443e-05,  6.3305e-04,  ...,  1.3704e-05,\n",
      "         -6.3782e-04, -7.2544e-02],\n",
      "        ...,\n",
      "        [ 1.3971e-03,  6.3928e-05, -2.5574e-05,  ...,  6.4038e-05,\n",
      "          3.8587e-05, -2.9802e-02],\n",
      "        [-2.3951e-03,  1.5011e-03, -4.0750e-03,  ...,  2.4438e-05,\n",
      "          7.2980e-03, -5.0599e-02],\n",
      "        [ 2.3694e-03, -1.7062e-03,  1.3901e-02,  ..., -3.1450e-04,\n",
      "         -1.5780e-02,  3.6980e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.0662e+01, -2.0437e+01, -1.2584e+01,  ..., -4.5299e-06,\n",
      "         -2.8489e+01, -1.3768e+01],\n",
      "        [-6.9096e+00, -1.7651e+01, -6.1833e+00,  ..., -1.9195e+01,\n",
      "         -6.2302e+00, -9.6758e+00],\n",
      "        [-2.9952e+01, -1.8153e+01, -1.0383e-04,  ..., -9.5228e+00,\n",
      "         -1.3771e+01, -1.0464e+01],\n",
      "        ...,\n",
      "        [-7.3102e+00, -1.9071e+01, -7.1706e+00,  ..., -1.2402e+01,\n",
      "         -1.2766e+01, -1.6002e-03],\n",
      "        [-6.8403e-04, -3.0114e+01, -1.8493e+01,  ..., -2.8896e+01,\n",
      "         -1.7137e+01, -7.7227e+00],\n",
      "        [-2.3341e+01, -1.1048e+01, -9.9068e+00,  ..., -1.0478e-04,\n",
      "         -1.6662e+01, -1.0152e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0113 loss_train: 0.0336 acc_train: 0.9929 loss_val: 1.2574 acc_val: 0.7733 time: 0.6612s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-3.5134e-03,  1.6296e-03, -4.8235e-03,  ..., -2.0956e-06,\n",
      "         -1.1742e-03, -5.3187e-03],\n",
      "        [ 1.8210e-03,  2.7076e-04,  1.4268e-05,  ..., -4.1207e-05,\n",
      "          1.7049e-04, -6.7079e-03],\n",
      "        [ 4.3911e-03,  1.8443e-05,  6.3305e-04,  ...,  1.3704e-05,\n",
      "         -6.3782e-04, -7.2544e-02],\n",
      "        ...,\n",
      "        [ 1.3971e-03,  6.3928e-05, -2.5574e-05,  ...,  6.4038e-05,\n",
      "          3.8587e-05, -2.9802e-02],\n",
      "        [-2.3951e-03,  1.5011e-03, -4.0750e-03,  ...,  2.4438e-05,\n",
      "          7.2980e-03, -5.0599e-02],\n",
      "        [ 2.3694e-03, -1.7062e-03,  1.3901e-02,  ..., -3.1450e-04,\n",
      "         -1.5780e-02,  3.6980e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-3.2641e-03,  1.3837e-03, -3.8477e-03,  ..., -3.8628e-05,\n",
      "         -1.0345e-03, -5.0522e-03],\n",
      "        [ 7.0441e-04,  2.9487e-04,  2.1766e-05,  ..., -2.1827e-05,\n",
      "          2.0687e-04, -6.5354e-03],\n",
      "        [ 4.1558e-03,  7.3408e-04,  3.2096e-04,  ...,  2.9198e-05,\n",
      "         -5.7432e-04, -7.1429e-02],\n",
      "        ...,\n",
      "        [ 6.1071e-04,  4.4384e-05, -4.2261e-05,  ...,  2.4292e-04,\n",
      "          3.4600e-05, -2.7806e-02],\n",
      "        [-2.3026e-03,  1.4002e-03, -3.8031e-03,  ...,  2.1155e-05,\n",
      "          7.0558e-03, -4.9619e-02],\n",
      "        [ 2.3095e-03, -1.4358e-03,  1.4638e-02,  ..., -1.8041e-04,\n",
      "         -1.5030e-02,  3.6642e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.9856e+01, -1.9737e+01, -1.2263e+01,  ..., -6.0797e-06,\n",
      "         -2.7612e+01, -1.3568e+01],\n",
      "        [-6.7454e+00, -1.7826e+01, -6.4443e+00,  ..., -1.9380e+01,\n",
      "         -6.3546e+00, -9.6599e+00],\n",
      "        [-2.9137e+01, -1.7935e+01, -1.1658e-04,  ..., -9.5490e+00,\n",
      "         -1.3415e+01, -1.0082e+01],\n",
      "        ...,\n",
      "        [-6.9708e+00, -1.9005e+01, -7.2883e+00,  ..., -1.2498e+01,\n",
      "         -1.2620e+01, -1.8158e-03],\n",
      "        [-6.6628e-04, -3.0187e+01, -1.8612e+01,  ..., -2.8939e+01,\n",
      "         -1.7164e+01, -7.7373e+00],\n",
      "        [-2.2995e+01, -1.0535e+01, -9.6995e+00,  ..., -1.2612e-04,\n",
      "         -1.6029e+01, -1.0176e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0114 loss_train: 0.0465 acc_train: 0.9786 loss_val: 1.2616 acc_val: 0.7767 time: 0.9275s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-3.2641e-03,  1.3837e-03, -3.8477e-03,  ..., -3.8628e-05,\n",
      "         -1.0345e-03, -5.0522e-03],\n",
      "        [ 7.0441e-04,  2.9487e-04,  2.1766e-05,  ..., -2.1827e-05,\n",
      "          2.0687e-04, -6.5354e-03],\n",
      "        [ 4.1558e-03,  7.3408e-04,  3.2096e-04,  ...,  2.9198e-05,\n",
      "         -5.7432e-04, -7.1429e-02],\n",
      "        ...,\n",
      "        [ 6.1071e-04,  4.4384e-05, -4.2261e-05,  ...,  2.4292e-04,\n",
      "          3.4600e-05, -2.7806e-02],\n",
      "        [-2.3026e-03,  1.4002e-03, -3.8031e-03,  ...,  2.1155e-05,\n",
      "          7.0558e-03, -4.9619e-02],\n",
      "        [ 2.3095e-03, -1.4358e-03,  1.4638e-02,  ..., -1.8041e-04,\n",
      "         -1.5030e-02,  3.6642e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-3.0213e-03,  1.1316e-03, -2.7595e-03,  ..., -6.8755e-05,\n",
      "         -9.0087e-04, -4.7760e-03],\n",
      "        [-3.2601e-04,  3.0320e-04,  2.2791e-05,  ...,  8.4968e-07,\n",
      "          2.2708e-04, -6.3541e-03],\n",
      "        [ 3.8715e-03,  1.3417e-03,  2.6970e-05,  ...,  3.3127e-05,\n",
      "         -5.0584e-04, -7.0246e-02],\n",
      "        ...,\n",
      "        [-1.4165e-04,  1.5320e-05, -4.5834e-05,  ...,  3.6215e-04,\n",
      "          2.8151e-05, -2.5835e-02],\n",
      "        [-2.2038e-03,  1.2794e-03, -3.5108e-03,  ...,  1.7051e-05,\n",
      "          6.8093e-03, -4.8596e-02],\n",
      "        [ 2.2383e-03, -1.1784e-03,  1.5095e-02,  ..., -4.9577e-05,\n",
      "         -1.4264e-02,  3.6311e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.0441e+01, -1.8818e+01, -1.2353e+01,  ..., -4.6492e-06,\n",
      "         -2.7153e+01, -1.4718e+01],\n",
      "        [-7.9922e+00, -1.6966e+01, -6.2481e+00,  ..., -1.8921e+01,\n",
      "         -5.7408e+00, -1.0653e+01],\n",
      "        [-2.9766e+01, -1.7146e+01, -1.3041e-04,  ..., -9.1410e+00,\n",
      "         -1.3088e+01, -1.0853e+01],\n",
      "        ...,\n",
      "        [-7.1048e+00, -1.7914e+01, -6.6816e+00,  ..., -1.1568e+01,\n",
      "         -1.1911e+01, -2.3736e-03],\n",
      "        [-9.5989e-04, -2.9074e+01, -1.7897e+01,  ..., -2.7956e+01,\n",
      "         -1.6372e+01, -7.5061e+00],\n",
      "        [-2.4371e+01, -9.7234e+00, -1.0099e+01,  ..., -1.0776e-04,\n",
      "         -1.5845e+01, -1.1912e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0115 loss_train: 0.0332 acc_train: 0.9857 loss_val: 1.3285 acc_val: 0.7733 time: 0.8721s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-3.0213e-03,  1.1316e-03, -2.7595e-03,  ..., -6.8755e-05,\n",
      "         -9.0087e-04, -4.7760e-03],\n",
      "        [-3.2601e-04,  3.0320e-04,  2.2791e-05,  ...,  8.4968e-07,\n",
      "          2.2708e-04, -6.3541e-03],\n",
      "        [ 3.8715e-03,  1.3417e-03,  2.6970e-05,  ...,  3.3127e-05,\n",
      "         -5.0584e-04, -7.0246e-02],\n",
      "        ...,\n",
      "        [-1.4165e-04,  1.5320e-05, -4.5834e-05,  ...,  3.6215e-04,\n",
      "          2.8151e-05, -2.5835e-02],\n",
      "        [-2.2038e-03,  1.2794e-03, -3.5108e-03,  ...,  1.7051e-05,\n",
      "          6.8093e-03, -4.8596e-02],\n",
      "        [ 2.2383e-03, -1.1784e-03,  1.5095e-02,  ..., -4.9577e-05,\n",
      "         -1.4264e-02,  3.6311e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-2.7840e-03,  8.7924e-04, -1.6176e-03,  ..., -9.0799e-05,\n",
      "         -7.7368e-04, -4.4978e-03],\n",
      "        [-1.2480e-03,  2.9682e-04,  1.7665e-05,  ...,  2.1151e-05,\n",
      "          2.3136e-04, -6.1593e-03],\n",
      "        [ 3.5479e-03,  1.8187e-03, -2.3983e-04,  ...,  2.5189e-05,\n",
      "         -4.3414e-04, -6.9010e-02],\n",
      "        ...,\n",
      "        [-8.1224e-04, -1.4907e-05, -3.6520e-05,  ...,  4.0628e-04,\n",
      "          1.9996e-05, -2.3898e-02],\n",
      "        [-2.1031e-03,  1.1429e-03, -2.8025e-03,  ...,  1.2421e-05,\n",
      "          6.5210e-03, -4.7548e-02],\n",
      "        [ 2.1707e-03, -9.3501e-04,  1.5378e-02,  ...,  7.1357e-05,\n",
      "         -1.3429e-02,  3.6010e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.1498e+01, -1.8120e+01, -1.2874e+01,  ..., -2.7418e-06,\n",
      "         -2.7225e+01, -1.6194e+01],\n",
      "        [-9.1568e+00, -1.5716e+01, -5.8475e+00,  ..., -1.8058e+01,\n",
      "         -4.9518e+00, -1.1463e+01],\n",
      "        [-3.0463e+01, -1.6062e+01, -2.7522e-04,  ..., -8.2508e+00,\n",
      "         -1.2853e+01, -1.1513e+01],\n",
      "        ...,\n",
      "        [-7.4472e+00, -1.6528e+01, -5.9230e+00,  ..., -1.0214e+01,\n",
      "         -1.1084e+01, -3.6996e-03],\n",
      "        [-1.4890e-03, -2.7720e+01, -1.7054e+01,  ..., -2.6715e+01,\n",
      "         -1.5476e+01, -7.1894e+00],\n",
      "        [-2.6023e+01, -9.0806e+00, -1.0779e+01,  ..., -1.3589e-04,\n",
      "         -1.6096e+01, -1.3789e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0116 loss_train: 0.0126 acc_train: 1.0000 loss_val: 1.4431 acc_val: 0.7633 time: 0.6605s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-2.7840e-03,  8.7924e-04, -1.6176e-03,  ..., -9.0799e-05,\n",
      "         -7.7368e-04, -4.4978e-03],\n",
      "        [-1.2480e-03,  2.9682e-04,  1.7665e-05,  ...,  2.1151e-05,\n",
      "          2.3136e-04, -6.1593e-03],\n",
      "        [ 3.5479e-03,  1.8187e-03, -2.3983e-04,  ...,  2.5189e-05,\n",
      "         -4.3414e-04, -6.9010e-02],\n",
      "        ...,\n",
      "        [-8.1224e-04, -1.4907e-05, -3.6520e-05,  ...,  4.0628e-04,\n",
      "          1.9996e-05, -2.3898e-02],\n",
      "        [-2.1031e-03,  1.1429e-03, -2.8025e-03,  ...,  1.2421e-05,\n",
      "          6.5210e-03, -4.7548e-02],\n",
      "        [ 2.1707e-03, -9.3501e-04,  1.5378e-02,  ...,  7.1357e-05,\n",
      "         -1.3429e-02,  3.6010e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-2.5783e-03,  6.3202e-04, -4.9610e-04,  ..., -1.0384e-04,\n",
      "         -6.5327e-04, -4.2486e-03],\n",
      "        [-2.0443e-03,  2.7736e-04,  8.3186e-06,  ...,  3.4464e-05,\n",
      "          2.2091e-04, -5.9401e-03],\n",
      "        [ 3.1941e-03,  2.1514e-03, -4.7214e-04,  ...,  9.2371e-06,\n",
      "         -3.6086e-04, -6.8009e-02],\n",
      "        ...,\n",
      "        [-1.3630e-03, -3.8374e-05, -1.8058e-05,  ...,  3.7443e-04,\n",
      "          1.0965e-05, -2.1999e-02],\n",
      "        [-1.9924e-03,  9.9512e-04, -2.1038e-03,  ...,  7.5612e-06,\n",
      "          6.2381e-03, -4.6532e-02],\n",
      "        [ 2.0549e-03, -7.0654e-04,  1.5436e-02,  ...,  1.7687e-04,\n",
      "         -1.2624e-02,  3.5640e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.0593e+01, -1.7226e+01, -1.1723e+01,  ..., -8.2254e-06,\n",
      "         -2.5982e+01, -1.5761e+01],\n",
      "        [-9.4508e+00, -1.6401e+01, -6.2048e+00,  ..., -1.8732e+01,\n",
      "         -5.5453e+00, -1.1683e+01],\n",
      "        [-3.0013e+01, -1.6524e+01, -1.1753e-04,  ..., -9.1941e+00,\n",
      "         -1.2794e+01, -1.1534e+01],\n",
      "        ...,\n",
      "        [-7.1679e+00, -1.6532e+01, -5.6823e+00,  ..., -1.0534e+01,\n",
      "         -1.0864e+01, -4.9312e-03],\n",
      "        [-1.7965e-03, -2.7773e+01, -1.6961e+01,  ..., -2.6834e+01,\n",
      "         -1.5451e+01, -7.1933e+00],\n",
      "        [-2.5539e+01, -8.4089e+00, -1.0023e+01,  ..., -2.6866e-04,\n",
      "         -1.5207e+01, -1.3630e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0117 loss_train: 0.0360 acc_train: 0.9929 loss_val: 1.4673 acc_val: 0.7567 time: 0.6838s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-2.5783e-03,  6.3202e-04, -4.9610e-04,  ..., -1.0384e-04,\n",
      "         -6.5327e-04, -4.2486e-03],\n",
      "        [-2.0443e-03,  2.7736e-04,  8.3186e-06,  ...,  3.4464e-05,\n",
      "          2.2091e-04, -5.9401e-03],\n",
      "        [ 3.1941e-03,  2.1514e-03, -4.7214e-04,  ...,  9.2371e-06,\n",
      "         -3.6086e-04, -6.8009e-02],\n",
      "        ...,\n",
      "        [-1.3630e-03, -3.8374e-05, -1.8058e-05,  ...,  3.7443e-04,\n",
      "          1.0965e-05, -2.1999e-02],\n",
      "        [-1.9924e-03,  9.9512e-04, -2.1038e-03,  ...,  7.5612e-06,\n",
      "          6.2381e-03, -4.6532e-02],\n",
      "        [ 2.0549e-03, -7.0654e-04,  1.5436e-02,  ...,  1.7687e-04,\n",
      "         -1.2624e-02,  3.5640e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-2.3779e-03,  3.9475e-04,  5.4879e-04,  ..., -1.0771e-04,\n",
      "         -5.4043e-04, -3.9707e-03],\n",
      "        [-2.7031e-03,  2.4692e-04, -2.3603e-06,  ...,  3.8250e-05,\n",
      "          1.9773e-04, -5.7659e-03],\n",
      "        [ 2.8117e-03,  2.3351e-03, -6.6457e-04,  ..., -8.4167e-06,\n",
      "         -2.8757e-04, -6.6986e-02],\n",
      "        ...,\n",
      "        [-1.7674e-03, -4.9604e-05,  3.6195e-06,  ...,  2.7316e-04,\n",
      "          2.9373e-06, -2.0160e-02],\n",
      "        [-1.8804e-03,  8.4018e-04, -1.3686e-03,  ...,  2.7564e-06,\n",
      "          5.8383e-03, -4.5511e-02],\n",
      "        [ 1.9541e-03, -4.9357e-04,  1.5315e-02,  ...,  2.6272e-04,\n",
      "         -1.1888e-02,  3.5233e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.8238e+01, -1.6755e+01, -9.9912e+00,  ..., -4.6967e-05,\n",
      "         -2.4563e+01, -1.3730e+01],\n",
      "        [-8.3831e+00, -1.8249e+01, -6.9369e+00,  ..., -2.0072e+01,\n",
      "         -7.0805e+00, -1.0771e+01],\n",
      "        [-2.8323e+01, -1.7786e+01, -6.6159e-05,  ..., -1.0656e+01,\n",
      "         -1.3025e+01, -1.0433e+01],\n",
      "        ...,\n",
      "        [-6.5420e+00, -1.7963e+01, -6.3851e+00,  ..., -1.2119e+01,\n",
      "         -1.1633e+01, -3.9465e-03],\n",
      "        [-1.4212e-03, -2.9089e+01, -1.7689e+01,  ..., -2.8031e+01,\n",
      "         -1.6373e+01, -7.3810e+00],\n",
      "        [-2.3302e+01, -8.3765e+00, -8.6107e+00,  ..., -4.2394e-04,\n",
      "         -1.4203e+01, -1.1442e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0118 loss_train: 0.0372 acc_train: 0.9929 loss_val: 1.3882 acc_val: 0.7533 time: 0.6760s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-2.3779e-03,  3.9475e-04,  5.4879e-04,  ..., -1.0771e-04,\n",
      "         -5.4043e-04, -3.9707e-03],\n",
      "        [-2.7031e-03,  2.4692e-04, -2.3603e-06,  ...,  3.8250e-05,\n",
      "          1.9773e-04, -5.7659e-03],\n",
      "        [ 2.8117e-03,  2.3351e-03, -6.6457e-04,  ..., -8.4167e-06,\n",
      "         -2.8757e-04, -6.6986e-02],\n",
      "        ...,\n",
      "        [-1.7674e-03, -4.9604e-05,  3.6195e-06,  ...,  2.7316e-04,\n",
      "          2.9373e-06, -2.0160e-02],\n",
      "        [-1.8804e-03,  8.4018e-04, -1.3686e-03,  ...,  2.7564e-06,\n",
      "          5.8383e-03, -4.5511e-02],\n",
      "        [ 1.9541e-03, -4.9357e-04,  1.5315e-02,  ...,  2.6272e-04,\n",
      "         -1.1888e-02,  3.5233e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-2.1790e-03,  1.7162e-04,  1.4658e-03,  ..., -1.0296e-04,\n",
      "         -4.3588e-04, -3.6900e-03],\n",
      "        [-3.2173e-03,  2.0791e-04, -1.1379e-05,  ...,  3.2475e-05,\n",
      "          1.6443e-04, -5.4295e-03],\n",
      "        [ 2.4166e-03,  2.3735e-03, -8.1365e-04,  ..., -2.1417e-05,\n",
      "         -2.1567e-04, -6.5903e-02],\n",
      "        ...,\n",
      "        [-2.0112e-03, -4.6791e-05,  2.2212e-05,  ...,  1.8599e-04,\n",
      "         -1.6111e-05, -1.8359e-02],\n",
      "        [-1.7652e-03,  6.8201e-04, -6.4583e-04,  ..., -1.7379e-06,\n",
      "          5.4333e-03, -4.4402e-02],\n",
      "        [ 1.8818e-03, -2.9652e-04,  1.5174e-02,  ...,  3.2612e-04,\n",
      "         -1.1123e-02,  3.4909e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.6503e+01, -1.6618e+01, -8.8652e+00,  ..., -1.4662e-04,\n",
      "         -2.3714e+01, -1.2146e+01],\n",
      "        [-7.4240e+00, -1.9371e+01, -7.3362e+00,  ..., -2.0778e+01,\n",
      "         -8.0535e+00, -9.8694e+00],\n",
      "        [-2.6900e+01, -1.8544e+01, -1.2445e-04,  ..., -1.1388e+01,\n",
      "         -1.3217e+01, -9.3694e+00],\n",
      "        ...,\n",
      "        [-6.2179e+00, -1.8909e+01, -6.8639e+00,  ..., -1.3057e+01,\n",
      "         -1.2164e+01, -3.8375e-03],\n",
      "        [-1.2387e-03, -2.9951e+01, -1.8152e+01,  ..., -2.8760e+01,\n",
      "         -1.6997e+01, -7.4291e+00],\n",
      "        [-2.1572e+01, -8.5916e+00, -7.6595e+00,  ..., -7.2489e-04,\n",
      "         -1.3657e+01, -9.6224e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0119 loss_train: 0.0144 acc_train: 1.0000 loss_val: 1.3839 acc_val: 0.7633 time: 0.6567s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-2.1790e-03,  1.7162e-04,  1.4658e-03,  ..., -1.0296e-04,\n",
      "         -4.3588e-04, -3.6900e-03],\n",
      "        [-3.2173e-03,  2.0791e-04, -1.1379e-05,  ...,  3.2475e-05,\n",
      "          1.6443e-04, -5.4295e-03],\n",
      "        [ 2.4166e-03,  2.3735e-03, -8.1365e-04,  ..., -2.1417e-05,\n",
      "         -2.1567e-04, -6.5903e-02],\n",
      "        ...,\n",
      "        [-2.0112e-03, -4.6791e-05,  2.2212e-05,  ...,  1.8599e-04,\n",
      "         -1.6111e-05, -1.8359e-02],\n",
      "        [-1.7652e-03,  6.8201e-04, -6.4583e-04,  ..., -1.7379e-06,\n",
      "          5.4333e-03, -4.4402e-02],\n",
      "        [ 1.8818e-03, -2.9652e-04,  1.5174e-02,  ...,  3.2612e-04,\n",
      "         -1.1123e-02,  3.4909e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-1.9814e-03, -3.3867e-05,  2.2187e-03,  ..., -9.0752e-05,\n",
      "         -3.3651e-04, -3.3734e-03],\n",
      "        [-3.5850e-03,  1.6294e-04, -1.6455e-05,  ...,  1.9412e-05,\n",
      "          1.2401e-04, -5.0515e-03],\n",
      "        [ 2.0171e-03,  2.2779e-03, -9.1782e-04,  ..., -2.5607e-05,\n",
      "         -1.4642e-04, -6.4755e-02],\n",
      "        ...,\n",
      "        [-2.0923e-03, -3.1965e-05,  3.2831e-05,  ...,  7.3902e-05,\n",
      "         -3.1976e-05, -1.6554e-02],\n",
      "        [-1.5874e-03,  5.2427e-04,  8.9346e-04,  ..., -5.7054e-06,\n",
      "          5.0655e-03, -4.3206e-02],\n",
      "        [ 1.9482e-03, -1.1567e-04,  1.5222e-02,  ...,  3.6571e-04,\n",
      "         -1.0446e-02,  3.4778e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.7737e+01, -1.6355e+01, -9.8160e+00,  ..., -5.5431e-05,\n",
      "         -2.4029e+01, -1.3935e+01],\n",
      "        [-7.9507e+00, -1.7894e+01, -6.7833e+00,  ..., -1.9594e+01,\n",
      "         -6.9418e+00, -1.0259e+01],\n",
      "        [-2.7604e+01, -1.7403e+01, -8.6304e-05,  ..., -1.0361e+01,\n",
      "         -1.2673e+01, -1.0197e+01],\n",
      "        ...,\n",
      "        [-6.4072e+00, -1.7695e+01, -6.3191e+00,  ..., -1.1811e+01,\n",
      "         -1.1433e+01, -4.2867e-03],\n",
      "        [-1.5052e-03, -2.8628e+01, -1.7458e+01,  ..., -2.7506e+01,\n",
      "         -1.6079e+01, -7.2274e+00],\n",
      "        [-2.3351e+01, -8.4089e+00, -8.6151e+00,  ..., -4.1452e-04,\n",
      "         -1.4238e+01, -1.1558e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0120 loss_train: 0.0677 acc_train: 0.9929 loss_val: 1.3276 acc_val: 0.7500 time: 0.6780s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-1.9814e-03, -3.3867e-05,  2.2187e-03,  ..., -9.0752e-05,\n",
      "         -3.3651e-04, -3.3734e-03],\n",
      "        [-3.5850e-03,  1.6294e-04, -1.6455e-05,  ...,  1.9412e-05,\n",
      "          1.2401e-04, -5.0515e-03],\n",
      "        [ 2.0171e-03,  2.2779e-03, -9.1782e-04,  ..., -2.5607e-05,\n",
      "         -1.4642e-04, -6.4755e-02],\n",
      "        ...,\n",
      "        [-2.0923e-03, -3.1965e-05,  3.2831e-05,  ...,  7.3902e-05,\n",
      "         -3.1976e-05, -1.6554e-02],\n",
      "        [-1.5874e-03,  5.2427e-04,  8.9346e-04,  ..., -5.7054e-06,\n",
      "          5.0655e-03, -4.3206e-02],\n",
      "        [ 1.9482e-03, -1.1567e-04,  1.5222e-02,  ...,  3.6571e-04,\n",
      "         -1.0446e-02,  3.4778e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-1.7902e-03, -2.1887e-04,  2.7736e-03,  ..., -7.2703e-05,\n",
      "         -2.4326e-04, -3.0566e-03],\n",
      "        [-3.8086e-03,  1.1463e-04, -1.6575e-05,  ...,  2.8942e-06,\n",
      "          7.9663e-05, -4.5658e-03],\n",
      "        [ 1.6182e-03,  2.0659e-03, -9.7731e-04,  ..., -2.0314e-05,\n",
      "         -8.0915e-05, -6.3548e-02],\n",
      "        ...,\n",
      "        [-2.0202e-03, -1.0135e-05,  3.3241e-05,  ..., -4.1105e-05,\n",
      "         -4.3918e-05, -1.4831e-02],\n",
      "        [-1.3962e-03,  3.7029e-04,  2.6098e-03,  ..., -8.9771e-06,\n",
      "          4.7098e-03, -4.1948e-02],\n",
      "        [ 2.0769e-03,  4.8877e-05,  1.5944e-02,  ...,  3.8153e-04,\n",
      "         -9.6291e-03,  3.4755e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.9864e+01, -1.6726e+01, -1.1455e+01,  ..., -1.0729e-05,\n",
      "         -2.5250e+01, -1.6121e+01],\n",
      "        [-8.7856e+00, -1.5844e+01, -5.8440e+00,  ..., -1.7831e+01,\n",
      "         -5.4469e+00, -1.0675e+01],\n",
      "        [-2.8871e+01, -1.5867e+01, -2.2778e-04,  ..., -8.4997e+00,\n",
      "         -1.2299e+01, -1.1107e+01],\n",
      "        ...,\n",
      "        [-7.1356e+00, -1.6105e+01, -5.5382e+00,  ..., -9.8489e+00,\n",
      "         -1.0639e+01, -5.4600e-03],\n",
      "        [-2.2606e-03, -2.6800e+01, -1.6375e+01,  ..., -2.5695e+01,\n",
      "         -1.4868e+01, -6.7806e+00],\n",
      "        [-2.5826e+01, -8.7408e+00, -1.0048e+01,  ..., -2.0442e-04,\n",
      "         -1.5557e+01, -1.3770e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0121 loss_train: 0.0260 acc_train: 0.9929 loss_val: 1.3639 acc_val: 0.7633 time: 0.6923s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-1.7902e-03, -2.1887e-04,  2.7736e-03,  ..., -7.2703e-05,\n",
      "         -2.4326e-04, -3.0566e-03],\n",
      "        [-3.8086e-03,  1.1463e-04, -1.6575e-05,  ...,  2.8942e-06,\n",
      "          7.9663e-05, -4.5658e-03],\n",
      "        [ 1.6182e-03,  2.0659e-03, -9.7731e-04,  ..., -2.0314e-05,\n",
      "         -8.0915e-05, -6.3548e-02],\n",
      "        ...,\n",
      "        [-2.0202e-03, -1.0135e-05,  3.3241e-05,  ..., -4.1105e-05,\n",
      "         -4.3918e-05, -1.4831e-02],\n",
      "        [-1.3962e-03,  3.7029e-04,  2.6098e-03,  ..., -8.9771e-06,\n",
      "          4.7098e-03, -4.1948e-02],\n",
      "        [ 2.0769e-03,  4.8877e-05,  1.5944e-02,  ...,  3.8153e-04,\n",
      "         -9.6291e-03,  3.4755e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-1.6094e-03, -3.8126e-04,  3.1159e-03,  ..., -5.0746e-05,\n",
      "         -1.5684e-04, -2.7727e-03],\n",
      "        [-3.8946e-03,  6.5561e-05, -1.2164e-05,  ..., -1.2742e-05,\n",
      "          3.4532e-05, -4.0911e-03],\n",
      "        [ 1.2278e-03,  1.7599e-03, -9.9401e-04,  ..., -8.2947e-06,\n",
      "         -2.0098e-05, -6.2447e-02],\n",
      "        ...,\n",
      "        [-1.8139e-03,  1.2282e-05,  2.4269e-05,  ..., -1.3764e-04,\n",
      "         -5.0989e-05, -1.3243e-02],\n",
      "        [-1.2147e-03,  2.2301e-04,  3.8265e-03,  ..., -1.1437e-05,\n",
      "          4.3979e-03, -4.0761e-02],\n",
      "        [ 2.2089e-03,  1.9717e-04,  1.6440e-02,  ...,  3.7491e-04,\n",
      "         -8.8543e-03,  3.4642e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-4.0466e+01, -1.7162e+01, -1.2311e+01,  ..., -4.5299e-06,\n",
      "         -2.5756e+01, -1.6750e+01],\n",
      "        [-8.7336e+00, -1.4871e+01, -5.3817e+00,  ..., -1.6866e+01,\n",
      "         -4.6506e+00, -1.0466e+01],\n",
      "        [-2.8913e+01, -1.5167e+01, -6.1183e-04,  ..., -7.4418e+00,\n",
      "         -1.1993e+01, -1.1040e+01],\n",
      "        ...,\n",
      "        [-7.3605e+00, -1.5706e+01, -5.4967e+00,  ..., -9.1296e+00,\n",
      "         -1.0490e+01, -5.3318e-03],\n",
      "        [-2.5024e-03, -2.6169e+01, -1.6043e+01,  ..., -2.4973e+01,\n",
      "         -1.4422e+01, -6.5599e+00],\n",
      "        [-2.6603e+01, -9.2343e+00, -1.0729e+01,  ..., -1.2027e-04,\n",
      "         -1.6170e+01, -1.4296e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0122 loss_train: 0.0256 acc_train: 1.0000 loss_val: 1.3741 acc_val: 0.7667 time: 0.6573s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-1.6094e-03, -3.8126e-04,  3.1159e-03,  ..., -5.0746e-05,\n",
      "         -1.5684e-04, -2.7727e-03],\n",
      "        [-3.8946e-03,  6.5561e-05, -1.2164e-05,  ..., -1.2742e-05,\n",
      "          3.4532e-05, -4.0911e-03],\n",
      "        [ 1.2278e-03,  1.7599e-03, -9.9401e-04,  ..., -8.2947e-06,\n",
      "         -2.0098e-05, -6.2447e-02],\n",
      "        ...,\n",
      "        [-1.8139e-03,  1.2282e-05,  2.4269e-05,  ..., -1.3764e-04,\n",
      "         -5.0989e-05, -1.3243e-02],\n",
      "        [-1.2147e-03,  2.2301e-04,  3.8265e-03,  ..., -1.1437e-05,\n",
      "          4.3979e-03, -4.0761e-02],\n",
      "        [ 2.2089e-03,  1.9717e-04,  1.6440e-02,  ...,  3.7491e-04,\n",
      "         -8.8543e-03,  3.4642e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-1.4486e-03, -5.1954e-04,  3.2370e-03,  ..., -2.6945e-05,\n",
      "         -7.7668e-05, -2.5396e-03],\n",
      "        [-3.8533e-03,  1.8102e-05, -4.8440e-06,  ..., -2.3757e-05,\n",
      "         -8.4562e-06, -3.9319e-03],\n",
      "        [ 8.3810e-04,  1.3854e-03, -9.7123e-04,  ...,  5.5367e-06,\n",
      "          3.5277e-05, -6.1483e-02],\n",
      "        ...,\n",
      "        [-1.5003e-03,  2.9278e-05,  9.3082e-06,  ..., -2.0713e-04,\n",
      "         -5.3191e-05, -1.1738e-02],\n",
      "        [-1.0497e-03,  8.4999e-05,  4.5187e-03,  ..., -1.3025e-05,\n",
      "          4.0894e-03, -3.9705e-02],\n",
      "        [ 2.2791e-03,  3.2938e-04,  1.6665e-02,  ...,  3.4827e-04,\n",
      "         -8.9527e-03,  3.4319e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.8034e+01, -1.6685e+01, -1.0181e+01,  ..., -3.8385e-05,\n",
      "         -2.3606e+01, -1.4660e+01],\n",
      "        [-8.0564e+00, -1.6398e+01, -5.9575e+00,  ..., -1.8129e+01,\n",
      "         -5.4616e+00, -1.0074e+01],\n",
      "        [-2.7672e+01, -1.6652e+01, -1.1896e-04,  ..., -9.4634e+00,\n",
      "         -1.1833e+01, -1.0568e+01],\n",
      "        ...,\n",
      "        [-6.4599e+00, -1.7079e+01, -6.0151e+00,  ..., -1.0930e+01,\n",
      "         -1.0864e+01, -4.7782e-03],\n",
      "        [-1.8074e-03, -2.7506e+01, -1.6778e+01,  ..., -2.6293e+01,\n",
      "         -1.5063e+01, -6.9440e+00],\n",
      "        [-2.4305e+01, -9.0415e+00, -9.0823e+00,  ..., -2.3732e-04,\n",
      "         -1.4478e+01, -1.2251e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0123 loss_train: 0.0543 acc_train: 0.9786 loss_val: 1.3070 acc_val: 0.7733 time: 0.6449s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-1.4486e-03, -5.1954e-04,  3.2370e-03,  ..., -2.6945e-05,\n",
      "         -7.7668e-05, -2.5396e-03],\n",
      "        [-3.8533e-03,  1.8102e-05, -4.8440e-06,  ..., -2.3757e-05,\n",
      "         -8.4562e-06, -3.9319e-03],\n",
      "        [ 8.3810e-04,  1.3854e-03, -9.7123e-04,  ...,  5.5367e-06,\n",
      "          3.5277e-05, -6.1483e-02],\n",
      "        ...,\n",
      "        [-1.5003e-03,  2.9278e-05,  9.3082e-06,  ..., -2.0713e-04,\n",
      "         -5.3191e-05, -1.1738e-02],\n",
      "        [-1.0497e-03,  8.4999e-05,  4.5187e-03,  ..., -1.3025e-05,\n",
      "          4.0894e-03, -3.9705e-02],\n",
      "        [ 2.2791e-03,  3.2938e-04,  1.6665e-02,  ...,  3.4827e-04,\n",
      "         -8.9527e-03,  3.4319e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-1.2962e-03, -6.3292e-04,  3.1723e-03,  ..., -3.3228e-06,\n",
      "         -9.1310e-07, -2.3068e-03],\n",
      "        [-3.6975e-03, -2.5655e-05,  3.1043e-06,  ..., -2.7875e-05,\n",
      "         -4.6773e-05, -3.6878e-03],\n",
      "        [ 4.6589e-04,  9.6959e-04, -9.1348e-04,  ...,  1.6049e-05,\n",
      "          8.4621e-05, -6.0343e-02],\n",
      "        ...,\n",
      "        [-1.1111e-03,  3.6819e-05, -6.8531e-06,  ..., -2.3222e-04,\n",
      "         -5.0632e-05, -1.0321e-02],\n",
      "        [-9.0004e-04, -4.1618e-05,  4.6186e-03,  ..., -1.3732e-05,\n",
      "          3.8202e-03, -3.8561e-02],\n",
      "        [ 2.3639e-03,  4.4580e-04,  1.7251e-02,  ...,  3.0493e-04,\n",
      "         -8.6900e-03,  3.4164e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.6123e+01, -1.6614e+01, -9.0822e+00,  ..., -1.1598e-04,\n",
      "         -2.2581e+01, -1.3015e+01],\n",
      "        [-7.0728e+00, -1.7530e+01, -6.3905e+00,  ..., -1.8902e+01,\n",
      "         -6.1615e+00, -9.3456e+00],\n",
      "        [-2.6216e+01, -1.7478e+01, -1.2266e-04,  ..., -1.0353e+01,\n",
      "         -1.1828e+01, -9.6547e+00],\n",
      "        ...,\n",
      "        [-5.7741e+00, -1.8126e+01, -6.5694e+00,  ..., -1.2124e+01,\n",
      "         -1.1263e+01, -5.3689e-03],\n",
      "        [-1.3343e-03, -2.8611e+01, -1.7438e+01,  ..., -2.7284e+01,\n",
      "         -1.5677e+01, -7.1991e+00],\n",
      "        [-2.2304e+01, -9.2159e+00, -8.0986e+00,  ..., -4.3597e-04,\n",
      "         -1.3642e+01, -1.0369e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0124 loss_train: 0.0243 acc_train: 0.9929 loss_val: 1.2759 acc_val: 0.7667 time: 0.6961s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-1.2962e-03, -6.3292e-04,  3.1723e-03,  ..., -3.3228e-06,\n",
      "         -9.1310e-07, -2.3068e-03],\n",
      "        [-3.6975e-03, -2.5655e-05,  3.1043e-06,  ..., -2.7875e-05,\n",
      "         -4.6773e-05, -3.6878e-03],\n",
      "        [ 4.6589e-04,  9.6959e-04, -9.1348e-04,  ...,  1.6049e-05,\n",
      "          8.4621e-05, -6.0343e-02],\n",
      "        ...,\n",
      "        [-1.1111e-03,  3.6819e-05, -6.8531e-06,  ..., -2.3222e-04,\n",
      "         -5.0632e-05, -1.0321e-02],\n",
      "        [-9.0004e-04, -4.1618e-05,  4.6186e-03,  ..., -1.3732e-05,\n",
      "          3.8202e-03, -3.8561e-02],\n",
      "        [ 2.3639e-03,  4.4580e-04,  1.7251e-02,  ...,  3.0493e-04,\n",
      "         -8.6900e-03,  3.4164e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-1.1483e-03, -7.2118e-04,  2.9298e-03,  ...,  1.8289e-05,\n",
      "          6.9642e-05, -2.0710e-03],\n",
      "        [-3.4427e-03, -6.3979e-05,  9.4307e-06,  ..., -2.4719e-05,\n",
      "         -7.8407e-05, -3.2723e-03],\n",
      "        [ 1.2113e-04,  5.3935e-04, -8.2617e-04,  ...,  1.9761e-05,\n",
      "          1.2752e-04, -5.9134e-02],\n",
      "        ...,\n",
      "        [-6.8084e-04,  3.3759e-05, -1.9509e-05,  ..., -2.5139e-04,\n",
      "         -4.3970e-05, -8.9962e-03],\n",
      "        [-7.6578e-04, -1.5514e-04,  4.0679e-03,  ..., -1.3600e-05,\n",
      "          3.5544e-03, -3.7419e-02],\n",
      "        [ 2.4888e-03,  5.4685e-04,  1.7526e-02,  ...,  2.4883e-04,\n",
      "         -8.2314e-03,  3.4061e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.5329e+01, -1.6322e+01, -8.7217e+00,  ..., -1.6616e-04,\n",
      "         -2.1966e+01, -1.2671e+01],\n",
      "        [-6.8887e+00, -1.7711e+01, -6.5118e+00,  ..., -1.9060e+01,\n",
      "         -6.1840e+00, -9.2909e+00],\n",
      "        [-2.5609e+01, -1.7493e+01, -1.3887e-04,  ..., -1.0548e+01,\n",
      "         -1.1579e+01, -9.4938e+00],\n",
      "        ...,\n",
      "        [-5.3758e+00, -1.8240e+01, -6.6269e+00,  ..., -1.2370e+01,\n",
      "         -1.1158e+01, -7.0522e-03],\n",
      "        [-1.2095e-03, -2.8848e+01, -1.7596e+01,  ..., -2.7526e+01,\n",
      "         -1.5732e+01, -7.3433e+00],\n",
      "        [-2.1622e+01, -9.0880e+00, -7.7948e+00,  ..., -5.7490e-04,\n",
      "         -1.3177e+01, -9.9477e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0125 loss_train: 0.0220 acc_train: 1.0000 loss_val: 1.2947 acc_val: 0.7667 time: 0.6450s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-1.1483e-03, -7.2118e-04,  2.9298e-03,  ...,  1.8289e-05,\n",
      "          6.9642e-05, -2.0710e-03],\n",
      "        [-3.4427e-03, -6.3979e-05,  9.4307e-06,  ..., -2.4719e-05,\n",
      "         -7.8407e-05, -3.2723e-03],\n",
      "        [ 1.2113e-04,  5.3935e-04, -8.2617e-04,  ...,  1.9761e-05,\n",
      "          1.2752e-04, -5.9134e-02],\n",
      "        ...,\n",
      "        [-6.8084e-04,  3.3759e-05, -1.9509e-05,  ..., -2.5139e-04,\n",
      "         -4.3970e-05, -8.9962e-03],\n",
      "        [-7.6578e-04, -1.5514e-04,  4.0679e-03,  ..., -1.3600e-05,\n",
      "          3.5544e-03, -3.7419e-02],\n",
      "        [ 2.4888e-03,  5.4685e-04,  1.7526e-02,  ...,  2.4883e-04,\n",
      "         -8.2314e-03,  3.4061e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-9.9908e-04, -7.8468e-04,  2.5689e-03,  ...,  3.6379e-05,\n",
      "          1.4078e-04, -1.8554e-03],\n",
      "        [-3.1057e-03, -9.5550e-05,  1.2532e-05,  ..., -1.5740e-05,\n",
      "         -1.0195e-04, -2.8588e-03],\n",
      "        [-1.9260e-04,  1.2011e-04, -7.1531e-04,  ...,  1.5957e-05,\n",
      "          1.6378e-04, -5.7815e-02],\n",
      "        ...,\n",
      "        [-2.4359e-04,  2.1899e-05, -2.5370e-05,  ..., -2.8208e-04,\n",
      "         -3.4155e-05, -7.7674e-03],\n",
      "        [-6.4900e-04, -2.5430e-04,  3.0952e-03,  ..., -1.2715e-05,\n",
      "          3.2971e-03, -3.6246e-02],\n",
      "        [ 2.7554e-03,  6.3304e-04,  1.7551e-02,  ...,  1.8423e-04,\n",
      "         -7.3985e-03,  3.4111e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.6214e+01, -1.6505e+01, -1.0323e+01,  ..., -3.3736e-05,\n",
      "         -2.3023e+01, -1.4025e+01],\n",
      "        [-7.0347e+00, -1.6606e+01, -6.1849e+00,  ..., -1.8091e+01,\n",
      "         -5.4826e+00, -9.3741e+00],\n",
      "        [-2.5689e+01, -1.6257e+01, -2.1896e-04,  ..., -9.0501e+00,\n",
      "         -1.1222e+01, -9.5585e+00],\n",
      "        ...,\n",
      "        [-5.5008e+00, -1.7430e+01, -6.4912e+00,  ..., -1.1355e+01,\n",
      "         -1.0830e+01, -6.5253e-03],\n",
      "        [-1.3610e-03, -2.7985e+01, -1.7215e+01,  ..., -2.6652e+01,\n",
      "         -1.5235e+01, -7.1941e+00],\n",
      "        [-2.2948e+01, -9.3124e+00, -9.1484e+00,  ..., -2.0895e-04,\n",
      "         -1.4285e+01, -1.1361e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0126 loss_train: 0.0336 acc_train: 0.9929 loss_val: 1.2274 acc_val: 0.7767 time: 0.6462s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-9.9908e-04, -7.8468e-04,  2.5689e-03,  ...,  3.6379e-05,\n",
      "          1.4078e-04, -1.8554e-03],\n",
      "        [-3.1057e-03, -9.5550e-05,  1.2532e-05,  ..., -1.5740e-05,\n",
      "         -1.0195e-04, -2.8588e-03],\n",
      "        [-1.9260e-04,  1.2011e-04, -7.1531e-04,  ...,  1.5957e-05,\n",
      "          1.6378e-04, -5.7815e-02],\n",
      "        ...,\n",
      "        [-2.4359e-04,  2.1899e-05, -2.5370e-05,  ..., -2.8208e-04,\n",
      "         -3.4155e-05, -7.7674e-03],\n",
      "        [-6.4900e-04, -2.5430e-04,  3.0952e-03,  ..., -1.2715e-05,\n",
      "          3.2971e-03, -3.6246e-02],\n",
      "        [ 2.7554e-03,  6.3304e-04,  1.7551e-02,  ...,  1.8423e-04,\n",
      "         -7.3985e-03,  3.4111e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-8.3958e-04, -8.2430e-04,  2.1049e-03,  ...,  4.9844e-05,\n",
      "          2.0593e-04, -1.6689e-03],\n",
      "        [-2.7045e-03, -1.1948e-04,  1.1844e-05,  ..., -3.7075e-06,\n",
      "         -1.1664e-04, -2.4209e-03],\n",
      "        [-4.7267e-04, -2.6559e-04, -5.8738e-04,  ...,  6.7134e-06,\n",
      "          1.9322e-04, -5.6419e-02],\n",
      "        ...,\n",
      "        [ 1.6978e-04,  5.2569e-06, -2.3382e-05,  ..., -2.8368e-04,\n",
      "         -1.1395e-05, -6.6371e-03],\n",
      "        [-6.0019e-04, -3.3825e-04,  1.9372e-03,  ..., -1.1195e-05,\n",
      "          3.0550e-03, -3.5135e-02],\n",
      "        [ 3.0177e-03,  7.0495e-04,  1.7462e-02,  ...,  1.1553e-04,\n",
      "         -6.4266e-03,  3.4131e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.7299e+01, -1.6362e+01, -1.2052e+01,  ..., -6.0797e-06,\n",
      "         -2.4009e+01, -1.5802e+01],\n",
      "        [-7.4174e+00, -1.5111e+01, -5.7882e+00,  ..., -1.6918e+01,\n",
      "         -4.4897e+00, -9.7448e+00],\n",
      "        [-2.5931e+01, -1.4533e+01, -8.4543e-04,  ..., -7.1822e+00,\n",
      "         -1.0721e+01, -9.8621e+00],\n",
      "        ...,\n",
      "        [-5.6382e+00, -1.6214e+01, -6.1897e+00,  ..., -9.9671e+00,\n",
      "         -1.0279e+01, -6.4921e-03],\n",
      "        [-1.5590e-03, -2.6897e+01, -1.6741e+01,  ..., -2.5618e+01,\n",
      "         -1.4612e+01, -7.0708e+00],\n",
      "        [-2.4439e+01, -9.1906e+00, -1.0579e+01,  ..., -1.2957e-04,\n",
      "         -1.5255e+01, -1.3176e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0127 loss_train: 0.0202 acc_train: 1.0000 loss_val: 1.2579 acc_val: 0.7800 time: 0.6583s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-8.3958e-04, -8.2430e-04,  2.1049e-03,  ...,  4.9844e-05,\n",
      "          2.0593e-04, -1.6689e-03],\n",
      "        [-2.7045e-03, -1.1948e-04,  1.1844e-05,  ..., -3.7075e-06,\n",
      "         -1.1664e-04, -2.4209e-03],\n",
      "        [-4.7267e-04, -2.6559e-04, -5.8738e-04,  ...,  6.7134e-06,\n",
      "          1.9322e-04, -5.6419e-02],\n",
      "        ...,\n",
      "        [ 1.6978e-04,  5.2569e-06, -2.3382e-05,  ..., -2.8368e-04,\n",
      "         -1.1395e-05, -6.6371e-03],\n",
      "        [-6.0019e-04, -3.3825e-04,  1.9372e-03,  ..., -1.1195e-05,\n",
      "          3.0550e-03, -3.5135e-02],\n",
      "        [ 3.0177e-03,  7.0495e-04,  1.7462e-02,  ...,  1.1553e-04,\n",
      "         -6.4266e-03,  3.4131e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-6.8990e-04, -8.4135e-04,  1.5385e-03,  ...,  5.8047e-05,\n",
      "          2.6815e-04, -1.5113e-03],\n",
      "        [-2.2574e-03, -1.3533e-04,  7.9088e-06,  ...,  8.0930e-06,\n",
      "         -1.2235e-04, -2.2593e-03],\n",
      "        [-7.1892e-04, -5.9908e-04, -4.4891e-04,  ..., -4.0925e-06,\n",
      "          2.1590e-04, -5.5046e-02],\n",
      "        ...,\n",
      "        [ 5.3121e-04, -1.1212e-05, -1.4845e-05,  ..., -2.3260e-04,\n",
      "          1.0166e-05, -5.5896e-03],\n",
      "        [-5.7726e-04, -4.0655e-04,  2.7349e-04,  ..., -9.1855e-06,\n",
      "          2.8951e-03, -3.4125e-02],\n",
      "        [ 3.1711e-03,  7.6325e-04,  1.6853e-02,  ...,  4.6949e-05,\n",
      "         -5.6160e-03,  3.4059e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.7091e+01, -1.5741e+01, -1.2143e+01,  ..., -5.6028e-06,\n",
      "         -2.3894e+01, -1.6211e+01],\n",
      "        [-7.5867e+00, -1.4951e+01, -5.7792e+00,  ..., -1.6868e+01,\n",
      "         -4.4653e+00, -9.9136e+00],\n",
      "        [-2.5847e+01, -1.4133e+01, -9.8442e-04,  ..., -7.0073e+00,\n",
      "         -1.0690e+01, -1.0042e+01],\n",
      "        ...,\n",
      "        [-5.4475e+00, -1.5800e+01, -5.9599e+00,  ..., -9.6961e+00,\n",
      "         -1.0017e+01, -8.0889e-03],\n",
      "        [-1.6608e-03, -2.6683e+01, -1.6602e+01,  ..., -2.5473e+01,\n",
      "         -1.4498e+01, -7.1116e+00],\n",
      "        [-2.4475e+01, -8.7047e+00, -1.0719e+01,  ..., -1.8941e-04,\n",
      "         -1.5202e+01, -1.3629e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0128 loss_train: 0.0275 acc_train: 1.0000 loss_val: 1.2861 acc_val: 0.7700 time: 0.7003s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-6.8990e-04, -8.4135e-04,  1.5385e-03,  ...,  5.8047e-05,\n",
      "          2.6815e-04, -1.5113e-03],\n",
      "        [-2.2574e-03, -1.3533e-04,  7.9088e-06,  ...,  8.0930e-06,\n",
      "         -1.2235e-04, -2.2593e-03],\n",
      "        [-7.1892e-04, -5.9908e-04, -4.4891e-04,  ..., -4.0925e-06,\n",
      "          2.1590e-04, -5.5046e-02],\n",
      "        ...,\n",
      "        [ 5.3121e-04, -1.1212e-05, -1.4845e-05,  ..., -2.3260e-04,\n",
      "          1.0166e-05, -5.5896e-03],\n",
      "        [-5.7726e-04, -4.0655e-04,  2.7349e-04,  ..., -9.1855e-06,\n",
      "          2.8951e-03, -3.4125e-02],\n",
      "        [ 3.1711e-03,  7.6325e-04,  1.6853e-02,  ...,  4.6949e-05,\n",
      "         -5.6160e-03,  3.4059e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-5.4803e-04, -8.3755e-04,  9.4088e-04,  ...,  6.0820e-05,\n",
      "          3.1838e-04, -1.3930e-03],\n",
      "        [-1.7825e-03, -1.4308e-04,  2.1308e-06,  ...,  1.6726e-05,\n",
      "         -1.1953e-04, -2.2347e-03],\n",
      "        [-9.2838e-04, -8.6630e-04, -3.0622e-04,  ..., -1.2357e-05,\n",
      "          2.3196e-04, -5.3762e-02],\n",
      "        ...,\n",
      "        [ 8.1965e-04, -2.3036e-05, -2.8324e-06,  ..., -1.4318e-04,\n",
      "          2.8763e-05, -4.6292e-03],\n",
      "        [-5.9477e-04, -4.5913e-04, -1.6251e-03,  ..., -6.8451e-06,\n",
      "          2.7399e-03, -3.3185e-02],\n",
      "        [ 3.2506e-03,  8.0866e-04,  1.5936e-02,  ..., -1.7687e-05,\n",
      "         -5.2364e-03,  3.3904e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.5557e+01, -1.5232e+01, -1.1074e+01,  ..., -1.5974e-05,\n",
      "         -2.3184e+01, -1.5037e+01],\n",
      "        [-7.0916e+00, -1.6324e+01, -6.2659e+00,  ..., -1.7928e+01,\n",
      "         -5.6244e+00, -9.4841e+00],\n",
      "        [-2.4979e+01, -1.5015e+01, -4.0475e-04,  ..., -8.1291e+00,\n",
      "         -1.1057e+01, -9.5864e+00],\n",
      "        ...,\n",
      "        [-4.9707e+00, -1.6503e+01, -6.1404e+00,  ..., -1.0661e+01,\n",
      "         -1.0310e+01, -1.0816e-02],\n",
      "        [-1.5663e-03, -2.7483e+01, -1.6940e+01,  ..., -2.6252e+01,\n",
      "         -1.5038e+01, -7.2656e+00],\n",
      "        [-2.2947e+01, -8.4531e+00, -9.9055e+00,  ..., -2.6783e-04,\n",
      "         -1.4656e+01, -1.2376e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0129 loss_train: 0.0299 acc_train: 0.9929 loss_val: 1.2250 acc_val: 0.7700 time: 0.6892s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-5.4803e-04, -8.3755e-04,  9.4088e-04,  ...,  6.0820e-05,\n",
      "          3.1838e-04, -1.3930e-03],\n",
      "        [-1.7825e-03, -1.4308e-04,  2.1308e-06,  ...,  1.6726e-05,\n",
      "         -1.1953e-04, -2.2347e-03],\n",
      "        [-9.2838e-04, -8.6630e-04, -3.0622e-04,  ..., -1.2357e-05,\n",
      "          2.3196e-04, -5.3762e-02],\n",
      "        ...,\n",
      "        [ 8.1965e-04, -2.3036e-05, -2.8324e-06,  ..., -1.4318e-04,\n",
      "          2.8763e-05, -4.6292e-03],\n",
      "        [-5.9477e-04, -4.5913e-04, -1.6251e-03,  ..., -6.8451e-06,\n",
      "          2.7399e-03, -3.3185e-02],\n",
      "        [ 3.2506e-03,  8.0866e-04,  1.5936e-02,  ..., -1.7687e-05,\n",
      "         -5.2364e-03,  3.3904e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-4.0713e-04, -8.1490e-04,  3.5549e-04,  ...,  5.8445e-05,\n",
      "          3.5604e-04, -1.2745e-03],\n",
      "        [-1.2973e-03, -1.4311e-04, -3.6917e-06,  ...,  2.0314e-05,\n",
      "         -1.0916e-04, -2.3559e-03],\n",
      "        [-1.1040e-03, -1.0582e-03, -1.6526e-04,  ..., -1.5274e-05,\n",
      "          2.4171e-04, -5.2462e-02],\n",
      "        ...,\n",
      "        [ 1.0211e-03, -2.7413e-05,  8.8468e-06,  ..., -1.0895e-04,\n",
      "          4.2435e-05, -3.7628e-03],\n",
      "        [-6.7691e-04, -4.9628e-04, -3.9921e-03,  ..., -4.3379e-06,\n",
      "          2.6113e-03, -3.2313e-02],\n",
      "        [ 3.2347e-03,  8.4195e-04,  1.4631e-02,  ..., -7.5096e-05,\n",
      "         -4.8823e-03,  3.3665e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.3861e+01, -1.4570e+01, -9.6581e+00,  ..., -6.5444e-05,\n",
      "         -2.2157e+01, -1.3700e+01],\n",
      "        [-6.6456e+00, -1.7665e+01, -6.7345e+00,  ..., -1.9019e+01,\n",
      "         -6.6832e+00, -9.1393e+00],\n",
      "        [-2.4109e+01, -1.6031e+01, -2.3970e-04,  ..., -9.5548e+00,\n",
      "         -1.1399e+01, -9.2335e+00],\n",
      "        ...,\n",
      "        [-4.4525e+00, -1.7228e+01, -6.2766e+00,  ..., -1.1695e+01,\n",
      "         -1.0561e+01, -1.6311e-02],\n",
      "        [-1.4576e-03, -2.8379e+01, -1.7322e+01,  ..., -2.7152e+01,\n",
      "         -1.5615e+01, -7.4671e+00],\n",
      "        [-2.1177e+01, -8.0863e+00, -8.8135e+00,  ..., -4.7565e-04,\n",
      "         -1.3791e+01, -1.0928e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0130 loss_train: 0.0217 acc_train: 1.0000 loss_val: 1.2435 acc_val: 0.7733 time: 0.8979s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-4.0713e-04, -8.1490e-04,  3.5549e-04,  ...,  5.8445e-05,\n",
      "          3.5604e-04, -1.2745e-03],\n",
      "        [-1.2973e-03, -1.4311e-04, -3.6917e-06,  ...,  2.0314e-05,\n",
      "         -1.0916e-04, -2.3559e-03],\n",
      "        [-1.1040e-03, -1.0582e-03, -1.6526e-04,  ..., -1.5274e-05,\n",
      "          2.4171e-04, -5.2462e-02],\n",
      "        ...,\n",
      "        [ 1.0211e-03, -2.7413e-05,  8.8468e-06,  ..., -1.0895e-04,\n",
      "          4.2435e-05, -3.7628e-03],\n",
      "        [-6.7691e-04, -4.9628e-04, -3.9921e-03,  ..., -4.3379e-06,\n",
      "          2.6113e-03, -3.2313e-02],\n",
      "        [ 3.2347e-03,  8.4195e-04,  1.4631e-02,  ..., -7.5096e-05,\n",
      "         -4.8823e-03,  3.3665e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-2.5845e-04, -7.7567e-04, -1.2916e-04,  ...,  5.1589e-05,\n",
      "          3.9110e-04, -1.0096e-03],\n",
      "        [-8.1569e-04, -1.3613e-04, -7.9078e-06,  ...,  1.8417e-05,\n",
      "         -9.2611e-05, -2.2529e-03],\n",
      "        [-1.2417e-03, -1.1707e-03, -3.1363e-05,  ..., -1.2261e-05,\n",
      "          2.4553e-04, -5.1014e-02],\n",
      "        ...,\n",
      "        [ 1.1291e-03, -2.3830e-05,  1.6819e-05,  ..., -6.8111e-05,\n",
      "          5.3343e-05, -2.9098e-03],\n",
      "        [-7.6993e-04, -5.1861e-04, -5.9375e-03,  ..., -1.8225e-06,\n",
      "          2.4854e-03, -3.1338e-02],\n",
      "        [ 3.3528e-03,  8.6395e-04,  1.3814e-02,  ..., -1.2270e-04,\n",
      "         -4.5477e-03,  3.3563e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.3734e+01, -1.4261e+01, -9.5950e+00,  ..., -6.9735e-05,\n",
      "         -2.2215e+01, -1.3793e+01],\n",
      "        [-6.8193e+00, -1.7726e+01, -6.6930e+00,  ..., -1.9088e+01,\n",
      "         -6.8272e+00, -9.1767e+00],\n",
      "        [-2.4131e+01, -1.6009e+01, -2.2540e-04,  ..., -9.6409e+00,\n",
      "         -1.1562e+01, -9.3354e+00],\n",
      "        ...,\n",
      "        [-4.5048e+00, -1.7090e+01, -6.0913e+00,  ..., -1.1576e+01,\n",
      "         -1.0511e+01, -1.6512e-02],\n",
      "        [-1.7122e-03, -2.8216e+01, -1.7108e+01,  ..., -2.7009e+01,\n",
      "         -1.5535e+01, -7.3853e+00],\n",
      "        [-2.1242e+01, -7.9061e+00, -8.8680e+00,  ..., -5.2557e-04,\n",
      "         -1.3937e+01, -1.1091e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0131 loss_train: 0.0261 acc_train: 0.9929 loss_val: 1.2602 acc_val: 0.7700 time: 0.8081s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-2.5845e-04, -7.7567e-04, -1.2916e-04,  ...,  5.1589e-05,\n",
      "          3.9110e-04, -1.0096e-03],\n",
      "        [-8.1569e-04, -1.3613e-04, -7.9078e-06,  ...,  1.8417e-05,\n",
      "         -9.2611e-05, -2.2529e-03],\n",
      "        [-1.2417e-03, -1.1707e-03, -3.1363e-05,  ..., -1.2261e-05,\n",
      "          2.4553e-04, -5.1014e-02],\n",
      "        ...,\n",
      "        [ 1.1291e-03, -2.3830e-05,  1.6819e-05,  ..., -6.8111e-05,\n",
      "          5.3343e-05, -2.9098e-03],\n",
      "        [-7.6993e-04, -5.1861e-04, -5.9375e-03,  ..., -1.8225e-06,\n",
      "          2.4854e-03, -3.1338e-02],\n",
      "        [ 3.3528e-03,  8.6395e-04,  1.3814e-02,  ..., -1.2270e-04,\n",
      "         -4.5477e-03,  3.3563e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-1.1282e-04, -7.2228e-04, -4.9445e-04,  ...,  4.1220e-05,\n",
      "          4.2152e-04, -8.9267e-04],\n",
      "        [-3.5462e-04, -1.2313e-04, -9.4690e-06,  ...,  1.2024e-05,\n",
      "         -7.1550e-05, -2.0008e-03],\n",
      "        [-1.3449e-03, -1.2048e-03,  9.0875e-05,  ..., -4.9867e-06,\n",
      "          2.4389e-04, -4.9545e-02],\n",
      "        ...,\n",
      "        [ 1.1445e-03, -1.4013e-05,  1.9094e-05,  ..., -3.2464e-05,\n",
      "          6.1147e-05, -2.0703e-03],\n",
      "        [-8.3007e-04, -5.2698e-04, -7.2563e-03,  ...,  5.5571e-07,\n",
      "          2.4601e-03, -3.0326e-02],\n",
      "        [ 3.6187e-03,  8.7549e-04,  1.3310e-02,  ..., -1.5870e-04,\n",
      "         -4.2328e-03,  3.3574e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.5771e+01, -1.3440e+01, -1.0429e+01,  ..., -3.1113e-05,\n",
      "         -2.2472e+01, -1.6254e+01],\n",
      "        [-8.6034e+00, -1.5573e+01, -5.7577e+00,  ..., -1.7683e+01,\n",
      "         -5.2035e+00, -1.0515e+01],\n",
      "        [-2.6282e+01, -1.4472e+01, -2.3684e-04,  ..., -8.5709e+00,\n",
      "         -1.1235e+01, -1.1284e+01],\n",
      "        ...,\n",
      "        [-5.1708e+00, -1.4929e+01, -4.6349e+00,  ..., -9.4853e+00,\n",
      "         -9.2195e+00, -2.0731e-02],\n",
      "        [-3.3146e-03, -2.6261e+01, -1.5787e+01,  ..., -2.5302e+01,\n",
      "         -1.4191e+01, -7.0469e+00],\n",
      "        [-2.3790e+01, -7.0368e+00, -9.7931e+00,  ..., -9.3678e-04,\n",
      "         -1.4278e+01, -1.3906e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0132 loss_train: 0.0451 acc_train: 0.9857 loss_val: 1.4105 acc_val: 0.7500 time: 1.2045s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-1.1282e-04, -7.2228e-04, -4.9445e-04,  ...,  4.1220e-05,\n",
      "          4.2152e-04, -8.9267e-04],\n",
      "        [-3.5462e-04, -1.2313e-04, -9.4690e-06,  ...,  1.2024e-05,\n",
      "         -7.1550e-05, -2.0008e-03],\n",
      "        [-1.3449e-03, -1.2048e-03,  9.0875e-05,  ..., -4.9867e-06,\n",
      "          2.4389e-04, -4.9545e-02],\n",
      "        ...,\n",
      "        [ 1.1445e-03, -1.4013e-05,  1.9094e-05,  ..., -3.2464e-05,\n",
      "          6.1147e-05, -2.0703e-03],\n",
      "        [-8.3007e-04, -5.2698e-04, -7.2563e-03,  ...,  5.5571e-07,\n",
      "          2.4601e-03, -3.0326e-02],\n",
      "        [ 3.6187e-03,  8.7549e-04,  1.3310e-02,  ..., -1.5870e-04,\n",
      "         -4.2328e-03,  3.3574e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 5.3108e-06, -6.5727e-04, -9.0578e-04,  ...,  2.8501e-05,\n",
      "          4.4146e-04, -7.9076e-04],\n",
      "        [ 7.3330e-05, -1.0531e-04, -8.1765e-06,  ...,  3.1811e-06,\n",
      "         -4.7778e-05, -1.7897e-03],\n",
      "        [-1.4133e-03, -1.1658e-03,  1.9772e-04,  ...,  3.4459e-06,\n",
      "          2.3732e-04, -4.8203e-02],\n",
      "        ...,\n",
      "        [ 1.0747e-03, -1.2574e-06,  1.5532e-05,  ...,  5.8825e-06,\n",
      "          6.2770e-05, -1.3550e-03],\n",
      "        [-8.7232e-04, -5.2250e-04, -7.9664e-03,  ...,  2.6725e-06,\n",
      "          2.4577e-03, -2.9379e-02],\n",
      "        [ 3.6697e-03,  8.7744e-04,  1.1989e-02,  ..., -1.8212e-04,\n",
      "         -4.0536e-03,  3.3525e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.5959e+01, -1.3533e+01, -1.0527e+01,  ..., -2.8252e-05,\n",
      "         -2.2598e+01, -1.6323e+01],\n",
      "        [-8.9344e+00, -1.4815e+01, -5.3053e+00,  ..., -1.7041e+01,\n",
      "         -4.5991e+00, -1.0577e+01],\n",
      "        [-2.6691e+01, -1.4203e+01, -3.0704e-04,  ..., -8.2198e+00,\n",
      "         -1.1241e+01, -1.1467e+01],\n",
      "        ...,\n",
      "        [-5.5467e+00, -1.4522e+01, -4.3870e+00,  ..., -8.9078e+00,\n",
      "         -9.0666e+00, -2.0906e-02],\n",
      "        [-3.9402e-03, -2.5688e+01, -1.5362e+01,  ..., -2.4717e+01,\n",
      "         -1.3783e+01, -6.8242e+00],\n",
      "        [-2.4157e+01, -7.1943e+00, -9.9305e+00,  ..., -8.0124e-04,\n",
      "         -1.4516e+01, -1.4033e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0133 loss_train: 0.0397 acc_train: 0.9929 loss_val: 1.4505 acc_val: 0.7533 time: 0.8125s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 5.3108e-06, -6.5727e-04, -9.0578e-04,  ...,  2.8501e-05,\n",
      "          4.4146e-04, -7.9076e-04],\n",
      "        [ 7.3330e-05, -1.0531e-04, -8.1765e-06,  ...,  3.1811e-06,\n",
      "         -4.7778e-05, -1.7897e-03],\n",
      "        [-1.4133e-03, -1.1658e-03,  1.9772e-04,  ...,  3.4459e-06,\n",
      "          2.3732e-04, -4.8203e-02],\n",
      "        ...,\n",
      "        [ 1.0747e-03, -1.2574e-06,  1.5532e-05,  ...,  5.8825e-06,\n",
      "          6.2770e-05, -1.3550e-03],\n",
      "        [-8.7232e-04, -5.2250e-04, -7.9664e-03,  ...,  2.6725e-06,\n",
      "          2.4577e-03, -2.9379e-02],\n",
      "        [ 3.6697e-03,  8.7744e-04,  1.1989e-02,  ..., -1.8212e-04,\n",
      "         -4.0536e-03,  3.3525e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.1901e-04, -5.8321e-04, -1.2300e-03,  ...,  1.4684e-05,\n",
      "          4.5258e-04, -7.3182e-04],\n",
      "        [ 4.5709e-04, -8.3980e-05, -4.6651e-06,  ..., -5.6239e-06,\n",
      "         -2.3120e-05, -1.4910e-03],\n",
      "        [-1.4491e-03, -1.0627e-03,  2.8639e-04,  ...,  9.7757e-06,\n",
      "          2.2643e-04, -4.6956e-02],\n",
      "        ...,\n",
      "        [ 9.3285e-04,  1.0618e-05,  7.7253e-06,  ...,  3.9670e-05,\n",
      "          5.8779e-05, -7.2025e-04],\n",
      "        [-8.8016e-04, -5.0646e-04, -8.0349e-03,  ...,  4.4297e-06,\n",
      "          2.4437e-03, -2.8485e-02],\n",
      "        [ 3.7638e-03,  8.7066e-04,  1.0700e-02,  ..., -1.9278e-04,\n",
      "         -4.1030e-03,  3.3465e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.4634e+01, -1.4318e+01, -9.9384e+00,  ..., -4.9351e-05,\n",
      "         -2.2654e+01, -1.4508e+01],\n",
      "        [-7.8493e+00, -1.5805e+01, -5.5590e+00,  ..., -1.7537e+01,\n",
      "         -5.3262e+00, -9.5588e+00],\n",
      "        [-2.5615e+01, -1.5258e+01, -2.0979e-04,  ..., -8.8112e+00,\n",
      "         -1.1619e+01, -1.0296e+01],\n",
      "        ...,\n",
      "        [-5.4878e+00, -1.5854e+01, -5.2402e+00,  ..., -9.9219e+00,\n",
      "         -1.0007e+01, -1.1739e-02],\n",
      "        [-2.8767e-03, -2.6542e+01, -1.5849e+01,  ..., -2.5310e+01,\n",
      "         -1.4352e+01, -6.7763e+00],\n",
      "        [-2.2812e+01, -8.1573e+00, -9.4814e+00,  ..., -3.6865e-04,\n",
      "         -1.4790e+01, -1.2127e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0134 loss_train: 0.0279 acc_train: 1.0000 loss_val: 1.3092 acc_val: 0.7667 time: 0.6302s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.1901e-04, -5.8321e-04, -1.2300e-03,  ...,  1.4684e-05,\n",
      "          4.5258e-04, -7.3182e-04],\n",
      "        [ 4.5709e-04, -8.3980e-05, -4.6651e-06,  ..., -5.6239e-06,\n",
      "         -2.3120e-05, -1.4910e-03],\n",
      "        [-1.4491e-03, -1.0627e-03,  2.8639e-04,  ...,  9.7757e-06,\n",
      "          2.2643e-04, -4.6956e-02],\n",
      "        ...,\n",
      "        [ 9.3285e-04,  1.0618e-05,  7.7253e-06,  ...,  3.9670e-05,\n",
      "          5.8779e-05, -7.2025e-04],\n",
      "        [-8.8016e-04, -5.0646e-04, -8.0349e-03,  ...,  4.4297e-06,\n",
      "          2.4437e-03, -2.8485e-02],\n",
      "        [ 3.7638e-03,  8.7066e-04,  1.0700e-02,  ..., -1.9278e-04,\n",
      "         -4.1030e-03,  3.3465e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 2.0696e-04, -5.0264e-04, -1.5755e-03,  ...,  9.9697e-07,\n",
      "          4.1491e-04, -7.0711e-04],\n",
      "        [ 7.8916e-04, -6.0532e-05, -1.4981e-07,  ..., -1.2134e-05,\n",
      "          7.0489e-07, -1.2960e-03],\n",
      "        [-1.4545e-03, -9.0742e-04,  3.5504e-04,  ...,  1.1822e-05,\n",
      "          2.1184e-04, -4.5838e-02],\n",
      "        ...,\n",
      "        [ 7.3596e-04,  1.8382e-05, -1.6195e-06,  ...,  6.2643e-05,\n",
      "          4.9912e-05, -1.6053e-04],\n",
      "        [-9.0524e-04, -4.8031e-04, -7.7124e-03,  ...,  5.7584e-06,\n",
      "          2.4814e-03, -2.7689e-02],\n",
      "        [ 3.7740e-03,  8.5604e-04,  9.1287e-03,  ..., -1.9126e-04,\n",
      "         -4.2739e-03,  3.3286e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.2609e+01, -1.4761e+01, -8.6743e+00,  ..., -1.7629e-04,\n",
      "         -2.1894e+01, -1.2195e+01],\n",
      "        [-6.4901e+00, -1.7317e+01, -6.0507e+00,  ..., -1.8501e+01,\n",
      "         -6.2794e+00, -8.4904e+00],\n",
      "        [-2.4009e+01, -1.6702e+01, -2.1765e-04,  ..., -1.0025e+01,\n",
      "         -1.1866e+01, -8.9670e+00],\n",
      "        ...,\n",
      "        [-5.0840e+00, -1.7368e+01, -6.0443e+00,  ..., -1.1373e+01,\n",
      "         -1.0797e+01, -1.0288e-02],\n",
      "        [-1.9424e-03, -2.7955e+01, -1.6639e+01,  ..., -2.6508e+01,\n",
      "         -1.5175e+01, -6.9522e+00],\n",
      "        [-2.0465e+01, -8.8314e+00, -8.3952e+00,  ..., -4.4717e-04,\n",
      "         -1.4213e+01, -9.5065e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0135 loss_train: 0.0210 acc_train: 1.0000 loss_val: 1.2393 acc_val: 0.7733 time: 0.6040s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 2.0696e-04, -5.0264e-04, -1.5755e-03,  ...,  9.9697e-07,\n",
      "          4.1491e-04, -7.0711e-04],\n",
      "        [ 7.8916e-04, -6.0532e-05, -1.4981e-07,  ..., -1.2134e-05,\n",
      "          7.0489e-07, -1.2960e-03],\n",
      "        [-1.4545e-03, -9.0742e-04,  3.5504e-04,  ...,  1.1822e-05,\n",
      "          2.1184e-04, -4.5838e-02],\n",
      "        ...,\n",
      "        [ 7.3596e-04,  1.8382e-05, -1.6195e-06,  ...,  6.2643e-05,\n",
      "          4.9912e-05, -1.6053e-04],\n",
      "        [-9.0524e-04, -4.8031e-04, -7.7124e-03,  ...,  5.7584e-06,\n",
      "          2.4814e-03, -2.7689e-02],\n",
      "        [ 3.7740e-03,  8.5604e-04,  9.1287e-03,  ..., -1.9126e-04,\n",
      "         -4.2739e-03,  3.3286e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 2.8756e-04, -4.1803e-04, -1.7790e-03,  ..., -1.1452e-05,\n",
      "          3.8369e-04, -6.9095e-04],\n",
      "        [ 1.0637e-03, -3.6323e-05,  3.9732e-06,  ..., -1.4885e-05,\n",
      "          2.2184e-05, -1.1328e-03],\n",
      "        [-1.4316e-03, -7.1391e-04,  4.0279e-04,  ...,  9.2109e-06,\n",
      "          1.9420e-04, -4.4792e-02],\n",
      "        ...,\n",
      "        [ 5.0386e-04,  2.0240e-05, -9.5807e-06,  ...,  7.5578e-05,\n",
      "          4.2331e-05,  3.6056e-04],\n",
      "        [-1.0336e-03, -4.4556e-04, -7.0640e-03,  ...,  6.6210e-06,\n",
      "          2.5845e-03, -2.6879e-02],\n",
      "        [ 3.7007e-03,  8.3443e-04,  7.6397e-03,  ..., -1.7877e-04,\n",
      "         -4.3905e-03,  3.3104e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.1644e+01, -1.4708e+01, -7.8355e+00,  ..., -4.1059e-04,\n",
      "         -2.1204e+01, -1.1134e+01],\n",
      "        [-5.9736e+00, -1.7747e+01, -6.1535e+00,  ..., -1.8808e+01,\n",
      "         -6.4054e+00, -8.1229e+00],\n",
      "        [-2.3375e+01, -1.7291e+01, -2.7724e-04,  ..., -1.0673e+01,\n",
      "         -1.1864e+01, -8.5476e+00],\n",
      "        ...,\n",
      "        [-4.9450e+00, -1.7891e+01, -6.2625e+00,  ..., -1.1894e+01,\n",
      "         -1.1000e+01, -1.0587e-02],\n",
      "        [-1.6152e-03, -2.8513e+01, -1.6945e+01,  ..., -2.6999e+01,\n",
      "         -1.5430e+01, -7.0446e+00],\n",
      "        [-1.9373e+01, -8.9615e+00, -7.7334e+00,  ..., -8.1006e-04,\n",
      "         -1.3713e+01, -8.3252e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0136 loss_train: 0.0211 acc_train: 1.0000 loss_val: 1.2636 acc_val: 0.7600 time: 0.7314s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 2.8756e-04, -4.1803e-04, -1.7790e-03,  ..., -1.1452e-05,\n",
      "          3.8369e-04, -6.9095e-04],\n",
      "        [ 1.0637e-03, -3.6323e-05,  3.9732e-06,  ..., -1.4885e-05,\n",
      "          2.2184e-05, -1.1328e-03],\n",
      "        [-1.4316e-03, -7.1391e-04,  4.0279e-04,  ...,  9.2109e-06,\n",
      "          1.9420e-04, -4.4792e-02],\n",
      "        ...,\n",
      "        [ 5.0386e-04,  2.0240e-05, -9.5807e-06,  ...,  7.5578e-05,\n",
      "          4.2331e-05,  3.6056e-04],\n",
      "        [-1.0336e-03, -4.4556e-04, -7.0640e-03,  ...,  6.6210e-06,\n",
      "          2.5845e-03, -2.6879e-02],\n",
      "        [ 3.7007e-03,  8.3443e-04,  7.6397e-03,  ..., -1.7877e-04,\n",
      "         -4.3905e-03,  3.3104e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 3.7031e-04, -3.3172e-04, -1.8517e-03,  ..., -2.1755e-05,\n",
      "          3.6155e-04, -6.3199e-04],\n",
      "        [ 1.2774e-03, -1.2627e-05,  6.5461e-06,  ..., -1.3514e-05,\n",
      "          4.0099e-05, -8.6225e-04],\n",
      "        [-1.3840e-03, -4.9703e-04,  4.2969e-04,  ...,  3.3639e-06,\n",
      "          1.7414e-04, -4.3702e-02],\n",
      "        ...,\n",
      "        [ 2.5736e-04,  1.6219e-05, -1.3910e-05,  ...,  7.0623e-05,\n",
      "          3.6727e-05,  8.4476e-04],\n",
      "        [-1.1681e-03, -4.0383e-04, -6.1512e-03,  ...,  7.0103e-06,\n",
      "          2.7968e-03, -2.6007e-02],\n",
      "        [ 3.7172e-03,  8.0669e-04,  6.4541e-03,  ..., -1.5707e-04,\n",
      "         -4.1160e-03,  3.3033e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.2944e+01, -1.4222e+01, -8.1430e+00,  ..., -2.9536e-04,\n",
      "         -2.1010e+01, -1.2472e+01],\n",
      "        [-7.2742e+00, -1.6370e+01, -5.6416e+00,  ..., -1.8025e+01,\n",
      "         -5.1240e+00, -9.1803e+00],\n",
      "        [-2.4740e+01, -1.6431e+01, -1.3231e-04,  ..., -1.0232e+01,\n",
      "         -1.1311e+01, -9.7965e+00],\n",
      "        ...,\n",
      "        [-5.3986e+00, -1.6804e+01, -5.5885e+00,  ..., -1.0819e+01,\n",
      "         -1.0331e+01, -1.0062e-02],\n",
      "        [-2.2027e-03, -2.7361e+01, -1.6236e+01,  ..., -2.6010e+01,\n",
      "         -1.4534e+01, -6.8589e+00],\n",
      "        [-2.1281e+01, -8.4777e+00, -8.2111e+00,  ..., -5.2093e-04,\n",
      "         -1.3778e+01, -1.0126e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0137 loss_train: 0.0350 acc_train: 0.9929 loss_val: 1.3396 acc_val: 0.7567 time: 0.9698s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 3.7031e-04, -3.3172e-04, -1.8517e-03,  ..., -2.1755e-05,\n",
      "          3.6155e-04, -6.3199e-04],\n",
      "        [ 1.2774e-03, -1.2627e-05,  6.5461e-06,  ..., -1.3514e-05,\n",
      "          4.0099e-05, -8.6225e-04],\n",
      "        [-1.3840e-03, -4.9703e-04,  4.2969e-04,  ...,  3.3639e-06,\n",
      "          1.7414e-04, -4.3702e-02],\n",
      "        ...,\n",
      "        [ 2.5736e-04,  1.6219e-05, -1.3910e-05,  ...,  7.0623e-05,\n",
      "          3.6727e-05,  8.4476e-04],\n",
      "        [-1.1681e-03, -4.0383e-04, -6.1512e-03,  ...,  7.0103e-06,\n",
      "          2.7968e-03, -2.6007e-02],\n",
      "        [ 3.7172e-03,  8.0669e-04,  6.4541e-03,  ..., -1.5707e-04,\n",
      "         -4.1160e-03,  3.3033e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 4.5166e-04, -2.4589e-04, -1.8057e-03,  ..., -2.9262e-05,\n",
      "          3.4616e-04, -4.9924e-04],\n",
      "        [ 1.4294e-03,  9.4179e-06,  6.9648e-06,  ..., -8.7600e-06,\n",
      "          5.3575e-05, -5.7033e-04],\n",
      "        [-1.3150e-03, -2.7169e-04,  4.3658e-04,  ..., -3.1976e-06,\n",
      "          1.5233e-04, -4.2520e-02],\n",
      "        ...,\n",
      "        [ 1.5459e-05,  8.0013e-06, -1.3648e-05,  ...,  5.2535e-05,\n",
      "          2.8338e-05,  1.2802e-03],\n",
      "        [-1.3065e-03, -3.5671e-04, -5.0421e-03,  ...,  6.9472e-06,\n",
      "          3.0265e-03, -2.5050e-02],\n",
      "        [ 3.7325e-03,  7.7366e-04,  5.2946e-03,  ..., -1.2825e-04,\n",
      "         -3.7035e-03,  3.3062e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.4665e+01, -1.4078e+01, -9.1832e+00,  ..., -1.0418e-04,\n",
      "         -2.1638e+01, -1.4087e+01],\n",
      "        [-8.4800e+00, -1.4479e+01, -4.8866e+00,  ..., -1.6711e+01,\n",
      "         -3.5862e+00, -1.0000e+01],\n",
      "        [-2.6104e+01, -1.5247e+01, -1.5484e-04,  ..., -9.1792e+00,\n",
      "         -1.0889e+01, -1.0775e+01],\n",
      "        ...,\n",
      "        [-6.1536e+00, -1.5465e+01, -4.8737e+00,  ..., -9.2633e+00,\n",
      "         -9.6725e+00, -1.1454e-02],\n",
      "        [-3.2838e-03, -2.5953e+01, -1.5386e+01,  ..., -2.4699e+01,\n",
      "         -1.3551e+01, -6.5090e+00],\n",
      "        [-2.3455e+01, -8.3024e+00, -9.1832e+00,  ..., -3.5721e-04,\n",
      "         -1.4506e+01, -1.2032e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0138 loss_train: 0.0182 acc_train: 1.0000 loss_val: 1.4641 acc_val: 0.7533 time: 0.7945s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 4.5166e-04, -2.4589e-04, -1.8057e-03,  ..., -2.9262e-05,\n",
      "          3.4616e-04, -4.9924e-04],\n",
      "        [ 1.4294e-03,  9.4179e-06,  6.9648e-06,  ..., -8.7600e-06,\n",
      "          5.3575e-05, -5.7033e-04],\n",
      "        [-1.3150e-03, -2.7169e-04,  4.3658e-04,  ..., -3.1976e-06,\n",
      "          1.5233e-04, -4.2520e-02],\n",
      "        ...,\n",
      "        [ 1.5459e-05,  8.0013e-06, -1.3648e-05,  ...,  5.2535e-05,\n",
      "          2.8338e-05,  1.2802e-03],\n",
      "        [-1.3065e-03, -3.5671e-04, -5.0421e-03,  ...,  6.9472e-06,\n",
      "          3.0265e-03, -2.5050e-02],\n",
      "        [ 3.7325e-03,  7.7366e-04,  5.2946e-03,  ..., -1.2825e-04,\n",
      "         -3.7035e-03,  3.3062e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 5.1299e-04, -1.6249e-04, -1.6540e-03,  ..., -3.3610e-05,\n",
      "          3.2963e-04, -4.0807e-04],\n",
      "        [ 1.5194e-03,  2.8859e-05,  5.3075e-06,  ..., -2.1781e-06,\n",
      "          6.2116e-05, -1.5640e-04],\n",
      "        [-1.4071e-03, -5.1977e-05,  4.2505e-04,  ..., -7.9054e-06,\n",
      "          1.2937e-04, -4.1470e-02],\n",
      "        ...,\n",
      "        [-2.0429e-04, -1.6940e-06, -9.3004e-06,  ...,  2.6127e-05,\n",
      "          1.6892e-05,  1.5819e-03],\n",
      "        [-1.4343e-03, -3.0579e-04, -3.8063e-03,  ...,  6.4777e-06,\n",
      "          3.2435e-03, -2.4140e-02],\n",
      "        [ 3.7546e-03,  7.3614e-04,  4.1741e-03,  ..., -9.4684e-05,\n",
      "         -3.3943e-03,  3.3065e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.4024e+01, -1.5064e+01, -9.8192e+00,  ..., -5.6742e-05,\n",
      "         -2.2819e+01, -1.3107e+01],\n",
      "        [-7.2592e+00, -1.5407e+01, -5.2327e+00,  ..., -1.7020e+01,\n",
      "         -4.4833e+00, -8.8575e+00],\n",
      "        [-2.4765e+01, -1.5656e+01, -2.8058e-04,  ..., -8.7656e+00,\n",
      "         -1.1288e+01, -9.2420e+00],\n",
      "        ...,\n",
      "        [-6.3084e+00, -1.6598e+01, -5.8286e+00,  ..., -9.8030e+00,\n",
      "         -1.0694e+01, -5.4506e-03],\n",
      "        [-2.6672e-03, -2.6701e+01, -1.5915e+01,  ..., -2.5072e+01,\n",
      "         -1.4174e+01, -6.3961e+00],\n",
      "        [-2.2686e+01, -9.4539e+00, -9.6566e+00,  ..., -1.6426e-04,\n",
      "         -1.5736e+01, -1.0738e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0139 loss_train: 0.0343 acc_train: 0.9929 loss_val: 1.2762 acc_val: 0.7733 time: 0.7247s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 5.1299e-04, -1.6249e-04, -1.6540e-03,  ..., -3.3610e-05,\n",
      "          3.2963e-04, -4.0807e-04],\n",
      "        [ 1.5194e-03,  2.8859e-05,  5.3075e-06,  ..., -2.1781e-06,\n",
      "          6.2116e-05, -1.5640e-04],\n",
      "        [-1.4071e-03, -5.1977e-05,  4.2505e-04,  ..., -7.9054e-06,\n",
      "          1.2937e-04, -4.1470e-02],\n",
      "        ...,\n",
      "        [-2.0429e-04, -1.6940e-06, -9.3004e-06,  ...,  2.6127e-05,\n",
      "          1.6892e-05,  1.5819e-03],\n",
      "        [-1.4343e-03, -3.0579e-04, -3.8063e-03,  ...,  6.4777e-06,\n",
      "          3.2435e-03, -2.4140e-02],\n",
      "        [ 3.7546e-03,  7.3614e-04,  4.1741e-03,  ..., -9.4684e-05,\n",
      "         -3.3943e-03,  3.3065e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 5.7490e-04, -8.3272e-05, -1.4163e-03,  ..., -3.4732e-05,\n",
      "          3.1319e-04, -7.6228e-04],\n",
      "        [ 1.5512e-03,  4.4959e-05,  2.2532e-06,  ...,  4.3391e-06,\n",
      "          6.5604e-05,  1.8531e-04],\n",
      "        [-1.4677e-03,  1.4962e-04,  3.9729e-04,  ..., -9.1302e-06,\n",
      "          1.0586e-04, -4.0534e-02],\n",
      "        ...,\n",
      "        [-3.8749e-04, -9.9707e-06, -2.5605e-06,  ..., -3.9358e-06,\n",
      "          7.6020e-06,  1.8126e-03],\n",
      "        [-1.6028e-03, -2.5261e-04, -2.5127e-03,  ...,  5.6674e-06,\n",
      "          3.3283e-03, -2.3355e-02],\n",
      "        [ 3.6974e-03,  6.9491e-04,  3.1032e-03,  ..., -5.8769e-05,\n",
      "         -3.2140e-03,  3.2950e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.2628e+01, -1.5575e+01, -9.6153e+00,  ..., -7.6410e-05,\n",
      "         -2.3239e+01, -1.1566e+01],\n",
      "        [-5.9776e+00, -1.7168e+01, -5.9453e+00,  ..., -1.8078e+01,\n",
      "         -6.0322e+00, -7.7353e+00],\n",
      "        [-2.3014e+01, -1.6572e+01, -6.1862e-04,  ..., -9.2257e+00,\n",
      "         -1.1759e+01, -7.6602e+00],\n",
      "        ...,\n",
      "        [-6.1185e+00, -1.7896e+01, -6.5842e+00,  ..., -1.0889e+01,\n",
      "         -1.1540e+01, -4.0917e-03],\n",
      "        [-2.3635e-03, -2.7829e+01, -1.6525e+01,  ..., -2.5932e+01,\n",
      "         -1.4988e+01, -6.4187e+00],\n",
      "        [-2.0958e+01, -1.0187e+01, -9.3444e+00,  ..., -2.7986e-04,\n",
      "         -1.6151e+01, -8.7751e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0140 loss_train: 0.0289 acc_train: 0.9929 loss_val: 1.1572 acc_val: 0.7733 time: 0.7604s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 5.7490e-04, -8.3272e-05, -1.4163e-03,  ..., -3.4732e-05,\n",
      "          3.1319e-04, -7.6228e-04],\n",
      "        [ 1.5512e-03,  4.4959e-05,  2.2532e-06,  ...,  4.3391e-06,\n",
      "          6.5604e-05,  1.8531e-04],\n",
      "        [-1.4677e-03,  1.4962e-04,  3.9729e-04,  ..., -9.1302e-06,\n",
      "          1.0586e-04, -4.0534e-02],\n",
      "        ...,\n",
      "        [-3.8749e-04, -9.9707e-06, -2.5605e-06,  ..., -3.9358e-06,\n",
      "          7.6020e-06,  1.8126e-03],\n",
      "        [-1.6028e-03, -2.5261e-04, -2.5127e-03,  ...,  5.6674e-06,\n",
      "          3.3283e-03, -2.3355e-02],\n",
      "        [ 3.6974e-03,  6.9491e-04,  3.1032e-03,  ..., -5.8769e-05,\n",
      "         -3.2140e-03,  3.2950e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 6.2768e-04, -9.7068e-06, -1.1150e-03,  ..., -3.2835e-05,\n",
      "          3.0761e-04, -2.3321e-03],\n",
      "        [ 1.5285e-03,  5.7215e-05, -1.1697e-06,  ...,  9.0854e-06,\n",
      "          6.4271e-05,  4.6220e-04],\n",
      "        [-1.5001e-03,  3.2280e-04,  3.5592e-04,  ..., -6.7258e-06,\n",
      "          8.2348e-05, -3.9707e-02],\n",
      "        ...,\n",
      "        [-5.2379e-04, -1.4597e-05,  4.3056e-06,  ..., -3.0328e-05,\n",
      "         -1.4867e-06,  1.9906e-03],\n",
      "        [-2.0004e-03, -1.9860e-04, -1.2267e-03,  ...,  4.5962e-06,\n",
      "          3.7595e-03, -2.2826e-02],\n",
      "        [ 3.5535e-03,  6.5071e-04,  2.0921e-03,  ..., -2.2840e-05,\n",
      "         -2.6287e-03,  3.2638e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.2438e+01, -1.4434e+01, -9.0121e+00,  ..., -1.2850e-04,\n",
      "         -2.2223e+01, -1.2008e+01],\n",
      "        [-6.9520e+00, -1.7499e+01, -6.2987e+00,  ..., -1.8794e+01,\n",
      "         -6.2168e+00, -8.7673e+00],\n",
      "        [-2.3263e+01, -1.6416e+01, -3.5196e-04,  ..., -9.9129e+00,\n",
      "         -1.1399e+01, -8.4726e+00],\n",
      "        ...,\n",
      "        [-5.7968e+00, -1.7468e+01, -6.1029e+00,  ..., -1.0943e+01,\n",
      "         -1.1040e+01, -6.5031e-03],\n",
      "        [-2.5650e-03, -2.7753e+01, -1.6396e+01,  ..., -2.6156e+01,\n",
      "         -1.4858e+01, -6.6620e+00],\n",
      "        [-2.1063e+01, -9.1884e+00, -8.8832e+00,  ..., -3.2765e-04,\n",
      "         -1.5313e+01, -9.3562e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0141 loss_train: 0.0361 acc_train: 0.9929 loss_val: 1.2468 acc_val: 0.7633 time: 0.8980s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 6.2768e-04, -9.7068e-06, -1.1150e-03,  ..., -3.2835e-05,\n",
      "          3.0761e-04, -2.3321e-03],\n",
      "        [ 1.5285e-03,  5.7215e-05, -1.1697e-06,  ...,  9.0854e-06,\n",
      "          6.4271e-05,  4.6220e-04],\n",
      "        [-1.5001e-03,  3.2280e-04,  3.5592e-04,  ..., -6.7258e-06,\n",
      "          8.2348e-05, -3.9707e-02],\n",
      "        ...,\n",
      "        [-5.2379e-04, -1.4597e-05,  4.3056e-06,  ..., -3.0328e-05,\n",
      "         -1.4867e-06,  1.9906e-03],\n",
      "        [-2.0004e-03, -1.9860e-04, -1.2267e-03,  ...,  4.5962e-06,\n",
      "          3.7595e-03, -2.2826e-02],\n",
      "        [ 3.5535e-03,  6.5071e-04,  2.0921e-03,  ..., -2.2840e-05,\n",
      "         -2.6287e-03,  3.2638e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 6.8698e-04,  5.6987e-05, -7.7470e-04,  ..., -2.8359e-05,\n",
      "          3.0354e-04, -3.7350e-03],\n",
      "        [ 1.4575e-03,  6.5363e-05, -3.9162e-06,  ...,  1.0974e-05,\n",
      "          5.8657e-05,  7.1012e-04],\n",
      "        [-1.5007e-03,  4.5988e-04,  3.0391e-04,  ..., -1.9576e-06,\n",
      "          5.9330e-05, -3.8918e-02],\n",
      "        ...,\n",
      "        [-6.0741e-04, -1.4586e-05,  9.1967e-06,  ..., -4.6392e-05,\n",
      "         -9.5609e-06,  2.1835e-03],\n",
      "        [-2.3788e-03, -1.4511e-04, -7.4093e-06,  ...,  3.3524e-06,\n",
      "          4.4700e-03, -2.2359e-02],\n",
      "        [ 3.4314e-03,  6.0426e-04,  1.1489e-03,  ...,  1.0976e-05,\n",
      "         -1.9231e-03,  3.2354e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.2722e+01, -1.3036e+01, -8.7162e+00,  ..., -1.6819e-04,\n",
      "         -2.1189e+01, -1.3109e+01],\n",
      "        [-8.0066e+00, -1.7194e+01, -6.4239e+00,  ..., -1.9027e+01,\n",
      "         -5.8999e+00, -9.8905e+00],\n",
      "        [-2.3808e+01, -1.5765e+01, -2.4483e-04,  ..., -1.0173e+01,\n",
      "         -1.0822e+01, -9.5733e+00],\n",
      "        ...,\n",
      "        [-5.5170e+00, -1.6549e+01, -5.4345e+00,  ..., -1.0515e+01,\n",
      "         -1.0246e+01, -1.1340e-02],\n",
      "        [-3.1625e-03, -2.7314e+01, -1.6152e+01,  ..., -2.6035e+01,\n",
      "         -1.4484e+01, -6.8905e+00],\n",
      "        [-2.1729e+01, -7.8708e+00, -8.6758e+00,  ..., -5.7621e-04,\n",
      "         -1.4420e+01, -1.0680e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0142 loss_train: 0.0213 acc_train: 1.0000 loss_val: 1.3729 acc_val: 0.7500 time: 0.8026s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 6.8698e-04,  5.6987e-05, -7.7470e-04,  ..., -2.8359e-05,\n",
      "          3.0354e-04, -3.7350e-03],\n",
      "        [ 1.4575e-03,  6.5363e-05, -3.9162e-06,  ...,  1.0974e-05,\n",
      "          5.8657e-05,  7.1012e-04],\n",
      "        [-1.5007e-03,  4.5988e-04,  3.0391e-04,  ..., -1.9576e-06,\n",
      "          5.9330e-05, -3.8918e-02],\n",
      "        ...,\n",
      "        [-6.0741e-04, -1.4586e-05,  9.1967e-06,  ..., -4.6392e-05,\n",
      "         -9.5609e-06,  2.1835e-03],\n",
      "        [-2.3788e-03, -1.4511e-04, -7.4093e-06,  ...,  3.3524e-06,\n",
      "          4.4700e-03, -2.2359e-02],\n",
      "        [ 3.4314e-03,  6.0426e-04,  1.1489e-03,  ...,  1.0976e-05,\n",
      "         -1.9231e-03,  3.2354e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 7.3737e-04,  1.1586e-04, -4.1967e-04,  ..., -2.1920e-05,\n",
      "          2.9497e-04, -4.9685e-03],\n",
      "        [ 1.3453e-03,  6.9370e-05, -5.2353e-06,  ...,  9.7710e-06,\n",
      "          4.9546e-05,  1.0310e-03],\n",
      "        [-1.4799e-03,  5.5601e-04,  2.4437e-04,  ...,  3.1082e-06,\n",
      "          3.7252e-05, -3.8095e-02],\n",
      "        ...,\n",
      "        [-6.3713e-04, -1.0374e-05,  1.0803e-05,  ..., -5.3999e-05,\n",
      "         -1.6448e-05,  2.3201e-03],\n",
      "        [-2.6394e-03, -9.3340e-05,  1.0944e-03,  ...,  2.0266e-06,\n",
      "          5.1110e-03, -2.1841e-02],\n",
      "        [ 3.4820e-03,  5.5620e-04,  2.8043e-04,  ...,  4.0871e-05,\n",
      "         -1.2459e-03,  3.2238e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.2987e+01, -1.2540e+01, -9.3652e+00,  ..., -9.0237e-05,\n",
      "         -2.1373e+01, -1.3916e+01],\n",
      "        [-7.8613e+00, -1.6844e+01, -6.4898e+00,  ..., -1.8789e+01,\n",
      "         -5.7419e+00, -9.9527e+00],\n",
      "        [-2.3578e+01, -1.5040e+01, -2.8320e-04,  ..., -9.5948e+00,\n",
      "         -1.0544e+01, -9.6058e+00],\n",
      "        ...,\n",
      "        [-5.3367e+00, -1.6062e+01, -5.4160e+00,  ..., -1.0060e+01,\n",
      "         -1.0022e+01, -1.2313e-02],\n",
      "        [-2.6088e-03, -2.7170e+01, -1.6342e+01,  ..., -2.5933e+01,\n",
      "         -1.4503e+01, -7.0825e+00],\n",
      "        [-2.2121e+01, -7.4682e+00, -9.1770e+00,  ..., -6.8593e-04,\n",
      "         -1.4608e+01, -1.1428e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0143 loss_train: 0.0264 acc_train: 0.9929 loss_val: 1.3645 acc_val: 0.7500 time: 0.6652s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 7.3737e-04,  1.1586e-04, -4.1967e-04,  ..., -2.1920e-05,\n",
      "          2.9497e-04, -4.9685e-03],\n",
      "        [ 1.3453e-03,  6.9370e-05, -5.2353e-06,  ...,  9.7710e-06,\n",
      "          4.9546e-05,  1.0310e-03],\n",
      "        [-1.4799e-03,  5.5601e-04,  2.4437e-04,  ...,  3.1082e-06,\n",
      "          3.7252e-05, -3.8095e-02],\n",
      "        ...,\n",
      "        [-6.3713e-04, -1.0374e-05,  1.0803e-05,  ..., -5.3999e-05,\n",
      "         -1.6448e-05,  2.3201e-03],\n",
      "        [-2.6394e-03, -9.3340e-05,  1.0944e-03,  ...,  2.0266e-06,\n",
      "          5.1110e-03, -2.1841e-02],\n",
      "        [ 3.4820e-03,  5.5620e-04,  2.8043e-04,  ...,  4.0871e-05,\n",
      "         -1.2459e-03,  3.2238e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 7.6918e-04,  1.6624e-04, -7.3086e-05,  ..., -1.4246e-05,\n",
      "          2.7933e-04, -6.0664e-03],\n",
      "        [ 1.2025e-03,  6.9417e-05, -4.8677e-06,  ...,  6.0847e-06,\n",
      "          3.7891e-05,  1.3948e-03],\n",
      "        [-1.4313e-03,  6.0921e-04,  1.8046e-04,  ...,  6.4757e-06,\n",
      "          1.6498e-05, -3.7278e-02],\n",
      "        ...,\n",
      "        [-6.1539e-04, -3.5690e-06,  8.9381e-06,  ..., -5.0223e-05,\n",
      "         -2.1146e-05,  2.4021e-03],\n",
      "        [-2.7882e-03, -4.4347e-05,  2.0381e-03,  ...,  7.0627e-07,\n",
      "          5.5328e-03, -2.1220e-02],\n",
      "        [ 3.5287e-03,  5.0717e-04, -5.0817e-04,  ...,  6.5428e-05,\n",
      "         -9.7572e-04,  3.2260e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.3136e+01, -1.3359e+01, -1.0254e+01,  ..., -3.7789e-05,\n",
      "         -2.2581e+01, -1.3807e+01],\n",
      "        [-6.9310e+00, -1.6917e+01, -6.5020e+00,  ..., -1.8493e+01,\n",
      "         -5.9984e+00, -9.1513e+00],\n",
      "        [-2.2901e+01, -1.4914e+01, -4.3550e-04,  ..., -8.8081e+00,\n",
      "         -1.0801e+01, -8.7273e+00],\n",
      "        ...,\n",
      "        [-5.4645e+00, -1.6367e+01, -5.9189e+00,  ..., -9.9190e+00,\n",
      "         -1.0501e+01, -8.5008e-03],\n",
      "        [-1.8924e-03, -2.7369e+01, -1.6683e+01,  ..., -2.5922e+01,\n",
      "         -1.4812e+01, -7.0957e+00],\n",
      "        [-2.2222e+01, -8.2500e+00, -9.8531e+00,  ..., -3.2777e-04,\n",
      "         -1.5682e+01, -1.1198e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0144 loss_train: 0.0240 acc_train: 1.0000 loss_val: 1.2514 acc_val: 0.7700 time: 0.6534s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 7.6918e-04,  1.6624e-04, -7.3086e-05,  ..., -1.4246e-05,\n",
      "          2.7933e-04, -6.0664e-03],\n",
      "        [ 1.2025e-03,  6.9417e-05, -4.8677e-06,  ...,  6.0847e-06,\n",
      "          3.7891e-05,  1.3948e-03],\n",
      "        [-1.4313e-03,  6.0921e-04,  1.8046e-04,  ...,  6.4757e-06,\n",
      "          1.6498e-05, -3.7278e-02],\n",
      "        ...,\n",
      "        [-6.1539e-04, -3.5690e-06,  8.9381e-06,  ..., -5.0223e-05,\n",
      "         -2.1146e-05,  2.4021e-03],\n",
      "        [-2.7882e-03, -4.4347e-05,  2.0381e-03,  ...,  7.0627e-07,\n",
      "          5.5328e-03, -2.1220e-02],\n",
      "        [ 3.5287e-03,  5.0717e-04, -5.0817e-04,  ...,  6.5428e-05,\n",
      "         -9.7572e-04,  3.2260e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 7.9442e-04,  2.0771e-04,  2.4452e-04,  ..., -6.1012e-06,\n",
      "          2.5937e-04, -7.0228e-03],\n",
      "        [ 1.0341e-03,  6.5871e-05, -3.0806e-06,  ...,  1.1298e-06,\n",
      "          2.4733e-05,  1.7323e-03],\n",
      "        [-1.3742e-03,  6.2030e-04,  1.1522e-04,  ...,  6.9902e-06,\n",
      "         -2.6100e-06, -3.6603e-02],\n",
      "        ...,\n",
      "        [-5.6689e-04,  3.6141e-06,  4.5001e-06,  ...,  1.8344e-04,\n",
      "         -1.0951e-04,  2.6462e-03],\n",
      "        [-2.9166e-03,  9.7199e-07,  2.7939e-03,  ..., -5.2934e-07,\n",
      "          5.9133e-03, -2.0649e-02],\n",
      "        [ 3.5027e-03,  4.5773e-04, -1.2132e-03,  ...,  8.3677e-05,\n",
      "         -1.0937e-03,  3.2258e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.3257e+01, -1.4205e+01, -1.0584e+01,  ..., -2.7418e-05,\n",
      "         -2.3327e+01, -1.3458e+01],\n",
      "        [-6.3624e+00, -1.7071e+01, -6.3444e+00,  ..., -1.8268e+01,\n",
      "         -6.2212e+00, -8.4714e+00],\n",
      "        [-2.2655e+01, -1.5249e+01, -5.8336e-04,  ..., -8.5125e+00,\n",
      "         -1.1149e+01, -8.1461e+00],\n",
      "        ...,\n",
      "        [-5.7075e+00, -1.6773e+01, -6.1949e+00,  ..., -9.9234e+00,\n",
      "         -1.0912e+01, -6.3179e-03],\n",
      "        [-1.7729e-03, -2.7484e+01, -1.6728e+01,  ..., -2.5810e+01,\n",
      "         -1.4955e+01, -6.9523e+00],\n",
      "        [-2.2292e+01, -9.0662e+00, -1.0129e+01,  ..., -1.7629e-04,\n",
      "         -1.6394e+01, -1.0784e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0145 loss_train: 0.0253 acc_train: 1.0000 loss_val: 1.1828 acc_val: 0.7700 time: 0.6985s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 7.9442e-04,  2.0771e-04,  2.4452e-04,  ..., -6.1012e-06,\n",
      "          2.5937e-04, -7.0228e-03],\n",
      "        [ 1.0341e-03,  6.5871e-05, -3.0806e-06,  ...,  1.1298e-06,\n",
      "          2.4733e-05,  1.7323e-03],\n",
      "        [-1.3742e-03,  6.2030e-04,  1.1522e-04,  ...,  6.9902e-06,\n",
      "         -2.6100e-06, -3.6603e-02],\n",
      "        ...,\n",
      "        [-5.6689e-04,  3.6141e-06,  4.5001e-06,  ...,  1.8344e-04,\n",
      "         -1.0951e-04,  2.6462e-03],\n",
      "        [-2.9166e-03,  9.7199e-07,  2.7939e-03,  ..., -5.2934e-07,\n",
      "          5.9133e-03, -2.0649e-02],\n",
      "        [ 3.5027e-03,  4.5773e-04, -1.2132e-03,  ...,  8.3677e-05,\n",
      "         -1.0937e-03,  3.2258e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 8.2986e-04,  2.4010e-04,  5.1625e-04,  ...,  1.7769e-06,\n",
      "          2.3179e-04, -7.8600e-03],\n",
      "        [ 8.4740e-04,  5.9250e-05, -5.4201e-07,  ..., -3.6488e-06,\n",
      "          1.1125e-05,  2.0016e-03],\n",
      "        [-1.2961e-03,  5.9251e-04,  5.1474e-05,  ...,  4.7165e-06,\n",
      "         -1.9813e-05, -3.6089e-02],\n",
      "        ...,\n",
      "        [-4.7953e-04,  9.0498e-06, -9.0029e-07,  ...,  3.5809e-04,\n",
      "         -1.7911e-04,  2.7671e-03],\n",
      "        [-3.0767e-03,  4.1887e-05,  3.3437e-03,  ..., -1.6132e-06,\n",
      "          6.3464e-03, -2.0197e-02],\n",
      "        [ 3.3985e-03,  4.0840e-04, -1.8326e-03,  ...,  9.5113e-05,\n",
      "         -1.3020e-03,  3.2180e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.2663e+01, -1.4595e+01, -1.0076e+01,  ..., -4.5656e-05,\n",
      "         -2.2885e+01, -1.2695e+01],\n",
      "        [-5.9238e+00, -1.7544e+01, -6.4028e+00,  ..., -1.8519e+01,\n",
      "         -6.4366e+00, -8.1606e+00],\n",
      "        [-2.2190e+01, -1.5939e+01, -6.1541e-04,  ..., -9.0509e+00,\n",
      "         -1.1168e+01, -7.8497e+00],\n",
      "        ...,\n",
      "        [-5.4402e+00, -1.7325e+01, -6.3714e+00,  ..., -1.0464e+01,\n",
      "         -1.1027e+01, -6.9938e-03],\n",
      "        [-1.4275e-03, -2.8043e+01, -1.7044e+01,  ..., -2.6278e+01,\n",
      "         -1.5240e+01, -7.1341e+00],\n",
      "        [-2.1531e+01, -9.3669e+00, -9.6896e+00,  ..., -1.9322e-04,\n",
      "         -1.5903e+01, -9.9936e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0146 loss_train: 0.0227 acc_train: 0.9929 loss_val: 1.1773 acc_val: 0.7667 time: 0.6480s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 8.2986e-04,  2.4010e-04,  5.1625e-04,  ...,  1.7769e-06,\n",
      "          2.3179e-04, -7.8600e-03],\n",
      "        [ 8.4740e-04,  5.9250e-05, -5.4201e-07,  ..., -3.6488e-06,\n",
      "          1.1125e-05,  2.0016e-03],\n",
      "        [-1.2961e-03,  5.9251e-04,  5.1474e-05,  ...,  4.7165e-06,\n",
      "         -1.9813e-05, -3.6089e-02],\n",
      "        ...,\n",
      "        [-4.7953e-04,  9.0498e-06, -9.0029e-07,  ...,  3.5809e-04,\n",
      "         -1.7911e-04,  2.7671e-03],\n",
      "        [-3.0767e-03,  4.1887e-05,  3.3437e-03,  ..., -1.6132e-06,\n",
      "          6.3464e-03, -2.0197e-02],\n",
      "        [ 3.3985e-03,  4.0840e-04, -1.8326e-03,  ...,  9.5113e-05,\n",
      "         -1.3020e-03,  3.2180e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 8.7917e-04,  2.6348e-04,  7.2952e-04,  ...,  8.7409e-06,\n",
      "          2.0687e-04, -8.5247e-03],\n",
      "        [ 6.5024e-04,  5.0184e-05,  1.9143e-06,  ..., -6.9837e-06,\n",
      "         -1.9449e-06,  2.2352e-03],\n",
      "        [-1.2044e-03,  5.3118e-04, -8.2641e-06,  ...,  8.0843e-07,\n",
      "         -3.4918e-05, -3.5636e-02],\n",
      "        ...,\n",
      "        [-3.6366e-04,  1.1314e-05, -5.4990e-06,  ...,  4.4447e-04,\n",
      "         -2.2520e-04,  2.8679e-03],\n",
      "        [-3.2423e-03,  7.7835e-05,  3.6806e-03,  ..., -2.4936e-06,\n",
      "          6.9326e-03, -1.9779e-02],\n",
      "        [ 3.3199e-03,  3.5967e-04, -2.3655e-03,  ...,  9.9682e-05,\n",
      "         -1.5201e-03,  3.2108e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.2772e+01, -1.4335e+01, -9.3742e+00,  ..., -8.8211e-05,\n",
      "         -2.1952e+01, -1.2810e+01],\n",
      "        [-6.7280e+00, -1.7409e+01, -6.2662e+00,  ..., -1.8662e+01,\n",
      "         -6.0997e+00, -8.9103e+00],\n",
      "        [-2.2866e+01, -1.6139e+01, -3.3349e-04,  ..., -9.6568e+00,\n",
      "         -1.0936e+01, -8.7283e+00],\n",
      "        ...,\n",
      "        [-5.3253e+00, -1.7114e+01, -5.9060e+00,  ..., -1.0460e+01,\n",
      "         -1.0615e+01, -9.0919e-03],\n",
      "        [-1.4652e-03, -2.7966e+01, -1.6876e+01,  ..., -2.6327e+01,\n",
      "         -1.5023e+01, -7.3003e+00],\n",
      "        [-2.1733e+01, -9.0009e+00, -9.1592e+00,  ..., -2.6270e-04,\n",
      "         -1.5019e+01, -1.0296e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0147 loss_train: 0.0209 acc_train: 1.0000 loss_val: 1.2641 acc_val: 0.7667 time: 0.6896s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 8.7917e-04,  2.6348e-04,  7.2952e-04,  ...,  8.7409e-06,\n",
      "          2.0687e-04, -8.5247e-03],\n",
      "        [ 6.5024e-04,  5.0184e-05,  1.9143e-06,  ..., -6.9837e-06,\n",
      "         -1.9449e-06,  2.2352e-03],\n",
      "        [-1.2044e-03,  5.3118e-04, -8.2641e-06,  ...,  8.0843e-07,\n",
      "         -3.4918e-05, -3.5636e-02],\n",
      "        ...,\n",
      "        [-3.6366e-04,  1.1314e-05, -5.4990e-06,  ...,  4.4447e-04,\n",
      "         -2.2520e-04,  2.8679e-03],\n",
      "        [-3.2423e-03,  7.7835e-05,  3.6806e-03,  ..., -2.4936e-06,\n",
      "          6.9326e-03, -1.9779e-02],\n",
      "        [ 3.3199e-03,  3.5967e-04, -2.3655e-03,  ...,  9.9682e-05,\n",
      "         -1.5201e-03,  3.2108e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 9.1877e-04,  2.7812e-04,  8.7654e-04,  ...,  1.4280e-05,\n",
      "          1.8384e-04, -9.0695e-03],\n",
      "        [ 4.5569e-04,  3.9372e-05,  3.5544e-06,  ..., -8.1105e-06,\n",
      "         -1.3614e-05,  2.4687e-03],\n",
      "        [-1.0960e-03,  4.4318e-04, -6.1877e-05,  ..., -3.0406e-06,\n",
      "         -4.7792e-05, -3.5134e-02],\n",
      "        ...,\n",
      "        [-2.3086e-04,  1.0039e-05, -7.9401e-06,  ...,  4.3359e-04,\n",
      "         -2.4567e-04,  2.9092e-03],\n",
      "        [-3.4447e-03,  1.0842e-04,  3.8085e-03,  ..., -3.1357e-06,\n",
      "          7.5294e-03, -1.9433e-02],\n",
      "        [ 3.2360e-03,  3.1197e-04, -2.8125e-03,  ...,  9.7748e-05,\n",
      "         -1.6403e-03,  3.2009e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.3034e+01, -1.4058e+01, -8.9072e+00,  ..., -1.3839e-04,\n",
      "         -2.1306e+01, -1.3072e+01],\n",
      "        [-7.4766e+00, -1.7128e+01, -6.0563e+00,  ..., -1.8630e+01,\n",
      "         -5.7460e+00, -9.5210e+00],\n",
      "        [-2.3611e+01, -1.6159e+01, -2.1289e-04,  ..., -9.9975e+00,\n",
      "         -1.0782e+01, -9.5341e+00],\n",
      "        ...,\n",
      "        [-5.3408e+00, -1.6767e+01, -5.4147e+00,  ..., -1.0268e+01,\n",
      "         -1.0202e+01, -1.1486e-02],\n",
      "        [-1.6930e-03, -2.7709e+01, -1.6584e+01,  ..., -2.6181e+01,\n",
      "         -1.4731e+01, -7.3428e+00],\n",
      "        [-2.2097e+01, -8.6518e+00, -8.8369e+00,  ..., -3.4279e-04,\n",
      "         -1.4411e+01, -1.0723e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0148 loss_train: 0.0146 acc_train: 1.0000 loss_val: 1.3472 acc_val: 0.7633 time: 0.6305s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 9.1877e-04,  2.7812e-04,  8.7654e-04,  ...,  1.4280e-05,\n",
      "          1.8384e-04, -9.0695e-03],\n",
      "        [ 4.5569e-04,  3.9372e-05,  3.5544e-06,  ..., -8.1105e-06,\n",
      "         -1.3614e-05,  2.4687e-03],\n",
      "        [-1.0960e-03,  4.4318e-04, -6.1877e-05,  ..., -3.0406e-06,\n",
      "         -4.7792e-05, -3.5134e-02],\n",
      "        ...,\n",
      "        [-2.3086e-04,  1.0039e-05, -7.9401e-06,  ...,  4.3359e-04,\n",
      "         -2.4567e-04,  2.9092e-03],\n",
      "        [-3.4447e-03,  1.0842e-04,  3.8085e-03,  ..., -3.1357e-06,\n",
      "          7.5294e-03, -1.9433e-02],\n",
      "        [ 3.2360e-03,  3.1197e-04, -2.8125e-03,  ...,  9.7748e-05,\n",
      "         -1.6403e-03,  3.2009e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 9.4947e-04,  2.8448e-04,  9.5432e-04,  ...,  1.8050e-05,\n",
      "          1.6090e-04, -9.5503e-03],\n",
      "        [ 2.6451e-04,  2.7540e-05,  3.9578e-06,  ..., -6.9307e-06,\n",
      "         -2.3196e-05,  2.5244e-03],\n",
      "        [-9.7653e-04,  3.3640e-04, -1.0769e-04,  ..., -5.3131e-06,\n",
      "         -5.8364e-05, -3.4647e-02],\n",
      "        ...,\n",
      "        [-9.2974e-05,  5.9304e-06, -7.6632e-06,  ...,  3.3672e-04,\n",
      "         -2.4098e-04,  2.9113e-03],\n",
      "        [-3.6184e-03,  1.3342e-04,  3.7409e-03,  ..., -3.5223e-06,\n",
      "          7.9544e-03, -1.9197e-02],\n",
      "        [ 3.1507e-03,  2.6566e-04, -3.1751e-03,  ...,  9.0038e-05,\n",
      "         -1.7951e-03,  3.1908e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.2937e+01, -1.3840e+01, -8.1769e+00,  ..., -2.8463e-04,\n",
      "         -2.0645e+01, -1.2908e+01],\n",
      "        [-7.8857e+00, -1.7205e+01, -5.9684e+00,  ..., -1.8817e+01,\n",
      "         -5.6926e+00, -9.8620e+00],\n",
      "        [-2.3994e+01, -1.6483e+01, -1.6509e-04,  ..., -1.0574e+01,\n",
      "         -1.0804e+01, -1.0022e+01],\n",
      "        ...,\n",
      "        [-5.2889e+00, -1.6686e+01, -5.0234e+00,  ..., -1.0359e+01,\n",
      "         -9.9301e+00, -1.4972e-02],\n",
      "        [-1.8659e-03, -2.7750e+01, -1.6448e+01,  ..., -2.6301e+01,\n",
      "         -1.4645e+01, -7.4151e+00],\n",
      "        [-2.2013e+01, -8.3783e+00, -8.2661e+00,  ..., -5.1128e-04,\n",
      "         -1.3747e+01, -1.0672e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0149 loss_train: 0.0174 acc_train: 1.0000 loss_val: 1.4212 acc_val: 0.7567 time: 0.6275s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 9.4947e-04,  2.8448e-04,  9.5432e-04,  ...,  1.8050e-05,\n",
      "          1.6090e-04, -9.5503e-03],\n",
      "        [ 2.6451e-04,  2.7540e-05,  3.9578e-06,  ..., -6.9307e-06,\n",
      "         -2.3196e-05,  2.5244e-03],\n",
      "        [-9.7653e-04,  3.3640e-04, -1.0769e-04,  ..., -5.3131e-06,\n",
      "         -5.8364e-05, -3.4647e-02],\n",
      "        ...,\n",
      "        [-9.2974e-05,  5.9304e-06, -7.6632e-06,  ...,  3.3672e-04,\n",
      "         -2.4098e-04,  2.9113e-03],\n",
      "        [-3.6184e-03,  1.3342e-04,  3.7409e-03,  ..., -3.5223e-06,\n",
      "          7.9544e-03, -1.9197e-02],\n",
      "        [ 3.1507e-03,  2.6566e-04, -3.1751e-03,  ...,  9.0038e-05,\n",
      "         -1.7951e-03,  3.1908e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 9.7432e-04,  2.8318e-04,  9.6445e-04,  ...,  1.9891e-05,\n",
      "          1.3898e-04, -9.9169e-03],\n",
      "        [ 8.4064e-05,  1.5404e-05,  3.1175e-06,  ..., -3.9803e-06,\n",
      "         -3.0212e-05,  2.6426e-03],\n",
      "        [-8.4895e-04,  2.1915e-04, -1.4451e-04,  ..., -5.2541e-06,\n",
      "         -6.6616e-05, -3.3970e-02],\n",
      "        ...,\n",
      "        [ 3.8812e-05,  4.6694e-07, -5.0091e-06,  ...,  1.8232e-04,\n",
      "         -2.1100e-04,  2.8949e-03],\n",
      "        [-3.6781e-03,  1.5275e-04,  3.4993e-03,  ..., -3.6537e-06,\n",
      "          8.1485e-03, -1.8988e-02],\n",
      "        [ 3.1297e-03,  2.2109e-04, -3.4561e-03,  ...,  7.7561e-05,\n",
      "         -2.1578e-03,  3.1828e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.3271e+01, -1.4052e+01, -8.2712e+00,  ..., -2.5889e-04,\n",
      "         -2.1031e+01, -1.2996e+01],\n",
      "        [-8.0125e+00, -1.6965e+01, -5.7459e+00,  ..., -1.8574e+01,\n",
      "         -5.5856e+00, -9.8452e+00],\n",
      "        [-2.4372e+01, -1.6483e+01, -1.3637e-04,  ..., -1.0458e+01,\n",
      "         -1.1007e+01, -1.0183e+01],\n",
      "        ...,\n",
      "        [-5.5255e+00, -1.6577e+01, -4.8544e+00,  ..., -1.0123e+01,\n",
      "         -9.9287e+00, -1.4828e-02],\n",
      "        [-1.9469e-03, -2.7578e+01, -1.6277e+01,  ..., -2.6084e+01,\n",
      "         -1.4552e+01, -7.3301e+00],\n",
      "        [-2.2380e+01, -8.5388e+00, -8.3473e+00,  ..., -4.5397e-04,\n",
      "         -1.4064e+01, -1.0807e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0150 loss_train: 0.0165 acc_train: 1.0000 loss_val: 1.4125 acc_val: 0.7600 time: 0.6133s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 9.7432e-04,  2.8318e-04,  9.6445e-04,  ...,  1.9891e-05,\n",
      "          1.3898e-04, -9.9169e-03],\n",
      "        [ 8.4064e-05,  1.5404e-05,  3.1175e-06,  ..., -3.9803e-06,\n",
      "         -3.0212e-05,  2.6426e-03],\n",
      "        [-8.4895e-04,  2.1915e-04, -1.4451e-04,  ..., -5.2541e-06,\n",
      "         -6.6616e-05, -3.3970e-02],\n",
      "        ...,\n",
      "        [ 3.8812e-05,  4.6694e-07, -5.0091e-06,  ...,  1.8232e-04,\n",
      "         -2.1100e-04,  2.8949e-03],\n",
      "        [-3.6781e-03,  1.5275e-04,  3.4993e-03,  ..., -3.6537e-06,\n",
      "          8.1485e-03, -1.8988e-02],\n",
      "        [ 3.1297e-03,  2.2109e-04, -3.4561e-03,  ...,  7.7561e-05,\n",
      "         -2.1578e-03,  3.1828e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 9.8083e-04,  2.7497e-04,  9.1263e-04,  ...,  1.9825e-05,\n",
      "          1.4502e-04, -1.0190e-02],\n",
      "        [-7.8002e-05,  3.6283e-06,  1.4061e-06,  ..., -2.2932e-07,\n",
      "         -3.4407e-05,  2.7558e-03],\n",
      "        [-7.2109e-04,  9.9652e-05, -1.7162e-04,  ..., -3.1052e-06,\n",
      "         -7.2585e-05, -3.3221e-02],\n",
      "        ...,\n",
      "        [ 1.5657e-04, -4.6062e-06, -1.0350e-06,  ...,  4.9244e-08,\n",
      "         -1.5884e-04,  2.8399e-03],\n",
      "        [-3.6750e-03,  1.6646e-04,  3.1116e-03,  ..., -3.5456e-06,\n",
      "          8.3690e-03, -1.8799e-02],\n",
      "        [ 3.1284e-03,  1.7854e-04, -3.6591e-03,  ...,  6.1525e-05,\n",
      "         -1.8754e-03,  3.1911e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.3415e+01, -1.5084e+01, -1.0026e+01,  ..., -4.6610e-05,\n",
      "         -2.2905e+01, -1.3048e+01],\n",
      "        [-6.7637e+00, -1.6494e+01, -5.6283e+00,  ..., -1.7748e+01,\n",
      "         -5.5439e+00, -8.7730e+00],\n",
      "        [-2.3499e+01, -1.5795e+01, -3.1240e-04,  ..., -8.8645e+00,\n",
      "         -1.1143e+01, -8.9817e+00],\n",
      "        ...,\n",
      "        [-5.6945e+00, -1.6775e+01, -5.6333e+00,  ..., -9.6868e+00,\n",
      "         -1.0563e+01, -7.9506e-03],\n",
      "        [-1.3390e-03, -2.7581e+01, -1.6653e+01,  ..., -2.5774e+01,\n",
      "         -1.4838e+01, -7.2420e+00],\n",
      "        [-2.2395e+01, -9.4604e+00, -9.6058e+00,  ..., -1.6938e-04,\n",
      "         -1.5593e+01, -1.0633e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0151 loss_train: 0.0396 acc_train: 0.9857 loss_val: 1.2479 acc_val: 0.7600 time: 0.6129s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 9.8083e-04,  2.7497e-04,  9.1263e-04,  ...,  1.9825e-05,\n",
      "          1.4502e-04, -1.0190e-02],\n",
      "        [-7.8002e-05,  3.6283e-06,  1.4061e-06,  ..., -2.2932e-07,\n",
      "         -3.4407e-05,  2.7558e-03],\n",
      "        [-7.2109e-04,  9.9652e-05, -1.7162e-04,  ..., -3.1052e-06,\n",
      "         -7.2585e-05, -3.3221e-02],\n",
      "        ...,\n",
      "        [ 1.5657e-04, -4.6062e-06, -1.0350e-06,  ...,  4.9244e-08,\n",
      "         -1.5884e-04,  2.8399e-03],\n",
      "        [-3.6750e-03,  1.6646e-04,  3.1116e-03,  ..., -3.5456e-06,\n",
      "          8.3690e-03, -1.8799e-02],\n",
      "        [ 3.1284e-03,  1.7854e-04, -3.6591e-03,  ...,  6.1525e-05,\n",
      "         -1.8754e-03,  3.1911e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 9.5682e-04,  2.6070e-04,  8.0792e-04,  ...,  1.8035e-05,\n",
      "          1.4900e-04, -1.0395e-02],\n",
      "        [-2.2171e-04, -7.2000e-06, -5.7057e-07,  ...,  3.2214e-06,\n",
      "         -3.5747e-05,  2.8202e-03],\n",
      "        [-6.0870e-04, -1.4484e-05, -1.8879e-04,  ...,  7.8463e-08,\n",
      "         -7.6354e-05, -3.2443e-02],\n",
      "        ...,\n",
      "        [ 2.5064e-04, -7.8171e-06,  2.8814e-06,  ..., -1.6458e-04,\n",
      "         -9.6575e-05,  2.7915e-03],\n",
      "        [-3.6494e-03,  1.7477e-04,  2.6103e-03,  ..., -3.2270e-06,\n",
      "          8.6383e-03, -1.8718e-02],\n",
      "        [ 3.1075e-03,  1.3825e-04, -3.7884e-03,  ...,  4.3247e-05,\n",
      "         -1.5373e-03,  3.1888e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.3004e+01, -1.5622e+01, -1.1223e+01,  ..., -1.6093e-05,\n",
      "         -2.4040e+01, -1.2862e+01],\n",
      "        [-5.3030e+00, -1.6398e+01, -5.8051e+00,  ..., -1.7320e+01,\n",
      "         -5.6955e+00, -7.7410e+00],\n",
      "        [-2.2048e+01, -1.5205e+01, -1.0293e-03,  ..., -7.6253e+00,\n",
      "         -1.1097e+01, -7.6109e+00],\n",
      "        ...,\n",
      "        [-5.4550e+00, -1.7000e+01, -6.3631e+00,  ..., -9.5880e+00,\n",
      "         -1.0951e+01, -6.5522e-03],\n",
      "        [-9.7787e-04, -2.7865e+01, -1.7196e+01,  ..., -2.5856e+01,\n",
      "         -1.5230e+01, -7.3330e+00],\n",
      "        [-2.1716e+01, -9.9791e+00, -1.0386e+01,  ..., -1.1741e-04,\n",
      "         -1.6425e+01, -1.0125e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0152 loss_train: 0.0144 acc_train: 1.0000 loss_val: 1.1422 acc_val: 0.7800 time: 0.6256s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 9.5682e-04,  2.6070e-04,  8.0792e-04,  ...,  1.8035e-05,\n",
      "          1.4900e-04, -1.0395e-02],\n",
      "        [-2.2171e-04, -7.2000e-06, -5.7057e-07,  ...,  3.2214e-06,\n",
      "         -3.5747e-05,  2.8202e-03],\n",
      "        [-6.0870e-04, -1.4484e-05, -1.8879e-04,  ...,  7.8463e-08,\n",
      "         -7.6354e-05, -3.2443e-02],\n",
      "        ...,\n",
      "        [ 2.5064e-04, -7.8171e-06,  2.8814e-06,  ..., -1.6458e-04,\n",
      "         -9.6575e-05,  2.7915e-03],\n",
      "        [-3.6494e-03,  1.7477e-04,  2.6103e-03,  ..., -3.2270e-06,\n",
      "          8.6383e-03, -1.8718e-02],\n",
      "        [ 3.1075e-03,  1.3825e-04, -3.7884e-03,  ...,  4.3247e-05,\n",
      "         -1.5373e-03,  3.1888e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 9.3870e-04,  2.4128e-04,  6.6192e-04,  ...,  1.4840e-05,\n",
      "          1.5087e-04, -1.0550e-02],\n",
      "        [-3.4388e-04, -1.6597e-05, -2.1803e-06,  ...,  5.4526e-06,\n",
      "         -3.4404e-05,  2.6735e-03],\n",
      "        [-4.9144e-04, -1.1666e-04, -1.9621e-04,  ...,  2.9223e-06,\n",
      "         -7.8043e-05, -3.1814e-02],\n",
      "        ...,\n",
      "        [ 3.1586e-04, -8.3820e-06,  5.5050e-06,  ..., -3.0907e-04,\n",
      "         -1.1560e-05,  2.4737e-03],\n",
      "        [-3.7529e-03,  1.7796e-04,  2.0303e-03,  ..., -2.7375e-06,\n",
      "          9.0334e-03, -1.8758e-02],\n",
      "        [ 2.9056e-03,  1.0042e-04, -3.8490e-03,  ...,  2.4062e-05,\n",
      "         -1.1801e-03,  3.1655e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.3035e+01, -1.4290e+01, -1.1007e+01,  ..., -1.8120e-05,\n",
      "         -2.3028e+01, -1.3856e+01],\n",
      "        [-5.7600e+00, -1.5952e+01, -6.0399e+00,  ..., -1.7452e+01,\n",
      "         -5.2811e+00, -8.6671e+00],\n",
      "        [-2.2406e+01, -1.4347e+01, -6.4805e-04,  ..., -7.7834e+00,\n",
      "         -1.0423e+01, -8.7358e+00],\n",
      "        ...,\n",
      "        [-4.8991e+00, -1.5862e+01, -5.7421e+00,  ..., -9.0788e+00,\n",
      "         -9.9827e+00, -1.1904e-02],\n",
      "        [-8.1970e-04, -2.7520e+01, -1.7218e+01,  ..., -2.5884e+01,\n",
      "         -1.4996e+01, -7.7561e+00],\n",
      "        [-2.1958e+01, -8.6714e+00, -1.0220e+01,  ..., -2.2135e-04,\n",
      "         -1.5446e+01, -1.1236e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0153 loss_train: 0.0273 acc_train: 1.0000 loss_val: 1.2237 acc_val: 0.7700 time: 0.5852s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 9.3870e-04,  2.4128e-04,  6.6192e-04,  ...,  1.4840e-05,\n",
      "          1.5087e-04, -1.0550e-02],\n",
      "        [-3.4388e-04, -1.6597e-05, -2.1803e-06,  ...,  5.4526e-06,\n",
      "         -3.4404e-05,  2.6735e-03],\n",
      "        [-4.9144e-04, -1.1666e-04, -1.9621e-04,  ...,  2.9223e-06,\n",
      "         -7.8043e-05, -3.1814e-02],\n",
      "        ...,\n",
      "        [ 3.1586e-04, -8.3820e-06,  5.5050e-06,  ..., -3.0907e-04,\n",
      "         -1.1560e-05,  2.4737e-03],\n",
      "        [-3.7529e-03,  1.7796e-04,  2.0303e-03,  ..., -2.7375e-06,\n",
      "          9.0334e-03, -1.8758e-02],\n",
      "        [ 2.9056e-03,  1.0042e-04, -3.8490e-03,  ...,  2.4062e-05,\n",
      "         -1.1801e-03,  3.1655e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 9.1374e-04,  2.1769e-04,  4.8776e-04,  ...,  1.0649e-05,\n",
      "          1.5046e-04, -1.0646e-02],\n",
      "        [-4.4236e-04, -7.6533e-05, -2.9611e-06,  ...,  5.9639e-06,\n",
      "         -3.0845e-05,  2.4055e-03],\n",
      "        [-3.7778e-04, -2.0164e-04, -1.9448e-04,  ...,  4.3129e-06,\n",
      "         -7.6685e-05, -3.1200e-02],\n",
      "        ...,\n",
      "        [ 3.4979e-04, -6.3795e-06,  6.1231e-06,  ..., -3.7972e-04,\n",
      "          6.7447e-05,  2.1781e-03],\n",
      "        [-3.7786e-03,  1.7645e-04,  1.4071e-03,  ..., -2.1236e-06,\n",
      "          9.2346e-03, -1.8762e-02],\n",
      "        [ 2.7084e-03,  6.5198e-05, -3.8466e-03,  ...,  5.2407e-06,\n",
      "         -1.1641e-03,  3.1398e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.2671e+01, -1.2936e+01, -1.0180e+01,  ..., -4.0888e-05,\n",
      "         -2.1627e+01, -1.4300e+01],\n",
      "        [-6.4874e+00, -1.5977e+01, -6.2826e+00,  ..., -1.7950e+01,\n",
      "         -5.1675e+00, -9.6404e+00],\n",
      "        [-2.2635e+01, -1.4158e+01, -3.5125e-04,  ..., -8.6785e+00,\n",
      "         -9.9050e+00, -9.7973e+00],\n",
      "        ...,\n",
      "        [-4.3210e+00, -1.4992e+01, -4.9739e+00,  ..., -8.9639e+00,\n",
      "         -8.9748e+00, -2.4019e-02],\n",
      "        [-8.4043e-04, -2.7435e+01, -1.7197e+01,  ..., -2.6163e+01,\n",
      "         -1.4845e+01, -8.1406e+00],\n",
      "        [-2.1789e+01, -7.3818e+00, -9.5878e+00,  ..., -6.9928e-04,\n",
      "         -1.4147e+01, -1.1829e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0154 loss_train: 0.0159 acc_train: 1.0000 loss_val: 1.3418 acc_val: 0.7500 time: 0.6084s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 9.1374e-04,  2.1769e-04,  4.8776e-04,  ...,  1.0649e-05,\n",
      "          1.5046e-04, -1.0646e-02],\n",
      "        [-4.4236e-04, -7.6533e-05, -2.9611e-06,  ...,  5.9639e-06,\n",
      "         -3.0845e-05,  2.4055e-03],\n",
      "        [-3.7778e-04, -2.0164e-04, -1.9448e-04,  ...,  4.3129e-06,\n",
      "         -7.6685e-05, -3.1200e-02],\n",
      "        ...,\n",
      "        [ 3.4979e-04, -6.3795e-06,  6.1231e-06,  ..., -3.7972e-04,\n",
      "          6.7447e-05,  2.1781e-03],\n",
      "        [-3.7786e-03,  1.7645e-04,  1.4071e-03,  ..., -2.1236e-06,\n",
      "          9.2346e-03, -1.8762e-02],\n",
      "        [ 2.7084e-03,  6.5198e-05, -3.8466e-03,  ...,  5.2407e-06,\n",
      "         -1.1641e-03,  3.1398e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 8.7812e-04,  1.9089e-04,  2.9920e-04,  ...,  5.9258e-06,\n",
      "          1.4723e-04, -1.0658e-02],\n",
      "        [-5.1574e-04, -1.2656e-04, -2.7489e-06,  ...,  4.7751e-06,\n",
      "         -2.5412e-05,  2.2086e-03],\n",
      "        [-2.7594e-04, -2.6569e-04, -1.8453e-04,  ...,  3.8243e-06,\n",
      "         -7.3711e-05, -3.0682e-02],\n",
      "        ...,\n",
      "        [ 3.5270e-04, -2.6520e-06,  4.7264e-06,  ..., -3.6567e-04,\n",
      "          1.3230e-04,  1.8893e-03],\n",
      "        [-3.6590e-03,  1.7070e-04,  7.7523e-04,  ..., -1.4355e-06,\n",
      "          9.2563e-03, -1.8667e-02],\n",
      "        [ 2.6060e-03,  3.2701e-05, -3.7870e-03,  ..., -1.2085e-05,\n",
      "         -1.5939e-03,  3.1349e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.1735e+01, -1.3269e+01, -9.4723e+00,  ..., -8.0463e-05,\n",
      "         -2.1413e+01, -1.3243e+01],\n",
      "        [-5.9625e+00, -1.7017e+01, -6.7157e+00,  ..., -1.8753e+01,\n",
      "         -5.9284e+00, -9.4037e+00],\n",
      "        [-2.1723e+01, -1.5090e+01, -3.5995e-04,  ..., -9.6239e+00,\n",
      "         -1.0094e+01, -9.3280e+00],\n",
      "        ...,\n",
      "        [-3.9366e+00, -1.5858e+01, -5.2774e+00,  ..., -9.8742e+00,\n",
      "         -9.3774e+00, -2.9051e-02],\n",
      "        [-7.2179e-04, -2.8206e+01, -1.7584e+01,  ..., -2.6904e+01,\n",
      "         -1.5323e+01, -8.3630e+00],\n",
      "        [-2.0568e+01, -7.7703e+00, -8.9413e+00,  ..., -5.7990e-04,\n",
      "         -1.3864e+01, -1.0565e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0155 loss_train: 0.0233 acc_train: 1.0000 loss_val: 1.2841 acc_val: 0.7500 time: 0.6297s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 8.7812e-04,  1.9089e-04,  2.9920e-04,  ...,  5.9258e-06,\n",
      "          1.4723e-04, -1.0658e-02],\n",
      "        [-5.1574e-04, -1.2656e-04, -2.7489e-06,  ...,  4.7751e-06,\n",
      "         -2.5412e-05,  2.2086e-03],\n",
      "        [-2.7594e-04, -2.6569e-04, -1.8453e-04,  ...,  3.8243e-06,\n",
      "         -7.3711e-05, -3.0682e-02],\n",
      "        ...,\n",
      "        [ 3.5270e-04, -2.6520e-06,  4.7264e-06,  ..., -3.6567e-04,\n",
      "          1.3230e-04,  1.8893e-03],\n",
      "        [-3.6590e-03,  1.7070e-04,  7.7523e-04,  ..., -1.4355e-06,\n",
      "          9.2563e-03, -1.8667e-02],\n",
      "        [ 2.6060e-03,  3.2701e-05, -3.7870e-03,  ..., -1.2085e-05,\n",
      "         -1.5939e-03,  3.1349e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 8.3942e-04,  1.6186e-04,  1.0965e-04,  ...,  1.1356e-06,\n",
      "          1.4312e-04, -1.0541e-02],\n",
      "        [-5.6410e-04, -1.6494e-04, -1.7028e-06,  ...,  2.3754e-06,\n",
      "         -1.8672e-05,  2.1459e-03],\n",
      "        [-1.7841e-04, -3.0676e-04, -1.6756e-04,  ...,  1.8310e-06,\n",
      "         -6.9354e-05, -3.0007e-02],\n",
      "        ...,\n",
      "        [ 3.2725e-04,  1.5148e-06,  1.9509e-06,  ..., -2.7812e-04,\n",
      "          1.7792e-04,  1.6301e-03],\n",
      "        [-3.4900e-03,  1.6127e-04,  1.6635e-04,  ..., -7.2334e-07,\n",
      "          9.3224e-03, -1.8450e-02],\n",
      "        [ 2.5674e-03,  3.0077e-06, -3.6764e-03,  ..., -2.6976e-05,\n",
      "         -1.9707e-03,  3.1418e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.1317e+01, -1.4089e+01, -8.9141e+00,  ..., -1.4042e-04,\n",
      "         -2.1773e+01, -1.2171e+01],\n",
      "        [-5.6680e+00, -1.7785e+01, -6.7611e+00,  ..., -1.9150e+01,\n",
      "         -6.5899e+00, -8.9591e+00],\n",
      "        [-2.1434e+01, -1.6131e+01, -4.0046e-04,  ..., -1.0206e+01,\n",
      "         -1.0792e+01, -8.8071e+00],\n",
      "        ...,\n",
      "        [-4.2227e+00, -1.6764e+01, -5.4814e+00,  ..., -1.0435e+01,\n",
      "         -1.0047e+01, -2.2033e-02],\n",
      "        [-7.6610e-04, -2.8637e+01, -1.7546e+01,  ..., -2.7139e+01,\n",
      "         -1.5616e+01, -8.1978e+00],\n",
      "        [-1.9788e+01, -8.6248e+00, -8.4163e+00,  ..., -4.9924e-04,\n",
      "         -1.4127e+01, -9.2345e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0156 loss_train: 0.0151 acc_train: 1.0000 loss_val: 1.2420 acc_val: 0.7633 time: 0.5986s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 8.3942e-04,  1.6186e-04,  1.0965e-04,  ...,  1.1356e-06,\n",
      "          1.4312e-04, -1.0541e-02],\n",
      "        [-5.6410e-04, -1.6494e-04, -1.7028e-06,  ...,  2.3754e-06,\n",
      "         -1.8672e-05,  2.1459e-03],\n",
      "        [-1.7841e-04, -3.0676e-04, -1.6756e-04,  ...,  1.8310e-06,\n",
      "         -6.9354e-05, -3.0007e-02],\n",
      "        ...,\n",
      "        [ 3.2725e-04,  1.5148e-06,  1.9509e-06,  ..., -2.7812e-04,\n",
      "          1.7792e-04,  1.6301e-03],\n",
      "        [-3.4900e-03,  1.6127e-04,  1.6635e-04,  ..., -7.2334e-07,\n",
      "          9.3224e-03, -1.8450e-02],\n",
      "        [ 2.5674e-03,  3.0077e-06, -3.6764e-03,  ..., -2.6976e-05,\n",
      "         -1.9707e-03,  3.1418e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 7.9890e-04,  1.3154e-04, -6.8605e-05,  ..., -3.2913e-06,\n",
      "          1.3778e-04, -1.0374e-02],\n",
      "        [-5.8470e-04, -1.9057e-04, -2.2689e-07,  ..., -4.5368e-07,\n",
      "         -1.1007e-05,  2.2203e-03],\n",
      "        [-9.2865e-05, -3.2442e-04, -1.4496e-04,  ..., -7.1484e-07,\n",
      "         -6.3841e-05, -2.9323e-02],\n",
      "        ...,\n",
      "        [ 2.7813e-04,  4.8190e-06, -1.1827e-06,  ..., -1.4165e-04,\n",
      "          2.0186e-04,  1.9944e-03],\n",
      "        [-3.2704e-03,  1.4871e-04, -3.9176e-04,  ..., -3.4336e-08,\n",
      "          9.5260e-03, -1.8062e-02],\n",
      "        [ 2.6941e-03, -2.3841e-05, -3.5214e-03,  ..., -3.8731e-05,\n",
      "         -1.9698e-03,  3.1671e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.3157e+01, -1.4478e+01, -9.3135e+00,  ..., -9.2621e-05,\n",
      "         -2.2692e+01, -1.3144e+01],\n",
      "        [-7.2166e+00, -1.6853e+01, -6.0349e+00,  ..., -1.8432e+01,\n",
      "         -6.0364e+00, -9.5899e+00],\n",
      "        [-2.3485e+01, -1.5896e+01, -1.8702e-04,  ..., -9.7722e+00,\n",
      "         -1.1251e+01, -9.8641e+00],\n",
      "        ...,\n",
      "        [-5.5445e+00, -1.5836e+01, -4.5533e+00,  ..., -9.1162e+00,\n",
      "         -9.7586e+00, -1.7246e-02],\n",
      "        [-1.7170e-03, -2.7229e+01, -1.6209e+01,  ..., -2.5708e+01,\n",
      "         -1.4644e+01, -7.4468e+00],\n",
      "        [-2.2153e+01, -8.9344e+00, -8.9802e+00,  ..., -2.8225e-04,\n",
      "         -1.5248e+01, -1.0624e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0157 loss_train: 0.0285 acc_train: 1.0000 loss_val: 1.2824 acc_val: 0.7633 time: 0.5858s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 7.9890e-04,  1.3154e-04, -6.8605e-05,  ..., -3.2913e-06,\n",
      "          1.3778e-04, -1.0374e-02],\n",
      "        [-5.8470e-04, -1.9057e-04, -2.2689e-07,  ..., -4.5368e-07,\n",
      "         -1.1007e-05,  2.2203e-03],\n",
      "        [-9.2865e-05, -3.2442e-04, -1.4496e-04,  ..., -7.1484e-07,\n",
      "         -6.3841e-05, -2.9323e-02],\n",
      "        ...,\n",
      "        [ 2.7813e-04,  4.8190e-06, -1.1827e-06,  ..., -1.4165e-04,\n",
      "          2.0186e-04,  1.9944e-03],\n",
      "        [-3.2704e-03,  1.4871e-04, -3.9176e-04,  ..., -3.4336e-08,\n",
      "          9.5260e-03, -1.8062e-02],\n",
      "        [ 2.6941e-03, -2.3841e-05, -3.5214e-03,  ..., -3.8731e-05,\n",
      "         -1.9698e-03,  3.1671e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 7.4326e-04,  1.0080e-04, -2.2514e-04,  ..., -6.9960e-06,\n",
      "          1.2736e-04, -1.0208e-02],\n",
      "        [-5.8285e-04, -2.0367e-04,  1.1770e-06,  ..., -2.8817e-06,\n",
      "         -3.2251e-06,  2.2634e-03],\n",
      "        [-1.6678e-05, -3.1974e-04, -1.1824e-04,  ..., -2.7218e-06,\n",
      "         -5.5256e-05, -2.8630e-02],\n",
      "        ...,\n",
      "        [ 2.1148e-04,  6.3384e-06, -3.6312e-06,  ...,  1.7030e-05,\n",
      "          2.0318e-04,  2.2067e-03],\n",
      "        [-3.0268e-03,  1.3365e-04, -8.7635e-04,  ...,  5.9008e-07,\n",
      "          9.9764e-03, -1.7729e-02],\n",
      "        [ 2.8580e-03, -4.7834e-05, -3.3283e-03,  ..., -4.6908e-05,\n",
      "         -1.9920e-03,  3.1860e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.4251e+01, -1.4865e+01, -9.9923e+00,  ..., -4.7206e-05,\n",
      "         -2.3524e+01, -1.3706e+01],\n",
      "        [-8.0374e+00, -1.6091e+01, -5.5896e+00,  ..., -1.7812e+01,\n",
      "         -5.5863e+00, -9.8539e+00],\n",
      "        [-2.4433e+01, -1.5477e+01, -1.9358e-04,  ..., -9.1201e+00,\n",
      "         -1.1427e+01, -1.0173e+01],\n",
      "        ...,\n",
      "        [-6.3674e+00, -1.5205e+01, -4.1470e+00,  ..., -8.1364e+00,\n",
      "         -9.6180e+00, -1.9903e-02],\n",
      "        [-2.8443e-03, -2.6270e+01, -1.5405e+01,  ..., -2.4698e+01,\n",
      "         -1.4001e+01, -6.9158e+00],\n",
      "        [-2.3446e+01, -9.2914e+00, -9.6076e+00,  ..., -1.7177e-04,\n",
      "         -1.6126e+01, -1.1316e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0158 loss_train: 0.0195 acc_train: 1.0000 loss_val: 1.3091 acc_val: 0.7567 time: 0.6911s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 7.4326e-04,  1.0080e-04, -2.2514e-04,  ..., -6.9960e-06,\n",
      "          1.2736e-04, -1.0208e-02],\n",
      "        [-5.8285e-04, -2.0367e-04,  1.1770e-06,  ..., -2.8817e-06,\n",
      "         -3.2251e-06,  2.2634e-03],\n",
      "        [-1.6678e-05, -3.1974e-04, -1.1824e-04,  ..., -2.7218e-06,\n",
      "         -5.5256e-05, -2.8630e-02],\n",
      "        ...,\n",
      "        [ 2.1148e-04,  6.3384e-06, -3.6312e-06,  ...,  1.7030e-05,\n",
      "          2.0318e-04,  2.2067e-03],\n",
      "        [-3.0268e-03,  1.3365e-04, -8.7635e-04,  ...,  5.9008e-07,\n",
      "          9.9764e-03, -1.7729e-02],\n",
      "        [ 2.8580e-03, -4.7834e-05, -3.3283e-03,  ..., -4.6908e-05,\n",
      "         -1.9920e-03,  3.1860e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 6.8100e-04,  7.0474e-05, -3.5187e-04,  ..., -9.7161e-06,\n",
      "          1.1607e-04, -1.0084e-02],\n",
      "        [-5.6073e-04, -2.0444e-04,  2.0751e-06,  ..., -4.2659e-06,\n",
      "          4.0373e-06,  2.2238e-03],\n",
      "        [ 2.2033e-06, -2.9512e-04, -8.8933e-05,  ..., -3.4182e-06,\n",
      "         -3.6233e-05, -2.8218e-02],\n",
      "        ...,\n",
      "        [ 1.3429e-04,  5.7776e-06, -4.6670e-06,  ...,  1.2551e-04,\n",
      "          1.8428e-04,  2.1690e-03],\n",
      "        [-2.7825e-03,  1.1669e-04, -1.2703e-03,  ...,  1.1163e-06,\n",
      "          1.0526e-02, -1.7869e-02],\n",
      "        [ 2.9936e-03, -6.8992e-05, -3.1036e-03,  ..., -5.1329e-05,\n",
      "         -2.0603e-03,  3.1798e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.3345e+01, -1.4639e+01, -1.0344e+01,  ..., -3.4332e-05,\n",
      "         -2.3168e+01, -1.3296e+01],\n",
      "        [-7.5552e+00, -1.6291e+01, -6.0938e+00,  ..., -1.8127e+01,\n",
      "         -5.6776e+00, -9.8319e+00],\n",
      "        [-2.3241e+01, -1.5150e+01, -2.8833e-04,  ..., -8.9866e+00,\n",
      "         -1.0861e+01, -9.4927e+00],\n",
      "        ...,\n",
      "        [-5.7819e+00, -1.5612e+01, -4.8788e+00,  ..., -8.6572e+00,\n",
      "         -9.7934e+00, -1.2647e-02],\n",
      "        [-2.0413e-03, -2.6720e+01, -1.6084e+01,  ..., -2.5213e+01,\n",
      "         -1.4309e+01, -7.2427e+00],\n",
      "        [-2.2363e+01, -9.1208e+00, -9.7818e+00,  ..., -1.8798e-04,\n",
      "         -1.5697e+01, -1.0723e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0159 loss_train: 0.0252 acc_train: 1.0000 loss_val: 1.2677 acc_val: 0.7700 time: 0.5841s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 6.8100e-04,  7.0474e-05, -3.5187e-04,  ..., -9.7161e-06,\n",
      "          1.1607e-04, -1.0084e-02],\n",
      "        [-5.6073e-04, -2.0444e-04,  2.0751e-06,  ..., -4.2659e-06,\n",
      "          4.0373e-06,  2.2238e-03],\n",
      "        [ 2.2033e-06, -2.9512e-04, -8.8933e-05,  ..., -3.4182e-06,\n",
      "         -3.6233e-05, -2.8218e-02],\n",
      "        ...,\n",
      "        [ 1.3429e-04,  5.7776e-06, -4.6670e-06,  ...,  1.2551e-04,\n",
      "          1.8428e-04,  2.1690e-03],\n",
      "        [-2.7825e-03,  1.1669e-04, -1.2703e-03,  ...,  1.1163e-06,\n",
      "          1.0526e-02, -1.7869e-02],\n",
      "        [ 2.9936e-03, -6.8992e-05, -3.1036e-03,  ..., -5.1329e-05,\n",
      "         -2.0603e-03,  3.1798e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 6.2179e-04,  4.1276e-05, -4.4337e-04,  ..., -1.1301e-05,\n",
      "          1.0492e-04, -9.9694e-03],\n",
      "        [-5.0795e-04, -1.9145e-04,  2.2323e-06,  ..., -4.3149e-06,\n",
      "          1.0238e-05,  2.1627e-03],\n",
      "        [ 2.3940e-05, -2.5400e-04, -5.8569e-05,  ..., -2.6408e-06,\n",
      "         -1.7737e-05, -2.7871e-02],\n",
      "        ...,\n",
      "        [ 5.3744e-05,  3.5033e-06, -4.0868e-06,  ...,  1.9730e-04,\n",
      "          1.4915e-04,  1.7103e-03],\n",
      "        [-2.5346e-03,  9.8420e-05, -1.5627e-03,  ...,  1.5200e-06,\n",
      "          1.1206e-02, -1.7978e-02],\n",
      "        [ 3.1186e-03, -8.7360e-05, -2.8535e-03,  ..., -5.2067e-05,\n",
      "         -2.1418e-03,  3.1697e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.1275e+01, -1.4543e+01, -1.0287e+01,  ..., -4.1126e-05,\n",
      "         -2.2496e+01, -1.1941e+01],\n",
      "        [-6.2206e+00, -1.7223e+01, -6.8495e+00,  ..., -1.8830e+01,\n",
      "         -6.3577e+00, -9.1992e+00],\n",
      "        [-2.0921e+01, -1.5368e+01, -6.9117e-04,  ..., -9.1769e+00,\n",
      "         -1.0446e+01, -7.9695e+00],\n",
      "        ...,\n",
      "        [-4.7288e+00, -1.6843e+01, -6.1414e+00,  ..., -1.0018e+01,\n",
      "         -1.0426e+01, -1.2482e-02],\n",
      "        [-1.1157e-03, -2.7887e+01, -1.7224e+01,  ..., -2.6306e+01,\n",
      "         -1.5156e+01, -7.7105e+00],\n",
      "        [-1.9622e+01, -9.1576e+00, -9.4368e+00,  ..., -3.3802e-04,\n",
      "         -1.4782e+01, -8.7890e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0160 loss_train: 0.0306 acc_train: 1.0000 loss_val: 1.1786 acc_val: 0.7600 time: 0.5782s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 6.2179e-04,  4.1276e-05, -4.4337e-04,  ..., -1.1301e-05,\n",
      "          1.0492e-04, -9.9694e-03],\n",
      "        [-5.0795e-04, -1.9145e-04,  2.2323e-06,  ..., -4.3149e-06,\n",
      "          1.0238e-05,  2.1627e-03],\n",
      "        [ 2.3940e-05, -2.5400e-04, -5.8569e-05,  ..., -2.6408e-06,\n",
      "         -1.7737e-05, -2.7871e-02],\n",
      "        ...,\n",
      "        [ 5.3744e-05,  3.5033e-06, -4.0868e-06,  ...,  1.9730e-04,\n",
      "          1.4915e-04,  1.7103e-03],\n",
      "        [-2.5346e-03,  9.8420e-05, -1.5627e-03,  ...,  1.5200e-06,\n",
      "          1.1206e-02, -1.7978e-02],\n",
      "        [ 3.1186e-03, -8.7360e-05, -2.8535e-03,  ..., -5.2067e-05,\n",
      "         -2.1418e-03,  3.1697e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 5.6219e-04,  1.3848e-05, -4.9698e-04,  ..., -1.1715e-05,\n",
      "          9.3865e-05, -9.8321e-03],\n",
      "        [-4.4235e-04, -1.8033e-04,  1.6684e-06,  ..., -3.1403e-06,\n",
      "          1.5078e-05,  2.1211e-03],\n",
      "        [ 2.6758e-05, -2.0055e-04, -2.8572e-05,  ..., -8.4873e-07,\n",
      "         -6.2541e-07, -2.7637e-02],\n",
      "        ...,\n",
      "        [-2.3342e-05,  3.7405e-07, -2.2312e-06,  ...,  2.1512e-04,\n",
      "          1.0475e-04,  1.2363e-03],\n",
      "        [-2.2920e-03,  7.9433e-05, -1.7484e-03,  ...,  1.7869e-06,\n",
      "          1.1951e-02, -1.8062e-02],\n",
      "        [ 3.2358e-03, -1.0301e-04, -2.5843e-03,  ..., -4.9421e-05,\n",
      "         -2.1253e-03,  3.1600e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.0928e+01, -1.3474e+01, -9.5885e+00,  ..., -7.4861e-05,\n",
      "         -2.1230e+01, -1.2226e+01],\n",
      "        [-6.9904e+00, -1.7253e+01, -6.9770e+00,  ..., -1.9223e+01,\n",
      "         -6.3255e+00, -1.0000e+01],\n",
      "        [-2.1300e+01, -1.5184e+01, -5.5131e-04,  ..., -9.8363e+00,\n",
      "         -1.0079e+01, -8.8868e+00],\n",
      "        ...,\n",
      "        [-4.2682e+00, -1.6297e+01, -5.6240e+00,  ..., -1.0057e+01,\n",
      "         -9.7676e+00, -2.1238e-02],\n",
      "        [-1.4326e-03, -2.7659e+01, -1.7009e+01,  ..., -2.6393e+01,\n",
      "         -1.4943e+01, -7.9138e+00],\n",
      "        [-1.9344e+01, -8.1890e+00, -8.8739e+00,  ..., -5.3022e-04,\n",
      "         -1.3639e+01, -9.1043e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0161 loss_train: 0.0349 acc_train: 0.9857 loss_val: 1.2762 acc_val: 0.7533 time: 0.6108s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 5.6219e-04,  1.3848e-05, -4.9698e-04,  ..., -1.1715e-05,\n",
      "          9.3865e-05, -9.8321e-03],\n",
      "        [-4.4235e-04, -1.8033e-04,  1.6684e-06,  ..., -3.1403e-06,\n",
      "          1.5078e-05,  2.1211e-03],\n",
      "        [ 2.6758e-05, -2.0055e-04, -2.8572e-05,  ..., -8.4873e-07,\n",
      "         -6.2541e-07, -2.7637e-02],\n",
      "        ...,\n",
      "        [-2.3342e-05,  3.7405e-07, -2.2312e-06,  ...,  2.1512e-04,\n",
      "          1.0475e-04,  1.2363e-03],\n",
      "        [-2.2920e-03,  7.9433e-05, -1.7484e-03,  ...,  1.7869e-06,\n",
      "          1.1951e-02, -1.8062e-02],\n",
      "        [ 3.2358e-03, -1.0301e-04, -2.5843e-03,  ..., -4.9421e-05,\n",
      "         -2.1253e-03,  3.1600e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 5.1510e-04, -1.1278e-05, -5.1275e-04,  ..., -1.1031e-05,\n",
      "          8.4628e-05, -9.5736e-03],\n",
      "        [-3.6664e-04, -1.6039e-04,  6.2998e-07,  ..., -1.1897e-06,\n",
      "          1.8339e-05,  2.3622e-03],\n",
      "        [ 2.1246e-05, -1.3936e-04, -2.2173e-07,  ...,  1.1210e-06,\n",
      "          1.5030e-05, -2.7216e-02],\n",
      "        ...,\n",
      "        [-9.1057e-05, -2.5669e-06,  1.7381e-07,  ...,  1.8605e-04,\n",
      "          5.4309e-05,  8.8413e-04],\n",
      "        [-1.9863e-03,  6.0270e-05, -1.8281e-03,  ...,  1.9127e-06,\n",
      "          1.2191e-02, -1.7734e-02],\n",
      "        [ 3.5643e-03, -1.1603e-04, -2.3017e-03,  ..., -4.3877e-05,\n",
      "         -3.1330e-03,  3.2047e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.2604e+01, -1.3779e+01, -1.0266e+01,  ..., -3.7312e-05,\n",
      "         -2.2173e+01, -1.3419e+01],\n",
      "        [-8.3787e+00, -1.5931e+01, -6.1278e+00,  ..., -1.8186e+01,\n",
      "         -5.5392e+00, -1.0566e+01],\n",
      "        [-2.3240e+01, -1.4576e+01, -2.8916e-04,  ..., -9.0300e+00,\n",
      "         -1.0475e+01, -9.9365e+00],\n",
      "        ...,\n",
      "        [-5.2811e+00, -1.5081e+01, -4.7111e+00,  ..., -8.5515e+00,\n",
      "         -9.3000e+00, -1.7456e-02],\n",
      "        [-3.1392e-03, -2.6054e+01, -1.5668e+01,  ..., -2.4848e+01,\n",
      "         -1.3902e+01, -7.2878e+00],\n",
      "        [-2.1627e+01, -8.4124e+00, -9.6626e+00,  ..., -3.0823e-04,\n",
      "         -1.4807e+01, -1.0714e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0162 loss_train: 0.0320 acc_train: 0.9929 loss_val: 1.3202 acc_val: 0.7567 time: 0.5987s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 5.1510e-04, -1.1278e-05, -5.1275e-04,  ..., -1.1031e-05,\n",
      "          8.4628e-05, -9.5736e-03],\n",
      "        [-3.6664e-04, -1.6039e-04,  6.2998e-07,  ..., -1.1897e-06,\n",
      "          1.8339e-05,  2.3622e-03],\n",
      "        [ 2.1246e-05, -1.3936e-04, -2.2173e-07,  ...,  1.1210e-06,\n",
      "          1.5030e-05, -2.7216e-02],\n",
      "        ...,\n",
      "        [-9.1057e-05, -2.5669e-06,  1.7381e-07,  ...,  1.8605e-04,\n",
      "          5.4309e-05,  8.8413e-04],\n",
      "        [-1.9863e-03,  6.0270e-05, -1.8281e-03,  ...,  1.9127e-06,\n",
      "          1.2191e-02, -1.7734e-02],\n",
      "        [ 3.5643e-03, -1.1603e-04, -2.3017e-03,  ..., -4.3877e-05,\n",
      "         -3.1330e-03,  3.2047e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 4.6181e-04, -3.3675e-05, -4.9322e-04,  ..., -9.4135e-06,\n",
      "          7.4293e-05, -9.2954e-03],\n",
      "        [-2.8524e-04, -1.3449e-04, -5.0822e-07,  ...,  9.0995e-07,\n",
      "          1.9928e-05,  2.5346e-03],\n",
      "        [-5.9756e-05, -7.5096e-05,  2.5388e-05,  ...,  2.4338e-06,\n",
      "          2.8819e-05, -2.6845e-02],\n",
      "        ...,\n",
      "        [-1.4478e-04, -4.4292e-06,  2.2885e-06,  ...,  1.2061e-04,\n",
      "          3.3869e-06,  4.8859e-04],\n",
      "        [-1.7637e-03,  4.1428e-05, -1.8079e-03,  ...,  1.9025e-06,\n",
      "          1.2374e-02, -1.7545e-02],\n",
      "        [ 3.7718e-03, -1.2654e-04, -2.0112e-03,  ..., -3.6061e-05,\n",
      "         -4.2110e-03,  3.2318e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.2905e+01, -1.3848e+01, -9.5462e+00,  ..., -7.4145e-05,\n",
      "         -2.1964e+01, -1.3328e+01],\n",
      "        [-9.1851e+00, -1.5664e+01, -5.6518e+00,  ..., -1.8003e+01,\n",
      "         -5.3855e+00, -1.0867e+01],\n",
      "        [-2.4230e+01, -1.4974e+01, -1.8595e-04,  ..., -9.4120e+00,\n",
      "         -1.0953e+01, -1.0540e+01],\n",
      "        ...,\n",
      "        [-5.7135e+00, -1.4760e+01, -4.0065e+00,  ..., -8.2770e+00,\n",
      "         -9.0561e+00, -2.6189e-02],\n",
      "        [-5.5611e-03, -2.5472e+01, -1.4825e+01,  ..., -2.4317e+01,\n",
      "         -1.3425e+01, -6.9238e+00],\n",
      "        [-2.2010e+01, -8.5017e+00, -9.1703e+00,  ..., -3.2944e-04,\n",
      "         -1.4724e+01, -1.0734e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0163 loss_train: 0.0238 acc_train: 0.9929 loss_val: 1.3758 acc_val: 0.7467 time: 0.5751s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 4.6181e-04, -3.3675e-05, -4.9322e-04,  ..., -9.4135e-06,\n",
      "          7.4293e-05, -9.2954e-03],\n",
      "        [-2.8524e-04, -1.3449e-04, -5.0822e-07,  ...,  9.0995e-07,\n",
      "          1.9928e-05,  2.5346e-03],\n",
      "        [-5.9756e-05, -7.5096e-05,  2.5388e-05,  ...,  2.4338e-06,\n",
      "          2.8819e-05, -2.6845e-02],\n",
      "        ...,\n",
      "        [-1.4478e-04, -4.4292e-06,  2.2885e-06,  ...,  1.2061e-04,\n",
      "          3.3869e-06,  4.8859e-04],\n",
      "        [-1.7637e-03,  4.1428e-05, -1.8079e-03,  ...,  1.9025e-06,\n",
      "          1.2374e-02, -1.7545e-02],\n",
      "        [ 3.7718e-03, -1.2654e-04, -2.0112e-03,  ..., -3.6061e-05,\n",
      "         -4.2110e-03,  3.2318e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 3.7235e-04, -5.3024e-05, -4.4298e-04,  ..., -7.0974e-06,\n",
      "          6.0712e-05, -9.0735e-03],\n",
      "        [-2.0155e-04, -1.0435e-04, -1.3737e-06,  ...,  2.5463e-06,\n",
      "          1.9881e-05,  2.6513e-03],\n",
      "        [-3.8286e-04, -1.2195e-05,  4.7385e-05,  ...,  2.6046e-06,\n",
      "          4.0598e-05, -2.6592e-02],\n",
      "        ...,\n",
      "        [-1.8146e-04, -4.7375e-06,  3.4449e-06,  ...,  4.0007e-05,\n",
      "         -4.2931e-05,  8.6476e-05],\n",
      "        [-1.5161e-03,  2.3355e-05, -1.6981e-03,  ...,  1.7698e-06,\n",
      "          1.2485e-02, -1.7961e-02],\n",
      "        [ 4.0035e-03, -1.3465e-04, -1.7180e-03,  ..., -2.6687e-05,\n",
      "         -5.5541e-03,  3.2485e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.0890e+01, -1.5002e+01, -8.9454e+00,  ..., -1.4602e-04,\n",
      "         -2.2246e+01, -1.1083e+01],\n",
      "        [-7.3979e+00, -1.7123e+01, -6.1299e+00,  ..., -1.8675e+01,\n",
      "         -6.6319e+00, -9.4927e+00],\n",
      "        [-2.2210e+01, -1.6265e+01, -3.4720e-04,  ..., -9.8250e+00,\n",
      "         -1.1681e+01, -8.6571e+00],\n",
      "        ...,\n",
      "        [-5.2132e+00, -1.6886e+01, -5.4616e+00,  ..., -9.9659e+00,\n",
      "         -1.0595e+01, -1.1538e-02],\n",
      "        [-2.7378e-03, -2.6920e+01, -1.5816e+01,  ..., -2.5382e+01,\n",
      "         -1.4534e+01, -7.0917e+00],\n",
      "        [-1.9335e+01, -9.7637e+00, -8.4887e+00,  ..., -6.1350e-04,\n",
      "         -1.4812e+01, -7.9585e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0164 loss_train: 0.0384 acc_train: 0.9929 loss_val: 1.2259 acc_val: 0.7633 time: 0.6564s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 3.7235e-04, -5.3024e-05, -4.4298e-04,  ..., -7.0974e-06,\n",
      "          6.0712e-05, -9.0735e-03],\n",
      "        [-2.0155e-04, -1.0435e-04, -1.3737e-06,  ...,  2.5463e-06,\n",
      "          1.9881e-05,  2.6513e-03],\n",
      "        [-3.8286e-04, -1.2195e-05,  4.7385e-05,  ...,  2.6046e-06,\n",
      "          4.0598e-05, -2.6592e-02],\n",
      "        ...,\n",
      "        [-1.8146e-04, -4.7375e-06,  3.4449e-06,  ...,  4.0007e-05,\n",
      "         -4.2931e-05,  8.6476e-05],\n",
      "        [-1.5161e-03,  2.3355e-05, -1.6981e-03,  ...,  1.7698e-06,\n",
      "          1.2485e-02, -1.7961e-02],\n",
      "        [ 4.0035e-03, -1.3465e-04, -1.7180e-03,  ..., -2.6687e-05,\n",
      "         -5.5541e-03,  3.2485e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 3.2698e-04, -6.9113e-05, -3.6824e-04,  ..., -4.3586e-06,\n",
      "          5.2163e-05, -8.8126e-03],\n",
      "        [-1.1614e-04, -4.6385e-05, -1.7151e-06,  ...,  3.2950e-06,\n",
      "          1.8360e-05,  2.9770e-03],\n",
      "        [-6.6571e-04,  4.5395e-05,  6.5134e-05,  ...,  1.6694e-06,\n",
      "          5.0284e-05, -2.6466e-02],\n",
      "        ...,\n",
      "        [-1.9968e-04, -3.5420e-06,  3.3516e-06,  ..., -1.0605e-04,\n",
      "         -8.0732e-05, -3.2691e-04],\n",
      "        [-1.2660e-03,  6.4364e-06, -1.5128e-03,  ...,  1.5348e-06,\n",
      "          1.2889e-02, -1.8403e-02],\n",
      "        [ 4.3176e-03, -1.4051e-04, -1.4267e-03,  ..., -1.6501e-05,\n",
      "         -6.0548e-03,  3.2555e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.0358e+01, -1.5082e+01, -9.7674e+00,  ..., -7.3073e-05,\n",
      "         -2.2479e+01, -1.1079e+01],\n",
      "        [-6.6039e+00, -1.6560e+01, -6.2337e+00,  ..., -1.8181e+01,\n",
      "         -6.2582e+00, -9.1343e+00],\n",
      "        [-2.1227e+01, -1.5505e+01, -6.1970e-04,  ..., -8.9023e+00,\n",
      "         -1.1285e+01, -7.9358e+00],\n",
      "        ...,\n",
      "        [-4.8662e+00, -1.6627e+01, -5.9162e+00,  ..., -9.6611e+00,\n",
      "         -1.0517e+01, -1.1748e-02],\n",
      "        [-1.8163e-03, -2.6865e+01, -1.6275e+01,  ..., -2.5343e+01,\n",
      "         -1.4603e+01, -7.3143e+00],\n",
      "        [-1.8855e+01, -9.8366e+00, -9.0882e+00,  ..., -5.4702e-04,\n",
      "         -1.4999e+01, -7.8752e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0165 loss_train: 0.0296 acc_train: 1.0000 loss_val: 1.1457 acc_val: 0.7733 time: 0.5743s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 3.2698e-04, -6.9113e-05, -3.6824e-04,  ..., -4.3586e-06,\n",
      "          5.2163e-05, -8.8126e-03],\n",
      "        [-1.1614e-04, -4.6385e-05, -1.7151e-06,  ...,  3.2950e-06,\n",
      "          1.8360e-05,  2.9770e-03],\n",
      "        [-6.6571e-04,  4.5395e-05,  6.5134e-05,  ...,  1.6694e-06,\n",
      "          5.0284e-05, -2.6466e-02],\n",
      "        ...,\n",
      "        [-1.9968e-04, -3.5420e-06,  3.3516e-06,  ..., -1.0605e-04,\n",
      "         -8.0732e-05, -3.2691e-04],\n",
      "        [-1.2660e-03,  6.4364e-06, -1.5128e-03,  ...,  1.5348e-06,\n",
      "          1.2889e-02, -1.8403e-02],\n",
      "        [ 4.3176e-03, -1.4051e-04, -1.4267e-03,  ..., -1.6501e-05,\n",
      "         -6.0548e-03,  3.2555e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 2.8451e-04, -8.1833e-05, -2.7625e-04,  ..., -1.4868e-06,\n",
      "          4.4670e-05, -8.5383e-03],\n",
      "        [-3.4835e-05,  8.5367e-06, -1.4721e-06,  ...,  3.0249e-06,\n",
      "          1.5617e-05,  3.2264e-03],\n",
      "        [-9.0736e-04,  9.4433e-05,  7.8246e-05,  ...,  1.2448e-07,\n",
      "          6.0856e-05, -2.6332e-02],\n",
      "        ...,\n",
      "        [-1.9635e-04, -1.3571e-06,  2.1572e-06,  ..., -2.7469e-04,\n",
      "         -9.4454e-05, -5.2508e-04],\n",
      "        [-1.0762e-03, -9.0062e-06, -1.2684e-03,  ...,  1.2222e-06,\n",
      "          1.3366e-02, -1.8897e-02],\n",
      "        [ 4.5934e-03, -1.4427e-04, -1.1415e-03,  ..., -6.2372e-06,\n",
      "         -6.2630e-03,  3.2510e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.1023e+01, -1.3978e+01, -1.0250e+01,  ..., -4.0173e-05,\n",
      "         -2.1871e+01, -1.2443e+01],\n",
      "        [-7.4576e+00, -1.5146e+01, -6.0272e+00,  ..., -1.7515e+01,\n",
      "         -5.1430e+00, -1.0048e+01],\n",
      "        [-2.1963e+01, -1.4048e+01, -5.1652e-04,  ..., -8.2206e+00,\n",
      "         -1.0471e+01, -8.9426e+00],\n",
      "        ...,\n",
      "        [-4.7225e+00, -1.4974e+01, -5.2795e+00,  ..., -8.4827e+00,\n",
      "         -9.3767e+00, -1.6325e-02],\n",
      "        [-2.1381e-03, -2.5804e+01, -1.5916e+01,  ..., -2.4639e+01,\n",
      "         -1.3886e+01, -7.4133e+00],\n",
      "        [-2.0106e+01, -8.7566e+00, -9.6468e+00,  ..., -2.8940e-04,\n",
      "         -1.4636e+01, -9.6121e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0166 loss_train: 0.0216 acc_train: 1.0000 loss_val: 1.2437 acc_val: 0.7667 time: 0.6586s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 2.8451e-04, -8.1833e-05, -2.7625e-04,  ..., -1.4868e-06,\n",
      "          4.4670e-05, -8.5383e-03],\n",
      "        [-3.4835e-05,  8.5367e-06, -1.4721e-06,  ...,  3.0249e-06,\n",
      "          1.5617e-05,  3.2264e-03],\n",
      "        [-9.0736e-04,  9.4433e-05,  7.8246e-05,  ...,  1.2448e-07,\n",
      "          6.0856e-05, -2.6332e-02],\n",
      "        ...,\n",
      "        [-1.9635e-04, -1.3571e-06,  2.1572e-06,  ..., -2.7469e-04,\n",
      "         -9.4454e-05, -5.2508e-04],\n",
      "        [-1.0762e-03, -9.0062e-06, -1.2684e-03,  ...,  1.2222e-06,\n",
      "          1.3366e-02, -1.8897e-02],\n",
      "        [ 4.5934e-03, -1.4427e-04, -1.1415e-03,  ..., -6.2372e-06,\n",
      "         -6.2630e-03,  3.2510e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 2.3590e-04, -9.1171e-05, -1.7475e-04,  ...,  1.2427e-06,\n",
      "          3.5567e-05, -8.2655e-03],\n",
      "        [ 3.9830e-05,  5.7651e-05, -7.7795e-07,  ...,  1.9095e-06,\n",
      "          1.1970e-05,  3.4872e-03],\n",
      "        [-1.1376e-03,  1.3252e-04,  8.6573e-05,  ..., -1.3229e-06,\n",
      "          6.9755e-05, -2.6176e-02],\n",
      "        ...,\n",
      "        [-1.7712e-04,  1.0406e-06,  3.6186e-07,  ..., -3.6833e-04,\n",
      "         -9.7368e-05, -8.2905e-04],\n",
      "        [-9.0883e-04, -2.2717e-05, -9.8283e-04,  ...,  8.5992e-07,\n",
      "          1.3732e-02, -1.9418e-02],\n",
      "        [ 4.8213e-03, -1.4608e-04, -8.6637e-04,  ...,  3.4353e-06,\n",
      "         -6.4893e-03,  3.2443e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.1045e+01, -1.3170e+01, -1.0153e+01,  ..., -4.3272e-05,\n",
      "         -2.1174e+01, -1.2946e+01],\n",
      "        [-7.9205e+00, -1.4621e+01, -6.0264e+00,  ..., -1.7406e+01,\n",
      "         -4.7172e+00, -1.0581e+01],\n",
      "        [-2.2191e+01, -1.3436e+01, -5.0198e-04,  ..., -8.1820e+00,\n",
      "         -1.0043e+01, -9.4806e+00],\n",
      "        ...,\n",
      "        [-4.5075e+00, -1.4034e+01, -4.8166e+00,  ..., -7.9686e+00,\n",
      "         -8.6359e+00, -2.3167e-02],\n",
      "        [-2.5174e-03, -2.5336e+01, -1.5746e+01,  ..., -2.4428e+01,\n",
      "         -1.3538e+01, -7.5449e+00],\n",
      "        [-2.0352e+01, -7.9539e+00, -9.6103e+00,  ..., -4.5349e-04,\n",
      "         -1.4021e+01, -1.0285e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0167 loss_train: 0.0193 acc_train: 1.0000 loss_val: 1.3443 acc_val: 0.7533 time: 0.5672s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 2.3590e-04, -9.1171e-05, -1.7475e-04,  ...,  1.2427e-06,\n",
      "          3.5567e-05, -8.2655e-03],\n",
      "        [ 3.9830e-05,  5.7651e-05, -7.7795e-07,  ...,  1.9095e-06,\n",
      "          1.1970e-05,  3.4872e-03],\n",
      "        [-1.1376e-03,  1.3252e-04,  8.6573e-05,  ..., -1.3229e-06,\n",
      "          6.9755e-05, -2.6176e-02],\n",
      "        ...,\n",
      "        [-1.7712e-04,  1.0406e-06,  3.6186e-07,  ..., -3.6833e-04,\n",
      "         -9.7368e-05, -8.2905e-04],\n",
      "        [-9.0883e-04, -2.2717e-05, -9.8283e-04,  ...,  8.5992e-07,\n",
      "          1.3732e-02, -1.9418e-02],\n",
      "        [ 4.8213e-03, -1.4608e-04, -8.6637e-04,  ...,  3.4353e-06,\n",
      "         -6.4893e-03,  3.2443e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.6272e-04, -9.7203e-05, -7.1402e-05,  ...,  3.5928e-06,\n",
      "          1.9243e-05, -7.9799e-03],\n",
      "        [ 1.0581e-04,  8.5801e-05,  1.0043e-07,  ...,  3.5059e-07,\n",
      "          7.7787e-06,  3.6910e-03],\n",
      "        [-1.3241e-03,  1.5821e-04,  9.0192e-05,  ..., -2.0710e-06,\n",
      "          7.6396e-05, -2.6001e-02],\n",
      "        ...,\n",
      "        [-1.4537e-04,  2.8787e-06, -1.3798e-06,  ..., -3.6887e-04,\n",
      "         -9.2116e-05, -1.1761e-03],\n",
      "        [-7.3263e-04, -3.4509e-05, -6.7463e-04,  ...,  4.7622e-07,\n",
      "          1.3658e-02, -1.9825e-02],\n",
      "        [ 4.8739e-03, -1.4612e-04, -6.0441e-04,  ...,  1.1945e-05,\n",
      "         -7.2210e-03,  3.2325e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-2.9733e+01, -1.3266e+01, -8.9133e+00,  ..., -1.4733e-04,\n",
      "         -2.0489e+01, -1.1417e+01],\n",
      "        [-7.5475e+00, -1.6223e+01, -6.5467e+00,  ..., -1.8620e+01,\n",
      "         -5.9481e+00, -1.0310e+01],\n",
      "        [-2.1331e+01, -1.4811e+01, -4.9329e-04,  ..., -9.5057e+00,\n",
      "         -1.0565e+01, -8.8451e+00],\n",
      "        ...,\n",
      "        [-4.2196e+00, -1.5457e+01, -5.2395e+00,  ..., -9.4917e+00,\n",
      "         -9.3892e+00, -2.4847e-02],\n",
      "        [-2.4963e-03, -2.6316e+01, -1.6105e+01,  ..., -2.5361e+01,\n",
      "         -1.4145e+01, -7.6659e+00],\n",
      "        [-1.8692e+01, -8.1855e+00, -8.5346e+00,  ..., -6.6890e-04,\n",
      "         -1.3341e+01, -8.5583e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0168 loss_train: 0.0274 acc_train: 0.9929 loss_val: 1.3070 acc_val: 0.7533 time: 0.5594s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.6272e-04, -9.7203e-05, -7.1402e-05,  ...,  3.5928e-06,\n",
      "          1.9243e-05, -7.9799e-03],\n",
      "        [ 1.0581e-04,  8.5801e-05,  1.0043e-07,  ...,  3.5059e-07,\n",
      "          7.7787e-06,  3.6910e-03],\n",
      "        [-1.3241e-03,  1.5821e-04,  9.0192e-05,  ..., -2.0710e-06,\n",
      "          7.6396e-05, -2.6001e-02],\n",
      "        ...,\n",
      "        [-1.4537e-04,  2.8787e-06, -1.3798e-06,  ..., -3.6887e-04,\n",
      "         -9.2116e-05, -1.1761e-03],\n",
      "        [-7.3263e-04, -3.4509e-05, -6.7463e-04,  ...,  4.7622e-07,\n",
      "          1.3658e-02, -1.9825e-02],\n",
      "        [ 4.8739e-03, -1.4612e-04, -6.0441e-04,  ...,  1.1945e-05,\n",
      "         -7.2210e-03,  3.2325e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 9.8769e-05, -1.0008e-04,  2.6708e-05,  ...,  5.3827e-06,\n",
      "          4.5100e-06, -7.5942e-03],\n",
      "        [ 1.6257e-04,  1.0640e-04,  8.6092e-07,  ..., -1.1586e-06,\n",
      "          3.4080e-06,  3.9953e-03],\n",
      "        [-1.5035e-03,  1.7097e-04,  8.9384e-05,  ..., -1.8690e-06,\n",
      "          8.0583e-05, -2.5600e-02],\n",
      "        ...,\n",
      "        [-1.0558e-04,  3.6310e-06, -2.4908e-06,  ..., -2.8402e-04,\n",
      "         -7.8383e-05, -1.4686e-03],\n",
      "        [-5.4655e-04, -4.4258e-05, -3.6165e-04,  ...,  9.8367e-08,\n",
      "          1.3700e-02, -2.0029e-02],\n",
      "        [ 5.0055e-03, -1.4453e-04, -3.5844e-04,  ...,  1.8849e-05,\n",
      "         -7.8716e-03,  3.2573e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.0198e+01, -1.4175e+01, -8.9830e+00,  ..., -1.4328e-04,\n",
      "         -2.1451e+01, -1.0982e+01],\n",
      "        [-7.5931e+00, -1.6365e+01, -6.2820e+00,  ..., -1.8449e+01,\n",
      "         -6.2479e+00, -9.9369e+00],\n",
      "        [-2.1761e+01, -1.5356e+01, -4.5802e-04,  ..., -9.3415e+00,\n",
      "         -1.1358e+01, -8.5061e+00],\n",
      "        ...,\n",
      "        [-5.0245e+00, -1.6024e+01, -5.3511e+00,  ..., -9.4882e+00,\n",
      "         -1.0109e+01, -1.3921e-02],\n",
      "        [-3.1907e-03, -2.6093e+01, -1.5659e+01,  ..., -2.4919e+01,\n",
      "         -1.4061e+01, -7.2166e+00],\n",
      "        [-1.9275e+01, -9.0583e+00, -8.7189e+00,  ..., -5.3523e-04,\n",
      "         -1.4344e+01, -8.2759e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0169 loss_train: 0.0237 acc_train: 1.0000 loss_val: 1.2580 acc_val: 0.7533 time: 0.5798s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 9.8769e-05, -1.0008e-04,  2.6708e-05,  ...,  5.3827e-06,\n",
      "          4.5100e-06, -7.5942e-03],\n",
      "        [ 1.6257e-04,  1.0640e-04,  8.6092e-07,  ..., -1.1586e-06,\n",
      "          3.4080e-06,  3.9953e-03],\n",
      "        [-1.5035e-03,  1.7097e-04,  8.9384e-05,  ..., -1.8690e-06,\n",
      "          8.0583e-05, -2.5600e-02],\n",
      "        ...,\n",
      "        [-1.0558e-04,  3.6310e-06, -2.4908e-06,  ..., -2.8402e-04,\n",
      "         -7.8383e-05, -1.4686e-03],\n",
      "        [-5.4655e-04, -4.4258e-05, -3.6165e-04,  ...,  9.8367e-08,\n",
      "          1.3700e-02, -2.0029e-02],\n",
      "        [ 5.0055e-03, -1.4453e-04, -3.5844e-04,  ...,  1.8849e-05,\n",
      "         -7.8716e-03,  3.2573e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 3.7399e-05, -1.0003e-04,  1.1349e-04,  ...,  6.4999e-06,\n",
      "         -6.6978e-06, -7.2127e-03],\n",
      "        [ 2.0790e-04,  1.1901e-04,  1.2672e-06,  ..., -2.1842e-06,\n",
      "         -7.9593e-07,  4.3096e-03],\n",
      "        [-1.7017e-03,  1.7118e-04,  8.4603e-05,  ..., -8.9222e-07,\n",
      "          8.3602e-05, -2.5205e-02],\n",
      "        ...,\n",
      "        [-6.0841e-05,  3.1624e-06, -2.6582e-06,  ..., -1.4622e-04,\n",
      "         -5.8044e-05, -1.7417e-03],\n",
      "        [-4.0474e-04, -5.1906e-05, -6.0405e-05,  ..., -2.4930e-07,\n",
      "          1.3768e-02, -2.0182e-02],\n",
      "        [ 5.1196e-03, -1.4151e-04, -1.3073e-04,  ...,  2.3847e-05,\n",
      "         -8.3104e-03,  3.2782e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.1103e+01, -1.4928e+01, -9.4654e+00,  ..., -9.2860e-05,\n",
      "         -2.2430e+01, -1.1104e+01],\n",
      "        [-7.9092e+00, -1.5956e+01, -5.8582e+00,  ..., -1.7899e+01,\n",
      "         -6.0758e+00, -9.7704e+00],\n",
      "        [-2.2504e+01, -1.5394e+01, -4.6314e-04,  ..., -8.7421e+00,\n",
      "         -1.1863e+01, -8.4245e+00],\n",
      "        ...,\n",
      "        [-5.9086e+00, -1.6116e+01, -5.3194e+00,  ..., -9.0017e+00,\n",
      "         -1.0546e+01, -9.0654e-03],\n",
      "        [-4.3267e-03, -2.5509e+01, -1.5050e+01,  ..., -2.4114e+01,\n",
      "         -1.3710e+01, -6.6859e+00],\n",
      "        [-2.0404e+01, -9.7640e+00, -9.2380e+00,  ..., -3.4064e-04,\n",
      "         -1.5398e+01, -8.5924e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0170 loss_train: 0.0143 acc_train: 1.0000 loss_val: 1.2347 acc_val: 0.7633 time: 0.5889s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 3.7399e-05, -1.0003e-04,  1.1349e-04,  ...,  6.4999e-06,\n",
      "         -6.6978e-06, -7.2127e-03],\n",
      "        [ 2.0790e-04,  1.1901e-04,  1.2672e-06,  ..., -2.1842e-06,\n",
      "         -7.9593e-07,  4.3096e-03],\n",
      "        [-1.7017e-03,  1.7118e-04,  8.4603e-05,  ..., -8.9222e-07,\n",
      "          8.3602e-05, -2.5205e-02],\n",
      "        ...,\n",
      "        [-6.0841e-05,  3.1624e-06, -2.6582e-06,  ..., -1.4622e-04,\n",
      "         -5.8044e-05, -1.7417e-03],\n",
      "        [-4.0474e-04, -5.1906e-05, -6.0405e-05,  ..., -2.4930e-07,\n",
      "          1.3768e-02, -2.0182e-02],\n",
      "        [ 5.1196e-03, -1.4151e-04, -1.3073e-04,  ...,  2.3847e-05,\n",
      "         -8.3104e-03,  3.2782e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-1.1141e-05, -9.7322e-05,  1.8417e-04,  ...,  6.9040e-06,\n",
      "         -8.0029e-06, -6.8226e-03],\n",
      "        [ 2.4124e-04,  1.3178e-04,  1.2202e-06,  ..., -2.4729e-06,\n",
      "         -4.5312e-06,  4.5662e-03],\n",
      "        [-1.8701e-03,  1.6001e-04,  7.6439e-05,  ...,  3.7008e-07,\n",
      "          8.4461e-05, -2.4953e-02],\n",
      "        ...,\n",
      "        [-1.3022e-05,  1.7363e-06, -1.9146e-06,  ..., -1.5729e-06,\n",
      "         -3.3874e-05, -2.0828e-03],\n",
      "        [-2.8408e-04, -5.7453e-05,  2.1471e-04,  ..., -5.4665e-07,\n",
      "          1.3893e-02, -2.0363e-02],\n",
      "        [ 5.2061e-03, -1.3721e-04,  7.6916e-05,  ...,  2.6792e-05,\n",
      "         -8.3687e-03,  3.2985e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.1445e+01, -1.5738e+01, -1.0287e+01,  ..., -5.0543e-05,\n",
      "         -2.3319e+01, -1.1021e+01],\n",
      "        [-7.4246e+00, -1.5646e+01, -5.6781e+00,  ..., -1.7352e+01,\n",
      "         -5.8898e+00, -9.2217e+00],\n",
      "        [-2.2240e+01, -1.5258e+01, -9.0951e-04,  ..., -7.8445e+00,\n",
      "         -1.2034e+01, -7.6824e+00],\n",
      "        ...,\n",
      "        [-6.3163e+00, -1.6467e+01, -5.8065e+00,  ..., -8.7702e+00,\n",
      "         -1.1047e+01, -5.5437e-03],\n",
      "        [-3.6894e-03, -2.5488e+01, -1.5155e+01,  ..., -2.3764e+01,\n",
      "         -1.3754e+01, -6.4421e+00],\n",
      "        [-2.0772e+01, -1.0452e+01, -9.9042e+00,  ..., -2.7319e-04,\n",
      "         -1.6205e+01, -8.5472e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0171 loss_train: 0.0220 acc_train: 1.0000 loss_val: 1.1798 acc_val: 0.7800 time: 0.5862s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-1.1141e-05, -9.7322e-05,  1.8417e-04,  ...,  6.9040e-06,\n",
      "         -8.0029e-06, -6.8226e-03],\n",
      "        [ 2.4124e-04,  1.3178e-04,  1.2202e-06,  ..., -2.4729e-06,\n",
      "         -4.5312e-06,  4.5662e-03],\n",
      "        [-1.8701e-03,  1.6001e-04,  7.6439e-05,  ...,  3.7008e-07,\n",
      "          8.4461e-05, -2.4953e-02],\n",
      "        ...,\n",
      "        [-1.3022e-05,  1.7363e-06, -1.9146e-06,  ..., -1.5729e-06,\n",
      "         -3.3874e-05, -2.0828e-03],\n",
      "        [-2.8408e-04, -5.7453e-05,  2.1471e-04,  ..., -5.4665e-07,\n",
      "          1.3893e-02, -2.0363e-02],\n",
      "        [ 5.2061e-03, -1.3721e-04,  7.6916e-05,  ...,  2.6792e-05,\n",
      "         -8.3687e-03,  3.2985e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-4.9313e-05, -9.2284e-05,  2.3549e-04,  ...,  6.6249e-06,\n",
      "         -7.8684e-06, -6.4700e-03],\n",
      "        [ 2.6251e-04,  1.3583e-04,  7.7794e-07,  ..., -2.0096e-06,\n",
      "         -7.5588e-06,  4.6822e-03],\n",
      "        [-1.9824e-03,  1.3928e-04,  6.5581e-05,  ...,  1.3514e-06,\n",
      "          8.3218e-05, -2.4784e-02],\n",
      "        ...,\n",
      "        [ 3.1220e-05, -1.0360e-07, -5.9672e-07,  ...,  1.2214e-04,\n",
      "         -1.7204e-06, -2.4690e-03],\n",
      "        [-1.7870e-04, -6.0954e-05,  4.5195e-04,  ..., -7.7871e-07,\n",
      "          1.4105e-02, -2.0627e-02],\n",
      "        [ 5.2800e-03, -1.3180e-04,  2.6318e-04,  ...,  2.7685e-05,\n",
      "         -8.3317e-03,  3.3006e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.1012e+01, -1.5537e+01, -1.0289e+01,  ..., -5.2808e-05,\n",
      "         -2.2704e+01, -1.0891e+01],\n",
      "        [-7.0381e+00, -1.5568e+01, -5.8566e+00,  ..., -1.7364e+01,\n",
      "         -5.6223e+00, -9.2135e+00],\n",
      "        [-2.1676e+01, -1.5141e+01, -1.0413e-03,  ..., -7.8350e+00,\n",
      "         -1.1548e+01, -7.4663e+00],\n",
      "        ...,\n",
      "        [-5.8853e+00, -1.6568e+01, -6.0410e+00,  ..., -9.0053e+00,\n",
      "         -1.0856e+01, -5.8839e-03],\n",
      "        [-2.4029e-03, -2.5953e+01, -1.5784e+01,  ..., -2.4242e+01,\n",
      "         -1.4008e+01, -6.8064e+00],\n",
      "        [-2.0270e+01, -1.0184e+01, -9.8509e+00,  ..., -3.1407e-04,\n",
      "         -1.5538e+01, -8.4065e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0172 loss_train: 0.0196 acc_train: 1.0000 loss_val: 1.1818 acc_val: 0.7833 time: 0.6185s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-4.9313e-05, -9.2284e-05,  2.3549e-04,  ...,  6.6249e-06,\n",
      "         -7.8684e-06, -6.4700e-03],\n",
      "        [ 2.6251e-04,  1.3583e-04,  7.7794e-07,  ..., -2.0096e-06,\n",
      "         -7.5588e-06,  4.6822e-03],\n",
      "        [-1.9824e-03,  1.3928e-04,  6.5581e-05,  ...,  1.3514e-06,\n",
      "          8.3218e-05, -2.4784e-02],\n",
      "        ...,\n",
      "        [ 3.1220e-05, -1.0360e-07, -5.9672e-07,  ...,  1.2214e-04,\n",
      "         -1.7204e-06, -2.4690e-03],\n",
      "        [-1.7870e-04, -6.0954e-05,  4.5195e-04,  ..., -7.7871e-07,\n",
      "          1.4105e-02, -2.0627e-02],\n",
      "        [ 5.2800e-03, -1.3180e-04,  2.6318e-04,  ...,  2.7685e-05,\n",
      "         -8.3317e-03,  3.3006e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-8.8526e-05, -8.5267e-05,  2.6580e-04,  ...,  5.7529e-06,\n",
      "         -9.5105e-06, -6.1137e-03],\n",
      "        [ 2.7210e-04, -1.8830e-05,  1.2297e-07,  ..., -1.0012e-06,\n",
      "         -9.7154e-06,  4.6172e-03],\n",
      "        [-2.0541e-03,  1.1126e-04,  5.2777e-05,  ...,  1.6576e-06,\n",
      "          8.4420e-05, -2.4685e-02],\n",
      "        ...,\n",
      "        [ 6.8535e-05, -1.7317e-06,  7.9519e-07,  ...,  2.0726e-04,\n",
      "          2.7485e-05, -3.0121e-03],\n",
      "        [-2.5722e-04, -6.2509e-05,  6.4259e-04,  ..., -9.3618e-07,\n",
      "          1.4202e-02, -2.0926e-02],\n",
      "        [ 5.2118e-03, -1.2544e-04,  4.2718e-04,  ...,  2.6660e-05,\n",
      "         -8.3952e-03,  3.2836e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-2.9679e+01, -1.4388e+01, -9.2934e+00,  ..., -1.2135e-04,\n",
      "         -2.0809e+01, -1.0456e+01],\n",
      "        [-6.7071e+00, -1.6034e+01, -6.3765e+00,  ..., -1.8075e+01,\n",
      "         -5.6540e+00, -9.5289e+00],\n",
      "        [-2.0800e+01, -1.5293e+01, -8.1208e-04,  ..., -8.8637e+00,\n",
      "         -1.0806e+01, -7.6332e+00],\n",
      "        ...,\n",
      "        [-4.8122e+00, -1.6635e+01, -6.0747e+00,  ..., -9.7854e+00,\n",
      "         -1.0308e+01, -1.1865e-02],\n",
      "        [-1.4408e-03, -2.6820e+01, -1.6635e+01,  ..., -2.5353e+01,\n",
      "         -1.4460e+01, -7.4992e+00],\n",
      "        [-1.8778e+01, -9.0880e+00, -9.0004e+00,  ..., -6.0302e-04,\n",
      "         -1.3666e+01, -7.9149e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0173 loss_train: 0.0168 acc_train: 1.0000 loss_val: 1.2542 acc_val: 0.7667 time: 0.6100s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-8.8526e-05, -8.5267e-05,  2.6580e-04,  ...,  5.7529e-06,\n",
      "         -9.5105e-06, -6.1137e-03],\n",
      "        [ 2.7210e-04, -1.8830e-05,  1.2297e-07,  ..., -1.0012e-06,\n",
      "         -9.7154e-06,  4.6172e-03],\n",
      "        [-2.0541e-03,  1.1126e-04,  5.2777e-05,  ...,  1.6576e-06,\n",
      "          8.4420e-05, -2.4685e-02],\n",
      "        ...,\n",
      "        [ 6.8535e-05, -1.7317e-06,  7.9519e-07,  ...,  2.0726e-04,\n",
      "          2.7485e-05, -3.0121e-03],\n",
      "        [-2.5722e-04, -6.2509e-05,  6.4259e-04,  ..., -9.3618e-07,\n",
      "          1.4202e-02, -2.0926e-02],\n",
      "        [ 5.2118e-03, -1.2544e-04,  4.2718e-04,  ...,  2.6660e-05,\n",
      "         -8.3952e-03,  3.2836e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-1.1953e-04, -7.6643e-05,  2.7503e-04,  ...,  4.4256e-06,\n",
      "         -7.3572e-06, -5.7243e-03],\n",
      "        [ 2.7225e-04, -2.3784e-04, -5.0889e-07,  ...,  2.0404e-07,\n",
      "         -1.0919e-05,  4.4904e-03],\n",
      "        [-2.0744e-03,  7.8507e-05,  3.8794e-05,  ...,  1.2205e-06,\n",
      "          7.9618e-05, -2.4346e-02],\n",
      "        ...,\n",
      "        [ 9.6438e-05, -2.6471e-06,  1.7816e-06,  ...,  2.3888e-04,\n",
      "          5.1033e-05, -3.4142e-03],\n",
      "        [-3.7300e-04, -6.2262e-05,  7.8112e-04,  ..., -1.0156e-06,\n",
      "          1.4144e-02, -2.1099e-02],\n",
      "        [ 5.1364e-03, -1.1830e-04,  5.6846e-04,  ...,  2.3965e-05,\n",
      "         -8.9964e-03,  3.2728e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-2.8936e+01, -1.3566e+01, -8.1427e+00,  ..., -3.3421e-04,\n",
      "         -1.9447e+01, -1.0077e+01],\n",
      "        [-6.6702e+00, -1.6428e+01, -6.5827e+00,  ..., -1.8616e+01,\n",
      "         -5.7411e+00, -9.7652e+00],\n",
      "        [-2.0629e+01, -1.5767e+01, -6.8510e-04,  ..., -9.9146e+00,\n",
      "         -1.0658e+01, -7.9941e+00],\n",
      "        ...,\n",
      "        [-4.3095e+00, -1.6727e+01, -5.8764e+00,  ..., -1.0310e+01,\n",
      "         -1.0028e+01, -1.8790e-02],\n",
      "        [-1.1805e-03, -2.7350e+01, -1.6977e+01,  ..., -2.6021e+01,\n",
      "         -1.4707e+01, -7.8314e+00],\n",
      "        [-1.7910e+01, -8.3283e+00, -8.1277e+00,  ..., -1.0711e-03,\n",
      "         -1.2343e+01, -7.5439e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0174 loss_train: 0.0174 acc_train: 1.0000 loss_val: 1.3523 acc_val: 0.7433 time: 0.6186s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-1.1953e-04, -7.6643e-05,  2.7503e-04,  ...,  4.4256e-06,\n",
      "         -7.3572e-06, -5.7243e-03],\n",
      "        [ 2.7225e-04, -2.3784e-04, -5.0889e-07,  ...,  2.0404e-07,\n",
      "         -1.0919e-05,  4.4904e-03],\n",
      "        [-2.0744e-03,  7.8507e-05,  3.8794e-05,  ...,  1.2205e-06,\n",
      "          7.9618e-05, -2.4346e-02],\n",
      "        ...,\n",
      "        [ 9.6438e-05, -2.6471e-06,  1.7816e-06,  ...,  2.3888e-04,\n",
      "          5.1033e-05, -3.4142e-03],\n",
      "        [-3.7300e-04, -6.2262e-05,  7.8112e-04,  ..., -1.0156e-06,\n",
      "          1.4144e-02, -2.1099e-02],\n",
      "        [ 5.1364e-03, -1.1830e-04,  5.6846e-04,  ...,  2.3965e-05,\n",
      "         -8.9964e-03,  3.2728e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-1.2251e-04, -6.6795e-05,  2.6452e-04,  ...,  2.8105e-06,\n",
      "         -1.5201e-05, -5.0311e-03],\n",
      "        [ 2.6233e-04, -4.2184e-04, -9.1103e-07,  ...,  1.2319e-06,\n",
      "         -1.1166e-05,  4.4586e-03],\n",
      "        [-2.0920e-03,  4.3665e-05,  2.4384e-05,  ...,  2.9901e-07,\n",
      "          6.0914e-05, -2.3692e-02],\n",
      "        ...,\n",
      "        [ 1.1346e-04, -2.6235e-06,  2.0650e-06,  ...,  2.1515e-04,\n",
      "          6.7040e-05, -3.7510e-03],\n",
      "        [-2.9530e-04, -6.0390e-05,  8.6524e-04,  ..., -1.0190e-06,\n",
      "          1.3910e-02, -2.0900e-02],\n",
      "        [ 5.2487e-03, -1.1052e-04,  6.8695e-04,  ...,  1.9938e-05,\n",
      "         -9.4841e-03,  3.2926e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.0219e+01, -1.3991e+01, -8.5307e+00,  ..., -2.2349e-04,\n",
      "         -2.0523e+01, -1.0585e+01],\n",
      "        [-7.2082e+00, -1.5722e+01, -6.0171e+00,  ..., -1.7953e+01,\n",
      "         -5.3794e+00, -9.7644e+00],\n",
      "        [-2.1908e+01, -1.5806e+01, -4.0463e-04,  ..., -9.6128e+00,\n",
      "         -1.1247e+01, -8.4345e+00],\n",
      "        ...,\n",
      "        [-5.3744e+00, -1.6467e+01, -5.5153e+00,  ..., -9.5588e+00,\n",
      "         -1.0252e+01, -1.0093e-02],\n",
      "        [-1.6339e-03, -2.6625e+01, -1.6316e+01,  ..., -2.5132e+01,\n",
      "         -1.4289e+01, -7.3020e+00],\n",
      "        [-1.9655e+01, -8.6926e+00, -8.7636e+00,  ..., -5.3058e-04,\n",
      "         -1.3601e+01, -8.4923e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0175 loss_train: 0.0233 acc_train: 1.0000 loss_val: 1.3265 acc_val: 0.7633 time: 0.7160s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-1.2251e-04, -6.6795e-05,  2.6452e-04,  ...,  2.8105e-06,\n",
      "         -1.5201e-05, -5.0311e-03],\n",
      "        [ 2.6233e-04, -4.2184e-04, -9.1103e-07,  ...,  1.2319e-06,\n",
      "         -1.1166e-05,  4.4586e-03],\n",
      "        [-2.0920e-03,  4.3665e-05,  2.4384e-05,  ...,  2.9901e-07,\n",
      "          6.0914e-05, -2.3692e-02],\n",
      "        ...,\n",
      "        [ 1.1346e-04, -2.6235e-06,  2.0650e-06,  ...,  2.1515e-04,\n",
      "          6.7040e-05, -3.7510e-03],\n",
      "        [-2.9530e-04, -6.0390e-05,  8.6524e-04,  ..., -1.0190e-06,\n",
      "          1.3910e-02, -2.0900e-02],\n",
      "        [ 5.2487e-03, -1.1052e-04,  6.8695e-04,  ...,  1.9938e-05,\n",
      "         -9.4841e-03,  3.2926e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-1.2233e-04, -5.6100e-05,  2.3687e-04,  ...,  1.0869e-06,\n",
      "         -2.1605e-05, -4.3775e-03],\n",
      "        [ 2.4364e-04, -5.6374e-04, -9.7184e-07,  ...,  1.7947e-06,\n",
      "         -1.0530e-05,  4.4289e-03],\n",
      "        [-2.0646e-03,  9.2669e-06,  1.0248e-05,  ..., -6.6240e-07,\n",
      "          4.1834e-05, -2.3008e-02],\n",
      "        ...,\n",
      "        [ 1.1919e-04, -1.7570e-06,  1.6148e-06,  ...,  1.4648e-04,\n",
      "          7.4572e-05, -4.0273e-03],\n",
      "        [-2.5830e-04, -5.7094e-05,  8.9567e-04,  ..., -9.5335e-07,\n",
      "          1.3687e-02, -2.0638e-02],\n",
      "        [ 5.3528e-03, -1.0225e-04,  7.8294e-04,  ...,  1.4970e-05,\n",
      "         -9.7957e-03,  3.3140e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.1807e+01, -1.4537e+01, -9.2756e+00,  ..., -1.0597e-04,\n",
      "         -2.2013e+01, -1.1350e+01],\n",
      "        [-7.7912e+00, -1.4735e+01, -5.3044e+00,  ..., -1.7001e+01,\n",
      "         -4.8824e+00, -9.7045e+00],\n",
      "        [-2.3273e+01, -1.5564e+01, -3.2336e-04,  ..., -8.9120e+00,\n",
      "         -1.1867e+01, -8.8368e+00],\n",
      "        ...,\n",
      "        [-6.6206e+00, -1.5967e+01, -5.0926e+00,  ..., -8.4333e+00,\n",
      "         -1.0498e+01, -8.3427e-03],\n",
      "        [-2.6471e-03, -2.5657e+01, -1.5446e+01,  ..., -2.3916e+01,\n",
      "         -1.3745e+01, -6.5868e+00],\n",
      "        [-2.1609e+01, -9.1876e+00, -9.6239e+00,  ..., -2.3911e-04,\n",
      "         -1.5197e+01, -9.5609e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0176 loss_train: 0.0129 acc_train: 1.0000 loss_val: 1.3231 acc_val: 0.7633 time: 0.7204s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-1.2233e-04, -5.6100e-05,  2.3687e-04,  ...,  1.0869e-06,\n",
      "         -2.1605e-05, -4.3775e-03],\n",
      "        [ 2.4364e-04, -5.6374e-04, -9.7184e-07,  ...,  1.7947e-06,\n",
      "         -1.0530e-05,  4.4289e-03],\n",
      "        [-2.0646e-03,  9.2669e-06,  1.0248e-05,  ..., -6.6240e-07,\n",
      "          4.1834e-05, -2.3008e-02],\n",
      "        ...,\n",
      "        [ 1.1919e-04, -1.7570e-06,  1.6148e-06,  ...,  1.4648e-04,\n",
      "          7.4572e-05, -4.0273e-03],\n",
      "        [-2.5830e-04, -5.7094e-05,  8.9567e-04,  ..., -9.5335e-07,\n",
      "          1.3687e-02, -2.0638e-02],\n",
      "        [ 5.3528e-03, -1.0225e-04,  7.8294e-04,  ...,  1.4970e-05,\n",
      "         -9.7957e-03,  3.3140e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-1.2494e-04, -4.4926e-05,  1.9559e-04,  ..., -5.7206e-07,\n",
      "         -1.1283e-05, -3.9476e-03],\n",
      "        [ 2.1771e-04, -6.5940e-04, -7.0335e-07,  ...,  1.7692e-06,\n",
      "         -9.1414e-06,  4.3154e-03],\n",
      "        [-2.0766e-03, -2.2414e-05, -2.9882e-06,  ..., -1.2426e-06,\n",
      "          1.2367e-04, -2.3036e-02],\n",
      "        ...,\n",
      "        [ 1.1420e-04, -4.0711e-07,  6.5458e-07,  ...,  5.2420e-05,\n",
      "          7.3621e-05, -4.3435e-03],\n",
      "        [-2.1490e-04, -5.2597e-05,  8.7590e-04,  ..., -8.2958e-07,\n",
      "          1.3474e-02, -2.0529e-02],\n",
      "        [ 5.4699e-03, -9.3630e-05,  8.5705e-04,  ...,  9.4834e-06,\n",
      "         -1.0120e-02,  3.3156e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.1898e+01, -1.4912e+01, -9.3108e+00,  ..., -1.0597e-04,\n",
      "         -2.2580e+01, -1.1101e+01],\n",
      "        [-7.4208e+00, -1.4838e+01, -5.2703e+00,  ..., -1.6942e+01,\n",
      "         -5.0441e+00, -9.3365e+00],\n",
      "        [-2.3165e+01, -1.5895e+01, -3.6221e-04,  ..., -8.9533e+00,\n",
      "         -1.2243e+01, -8.5346e+00],\n",
      "        ...,\n",
      "        [-6.9143e+00, -1.6384e+01, -5.3506e+00,  ..., -8.4925e+00,\n",
      "         -1.1006e+01, -6.3303e-03],\n",
      "        [-2.5091e-03, -2.5868e+01, -1.5605e+01,  ..., -2.3919e+01,\n",
      "         -1.3929e+01, -6.4703e+00],\n",
      "        [-2.1763e+01, -9.5680e+00, -9.8149e+00,  ..., -2.0657e-04,\n",
      "         -1.5818e+01, -9.4109e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0177 loss_train: 0.0212 acc_train: 1.0000 loss_val: 1.2783 acc_val: 0.7700 time: 1.0022s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-1.2494e-04, -4.4926e-05,  1.9559e-04,  ..., -5.7206e-07,\n",
      "         -1.1283e-05, -3.9476e-03],\n",
      "        [ 2.1771e-04, -6.5940e-04, -7.0335e-07,  ...,  1.7692e-06,\n",
      "         -9.1414e-06,  4.3154e-03],\n",
      "        [-2.0766e-03, -2.2414e-05, -2.9882e-06,  ..., -1.2426e-06,\n",
      "          1.2367e-04, -2.3036e-02],\n",
      "        ...,\n",
      "        [ 1.1420e-04, -4.0711e-07,  6.5458e-07,  ...,  5.2420e-05,\n",
      "          7.3621e-05, -4.3435e-03],\n",
      "        [-2.1490e-04, -5.2597e-05,  8.7590e-04,  ..., -8.2958e-07,\n",
      "          1.3474e-02, -2.0529e-02],\n",
      "        [ 5.4699e-03, -9.3630e-05,  8.5705e-04,  ...,  9.4834e-06,\n",
      "         -1.0120e-02,  3.3156e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-1.2953e-04, -3.3618e-05,  1.4481e-04,  ..., -2.0154e-06,\n",
      "          2.5697e-05, -3.6111e-03],\n",
      "        [ 1.8620e-04, -7.0767e-04, -2.2620e-07,  ...,  1.2186e-06,\n",
      "         -7.1794e-06,  4.3464e-03],\n",
      "        [-2.0450e-03, -4.9494e-05, -1.4799e-05,  ..., -1.2249e-06,\n",
      "          1.9442e-04, -2.3088e-02],\n",
      "        ...,\n",
      "        [ 1.0019e-04,  9.4350e-07, -4.3739e-07,  ..., -4.2689e-05,\n",
      "          6.5038e-05, -4.8268e-03],\n",
      "        [-1.3697e-04, -4.7130e-05,  8.1171e-04,  ..., -6.6155e-07,\n",
      "          1.3343e-02, -2.0399e-02],\n",
      "        [ 5.5593e-03, -8.4786e-05,  9.1018e-04,  ...,  3.8929e-06,\n",
      "         -9.9679e-03,  3.3090e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.1229e+01, -1.5682e+01, -1.0107e+01,  ..., -7.0093e-05,\n",
      "         -2.3416e+01, -1.0444e+01],\n",
      "        [-6.1203e+00, -1.5461e+01, -5.7571e+00,  ..., -1.7162e+01,\n",
      "         -5.5582e+00, -8.4856e+00],\n",
      "        [-2.1566e+01, -1.6017e+01, -1.1160e-03,  ..., -8.4384e+00,\n",
      "         -1.2230e+01, -7.0748e+00],\n",
      "        ...,\n",
      "        [-6.7521e+00, -1.7315e+01, -6.3676e+00,  ..., -8.9729e+00,\n",
      "         -1.1757e+01, -3.1941e-03],\n",
      "        [-1.9134e-03, -2.6572e+01, -1.6350e+01,  ..., -2.4341e+01,\n",
      "         -1.4451e+01, -6.5687e+00],\n",
      "        [-2.1026e+01, -1.0328e+01, -1.0411e+01,  ..., -2.3720e-04,\n",
      "         -1.6548e+01, -8.6553e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0178 loss_train: 0.0252 acc_train: 0.9929 loss_val: 1.1613 acc_val: 0.7867 time: 0.7220s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-1.2953e-04, -3.3618e-05,  1.4481e-04,  ..., -2.0154e-06,\n",
      "          2.5697e-05, -3.6111e-03],\n",
      "        [ 1.8620e-04, -7.0767e-04, -2.2620e-07,  ...,  1.2186e-06,\n",
      "         -7.1794e-06,  4.3464e-03],\n",
      "        [-2.0450e-03, -4.9494e-05, -1.4799e-05,  ..., -1.2249e-06,\n",
      "          1.9442e-04, -2.3088e-02],\n",
      "        ...,\n",
      "        [ 1.0019e-04,  9.4350e-07, -4.3739e-07,  ..., -4.2689e-05,\n",
      "          6.5038e-05, -4.8268e-03],\n",
      "        [-1.3697e-04, -4.7130e-05,  8.1171e-04,  ..., -6.6155e-07,\n",
      "          1.3343e-02, -2.0399e-02],\n",
      "        [ 5.5593e-03, -8.4786e-05,  9.1018e-04,  ...,  3.8929e-06,\n",
      "         -9.9679e-03,  3.3090e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-9.7344e-05, -2.2493e-05,  8.8925e-05,  ..., -3.1262e-06,\n",
      "          1.9158e-05, -3.4348e-03],\n",
      "        [ 1.5078e-04, -7.6756e-04,  2.8027e-07,  ...,  3.5706e-07,\n",
      "         -4.8500e-06,  4.2415e-03],\n",
      "        [-1.9720e-03, -7.0574e-05, -2.4771e-05,  ..., -6.7361e-07,\n",
      "          2.5338e-04, -2.3279e-02],\n",
      "        ...,\n",
      "        [ 7.8958e-05,  1.8560e-06, -1.2722e-06,  ..., -1.2396e-04,\n",
      "          8.3686e-05, -5.3399e-03],\n",
      "        [-8.3256e-05, -4.0931e-05,  7.1067e-04,  ..., -4.6482e-07,\n",
      "          1.3135e-02, -2.0359e-02],\n",
      "        [ 5.6241e-03, -7.5839e-05,  9.4345e-04,  ..., -1.4162e-06,\n",
      "         -1.0103e-02,  3.2920e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-2.9773e+01, -1.5003e+01, -8.8545e+00,  ..., -2.1443e-04,\n",
      "         -2.1925e+01, -9.5480e+00],\n",
      "        [-5.9211e+00, -1.6621e+01, -6.4123e+00,  ..., -1.8381e+01,\n",
      "         -6.1683e+00, -8.7743e+00],\n",
      "        [-2.0572e+01, -1.6758e+01, -1.1322e-03,  ..., -9.8061e+00,\n",
      "         -1.1961e+01, -7.0056e+00],\n",
      "        ...,\n",
      "        [-5.9068e+00, -1.7844e+01, -6.3924e+00,  ..., -1.0074e+01,\n",
      "         -1.1559e+01, -4.8664e-03],\n",
      "        [-1.2195e-03, -2.7609e+01, -1.7064e+01,  ..., -2.5636e+01,\n",
      "         -1.5000e+01, -7.1940e+00],\n",
      "        [-1.9470e+01, -9.7472e+00, -9.4035e+00,  ..., -5.7621e-04,\n",
      "         -1.5142e+01, -7.7405e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0179 loss_train: 0.0217 acc_train: 1.0000 loss_val: 1.1926 acc_val: 0.7633 time: 0.5970s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-9.7344e-05, -2.2493e-05,  8.8925e-05,  ..., -3.1262e-06,\n",
      "          1.9158e-05, -3.4348e-03],\n",
      "        [ 1.5078e-04, -7.6756e-04,  2.8027e-07,  ...,  3.5706e-07,\n",
      "         -4.8500e-06,  4.2415e-03],\n",
      "        [-1.9720e-03, -7.0574e-05, -2.4771e-05,  ..., -6.7361e-07,\n",
      "          2.5338e-04, -2.3279e-02],\n",
      "        ...,\n",
      "        [ 7.8958e-05,  1.8560e-06, -1.2722e-06,  ..., -1.2396e-04,\n",
      "          8.3686e-05, -5.3399e-03],\n",
      "        [-8.3256e-05, -4.0931e-05,  7.1067e-04,  ..., -4.6482e-07,\n",
      "          1.3135e-02, -2.0359e-02],\n",
      "        [ 5.6241e-03, -7.5839e-05,  9.4345e-04,  ..., -1.4162e-06,\n",
      "         -1.0103e-02,  3.2920e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-6.6788e-05, -1.1835e-05,  3.2295e-05,  ..., -3.8300e-06,\n",
      "          1.5103e-05, -3.2701e-03],\n",
      "        [ 1.1314e-04, -8.4293e-04,  6.4336e-07,  ..., -5.2781e-07,\n",
      "         -2.3690e-06,  4.1024e-03],\n",
      "        [-1.8638e-03, -8.4788e-05, -3.2615e-05,  ...,  1.1934e-07,\n",
      "          3.0290e-04, -2.3671e-02],\n",
      "        ...,\n",
      "        [ 5.3394e-05,  2.0746e-06, -1.5856e-06,  ..., -1.7272e-04,\n",
      "          9.1775e-05, -5.6743e-03],\n",
      "        [-2.6937e-05, -3.4234e-05,  5.8163e-04,  ..., -2.5549e-07,\n",
      "          1.3244e-02, -2.0220e-02],\n",
      "        [ 5.6830e-03, -6.6896e-05,  9.5823e-04,  ..., -6.1133e-06,\n",
      "         -9.9295e-03,  3.2729e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-2.9597e+01, -1.3548e+01, -7.7179e+00,  ..., -4.8947e-04,\n",
      "         -2.0036e+01, -1.0048e+01],\n",
      "        [-7.1408e+00, -1.6815e+01, -6.7138e+00,  ..., -1.9142e+01,\n",
      "         -6.0379e+00, -1.0049e+01],\n",
      "        [-2.1131e+01, -1.6554e+01, -6.2375e-04,  ..., -1.0845e+01,\n",
      "         -1.1277e+01, -8.3321e+00],\n",
      "        ...,\n",
      "        [-5.3114e+00, -1.6975e+01, -5.4774e+00,  ..., -1.0089e+01,\n",
      "         -1.0443e+01, -1.1017e-02],\n",
      "        [-1.3414e-03, -2.7513e+01, -1.6961e+01,  ..., -2.6081e+01,\n",
      "         -1.4737e+01, -7.6316e+00],\n",
      "        [-1.9556e+01, -8.3388e+00, -8.6248e+00,  ..., -6.2577e-04,\n",
      "         -1.3503e+01, -8.4893e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0180 loss_train: 0.0256 acc_train: 0.9929 loss_val: 1.3612 acc_val: 0.7600 time: 0.6383s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-6.6788e-05, -1.1835e-05,  3.2295e-05,  ..., -3.8300e-06,\n",
      "          1.5103e-05, -3.2701e-03],\n",
      "        [ 1.1314e-04, -8.4293e-04,  6.4336e-07,  ..., -5.2781e-07,\n",
      "         -2.3690e-06,  4.1024e-03],\n",
      "        [-1.8638e-03, -8.4788e-05, -3.2615e-05,  ...,  1.1934e-07,\n",
      "          3.0290e-04, -2.3671e-02],\n",
      "        ...,\n",
      "        [ 5.3394e-05,  2.0746e-06, -1.5856e-06,  ..., -1.7272e-04,\n",
      "          9.1775e-05, -5.6743e-03],\n",
      "        [-2.6937e-05, -3.4234e-05,  5.8163e-04,  ..., -2.5549e-07,\n",
      "          1.3244e-02, -2.0220e-02],\n",
      "        [ 5.6830e-03, -6.6896e-05,  9.5823e-04,  ..., -6.1133e-06,\n",
      "         -9.9295e-03,  3.2729e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-4.2338e-05, -1.8899e-06, -2.1079e-05,  ..., -4.0980e-06,\n",
      "          2.4672e-05, -3.0846e-03],\n",
      "        [ 7.4899e-05, -8.6185e-04,  7.5442e-07,  ..., -1.1678e-06,\n",
      "          5.6045e-08,  4.1807e-03],\n",
      "        [-1.7378e-03, -9.1817e-05, -3.8166e-05,  ...,  7.8267e-07,\n",
      "          3.4016e-04, -2.3724e-02],\n",
      "        ...,\n",
      "        [ 2.5710e-05,  1.5933e-06, -1.3181e-06,  ..., -1.7787e-04,\n",
      "          9.0549e-05, -6.0117e-03],\n",
      "        [ 4.2810e-05, -2.7264e-05,  4.3408e-04,  ..., -4.9020e-08,\n",
      "          1.3300e-02, -1.9947e-02],\n",
      "        [ 5.8183e-03, -5.8058e-05,  9.5601e-04,  ..., -9.9390e-06,\n",
      "         -9.7117e-03,  3.3137e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.0888e+01, -1.4697e+01, -8.9096e+00,  ..., -1.6211e-04,\n",
      "         -2.1717e+01, -1.0535e+01],\n",
      "        [-7.2087e+00, -1.5960e+01, -5.9202e+00,  ..., -1.7981e+01,\n",
      "         -5.6612e+00, -9.4614e+00],\n",
      "        [-2.2297e+01, -1.6408e+01, -4.1202e-04,  ..., -9.6475e+00,\n",
      "         -1.1993e+01, -8.2284e+00],\n",
      "        ...,\n",
      "        [-6.4913e+00, -1.6978e+01, -5.5876e+00,  ..., -9.1632e+00,\n",
      "         -1.1076e+01, -5.8905e-03],\n",
      "        [-2.1123e-03, -2.6530e+01, -1.6044e+01,  ..., -2.4645e+01,\n",
      "         -1.4188e+01, -6.7688e+00],\n",
      "        [-2.1052e+01, -9.4842e+00, -9.7014e+00,  ..., -2.5877e-04,\n",
      "         -1.5318e+01, -9.0179e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0181 loss_train: 0.0307 acc_train: 0.9929 loss_val: 1.2579 acc_val: 0.7667 time: 0.7008s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-4.2338e-05, -1.8899e-06, -2.1079e-05,  ..., -4.0980e-06,\n",
      "          2.4672e-05, -3.0846e-03],\n",
      "        [ 7.4899e-05, -8.6185e-04,  7.5442e-07,  ..., -1.1678e-06,\n",
      "          5.6045e-08,  4.1807e-03],\n",
      "        [-1.7378e-03, -9.1817e-05, -3.8166e-05,  ...,  7.8267e-07,\n",
      "          3.4016e-04, -2.3724e-02],\n",
      "        ...,\n",
      "        [ 2.5710e-05,  1.5933e-06, -1.3181e-06,  ..., -1.7787e-04,\n",
      "          9.0549e-05, -6.0117e-03],\n",
      "        [ 4.2810e-05, -2.7264e-05,  4.3408e-04,  ..., -4.9020e-08,\n",
      "          1.3300e-02, -1.9947e-02],\n",
      "        [ 5.8183e-03, -5.8058e-05,  9.5601e-04,  ..., -9.9390e-06,\n",
      "         -9.7117e-03,  3.3137e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-1.6881e-05,  7.1399e-06, -6.7786e-05,  ..., -3.9457e-06,\n",
      "          3.2321e-05, -2.9170e-03],\n",
      "        [ 3.7551e-05, -8.7296e-04,  5.9981e-07,  ..., -1.3930e-06,\n",
      "          2.2407e-06,  4.1521e-03],\n",
      "        [-1.5853e-03, -9.1858e-05, -4.1382e-05,  ...,  1.0363e-06,\n",
      "          3.6541e-04, -2.3932e-02],\n",
      "        ...,\n",
      "        [-1.1814e-06,  6.3622e-07, -6.1768e-07,  ..., -1.4534e-04,\n",
      "          8.8907e-05, -6.3962e-03],\n",
      "        [ 8.0130e-05, -2.0234e-05,  2.7764e-04,  ...,  1.4073e-07,\n",
      "          1.3300e-02, -1.9731e-02],\n",
      "        [ 5.9441e-03, -4.9413e-05,  9.3845e-04,  ..., -1.2717e-05,\n",
      "         -9.5391e-03,  3.3406e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.1623e+01, -1.5296e+01, -9.6866e+00,  ..., -8.0105e-05,\n",
      "         -2.2587e+01, -1.0941e+01],\n",
      "        [-7.1894e+00, -1.5322e+01, -5.3944e+00,  ..., -1.7176e+01,\n",
      "         -5.3018e+00, -9.0734e+00],\n",
      "        [-2.2929e+01, -1.6137e+01, -4.7112e-04,  ..., -8.7649e+00,\n",
      "         -1.2284e+01, -8.1743e+00],\n",
      "        ...,\n",
      "        [-7.1260e+00, -1.6852e+01, -5.6439e+00,  ..., -8.4831e+00,\n",
      "         -1.1348e+01, -4.7950e-03],\n",
      "        [-3.0029e-03, -2.5887e+01, -1.5460e+01,  ..., -2.3697e+01,\n",
      "         -1.3802e+01, -6.2201e+00],\n",
      "        [-2.1896e+01, -1.0114e+01, -1.0377e+01,  ..., -1.5568e-04,\n",
      "         -1.6284e+01, -9.3851e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0182 loss_train: 0.0140 acc_train: 1.0000 loss_val: 1.2261 acc_val: 0.7867 time: 0.5935s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-1.6881e-05,  7.1399e-06, -6.7786e-05,  ..., -3.9457e-06,\n",
      "          3.2321e-05, -2.9170e-03],\n",
      "        [ 3.7551e-05, -8.7296e-04,  5.9981e-07,  ..., -1.3930e-06,\n",
      "          2.2407e-06,  4.1521e-03],\n",
      "        [-1.5853e-03, -9.1858e-05, -4.1382e-05,  ...,  1.0363e-06,\n",
      "          3.6541e-04, -2.3932e-02],\n",
      "        ...,\n",
      "        [-1.1814e-06,  6.3622e-07, -6.1768e-07,  ..., -1.4534e-04,\n",
      "          8.8907e-05, -6.3962e-03],\n",
      "        [ 8.0130e-05, -2.0234e-05,  2.7764e-04,  ...,  1.4073e-07,\n",
      "          1.3300e-02, -1.9731e-02],\n",
      "        [ 5.9441e-03, -4.9413e-05,  9.3845e-04,  ..., -1.2717e-05,\n",
      "         -9.5391e-03,  3.3406e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-1.3655e-05,  1.5094e-05, -1.0519e-04,  ..., -3.4275e-06,\n",
      "         -1.2390e-05, -2.8278e-03],\n",
      "        [ 1.9473e-06, -8.3181e-04,  2.5701e-07,  ..., -1.1746e-06,\n",
      "          4.0365e-06,  3.9987e-03],\n",
      "        [-1.4175e-03, -8.5571e-05, -4.2332e-05,  ...,  8.0686e-07,\n",
      "          3.7997e-04, -2.4172e-02],\n",
      "        ...,\n",
      "        [-2.5354e-05, -4.3706e-07,  2.3024e-07,  ..., -8.3374e-05,\n",
      "          1.1807e-04, -6.8414e-03],\n",
      "        [ 3.8146e-05, -1.3338e-05,  1.2150e-04,  ...,  3.0232e-07,\n",
      "          1.3336e-02, -1.9718e-02],\n",
      "        [ 5.8520e-03, -4.1040e-05,  9.0728e-04,  ..., -1.4357e-05,\n",
      "         -9.6429e-03,  3.3554e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.1427e+01, -1.5123e+01, -9.2208e+00,  ..., -1.1896e-04,\n",
      "         -2.2080e+01, -1.0829e+01],\n",
      "        [-7.2665e+00, -1.5340e+01, -5.1677e+00,  ..., -1.7110e+01,\n",
      "         -5.2801e+00, -8.9844e+00],\n",
      "        [-2.3355e+01, -1.6369e+01, -3.5876e-04,  ..., -8.9887e+00,\n",
      "         -1.2452e+01, -8.4688e+00],\n",
      "        ...,\n",
      "        [-7.1500e+00, -1.6916e+01, -5.4942e+00,  ..., -8.5557e+00,\n",
      "         -1.1304e+01, -5.3394e-03],\n",
      "        [-3.3653e-03, -2.5798e+01, -1.5206e+01,  ..., -2.3554e+01,\n",
      "         -1.3697e+01, -6.0974e+00],\n",
      "        [-2.1698e+01, -1.0055e+01, -1.0031e+01,  ..., -1.8643e-04,\n",
      "         -1.5924e+01, -9.2181e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0183 loss_train: 0.0234 acc_train: 1.0000 loss_val: 1.2325 acc_val: 0.7767 time: 0.6079s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-1.3655e-05,  1.5094e-05, -1.0519e-04,  ..., -3.4275e-06,\n",
      "         -1.2390e-05, -2.8278e-03],\n",
      "        [ 1.9473e-06, -8.3181e-04,  2.5701e-07,  ..., -1.1746e-06,\n",
      "          4.0365e-06,  3.9987e-03],\n",
      "        [-1.4175e-03, -8.5571e-05, -4.2332e-05,  ...,  8.0686e-07,\n",
      "          3.7997e-04, -2.4172e-02],\n",
      "        ...,\n",
      "        [-2.5354e-05, -4.3706e-07,  2.3024e-07,  ..., -8.3374e-05,\n",
      "          1.1807e-04, -6.8414e-03],\n",
      "        [ 3.8146e-05, -1.3338e-05,  1.2150e-04,  ...,  3.0232e-07,\n",
      "          1.3336e-02, -1.9718e-02],\n",
      "        [ 5.8520e-03, -4.1040e-05,  9.0728e-04,  ..., -1.4357e-05,\n",
      "         -9.6429e-03,  3.3554e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-3.9178e-05,  2.1857e-05, -1.3156e-04,  ..., -2.6280e-06,\n",
      "         -7.1097e-05, -3.1840e-03],\n",
      "        [-3.0442e-05, -8.9697e-04, -1.3977e-07,  ..., -6.2080e-07,\n",
      "          5.3390e-06,  3.5666e-03],\n",
      "        [-1.2391e-03, -7.3987e-05, -4.1186e-05,  ...,  2.4182e-07,\n",
      "          3.8356e-04, -2.4623e-02],\n",
      "        ...,\n",
      "        [-4.4966e-05, -1.2617e-06,  9.1499e-07,  ..., -8.6882e-06,\n",
      "          2.0869e-04, -7.2042e-03],\n",
      "        [ 1.7843e-05, -6.7508e-06, -2.5984e-05,  ...,  4.2729e-07,\n",
      "          1.3173e-02, -1.9840e-02],\n",
      "        [ 5.3936e-03, -3.3009e-05,  8.6428e-04,  ..., -1.4855e-05,\n",
      "         -1.0001e-02,  3.3394e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-2.8703e+01, -1.3938e+01, -6.1809e+00,  ..., -2.2129e-03,\n",
      "         -1.9158e+01, -8.8661e+00],\n",
      "        [-6.7208e+00, -1.7141e+01, -5.9115e+00,  ..., -1.8813e+01,\n",
      "         -6.3054e+00, -9.0156e+00],\n",
      "        [-2.2222e+01, -1.7894e+01, -3.0561e-04,  ..., -1.1350e+01,\n",
      "         -1.2519e+01, -8.5013e+00],\n",
      "        ...,\n",
      "        [-5.8798e+00, -1.7947e+01, -5.4789e+00,  ..., -1.0463e+01,\n",
      "         -1.1152e+01, -7.8849e-03],\n",
      "        [-2.0068e-03, -2.7288e+01, -1.6046e+01,  ..., -2.5388e+01,\n",
      "         -1.4480e+01, -6.8986e+00],\n",
      "        [-1.8643e+01, -9.1998e+00, -7.5225e+00,  ..., -1.5333e-03,\n",
      "         -1.3175e+01, -7.0261e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0184 loss_train: 0.0434 acc_train: 0.9857 loss_val: 1.3384 acc_val: 0.7433 time: 0.6332s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-3.9178e-05,  2.1857e-05, -1.3156e-04,  ..., -2.6280e-06,\n",
      "         -7.1097e-05, -3.1840e-03],\n",
      "        [-3.0442e-05, -8.9697e-04, -1.3977e-07,  ..., -6.2080e-07,\n",
      "          5.3390e-06,  3.5666e-03],\n",
      "        [-1.2391e-03, -7.3987e-05, -4.1186e-05,  ...,  2.4182e-07,\n",
      "          3.8356e-04, -2.4623e-02],\n",
      "        ...,\n",
      "        [-4.4966e-05, -1.2617e-06,  9.1499e-07,  ..., -8.6882e-06,\n",
      "          2.0869e-04, -7.2042e-03],\n",
      "        [ 1.7843e-05, -6.7508e-06, -2.5984e-05,  ...,  4.2729e-07,\n",
      "          1.3173e-02, -1.9840e-02],\n",
      "        [ 5.3936e-03, -3.3009e-05,  8.6428e-04,  ..., -1.4855e-05,\n",
      "         -1.0001e-02,  3.3394e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-5.1644e-05,  2.7355e-05, -1.4607e-04,  ..., -1.6512e-06,\n",
      "         -7.0270e-05, -3.4248e-03],\n",
      "        [-5.5721e-05, -8.7891e-04, -4.5029e-07,  ...,  6.8125e-08,\n",
      "          6.0920e-06,  3.3862e-03],\n",
      "        [-1.0599e-03, -5.8405e-05, -3.8196e-05,  ..., -3.7581e-07,\n",
      "          3.9231e-04, -2.4825e-02],\n",
      "        ...,\n",
      "        [-5.8626e-05, -1.5884e-06,  1.2117e-06,  ...,  4.9834e-05,\n",
      "          2.7212e-04, -7.1941e-03],\n",
      "        [ 9.1156e-05, -6.2012e-07, -1.5771e-04,  ...,  5.1048e-07,\n",
      "          1.3524e-02, -1.9674e-02],\n",
      "        [ 5.2677e-03, -2.5377e-05,  8.1128e-04,  ..., -1.4286e-05,\n",
      "         -8.1604e-03,  3.3462e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-2.8900e+01, -1.3422e+01, -7.2821e+00,  ..., -7.3942e-04,\n",
      "         -1.9048e+01, -9.9043e+00],\n",
      "        [-6.3704e+00, -1.6102e+01, -5.9101e+00,  ..., -1.8083e+01,\n",
      "         -5.4579e+00, -9.0367e+00],\n",
      "        [-2.1964e+01, -1.6658e+01, -2.8070e-04,  ..., -1.0469e+01,\n",
      "         -1.1637e+01, -8.6655e+00],\n",
      "        ...,\n",
      "        [-5.5066e+00, -1.6945e+01, -5.5467e+00,  ..., -9.6351e+00,\n",
      "         -1.0471e+01, -8.8461e-03],\n",
      "        [-1.4658e-03, -2.6852e+01, -1.6377e+01,  ..., -2.5120e+01,\n",
      "         -1.4227e+01, -7.1960e+00],\n",
      "        [-1.8985e+01, -8.7248e+00, -8.4098e+00,  ..., -7.2298e-04,\n",
      "         -1.3177e+01, -7.9998e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0185 loss_train: 0.0285 acc_train: 1.0000 loss_val: 1.2752 acc_val: 0.7633 time: 0.6053s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-5.1644e-05,  2.7355e-05, -1.4607e-04,  ..., -1.6512e-06,\n",
      "         -7.0270e-05, -3.4248e-03],\n",
      "        [-5.5721e-05, -8.7891e-04, -4.5029e-07,  ...,  6.8125e-08,\n",
      "          6.0920e-06,  3.3862e-03],\n",
      "        [-1.0599e-03, -5.8405e-05, -3.8196e-05,  ..., -3.7581e-07,\n",
      "          3.9231e-04, -2.4825e-02],\n",
      "        ...,\n",
      "        [-5.8626e-05, -1.5884e-06,  1.2117e-06,  ...,  4.9834e-05,\n",
      "          2.7212e-04, -7.1941e-03],\n",
      "        [ 9.1156e-05, -6.2012e-07, -1.5771e-04,  ...,  5.1048e-07,\n",
      "          1.3524e-02, -1.9674e-02],\n",
      "        [ 5.2677e-03, -2.5377e-05,  8.1128e-04,  ..., -1.4286e-05,\n",
      "         -8.1604e-03,  3.3462e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-4.0452e-05,  3.1556e-05, -1.4883e-04,  ..., -6.0878e-07,\n",
      "         -6.3517e-05, -3.6307e-03],\n",
      "        [-7.5038e-05, -8.1063e-04, -5.7664e-07,  ...,  6.6917e-07,\n",
      "          6.2880e-06,  3.2913e-03],\n",
      "        [-8.9841e-04, -4.0283e-05, -3.3679e-05,  ..., -7.6560e-07,\n",
      "          3.9275e-04, -2.4906e-02],\n",
      "        ...,\n",
      "        [-6.5656e-05, -1.3561e-06,  1.0526e-06,  ...,  8.9858e-05,\n",
      "          3.2697e-04, -7.1873e-03],\n",
      "        [ 1.9215e-04,  4.9308e-06, -2.6807e-04,  ...,  5.5009e-07,\n",
      "          1.3904e-02, -1.9387e-02],\n",
      "        [ 5.2451e-03, -1.8193e-05,  7.5007e-04,  ..., -1.2789e-05,\n",
      "         -6.3531e-03,  3.3565e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-2.9333e+01, -1.3261e+01, -8.9285e+00,  ..., -1.5103e-04,\n",
      "         -1.9560e+01, -1.1002e+01],\n",
      "        [-5.9054e+00, -1.4962e+01, -5.8311e+00,  ..., -1.7139e+01,\n",
      "         -4.6283e+00, -8.8380e+00],\n",
      "        [-2.1650e+01, -1.5212e+01, -3.8604e-04,  ..., -9.0572e+00,\n",
      "         -1.0848e+01, -8.5148e+00],\n",
      "        ...,\n",
      "        [-5.3547e+00, -1.5962e+01, -5.7783e+00,  ..., -8.5765e+00,\n",
      "         -9.9708e+00, -8.5750e-03],\n",
      "        [-1.2669e-03, -2.6238e+01, -1.6507e+01,  ..., -2.4527e+01,\n",
      "         -1.3896e+01, -7.2445e+00],\n",
      "        [-1.9614e+01, -8.6319e+00, -9.6399e+00,  ..., -3.7139e-04,\n",
      "         -1.3747e+01, -8.9727e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0186 loss_train: 0.0157 acc_train: 1.0000 loss_val: 1.2321 acc_val: 0.7600 time: 0.6192s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-4.0452e-05,  3.1556e-05, -1.4883e-04,  ..., -6.0878e-07,\n",
      "         -6.3517e-05, -3.6307e-03],\n",
      "        [-7.5038e-05, -8.1063e-04, -5.7664e-07,  ...,  6.6917e-07,\n",
      "          6.2880e-06,  3.2913e-03],\n",
      "        [-8.9841e-04, -4.0283e-05, -3.3679e-05,  ..., -7.6560e-07,\n",
      "          3.9275e-04, -2.4906e-02],\n",
      "        ...,\n",
      "        [-6.5656e-05, -1.3561e-06,  1.0526e-06,  ...,  8.9858e-05,\n",
      "          3.2697e-04, -7.1873e-03],\n",
      "        [ 1.9215e-04,  4.9308e-06, -2.6807e-04,  ...,  5.5009e-07,\n",
      "          1.3904e-02, -1.9387e-02],\n",
      "        [ 5.2451e-03, -1.8193e-05,  7.5007e-04,  ..., -1.2789e-05,\n",
      "         -6.3531e-03,  3.3565e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[-1.5152e-05,  3.4468e-05, -1.4076e-04,  ...,  3.9161e-07,\n",
      "         -6.5167e-05, -3.7875e-03],\n",
      "        [-8.9399e-05, -7.0090e-04, -4.9299e-07,  ...,  1.0067e-06,\n",
      "          5.9643e-06,  3.2196e-03],\n",
      "        [-7.3558e-04, -2.1118e-05, -2.7994e-05,  ..., -7.7481e-07,\n",
      "          3.6803e-04, -2.4862e-02],\n",
      "        ...,\n",
      "        [-6.6237e-05, -6.9491e-07,  5.3713e-07,  ...,  1.0326e-04,\n",
      "          3.4249e-04, -7.1385e-03],\n",
      "        [ 3.5614e-04,  9.8059e-06, -3.5311e-04,  ...,  5.4749e-07,\n",
      "          1.4061e-02, -1.9021e-02],\n",
      "        [ 5.3648e-03, -1.1496e-05,  6.8243e-04,  ..., -1.0556e-05,\n",
      "         -5.0497e-03,  3.3812e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-2.9816e+01, -1.3778e+01, -1.0023e+01,  ..., -5.6027e-05,\n",
      "         -2.0484e+01, -1.1454e+01],\n",
      "        [-5.7325e+00, -1.4524e+01, -5.6680e+00,  ..., -1.6601e+01,\n",
      "         -4.4175e+00, -8.5598e+00],\n",
      "        [-2.1564e+01, -1.4647e+01, -6.5282e-04,  ..., -8.0691e+00,\n",
      "         -1.0827e+01, -8.1636e+00],\n",
      "        ...,\n",
      "        [-5.6767e+00, -1.5674e+01, -5.9759e+00,  ..., -7.8933e+00,\n",
      "         -1.0077e+01, -6.6751e-03],\n",
      "        [-1.4741e-03, -2.5782e+01, -1.6298e+01,  ..., -2.3904e+01,\n",
      "         -1.3650e+01, -6.9839e+00],\n",
      "        [-2.0255e+01, -9.2635e+00, -1.0502e+01,  ..., -2.1312e-04,\n",
      "         -1.4764e+01, -9.3101e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0187 loss_train: 0.0156 acc_train: 1.0000 loss_val: 1.1899 acc_val: 0.7700 time: 0.6710s\n",
      "before step:  Parameter containing:\n",
      "tensor([[-1.5152e-05,  3.4468e-05, -1.4076e-04,  ...,  3.9161e-07,\n",
      "         -6.5167e-05, -3.7875e-03],\n",
      "        [-8.9399e-05, -7.0090e-04, -4.9299e-07,  ...,  1.0067e-06,\n",
      "          5.9643e-06,  3.2196e-03],\n",
      "        [-7.3558e-04, -2.1118e-05, -2.7994e-05,  ..., -7.7481e-07,\n",
      "          3.6803e-04, -2.4862e-02],\n",
      "        ...,\n",
      "        [-6.6237e-05, -6.9491e-07,  5.3713e-07,  ...,  1.0326e-04,\n",
      "          3.4249e-04, -7.1385e-03],\n",
      "        [ 3.5614e-04,  9.8059e-06, -3.5311e-04,  ...,  5.4749e-07,\n",
      "          1.4061e-02, -1.9021e-02],\n",
      "        [ 5.3648e-03, -1.1496e-05,  6.8243e-04,  ..., -1.0556e-05,\n",
      "         -5.0497e-03,  3.3812e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.0859e-05,  3.6132e-05, -1.2345e-04,  ...,  1.2563e-06,\n",
      "         -6.8423e-05, -3.9512e-03],\n",
      "        [-9.9038e-05, -5.7696e-04, -2.4798e-07,  ...,  1.0021e-06,\n",
      "          3.6114e-06,  3.0233e-03],\n",
      "        [-5.7004e-04, -2.3441e-06, -2.1522e-05,  ..., -4.3536e-07,\n",
      "          3.4095e-04, -2.4989e-02],\n",
      "        ...,\n",
      "        [-6.0928e-05,  1.3389e-07, -1.1850e-07,  ...,  9.1864e-05,\n",
      "          3.3323e-04, -7.1202e-03],\n",
      "        [ 5.1345e-04,  1.3936e-05, -4.1062e-04,  ...,  5.0687e-07,\n",
      "          1.3780e-02, -1.8745e-02],\n",
      "        [ 5.4277e-03, -5.3174e-06,  6.1006e-04,  ..., -7.8088e-06,\n",
      "         -4.5228e-03,  3.3985e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-2.9429e+01, -1.3786e+01, -8.9967e+00,  ..., -1.4435e-04,\n",
      "         -1.9997e+01, -1.0840e+01],\n",
      "        [-6.5015e+00, -1.5987e+01, -5.9477e+00,  ..., -1.7876e+01,\n",
      "         -5.5308e+00, -9.0099e+00],\n",
      "        [-2.1839e+01, -1.5823e+01, -3.6579e-04,  ..., -9.4110e+00,\n",
      "         -1.1400e+01, -8.4909e+00],\n",
      "        ...,\n",
      "        [-5.6859e+00, -1.6284e+01, -5.5987e+00,  ..., -8.7231e+00,\n",
      "         -1.0262e+01, -7.9610e-03],\n",
      "        [-2.0313e-03, -2.6040e+01, -1.5917e+01,  ..., -2.4277e+01,\n",
      "         -1.3716e+01, -6.9391e+00],\n",
      "        [-1.9836e+01, -9.4475e+00, -9.6854e+00,  ..., -3.1860e-04,\n",
      "         -1.4471e+01, -8.6395e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0188 loss_train: 0.0318 acc_train: 0.9929 loss_val: 1.1958 acc_val: 0.7700 time: 0.7461s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.0859e-05,  3.6132e-05, -1.2345e-04,  ...,  1.2563e-06,\n",
      "         -6.8423e-05, -3.9512e-03],\n",
      "        [-9.9038e-05, -5.7696e-04, -2.4798e-07,  ...,  1.0021e-06,\n",
      "          3.6114e-06,  3.0233e-03],\n",
      "        [-5.7004e-04, -2.3441e-06, -2.1522e-05,  ..., -4.3536e-07,\n",
      "          3.4095e-04, -2.4989e-02],\n",
      "        ...,\n",
      "        [-6.0928e-05,  1.3389e-07, -1.1850e-07,  ...,  9.1864e-05,\n",
      "          3.3323e-04, -7.1202e-03],\n",
      "        [ 5.1345e-04,  1.3936e-05, -4.1062e-04,  ...,  5.0687e-07,\n",
      "          1.3780e-02, -1.8745e-02],\n",
      "        [ 5.4277e-03, -5.3174e-06,  6.1006e-04,  ..., -7.8088e-06,\n",
      "         -4.5228e-03,  3.3985e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 4.1219e-05,  3.6619e-05, -9.9009e-05,  ...,  1.9133e-06,\n",
      "         -6.7794e-05, -4.0873e-03],\n",
      "        [-1.0332e-04, -4.0583e-04,  5.8690e-08,  ...,  6.8923e-07,\n",
      "          1.0396e-05,  2.9612e-03],\n",
      "        [-4.1870e-04,  1.4766e-05, -1.4646e-05,  ...,  6.7002e-08,\n",
      "          3.0824e-04, -2.4986e-02],\n",
      "        ...,\n",
      "        [-5.0753e-05,  8.3714e-07, -6.6816e-07,  ...,  5.5634e-05,\n",
      "          2.8912e-04, -7.1213e-03],\n",
      "        [ 5.7938e-04,  1.7279e-05, -4.4008e-04,  ...,  4.3465e-07,\n",
      "          1.3624e-02, -1.8450e-02],\n",
      "        [ 5.5821e-03,  3.2205e-07,  5.3461e-04,  ..., -4.7874e-06,\n",
      "         -3.8967e-03,  3.4227e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-2.9305e+01, -1.3869e+01, -8.6408e+00,  ..., -2.0240e-04,\n",
      "         -2.0042e+01, -1.0608e+01],\n",
      "        [-7.0337e+00, -1.6905e+01, -6.1022e+00,  ..., -1.8637e+01,\n",
      "         -6.2934e+00, -9.2719e+00],\n",
      "        [-2.1948e+01, -1.6400e+01, -3.4791e-04,  ..., -9.9940e+00,\n",
      "         -1.1808e+01, -8.5961e+00],\n",
      "        ...,\n",
      "        [-5.7433e+00, -1.6514e+01, -5.2945e+00,  ..., -9.0698e+00,\n",
      "         -1.0353e+01, -9.5377e-03],\n",
      "        [-3.1192e-03, -2.6036e+01, -1.5454e+01,  ..., -2.4339e+01,\n",
      "         -1.3667e+01, -6.8029e+00],\n",
      "        [-1.9744e+01, -9.6768e+00, -9.3901e+00,  ..., -3.8783e-04,\n",
      "         -1.4630e+01, -8.3310e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0189 loss_train: 0.0182 acc_train: 1.0000 loss_val: 1.2250 acc_val: 0.7667 time: 0.7496s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 4.1219e-05,  3.6619e-05, -9.9009e-05,  ...,  1.9133e-06,\n",
      "         -6.7794e-05, -4.0873e-03],\n",
      "        [-1.0332e-04, -4.0583e-04,  5.8690e-08,  ...,  6.8923e-07,\n",
      "          1.0396e-05,  2.9612e-03],\n",
      "        [-4.1870e-04,  1.4766e-05, -1.4646e-05,  ...,  6.7002e-08,\n",
      "          3.0824e-04, -2.4986e-02],\n",
      "        ...,\n",
      "        [-5.0753e-05,  8.3714e-07, -6.6816e-07,  ...,  5.5634e-05,\n",
      "          2.8912e-04, -7.1213e-03],\n",
      "        [ 5.7938e-04,  1.7279e-05, -4.4008e-04,  ...,  4.3465e-07,\n",
      "          1.3624e-02, -1.8450e-02],\n",
      "        [ 5.5821e-03,  3.2205e-07,  5.3461e-04,  ..., -4.7874e-06,\n",
      "         -3.8967e-03,  3.4227e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 7.0291e-05,  3.6028e-05, -6.9860e-05,  ...,  2.3179e-06,\n",
      "         -6.4551e-05, -4.2259e-03],\n",
      "        [-1.0318e-04, -2.2878e-04,  3.1519e-07,  ...,  1.9384e-07,\n",
      "          1.5685e-05,  2.8194e-03],\n",
      "        [-2.9371e-04,  2.9172e-05, -7.7347e-06,  ...,  4.9018e-07,\n",
      "          2.6612e-04, -2.4862e-02],\n",
      "        ...,\n",
      "        [-3.7073e-05,  1.1908e-06, -9.2614e-07,  ...,  1.0199e-05,\n",
      "          2.1818e-04, -7.2038e-03],\n",
      "        [ 6.2064e-04,  1.9818e-05, -4.4254e-04,  ...,  3.3890e-07,\n",
      "          1.3502e-02, -1.8143e-02],\n",
      "        [ 5.6986e-03,  5.4085e-06,  4.5759e-04,  ..., -1.7271e-06,\n",
      "         -3.0649e-03,  3.4362e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-2.9510e+01, -1.3226e+01, -8.6461e+00,  ..., -1.9107e-04,\n",
      "         -1.9669e+01, -1.1216e+01],\n",
      "        [-7.8079e+00, -1.7022e+01, -6.2294e+00,  ..., -1.9015e+01,\n",
      "         -6.3667e+00, -9.9639e+00],\n",
      "        [-2.2252e+01, -1.6056e+01, -3.0882e-04,  ..., -1.0175e+01,\n",
      "         -1.1528e+01, -9.2021e+00],\n",
      "        ...,\n",
      "        [-5.5286e+00, -1.5782e+01, -4.6800e+00,  ..., -8.8108e+00,\n",
      "         -9.6827e+00, -1.6338e-02],\n",
      "        [-4.6185e-03, -2.5649e+01, -1.5079e+01,  ..., -2.4251e+01,\n",
      "         -1.3355e+01, -6.8893e+00],\n",
      "        [-2.0062e+01, -9.1379e+00, -9.3847e+00,  ..., -3.2539e-04,\n",
      "         -1.4374e+01, -8.9236e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0190 loss_train: 0.0196 acc_train: 1.0000 loss_val: 1.2970 acc_val: 0.7500 time: 0.6282s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 7.0291e-05,  3.6028e-05, -6.9860e-05,  ...,  2.3179e-06,\n",
      "         -6.4551e-05, -4.2259e-03],\n",
      "        [-1.0318e-04, -2.2878e-04,  3.1519e-07,  ...,  1.9384e-07,\n",
      "          1.5685e-05,  2.8194e-03],\n",
      "        [-2.9371e-04,  2.9172e-05, -7.7347e-06,  ...,  4.9018e-07,\n",
      "          2.6612e-04, -2.4862e-02],\n",
      "        ...,\n",
      "        [-3.7073e-05,  1.1908e-06, -9.2614e-07,  ...,  1.0199e-05,\n",
      "          2.1818e-04, -7.2038e-03],\n",
      "        [ 6.2064e-04,  1.9818e-05, -4.4254e-04,  ...,  3.3890e-07,\n",
      "          1.3502e-02, -1.8143e-02],\n",
      "        [ 5.6986e-03,  5.4085e-06,  4.5759e-04,  ..., -1.7271e-06,\n",
      "         -3.0649e-03,  3.4362e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 9.9862e-05,  3.4477e-05, -3.8533e-05,  ...,  2.4542e-06,\n",
      "         -4.9174e-05, -4.2941e-03],\n",
      "        [-9.9059e-05, -4.9860e-05,  4.3738e-07,  ..., -3.1335e-07,\n",
      "          1.9195e-05,  2.7695e-03],\n",
      "        [-1.7428e-04,  4.0119e-05, -1.1228e-06,  ...,  6.5021e-07,\n",
      "          2.1310e-04, -2.4470e-02],\n",
      "        ...,\n",
      "        [-2.1434e-05,  1.1089e-06, -8.2797e-07,  ..., -4.3316e-05,\n",
      "          1.3802e-04, -7.2905e-03],\n",
      "        [ 6.1289e-04,  2.1558e-05, -4.2042e-04,  ...,  2.2857e-07,\n",
      "          1.3494e-02, -1.7796e-02],\n",
      "        [ 5.7637e-03,  9.9358e-06,  3.8043e-04,  ...,  1.1558e-06,\n",
      "         -2.1387e-03,  3.4587e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-2.9282e+01, -1.3674e+01, -9.8785e+00,  ..., -6.4729e-05,\n",
      "         -2.0608e+01, -1.1309e+01],\n",
      "        [-6.7258e+00, -1.6712e+01, -6.3719e+00,  ..., -1.8557e+01,\n",
      "         -6.2095e+00, -9.2927e+00],\n",
      "        [-2.1127e+01, -1.5504e+01, -5.5774e-04,  ..., -9.1618e+00,\n",
      "         -1.1369e+01, -8.2003e+00],\n",
      "        ...,\n",
      "        [-5.2125e+00, -1.5919e+01, -5.4979e+00,  ..., -8.6849e+00,\n",
      "         -9.9629e+00, -1.1273e-02],\n",
      "        [-2.6670e-03, -2.5849e+01, -1.5775e+01,  ..., -2.4326e+01,\n",
      "         -1.3617e+01, -7.1015e+00],\n",
      "        [-1.9759e+01, -9.5442e+00, -1.0202e+01,  ..., -2.5734e-04,\n",
      "         -1.5102e+01, -8.8156e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0191 loss_train: 0.0296 acc_train: 0.9929 loss_val: 1.1881 acc_val: 0.7667 time: 0.6289s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 9.9862e-05,  3.4477e-05, -3.8533e-05,  ...,  2.4542e-06,\n",
      "         -4.9174e-05, -4.2941e-03],\n",
      "        [-9.9059e-05, -4.9860e-05,  4.3738e-07,  ..., -3.1335e-07,\n",
      "          1.9195e-05,  2.7695e-03],\n",
      "        [-1.7428e-04,  4.0119e-05, -1.1228e-06,  ...,  6.5021e-07,\n",
      "          2.1310e-04, -2.4470e-02],\n",
      "        ...,\n",
      "        [-2.1434e-05,  1.1089e-06, -8.2797e-07,  ..., -4.3316e-05,\n",
      "          1.3802e-04, -7.2905e-03],\n",
      "        [ 6.1289e-04,  2.1558e-05, -4.2042e-04,  ...,  2.2857e-07,\n",
      "          1.3494e-02, -1.7796e-02],\n",
      "        [ 5.7637e-03,  9.9358e-06,  3.8043e-04,  ...,  1.1558e-06,\n",
      "         -2.1387e-03,  3.4587e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.3414e-04,  3.2101e-05, -7.4818e-06,  ...,  2.3340e-06,\n",
      "         -3.0256e-05, -4.0956e-03],\n",
      "        [-9.1317e-05,  1.1463e-04,  3.9554e-07,  ..., -6.7375e-07,\n",
      "          2.0813e-05,  2.7199e-03],\n",
      "        [-7.0479e-05,  4.7163e-05,  4.8994e-06,  ...,  4.9945e-07,\n",
      "          1.5054e-04, -2.4076e-02],\n",
      "        ...,\n",
      "        [-4.4795e-06,  6.6050e-07, -4.4258e-07,  ..., -8.5344e-05,\n",
      "          5.0742e-05, -7.3357e-03],\n",
      "        [ 5.8530e-04,  2.2528e-05, -3.7727e-04,  ...,  1.1282e-07,\n",
      "          1.3535e-02, -1.7505e-02],\n",
      "        [ 5.7953e-03,  1.3905e-05,  3.0441e-04,  ...,  3.6769e-06,\n",
      "         -1.2451e-03,  3.4752e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-2.9296e+01, -1.3726e+01, -1.1036e+01,  ..., -2.5153e-05,\n",
      "         -2.1196e+01, -1.1743e+01],\n",
      "        [-5.9684e+00, -1.5918e+01, -6.3562e+00,  ..., -1.7820e+01,\n",
      "         -5.6365e+00, -8.8771e+00],\n",
      "        [-2.0367e+01, -1.4586e+01, -1.0375e-03,  ..., -7.9730e+00,\n",
      "         -1.0975e+01, -7.5313e+00],\n",
      "        ...,\n",
      "        [-4.9577e+00, -1.5588e+01, -6.0403e+00,  ..., -8.2172e+00,\n",
      "         -9.8897e+00, -1.0678e-02],\n",
      "        [-1.8203e-03, -2.5710e+01, -1.6224e+01,  ..., -2.4130e+01,\n",
      "         -1.3610e+01, -7.2334e+00],\n",
      "        [-1.9806e+01, -9.6018e+00, -1.1018e+01,  ..., -1.9370e-04,\n",
      "         -1.5573e+01, -9.1192e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0192 loss_train: 0.0170 acc_train: 1.0000 loss_val: 1.1373 acc_val: 0.7633 time: 0.6493s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.3414e-04,  3.2101e-05, -7.4818e-06,  ...,  2.3340e-06,\n",
      "         -3.0256e-05, -4.0956e-03],\n",
      "        [-9.1317e-05,  1.1463e-04,  3.9554e-07,  ..., -6.7375e-07,\n",
      "          2.0813e-05,  2.7199e-03],\n",
      "        [-7.0479e-05,  4.7163e-05,  4.8994e-06,  ...,  4.9945e-07,\n",
      "          1.5054e-04, -2.4076e-02],\n",
      "        ...,\n",
      "        [-4.4795e-06,  6.6050e-07, -4.4258e-07,  ..., -8.5344e-05,\n",
      "          5.0742e-05, -7.3357e-03],\n",
      "        [ 5.8530e-04,  2.2528e-05, -3.7727e-04,  ...,  1.1282e-07,\n",
      "          1.3535e-02, -1.7505e-02],\n",
      "        [ 5.7953e-03,  1.3905e-05,  3.0441e-04,  ...,  3.6769e-06,\n",
      "         -1.2451e-03,  3.4752e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.6782e-04,  2.9044e-05,  2.1084e-05,  ...,  1.9937e-06,\n",
      "         -1.5182e-05, -3.8972e-03],\n",
      "        [-8.0383e-05,  2.1852e-04,  2.1981e-07,  ..., -7.8906e-07,\n",
      "          2.0586e-05,  2.5775e-03],\n",
      "        [ 1.9510e-05,  5.0178e-05,  1.0097e-05,  ...,  1.3599e-07,\n",
      "          7.2978e-05, -2.3775e-02],\n",
      "        ...,\n",
      "        [ 1.1224e-05,  3.2083e-08,  6.4340e-08,  ..., -1.0357e-04,\n",
      "          5.6942e-05, -7.3538e-03],\n",
      "        [ 4.6390e-04,  2.2774e-05, -3.1746e-04,  ...,  3.5014e-10,\n",
      "          1.3419e-02, -1.7339e-02],\n",
      "        [ 5.6193e-03,  1.7322e-05,  2.3068e-04,  ...,  5.6942e-06,\n",
      "         -1.1812e-03,  3.4775e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-2.8791e+01, -1.2625e+01, -9.9823e+00,  ..., -5.6742e-05,\n",
      "         -1.9826e+01, -1.1827e+01],\n",
      "        [-6.1826e+00, -1.6029e+01, -6.4737e+00,  ..., -1.8208e+01,\n",
      "         -5.5304e+00, -9.3387e+00],\n",
      "        [-2.0451e+01, -1.4809e+01, -6.1636e-04,  ..., -8.9864e+00,\n",
      "         -1.0732e+01, -8.2706e+00],\n",
      "        ...,\n",
      "        [-4.2274e+00, -1.5202e+01, -5.5374e+00,  ..., -8.5871e+00,\n",
      "         -9.1467e+00, -2.1459e-02],\n",
      "        [-1.6073e-03, -2.5949e+01, -1.6416e+01,  ..., -2.4660e+01,\n",
      "         -1.3667e+01, -7.6400e+00],\n",
      "        [-1.9231e+01, -8.5982e+00, -1.0165e+01,  ..., -3.2753e-04,\n",
      "         -1.4281e+01, -9.1724e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0193 loss_train: 0.0254 acc_train: 1.0000 loss_val: 1.2089 acc_val: 0.7533 time: 0.6550s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.6782e-04,  2.9044e-05,  2.1084e-05,  ...,  1.9937e-06,\n",
      "         -1.5182e-05, -3.8972e-03],\n",
      "        [-8.0383e-05,  2.1852e-04,  2.1981e-07,  ..., -7.8906e-07,\n",
      "          2.0586e-05,  2.5775e-03],\n",
      "        [ 1.9510e-05,  5.0178e-05,  1.0097e-05,  ...,  1.3599e-07,\n",
      "          7.2978e-05, -2.3775e-02],\n",
      "        ...,\n",
      "        [ 1.1224e-05,  3.2083e-08,  6.4340e-08,  ..., -1.0357e-04,\n",
      "          5.6942e-05, -7.3538e-03],\n",
      "        [ 4.6390e-04,  2.2774e-05, -3.1746e-04,  ...,  3.5014e-10,\n",
      "          1.3419e-02, -1.7339e-02],\n",
      "        [ 5.6193e-03,  1.7322e-05,  2.3068e-04,  ...,  5.6942e-06,\n",
      "         -1.1812e-03,  3.4775e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 1.9377e-04,  2.5459e-05,  4.5339e-05,  ...,  1.4880e-06,\n",
      "         -3.0071e-06, -3.6676e-03],\n",
      "        [-6.7028e-05,  2.9905e-04, -1.5678e-08,  ..., -6.4654e-07,\n",
      "          1.8709e-05,  2.3778e-03],\n",
      "        [ 1.0041e-04,  4.9331e-05,  1.4296e-05,  ..., -2.5414e-07,\n",
      "         -2.1816e-06, -2.3451e-02],\n",
      "        ...,\n",
      "        [ 2.4360e-05, -5.4599e-07,  4.9867e-07,  ..., -9.1809e-05,\n",
      "          6.0220e-05, -7.4219e-03],\n",
      "        [ 3.4409e-04,  2.2357e-05, -2.4587e-04,  ..., -1.0119e-07,\n",
      "          1.3260e-02, -1.7155e-02],\n",
      "        [ 5.4240e-03,  2.0200e-05,  1.6024e-04,  ...,  7.1140e-06,\n",
      "         -1.3250e-03,  3.4801e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-2.8814e+01, -1.1280e+01, -8.2347e+00,  ..., -2.8356e-04,\n",
      "         -1.8123e+01, -1.2084e+01],\n",
      "        [-7.3380e+00, -1.6151e+01, -6.3304e+00,  ..., -1.8699e+01,\n",
      "         -5.4731e+00, -1.0263e+01],\n",
      "        [-2.1518e+01, -1.5337e+01, -3.8604e-04,  ..., -1.0453e+01,\n",
      "         -1.0776e+01, -9.6728e+00],\n",
      "        ...,\n",
      "        [-3.9664e+00, -1.4432e+01, -4.2381e+00,  ..., -8.6718e+00,\n",
      "         -8.1250e+00, -4.5542e-02],\n",
      "        [-2.6569e-03, -2.5712e+01, -1.5847e+01,  ..., -2.4764e+01,\n",
      "         -1.3327e+01, -7.7045e+00],\n",
      "        [-1.9352e+01, -7.3857e+00, -8.9197e+00,  ..., -8.2495e-04,\n",
      "         -1.2841e+01, -9.5945e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0194 loss_train: 0.0207 acc_train: 0.9929 loss_val: 1.3858 acc_val: 0.7433 time: 0.7407s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 1.9377e-04,  2.5459e-05,  4.5339e-05,  ...,  1.4880e-06,\n",
      "         -3.0071e-06, -3.6676e-03],\n",
      "        [-6.7028e-05,  2.9905e-04, -1.5678e-08,  ..., -6.4654e-07,\n",
      "          1.8709e-05,  2.3778e-03],\n",
      "        [ 1.0041e-04,  4.9331e-05,  1.4296e-05,  ..., -2.5414e-07,\n",
      "         -2.1816e-06, -2.3451e-02],\n",
      "        ...,\n",
      "        [ 2.4360e-05, -5.4599e-07,  4.9867e-07,  ..., -9.1809e-05,\n",
      "          6.0220e-05, -7.4219e-03],\n",
      "        [ 3.4409e-04,  2.2357e-05, -2.4587e-04,  ..., -1.0119e-07,\n",
      "          1.3260e-02, -1.7155e-02],\n",
      "        [ 5.4240e-03,  2.0200e-05,  1.6024e-04,  ...,  7.1140e-06,\n",
      "         -1.3250e-03,  3.4801e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 2.1844e-04,  2.1496e-05,  6.3937e-05,  ...,  8.8283e-07,\n",
      "         -3.8914e-06, -3.3779e-03],\n",
      "        [-5.2346e-05,  3.4809e-04, -2.2272e-07,  ..., -3.1529e-07,\n",
      "          1.5491e-05,  2.4227e-03],\n",
      "        [ 1.2163e-04,  4.5051e-05,  1.7387e-05,  ..., -4.8988e-07,\n",
      "         -2.4884e-04, -2.3078e-02],\n",
      "        ...,\n",
      "        [ 3.4028e-05, -8.8175e-07,  7.1040e-07,  ..., -5.9875e-05,\n",
      "          5.6605e-05, -7.4988e-03],\n",
      "        [ 3.2724e-04,  2.1352e-05, -1.6758e-04,  ..., -1.8561e-07,\n",
      "          1.2736e-02, -1.6635e-02],\n",
      "        [ 5.4627e-03,  2.2558e-05,  9.3958e-05,  ...,  7.8930e-06,\n",
      "         -2.1350e-03,  3.5353e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-2.8937e+01, -1.3560e+01, -8.4758e+00,  ..., -2.3446e-04,\n",
      "         -2.0096e+01, -1.0611e+01],\n",
      "        [-6.7747e+00, -1.7067e+01, -6.1923e+00,  ..., -1.8842e+01,\n",
      "         -6.3186e+00, -9.2914e+00],\n",
      "        [-2.1151e+01, -1.6840e+01, -4.9066e-04,  ..., -1.0574e+01,\n",
      "         -1.2063e+01, -8.3619e+00],\n",
      "        ...,\n",
      "        [-4.8609e+00, -1.6549e+01, -5.2922e+00,  ..., -9.6131e+00,\n",
      "         -9.9998e+00, -1.5619e-02],\n",
      "        [-2.6584e-03, -2.6308e+01, -1.5814e+01,  ..., -2.4795e+01,\n",
      "         -1.3750e+01, -7.1861e+00],\n",
      "        [-1.9173e+01, -9.5023e+00, -9.0501e+00,  ..., -5.3117e-04,\n",
      "         -1.4532e+01, -7.9911e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0195 loss_train: 0.0276 acc_train: 1.0000 loss_val: 1.2546 acc_val: 0.7533 time: 0.6429s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 2.1844e-04,  2.1496e-05,  6.3937e-05,  ...,  8.8283e-07,\n",
      "         -3.8914e-06, -3.3779e-03],\n",
      "        [-5.2346e-05,  3.4809e-04, -2.2272e-07,  ..., -3.1529e-07,\n",
      "          1.5491e-05,  2.4227e-03],\n",
      "        [ 1.2163e-04,  4.5051e-05,  1.7387e-05,  ..., -4.8988e-07,\n",
      "         -2.4884e-04, -2.3078e-02],\n",
      "        ...,\n",
      "        [ 3.4028e-05, -8.8175e-07,  7.1040e-07,  ..., -5.9875e-05,\n",
      "          5.6605e-05, -7.4988e-03],\n",
      "        [ 3.2724e-04,  2.1352e-05, -1.6758e-04,  ..., -1.8561e-07,\n",
      "          1.2736e-02, -1.6635e-02],\n",
      "        [ 5.4627e-03,  2.2558e-05,  9.3958e-05,  ...,  7.8930e-06,\n",
      "         -2.1350e-03,  3.5353e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 2.3920e-04,  1.7303e-05,  7.6064e-05,  ...,  2.4822e-07,\n",
      "          4.6286e-07, -3.0436e-03],\n",
      "        [-3.4400e-05,  3.7116e-04, -3.3123e-07,  ...,  8.2768e-08,\n",
      "          1.1320e-05,  2.5459e-03],\n",
      "        [ 1.3374e-04,  3.7966e-05,  1.9325e-05,  ..., -4.7772e-07,\n",
      "         -4.6030e-04, -2.2609e-02],\n",
      "        ...,\n",
      "        [ 3.9670e-05, -8.8360e-07,  6.4397e-07,  ..., -1.3299e-05,\n",
      "          1.2030e-04, -7.4508e-03],\n",
      "        [ 3.0416e-04,  1.9844e-05, -8.7571e-05,  ..., -2.4853e-07,\n",
      "          1.2199e-02, -1.6066e-02],\n",
      "        [ 5.4762e-03,  2.4415e-05,  3.2544e-05,  ...,  8.0372e-06,\n",
      "         -2.6743e-03,  3.5828e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-2.9683e+01, -1.5274e+01, -9.5697e+00,  ..., -1.0704e-04,\n",
      "         -2.2075e+01, -1.0207e+01],\n",
      "        [-6.3239e+00, -1.6816e+01, -5.7996e+00,  ..., -1.8126e+01,\n",
      "         -6.3042e+00, -8.4511e+00],\n",
      "        [-2.1112e+01, -1.7184e+01, -7.8361e-04,  ..., -9.7802e+00,\n",
      "         -1.2743e+01, -7.4050e+00],\n",
      "        ...,\n",
      "        [-5.7551e+00, -1.7427e+01, -6.0283e+00,  ..., -9.4924e+00,\n",
      "         -1.1061e+01, -6.3614e-03],\n",
      "        [-2.8855e-03, -2.6251e+01, -1.5647e+01,  ..., -2.4175e+01,\n",
      "         -1.3760e+01, -6.5603e+00],\n",
      "        [-1.9867e+01, -1.1061e+01, -9.9077e+00,  ..., -5.7502e-04,\n",
      "         -1.6306e+01, -7.5826e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0196 loss_train: 0.0162 acc_train: 1.0000 loss_val: 1.1685 acc_val: 0.7767 time: 0.5924s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 2.3920e-04,  1.7303e-05,  7.6064e-05,  ...,  2.4822e-07,\n",
      "          4.6286e-07, -3.0436e-03],\n",
      "        [-3.4400e-05,  3.7116e-04, -3.3123e-07,  ...,  8.2768e-08,\n",
      "          1.1320e-05,  2.5459e-03],\n",
      "        [ 1.3374e-04,  3.7966e-05,  1.9325e-05,  ..., -4.7772e-07,\n",
      "         -4.6030e-04, -2.2609e-02],\n",
      "        ...,\n",
      "        [ 3.9670e-05, -8.8360e-07,  6.4397e-07,  ..., -1.3299e-05,\n",
      "          1.2030e-04, -7.4508e-03],\n",
      "        [ 3.0416e-04,  1.9844e-05, -8.7571e-05,  ..., -2.4853e-07,\n",
      "          1.2199e-02, -1.6066e-02],\n",
      "        [ 5.4762e-03,  2.4415e-05,  3.2544e-05,  ...,  8.0372e-06,\n",
      "         -2.6743e-03,  3.5828e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 2.5882e-04,  1.3022e-05,  8.1453e-05,  ..., -3.4947e-07,\n",
      "          6.6692e-06, -2.7377e-03],\n",
      "        [-1.4600e-05,  3.6933e-04, -3.1233e-07,  ...,  4.1593e-07,\n",
      "          6.6287e-06,  2.5384e-03],\n",
      "        [ 1.2550e-04,  2.8851e-05,  2.0125e-05,  ..., -2.4679e-07,\n",
      "         -6.3536e-04, -2.2244e-02],\n",
      "        ...,\n",
      "        [ 4.1176e-05, -5.8262e-07,  3.4993e-07,  ...,  3.1841e-05,\n",
      "          8.5999e-04, -7.4817e-03],\n",
      "        [ 2.4207e-05,  1.7921e-05, -1.0464e-05,  ..., -2.8749e-07,\n",
      "          1.2072e-02, -1.5619e-02],\n",
      "        [ 5.2857e-03,  2.5799e-05, -2.3437e-05,  ...,  7.5965e-06,\n",
      "         -2.1768e-03,  3.5986e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-3.1145e+01, -1.3660e+01, -9.9273e+00,  ..., -5.4835e-05,\n",
      "         -2.1106e+01, -1.2240e+01],\n",
      "        [-7.9650e+00, -1.4280e+01, -5.1318e+00,  ..., -1.6794e+01,\n",
      "         -4.1933e+00, -9.8550e+00],\n",
      "        [-2.2941e+01, -1.5445e+01, -2.6056e-04,  ..., -9.1606e+00,\n",
      "         -1.1728e+01, -9.2704e+00],\n",
      "        ...,\n",
      "        [-5.8542e+00, -1.4967e+01, -4.7577e+00,  ..., -7.6686e+00,\n",
      "         -9.3418e+00, -1.3431e-02],\n",
      "        [-3.6679e-03, -2.4661e+01, -1.4976e+01,  ..., -2.3158e+01,\n",
      "         -1.2592e+01, -6.6541e+00],\n",
      "        [-2.1869e+01, -9.4138e+00, -1.0420e+01,  ..., -1.5448e-04,\n",
      "         -1.5577e+01, -1.0057e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0197 loss_train: 0.0350 acc_train: 0.9857 loss_val: 1.3315 acc_val: 0.7633 time: 0.5843s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 2.5882e-04,  1.3022e-05,  8.1453e-05,  ..., -3.4947e-07,\n",
      "          6.6692e-06, -2.7377e-03],\n",
      "        [-1.4600e-05,  3.6933e-04, -3.1233e-07,  ...,  4.1593e-07,\n",
      "          6.6287e-06,  2.5384e-03],\n",
      "        [ 1.2550e-04,  2.8851e-05,  2.0125e-05,  ..., -2.4679e-07,\n",
      "         -6.3536e-04, -2.2244e-02],\n",
      "        ...,\n",
      "        [ 4.1176e-05, -5.8262e-07,  3.4993e-07,  ...,  3.1841e-05,\n",
      "          8.5999e-04, -7.4817e-03],\n",
      "        [ 2.4207e-05,  1.7921e-05, -1.0464e-05,  ..., -2.8749e-07,\n",
      "          1.2072e-02, -1.5619e-02],\n",
      "        [ 5.2857e-03,  2.5799e-05, -2.3437e-05,  ...,  7.5965e-06,\n",
      "         -2.1768e-03,  3.5986e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 2.5091e-04,  8.7837e-06,  8.0350e-05,  ..., -8.5367e-07,\n",
      "          1.3369e-05, -2.4898e-03],\n",
      "        [ 3.8471e-06,  3.2803e-04, -1.8480e-07,  ...,  5.8516e-07,\n",
      "          1.8498e-06,  2.3344e-03],\n",
      "        [ 9.8285e-05,  1.8550e-05,  1.9855e-05,  ...,  7.5557e-08,\n",
      "         -7.8964e-04, -2.2207e-02],\n",
      "        ...,\n",
      "        [ 3.8805e-05, -1.1088e-07, -4.3003e-08,  ...,  6.5126e-05,\n",
      "          1.4452e-03, -7.6867e-03],\n",
      "        [-2.2775e-04,  1.5678e-05,  5.9712e-05,  ..., -3.0196e-07,\n",
      "          1.2068e-02, -1.5667e-02],\n",
      "        [ 5.1269e-03,  2.6738e-05, -7.3561e-05,  ...,  6.6579e-06,\n",
      "         -1.6810e-03,  3.5906e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-2.8944e+01, -1.1799e+01, -8.0823e+00,  ..., -3.2813e-04,\n",
      "         -1.8062e+01, -1.1367e+01],\n",
      "        [-7.5308e+00, -1.4480e+01, -5.7795e+00,  ..., -1.7529e+01,\n",
      "         -3.8435e+00, -1.0256e+01],\n",
      "        [-2.1533e+01, -1.5436e+01, -3.5482e-04,  ..., -1.0469e+01,\n",
      "         -1.0506e+01, -9.3741e+00],\n",
      "        ...,\n",
      "        [-4.1946e+00, -1.5030e+01, -4.9624e+00,  ..., -8.9005e+00,\n",
      "         -8.4552e+00, -2.7519e-02],\n",
      "        [-2.1690e-03, -2.5600e+01, -1.6038e+01,  ..., -2.4590e+01,\n",
      "         -1.2938e+01, -7.5604e+00],\n",
      "        [-1.9333e+01, -7.6610e+00, -8.8291e+00,  ..., -7.3847e-04,\n",
      "         -1.2544e+01, -9.0508e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0198 loss_train: 0.0547 acc_train: 0.9857 loss_val: 1.4459 acc_val: 0.7400 time: 0.6079s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 2.5091e-04,  8.7837e-06,  8.0350e-05,  ..., -8.5367e-07,\n",
      "          1.3369e-05, -2.4898e-03],\n",
      "        [ 3.8471e-06,  3.2803e-04, -1.8480e-07,  ...,  5.8516e-07,\n",
      "          1.8498e-06,  2.3344e-03],\n",
      "        [ 9.8285e-05,  1.8550e-05,  1.9855e-05,  ...,  7.5557e-08,\n",
      "         -7.8964e-04, -2.2207e-02],\n",
      "        ...,\n",
      "        [ 3.8805e-05, -1.1088e-07, -4.3003e-08,  ...,  6.5126e-05,\n",
      "          1.4452e-03, -7.6867e-03],\n",
      "        [-2.2775e-04,  1.5678e-05,  5.9712e-05,  ..., -3.0196e-07,\n",
      "          1.2068e-02, -1.5667e-02],\n",
      "        [ 5.1269e-03,  2.6738e-05, -7.3561e-05,  ...,  6.6579e-06,\n",
      "         -1.6810e-03,  3.5906e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 2.3048e-04,  4.7047e-06,  7.3451e-05,  ..., -1.2225e-06,\n",
      "          1.9206e-05, -2.2044e-03],\n",
      "        [ 2.0343e-05,  2.7062e-04, -4.1537e-09,  ...,  5.5245e-07,\n",
      "         -2.6156e-06,  2.4809e-03],\n",
      "        [ 5.6839e-05,  7.9159e-06,  1.8631e-05,  ...,  3.3149e-07,\n",
      "         -9.1979e-04, -2.2008e-02],\n",
      "        ...,\n",
      "        [ 3.3138e-05,  3.5306e-07, -3.8190e-07,  ...,  7.9875e-05,\n",
      "          1.8141e-03, -7.9976e-03],\n",
      "        [-3.0511e-04,  1.3208e-05,  1.1969e-04,  ..., -2.9324e-07,\n",
      "          1.1668e-02, -1.5410e-02],\n",
      "        [ 5.4340e-03,  2.7264e-05, -1.1754e-04,  ...,  5.3354e-06,\n",
      "         -1.9795e-03,  3.6524e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-2.7002e+01, -1.4537e+01, -7.7292e+00,  ..., -7.3120e-04,\n",
      "         -1.9511e+01, -8.1435e+00],\n",
      "        [-5.5335e+00, -1.6459e+01, -6.4614e+00,  ..., -1.8456e+01,\n",
      "         -5.2984e+00, -8.6973e+00],\n",
      "        [-1.9104e+01, -1.7150e+01, -1.5803e-03,  ..., -1.0787e+01,\n",
      "         -1.1314e+01, -6.8501e+00],\n",
      "        ...,\n",
      "        [-4.2084e+00, -1.7903e+01, -6.8268e+00,  ..., -1.0802e+01,\n",
      "         -1.0457e+01, -1.7411e-02],\n",
      "        [-1.2919e-03, -2.7280e+01, -1.7046e+01,  ..., -2.5669e+01,\n",
      "         -1.4003e+01, -7.5167e+00],\n",
      "        [-1.6292e+01, -9.7819e+00, -8.1086e+00,  ..., -4.4860e-03,\n",
      "         -1.2880e+01, -5.4929e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0199 loss_train: 0.0264 acc_train: 0.9929 loss_val: 1.2669 acc_val: 0.7467 time: 0.6262s\n",
      "before step:  Parameter containing:\n",
      "tensor([[ 2.3048e-04,  4.7047e-06,  7.3451e-05,  ..., -1.2225e-06,\n",
      "          1.9206e-05, -2.2044e-03],\n",
      "        [ 2.0343e-05,  2.7062e-04, -4.1537e-09,  ...,  5.5245e-07,\n",
      "         -2.6156e-06,  2.4809e-03],\n",
      "        [ 5.6839e-05,  7.9159e-06,  1.8631e-05,  ...,  3.3149e-07,\n",
      "         -9.1979e-04, -2.2008e-02],\n",
      "        ...,\n",
      "        [ 3.3138e-05,  3.5306e-07, -3.8190e-07,  ...,  7.9875e-05,\n",
      "          1.8141e-03, -7.9976e-03],\n",
      "        [-3.0511e-04,  1.3208e-05,  1.1969e-04,  ..., -2.9324e-07,\n",
      "          1.1668e-02, -1.5410e-02],\n",
      "        [ 5.4340e-03,  2.7264e-05, -1.1754e-04,  ...,  5.3354e-06,\n",
      "         -1.9795e-03,  3.6524e-02]], requires_grad=True)\n",
      "after step:  Parameter containing:\n",
      "tensor([[ 2.1878e-04,  8.8722e-07,  6.1815e-05,  ..., -1.4315e-06,\n",
      "          2.7311e-05, -1.7254e-03],\n",
      "        [ 3.4421e-05,  1.8118e-04,  1.6035e-07,  ...,  3.4738e-07,\n",
      "         -6.4294e-06,  2.7304e-03],\n",
      "        [ 1.5039e-05, -2.2534e-06,  1.6603e-05,  ...,  4.0858e-07,\n",
      "         -1.0130e-03, -2.1641e-02],\n",
      "        ...,\n",
      "        [ 2.5004e-05,  6.4981e-07, -5.4776e-07,  ...,  7.4381e-05,\n",
      "          1.9927e-03, -8.2333e-03],\n",
      "        [-3.2770e-04,  1.0602e-05,  1.6706e-04,  ..., -2.6416e-07,\n",
      "          1.1336e-02, -1.5076e-02],\n",
      "        [ 5.7992e-03,  2.7408e-05, -1.5522e-04,  ...,  3.7598e-06,\n",
      "         -1.7305e-03,  3.7293e-02]], requires_grad=True)\n",
      "eval output:  tensor([[-2.7418e+01, -1.6526e+01, -8.5246e+00,  ..., -8.7402e-04,\n",
      "         -2.1589e+01, -7.3007e+00],\n",
      "        [-5.0884e+00, -1.6377e+01, -6.0895e+00,  ..., -1.7840e+01,\n",
      "         -5.4910e+00, -7.8451e+00],\n",
      "        [-1.9093e+01, -1.7536e+01, -2.7929e-03,  ..., -1.0052e+01,\n",
      "         -1.2015e+01, -5.9951e+00],\n",
      "        ...,\n",
      "        [-5.1124e+00, -1.8671e+01, -7.3723e+00,  ..., -1.0588e+01,\n",
      "         -1.1439e+01, -7.0975e-03],\n",
      "        [-1.7307e-03, -2.7082e+01, -1.6690e+01,  ..., -2.4937e+01,\n",
      "         -1.3952e+01, -6.8677e+00],\n",
      "        [-1.6820e+01, -1.1238e+01, -8.7453e+00,  ..., -6.5414e-03,\n",
      "         -1.4527e+01, -5.0598e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
      "Epoch: 0200 loss_train: 0.0237 acc_train: 1.0000 loss_val: 1.1772 acc_val: 0.7733 time: 0.6728s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 140.8612s\n",
      "Test set results: loss= 1.1168 accuracy= 0.7600\n",
      "inference time:  0.18878889083862305\n"
     ]
    }
   ],
   "source": [
    "loss_TRAIN, acc_TRAIN, loss_VAL, acc_VAL = run_experiment(num_epochs=200, model=model3, lr=lr, weight_decay=weight_decay, features=features, adj=adj, idx_train=idx_train, idx_val=idx_val, idx_test=idx_test, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_t = []\n",
    "for ten in loss_TRAIN:\n",
    "    l_t.append(ten.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(l_t, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_t = []\n",
    "for ten in acc_TRAIN:\n",
    "    a_t.append(ten.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(a_t, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_v = []\n",
    "for ten in loss_VAL:\n",
    "    l_v.append(ten.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(l_v, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_v = []\n",
    "for ten in acc_VAL:\n",
    "    a_v.append(ten.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(a_v, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = ite_GCN(nfeat=features.shape[1],\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=dropout,\n",
    "            train_nite = 3,\n",
    "            allow_grad=False,\n",
    "            smooth_fac=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(num_epochs=400, model=model4, lr=lr, weight_decay=weight_decay, features=features, adj=adj, idx_train=idx_train, idx_val=idx_val, idx_test=idx_test, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model3.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        print(name, param.grad.abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = GCN_3(nfeat=features.shape[1],\n",
    "            nhid=hidden,\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unspecified or invalid number of iterations for inference. Treat as the same as training iterations.\n",
      "Initialize a 1-layer GCN with  2 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "runrunrun!\n",
      "Epoch: 0001 loss_train: 1.9467 acc_train: 0.1500 loss_val: 1.8242 acc_val: 0.3500 time: 0.5056s\n",
      "Epoch: 0002 loss_train: 1.8288 acc_train: 0.2929 loss_val: 1.9568 acc_val: 0.3500 time: 0.5538s\n",
      "Epoch: 0003 loss_train: 1.9938 acc_train: 0.2929 loss_val: 1.7933 acc_val: 0.3500 time: 0.4208s\n",
      "Epoch: 0004 loss_train: 1.7844 acc_train: 0.2929 loss_val: 1.8393 acc_val: 0.1567 time: 0.3897s\n",
      "Epoch: 0005 loss_train: 1.8181 acc_train: 0.2000 loss_val: 1.8175 acc_val: 0.1567 time: 0.3952s\n",
      "Epoch: 0006 loss_train: 1.7826 acc_train: 0.2000 loss_val: 1.7674 acc_val: 0.1567 time: 0.3865s\n",
      "Epoch: 0007 loss_train: 1.7075 acc_train: 0.2000 loss_val: 1.6644 acc_val: 0.1700 time: 0.3814s\n",
      "Epoch: 0008 loss_train: 1.5878 acc_train: 0.2000 loss_val: 1.5229 acc_val: 0.3600 time: 0.3854s\n",
      "Epoch: 0009 loss_train: 1.4491 acc_train: 0.3786 loss_val: 1.3986 acc_val: 0.3500 time: 0.3834s\n",
      "Epoch: 0010 loss_train: 1.3233 acc_train: 0.3000 loss_val: 1.3006 acc_val: 0.5400 time: 0.3869s\n",
      "Epoch: 0011 loss_train: 1.1683 acc_train: 0.5929 loss_val: 1.2416 acc_val: 0.5633 time: 0.3818s\n",
      "Epoch: 0012 loss_train: 1.0475 acc_train: 0.6714 loss_val: 1.1486 acc_val: 0.5400 time: 0.3864s\n",
      "Epoch: 0013 loss_train: 0.9025 acc_train: 0.6214 loss_val: 1.1113 acc_val: 0.5767 time: 0.3825s\n",
      "Epoch: 0014 loss_train: 0.8180 acc_train: 0.6714 loss_val: 1.1090 acc_val: 0.6100 time: 0.3827s\n",
      "Epoch: 0015 loss_train: 0.7659 acc_train: 0.7214 loss_val: 1.0544 acc_val: 0.6067 time: 0.3914s\n",
      "Epoch: 0016 loss_train: 0.6561 acc_train: 0.7429 loss_val: 1.0225 acc_val: 0.6200 time: 0.4015s\n",
      "Epoch: 0017 loss_train: 0.5746 acc_train: 0.7429 loss_val: 1.0511 acc_val: 0.6633 time: 0.3801s\n",
      "Epoch: 0018 loss_train: 0.5410 acc_train: 0.8286 loss_val: 1.0392 acc_val: 0.7133 time: 0.3910s\n",
      "Epoch: 0019 loss_train: 0.4596 acc_train: 0.8929 loss_val: 1.0338 acc_val: 0.7033 time: 0.3933s\n",
      "Epoch: 0020 loss_train: 0.4081 acc_train: 0.8643 loss_val: 0.9550 acc_val: 0.7233 time: 0.3856s\n",
      "Epoch: 0021 loss_train: 0.3659 acc_train: 0.8643 loss_val: 0.9060 acc_val: 0.7533 time: 0.3874s\n",
      "Epoch: 0022 loss_train: 0.3071 acc_train: 0.9000 loss_val: 0.9537 acc_val: 0.7700 time: 0.4032s\n",
      "Epoch: 0023 loss_train: 0.2579 acc_train: 0.9429 loss_val: 0.9648 acc_val: 0.7667 time: 0.3970s\n",
      "Epoch: 0024 loss_train: 0.2174 acc_train: 0.9857 loss_val: 0.8970 acc_val: 0.7633 time: 0.3970s\n",
      "Epoch: 0025 loss_train: 0.1758 acc_train: 0.9786 loss_val: 0.8475 acc_val: 0.7933 time: 0.3964s\n",
      "Epoch: 0026 loss_train: 0.1318 acc_train: 0.9929 loss_val: 0.8300 acc_val: 0.7833 time: 0.4184s\n",
      "Epoch: 0027 loss_train: 0.1043 acc_train: 0.9857 loss_val: 0.8085 acc_val: 0.7800 time: 0.5664s\n",
      "Epoch: 0028 loss_train: 0.0838 acc_train: 1.0000 loss_val: 0.7704 acc_val: 0.7833 time: 0.4416s\n",
      "Epoch: 0029 loss_train: 0.0730 acc_train: 1.0000 loss_val: 0.8328 acc_val: 0.7767 time: 0.7429s\n",
      "Epoch: 0030 loss_train: 0.0601 acc_train: 1.0000 loss_val: 0.8029 acc_val: 0.7833 time: 0.4031s\n",
      "Epoch: 0031 loss_train: 0.0524 acc_train: 1.0000 loss_val: 0.7867 acc_val: 0.7833 time: 0.4014s\n",
      "Epoch: 0032 loss_train: 0.0530 acc_train: 1.0000 loss_val: 0.8305 acc_val: 0.7733 time: 0.3920s\n",
      "Epoch: 0033 loss_train: 0.0558 acc_train: 1.0000 loss_val: 0.7501 acc_val: 0.7800 time: 0.3996s\n",
      "Epoch: 0034 loss_train: 0.0555 acc_train: 0.9929 loss_val: 0.8290 acc_val: 0.7600 time: 0.4076s\n",
      "Epoch: 0035 loss_train: 0.0513 acc_train: 1.0000 loss_val: 0.7837 acc_val: 0.7667 time: 0.3967s\n",
      "Epoch: 0036 loss_train: 0.0523 acc_train: 1.0000 loss_val: 0.7824 acc_val: 0.7833 time: 0.4007s\n",
      "Epoch: 0037 loss_train: 0.0517 acc_train: 1.0000 loss_val: 0.7954 acc_val: 0.7633 time: 0.4195s\n",
      "Epoch: 0038 loss_train: 0.0588 acc_train: 1.0000 loss_val: 0.7615 acc_val: 0.7867 time: 0.3963s\n",
      "Epoch: 0039 loss_train: 0.0734 acc_train: 1.0000 loss_val: 0.9308 acc_val: 0.7400 time: 0.4045s\n",
      "Epoch: 0040 loss_train: 0.0918 acc_train: 0.9929 loss_val: 0.8980 acc_val: 0.7400 time: 0.4045s\n",
      "Epoch: 0041 loss_train: 0.1359 acc_train: 0.9571 loss_val: 1.2073 acc_val: 0.7133 time: 0.4084s\n",
      "Epoch: 0042 loss_train: 0.2017 acc_train: 0.9500 loss_val: 1.2419 acc_val: 0.6533 time: 0.4098s\n",
      "Epoch: 0043 loss_train: 0.3242 acc_train: 0.9000 loss_val: 1.6788 acc_val: 0.6100 time: 0.4070s\n",
      "Epoch: 0044 loss_train: 0.4434 acc_train: 0.7857 loss_val: 1.0729 acc_val: 0.7133 time: 0.4001s\n",
      "Epoch: 0045 loss_train: 0.0766 acc_train: 0.9929 loss_val: 1.9556 acc_val: 0.4567 time: 0.4087s\n",
      "Epoch: 0046 loss_train: 0.6047 acc_train: 0.7429 loss_val: 0.8607 acc_val: 0.7667 time: 0.4177s\n",
      "Epoch: 0047 loss_train: 0.0443 acc_train: 0.9929 loss_val: 1.5186 acc_val: 0.6600 time: 0.4027s\n",
      "Epoch: 0048 loss_train: 0.3690 acc_train: 0.8286 loss_val: 1.4108 acc_val: 0.7200 time: 0.4109s\n",
      "Epoch: 0049 loss_train: 0.2734 acc_train: 0.9071 loss_val: 0.8663 acc_val: 0.7867 time: 0.4034s\n",
      "Epoch: 0050 loss_train: 0.0689 acc_train: 0.9786 loss_val: 0.7618 acc_val: 0.7933 time: 0.4053s\n",
      "Epoch: 0051 loss_train: 0.0528 acc_train: 1.0000 loss_val: 0.8655 acc_val: 0.7467 time: 0.4241s\n",
      "Epoch: 0052 loss_train: 0.0673 acc_train: 0.9929 loss_val: 1.0597 acc_val: 0.6967 time: 0.4442s\n",
      "Epoch: 0053 loss_train: 0.1032 acc_train: 0.9929 loss_val: 1.1898 acc_val: 0.6667 time: 0.4165s\n",
      "Epoch: 0054 loss_train: 0.1371 acc_train: 0.9786 loss_val: 1.1039 acc_val: 0.6933 time: 0.4167s\n",
      "Epoch: 0055 loss_train: 0.1012 acc_train: 0.9929 loss_val: 0.9256 acc_val: 0.7433 time: 0.4154s\n",
      "Epoch: 0056 loss_train: 0.0566 acc_train: 0.9929 loss_val: 0.7912 acc_val: 0.7900 time: 0.4067s\n",
      "Epoch: 0057 loss_train: 0.0355 acc_train: 1.0000 loss_val: 0.7397 acc_val: 0.8133 time: 0.4381s\n",
      "Epoch: 0058 loss_train: 0.0315 acc_train: 1.0000 loss_val: 0.7636 acc_val: 0.7967 time: 0.4159s\n",
      "Epoch: 0059 loss_train: 0.0378 acc_train: 1.0000 loss_val: 0.8063 acc_val: 0.7967 time: 0.4114s\n",
      "Epoch: 0060 loss_train: 0.0408 acc_train: 1.0000 loss_val: 0.8268 acc_val: 0.7867 time: 0.4259s\n",
      "Epoch: 0061 loss_train: 0.0368 acc_train: 1.0000 loss_val: 0.8258 acc_val: 0.7967 time: 0.4063s\n",
      "Epoch: 0062 loss_train: 0.0312 acc_train: 1.0000 loss_val: 0.8148 acc_val: 0.7967 time: 0.4165s\n",
      "Epoch: 0063 loss_train: 0.0256 acc_train: 1.0000 loss_val: 0.8058 acc_val: 0.8033 time: 0.4197s\n",
      "Epoch: 0064 loss_train: 0.0204 acc_train: 1.0000 loss_val: 0.8121 acc_val: 0.7967 time: 0.4133s\n",
      "Epoch: 0065 loss_train: 0.0173 acc_train: 1.0000 loss_val: 0.8372 acc_val: 0.8000 time: 0.4173s\n",
      "Epoch: 0066 loss_train: 0.0178 acc_train: 1.0000 loss_val: 0.8635 acc_val: 0.7867 time: 0.4181s\n",
      "Epoch: 0067 loss_train: 0.0187 acc_train: 1.0000 loss_val: 0.8757 acc_val: 0.7933 time: 0.4149s\n",
      "Epoch: 0068 loss_train: 0.0185 acc_train: 1.0000 loss_val: 0.8711 acc_val: 0.7833 time: 0.4145s\n",
      "Epoch: 0069 loss_train: 0.0188 acc_train: 1.0000 loss_val: 0.8503 acc_val: 0.7933 time: 0.4120s\n",
      "Epoch: 0070 loss_train: 0.0191 acc_train: 1.0000 loss_val: 0.8259 acc_val: 0.7967 time: 0.4179s\n",
      "Epoch: 0071 loss_train: 0.0191 acc_train: 1.0000 loss_val: 0.8123 acc_val: 0.7933 time: 0.4133s\n",
      "Epoch: 0072 loss_train: 0.0201 acc_train: 1.0000 loss_val: 0.8120 acc_val: 0.7833 time: 0.4147s\n",
      "Epoch: 0073 loss_train: 0.0218 acc_train: 1.0000 loss_val: 0.8120 acc_val: 0.7867 time: 0.4050s\n",
      "Epoch: 0074 loss_train: 0.0231 acc_train: 1.0000 loss_val: 0.8044 acc_val: 0.8000 time: 0.4099s\n",
      "Epoch: 0075 loss_train: 0.0246 acc_train: 1.0000 loss_val: 0.7878 acc_val: 0.7933 time: 0.4213s\n",
      "Epoch: 0076 loss_train: 0.0255 acc_train: 1.0000 loss_val: 0.7763 acc_val: 0.7933 time: 0.4601s\n",
      "Epoch: 0077 loss_train: 0.0267 acc_train: 1.0000 loss_val: 0.7794 acc_val: 0.7900 time: 0.4132s\n",
      "Epoch: 0078 loss_train: 0.0285 acc_train: 1.0000 loss_val: 0.7835 acc_val: 0.7900 time: 0.4413s\n",
      "Epoch: 0079 loss_train: 0.0299 acc_train: 1.0000 loss_val: 0.7695 acc_val: 0.7933 time: 0.4322s\n",
      "Epoch: 0080 loss_train: 0.0308 acc_train: 1.0000 loss_val: 0.7549 acc_val: 0.7933 time: 0.6137s\n",
      "Epoch: 0081 loss_train: 0.0322 acc_train: 1.0000 loss_val: 0.7526 acc_val: 0.7900 time: 0.5195s\n",
      "Epoch: 0082 loss_train: 0.0332 acc_train: 1.0000 loss_val: 0.7454 acc_val: 0.7933 time: 0.4182s\n",
      "Epoch: 0083 loss_train: 0.0342 acc_train: 1.0000 loss_val: 0.7313 acc_val: 0.7933 time: 0.4271s\n",
      "Epoch: 0084 loss_train: 0.0354 acc_train: 1.0000 loss_val: 0.7398 acc_val: 0.8000 time: 0.4358s\n",
      "Epoch: 0085 loss_train: 0.0361 acc_train: 1.0000 loss_val: 0.7398 acc_val: 0.7900 time: 0.4218s\n",
      "Epoch: 0086 loss_train: 0.0366 acc_train: 1.0000 loss_val: 0.7289 acc_val: 0.7933 time: 0.4289s\n",
      "Epoch: 0087 loss_train: 0.0374 acc_train: 1.0000 loss_val: 0.7335 acc_val: 0.7967 time: 0.4249s\n",
      "Epoch: 0088 loss_train: 0.0376 acc_train: 1.0000 loss_val: 0.7238 acc_val: 0.7933 time: 0.4228s\n",
      "Epoch: 0089 loss_train: 0.0381 acc_train: 1.0000 loss_val: 0.7281 acc_val: 0.8000 time: 0.4166s\n",
      "Epoch: 0090 loss_train: 0.0383 acc_train: 1.0000 loss_val: 0.7263 acc_val: 0.7933 time: 0.4579s\n",
      "Epoch: 0091 loss_train: 0.0383 acc_train: 1.0000 loss_val: 0.7280 acc_val: 0.7933 time: 0.4513s\n",
      "Epoch: 0092 loss_train: 0.0376 acc_train: 1.0000 loss_val: 0.7298 acc_val: 0.7967 time: 0.4482s\n",
      "Epoch: 0093 loss_train: 0.0369 acc_train: 1.0000 loss_val: 0.7290 acc_val: 0.7967 time: 0.4245s\n",
      "Epoch: 0094 loss_train: 0.0367 acc_train: 1.0000 loss_val: 0.7270 acc_val: 0.8033 time: 0.4304s\n",
      "Epoch: 0095 loss_train: 0.0363 acc_train: 1.0000 loss_val: 0.7285 acc_val: 0.7967 time: 0.4326s\n",
      "Epoch: 0096 loss_train: 0.0352 acc_train: 1.0000 loss_val: 0.7411 acc_val: 0.7933 time: 0.4412s\n",
      "Epoch: 0097 loss_train: 0.0345 acc_train: 1.0000 loss_val: 0.7367 acc_val: 0.8000 time: 0.4288s\n",
      "Epoch: 0098 loss_train: 0.0340 acc_train: 1.0000 loss_val: 0.7341 acc_val: 0.7967 time: 0.4259s\n",
      "Epoch: 0099 loss_train: 0.0333 acc_train: 1.0000 loss_val: 0.7344 acc_val: 0.7967 time: 0.8066s\n",
      "Epoch: 0100 loss_train: 0.0322 acc_train: 1.0000 loss_val: 0.7393 acc_val: 0.7933 time: 0.4190s\n",
      "Epoch: 0101 loss_train: 0.0317 acc_train: 1.0000 loss_val: 0.7451 acc_val: 0.7967 time: 0.4249s\n",
      "Epoch: 0102 loss_train: 0.0312 acc_train: 1.0000 loss_val: 0.7376 acc_val: 0.7967 time: 0.4214s\n",
      "Epoch: 0103 loss_train: 0.0308 acc_train: 1.0000 loss_val: 0.7552 acc_val: 0.7900 time: 0.4100s\n",
      "Epoch: 0104 loss_train: 0.0302 acc_train: 1.0000 loss_val: 0.7366 acc_val: 0.7833 time: 0.4182s\n",
      "Epoch: 0105 loss_train: 0.0302 acc_train: 1.0000 loss_val: 0.7631 acc_val: 0.7800 time: 0.4301s\n",
      "Epoch: 0106 loss_train: 0.0313 acc_train: 1.0000 loss_val: 0.7410 acc_val: 0.7833 time: 0.4347s\n",
      "Epoch: 0107 loss_train: 0.0320 acc_train: 1.0000 loss_val: 0.7702 acc_val: 0.7833 time: 0.4302s\n",
      "Epoch: 0108 loss_train: 0.0304 acc_train: 1.0000 loss_val: 0.7457 acc_val: 0.7933 time: 0.4313s\n",
      "Epoch: 0109 loss_train: 0.0283 acc_train: 1.0000 loss_val: 0.7416 acc_val: 0.7867 time: 0.4268s\n",
      "Epoch: 0110 loss_train: 0.0295 acc_train: 1.0000 loss_val: 0.7660 acc_val: 0.7900 time: 0.4218s\n",
      "Epoch: 0111 loss_train: 0.0295 acc_train: 1.0000 loss_val: 0.7462 acc_val: 0.7900 time: 0.4327s\n",
      "Epoch: 0112 loss_train: 0.0280 acc_train: 1.0000 loss_val: 0.7431 acc_val: 0.7867 time: 0.4325s\n",
      "Epoch: 0113 loss_train: 0.0287 acc_train: 1.0000 loss_val: 0.7600 acc_val: 0.7900 time: 0.4214s\n",
      "Epoch: 0114 loss_train: 0.0290 acc_train: 1.0000 loss_val: 0.7494 acc_val: 0.7900 time: 0.4324s\n",
      "Epoch: 0115 loss_train: 0.0279 acc_train: 1.0000 loss_val: 0.7458 acc_val: 0.7833 time: 0.4291s\n",
      "Epoch: 0116 loss_train: 0.0283 acc_train: 1.0000 loss_val: 0.7586 acc_val: 0.7900 time: 0.4350s\n",
      "Epoch: 0117 loss_train: 0.0288 acc_train: 1.0000 loss_val: 0.7473 acc_val: 0.7867 time: 0.4431s\n",
      "Epoch: 0118 loss_train: 0.0279 acc_train: 1.0000 loss_val: 0.7474 acc_val: 0.7833 time: 0.4431s\n",
      "Epoch: 0119 loss_train: 0.0280 acc_train: 1.0000 loss_val: 0.7625 acc_val: 0.7800 time: 0.4336s\n",
      "Epoch: 0120 loss_train: 0.0286 acc_train: 1.0000 loss_val: 0.7432 acc_val: 0.7867 time: 0.4258s\n",
      "Epoch: 0121 loss_train: 0.0282 acc_train: 1.0000 loss_val: 0.7574 acc_val: 0.7933 time: 0.4377s\n",
      "Epoch: 0122 loss_train: 0.0278 acc_train: 1.0000 loss_val: 0.7521 acc_val: 0.8000 time: 0.4752s\n",
      "Epoch: 0123 loss_train: 0.0280 acc_train: 1.0000 loss_val: 0.7506 acc_val: 0.7900 time: 0.4204s\n",
      "Epoch: 0124 loss_train: 0.0285 acc_train: 1.0000 loss_val: 0.7582 acc_val: 0.7900 time: 0.4150s\n",
      "Epoch: 0125 loss_train: 0.0290 acc_train: 1.0000 loss_val: 0.7706 acc_val: 0.7867 time: 0.4308s\n",
      "Epoch: 0126 loss_train: 0.0295 acc_train: 1.0000 loss_val: 0.7439 acc_val: 0.7933 time: 0.4236s\n",
      "Epoch: 0127 loss_train: 0.0307 acc_train: 1.0000 loss_val: 0.7896 acc_val: 0.7833 time: 0.4387s\n",
      "Epoch: 0128 loss_train: 0.0301 acc_train: 1.0000 loss_val: 0.7460 acc_val: 0.7867 time: 0.4534s\n",
      "Epoch: 0129 loss_train: 0.0281 acc_train: 1.0000 loss_val: 0.7566 acc_val: 0.7967 time: 0.4800s\n",
      "Epoch: 0130 loss_train: 0.0276 acc_train: 1.0000 loss_val: 0.7743 acc_val: 0.7933 time: 0.5455s\n",
      "Epoch: 0131 loss_train: 0.0280 acc_train: 1.0000 loss_val: 0.7512 acc_val: 0.7967 time: 0.4458s\n",
      "Epoch: 0132 loss_train: 0.0274 acc_train: 1.0000 loss_val: 0.7600 acc_val: 0.7967 time: 0.4569s\n",
      "Epoch: 0133 loss_train: 0.0268 acc_train: 1.0000 loss_val: 0.7646 acc_val: 0.7900 time: 0.4126s\n",
      "Epoch: 0134 loss_train: 0.0276 acc_train: 1.0000 loss_val: 0.7557 acc_val: 0.7933 time: 0.4814s\n",
      "Epoch: 0135 loss_train: 0.0270 acc_train: 1.0000 loss_val: 0.7605 acc_val: 0.7900 time: 0.4710s\n",
      "Epoch: 0136 loss_train: 0.0262 acc_train: 1.0000 loss_val: 0.7621 acc_val: 0.7967 time: 0.4419s\n",
      "Epoch: 0137 loss_train: 0.0273 acc_train: 1.0000 loss_val: 0.7584 acc_val: 0.7967 time: 0.4373s\n",
      "Epoch: 0138 loss_train: 0.0271 acc_train: 1.0000 loss_val: 0.7586 acc_val: 0.7900 time: 0.4342s\n",
      "Epoch: 0139 loss_train: 0.0262 acc_train: 1.0000 loss_val: 0.7598 acc_val: 0.7967 time: 0.4424s\n",
      "Epoch: 0140 loss_train: 0.0266 acc_train: 1.0000 loss_val: 0.7541 acc_val: 0.8000 time: 0.4222s\n",
      "Epoch: 0141 loss_train: 0.0270 acc_train: 1.0000 loss_val: 0.7602 acc_val: 0.7900 time: 0.4333s\n",
      "Epoch: 0142 loss_train: 0.0266 acc_train: 1.0000 loss_val: 0.7620 acc_val: 0.7900 time: 0.4453s\n",
      "Epoch: 0143 loss_train: 0.0263 acc_train: 1.0000 loss_val: 0.7477 acc_val: 0.7900 time: 0.4499s\n",
      "Epoch: 0144 loss_train: 0.0267 acc_train: 1.0000 loss_val: 0.7705 acc_val: 0.7867 time: 0.4586s\n",
      "Epoch: 0145 loss_train: 0.0267 acc_train: 1.0000 loss_val: 0.7514 acc_val: 0.7900 time: 0.4720s\n",
      "Epoch: 0146 loss_train: 0.0261 acc_train: 1.0000 loss_val: 0.7549 acc_val: 0.7933 time: 0.4183s\n",
      "Epoch: 0147 loss_train: 0.0261 acc_train: 1.0000 loss_val: 0.7649 acc_val: 0.7833 time: 0.4377s\n",
      "Epoch: 0148 loss_train: 0.0264 acc_train: 1.0000 loss_val: 0.7544 acc_val: 0.7933 time: 0.4420s\n",
      "Epoch: 0149 loss_train: 0.0264 acc_train: 1.0000 loss_val: 0.7582 acc_val: 0.7933 time: 0.4528s\n",
      "Epoch: 0150 loss_train: 0.0262 acc_train: 1.0000 loss_val: 0.7630 acc_val: 0.7900 time: 0.4379s\n",
      "Epoch: 0151 loss_train: 0.0261 acc_train: 1.0000 loss_val: 0.7498 acc_val: 0.7867 time: 0.4497s\n",
      "Epoch: 0152 loss_train: 0.0262 acc_train: 1.0000 loss_val: 0.7832 acc_val: 0.7800 time: 0.4258s\n",
      "Epoch: 0153 loss_train: 0.0276 acc_train: 1.0000 loss_val: 0.7592 acc_val: 0.7833 time: 0.4248s\n",
      "Epoch: 0154 loss_train: 0.0320 acc_train: 1.0000 loss_val: 0.8997 acc_val: 0.7500 time: 0.6260s\n",
      "Epoch: 0155 loss_train: 0.0470 acc_train: 1.0000 loss_val: 0.9394 acc_val: 0.7367 time: 0.6935s\n",
      "Epoch: 0156 loss_train: 0.0981 acc_train: 0.9786 loss_val: 1.4594 acc_val: 0.6500 time: 0.5926s\n",
      "Epoch: 0157 loss_train: 0.2723 acc_train: 0.8857 loss_val: 1.8629 acc_val: 0.5567 time: 0.3995s\n",
      "Epoch: 0158 loss_train: 0.7853 acc_train: 0.6643 loss_val: 2.7092 acc_val: 0.4067 time: 0.4032s\n",
      "Epoch: 0159 loss_train: 1.2322 acc_train: 0.5000 loss_val: 3.2998 acc_val: 0.3000 time: 0.4218s\n",
      "Epoch: 0160 loss_train: 1.7792 acc_train: 0.4071 loss_val: 1.3737 acc_val: 0.6400 time: 0.4108s\n",
      "Epoch: 0161 loss_train: 0.5069 acc_train: 0.8071 loss_val: 1.4513 acc_val: 0.5633 time: 0.4051s\n",
      "Epoch: 0162 loss_train: 0.5779 acc_train: 0.7857 loss_val: 1.0326 acc_val: 0.7267 time: 0.4115s\n",
      "Epoch: 0163 loss_train: 0.3823 acc_train: 0.8929 loss_val: 1.0417 acc_val: 0.6733 time: 0.4045s\n",
      "Epoch: 0164 loss_train: 0.3761 acc_train: 0.9000 loss_val: 0.9242 acc_val: 0.7300 time: 0.4111s\n",
      "Epoch: 0165 loss_train: 0.2943 acc_train: 0.9357 loss_val: 0.7922 acc_val: 0.7533 time: 0.4017s\n",
      "Epoch: 0166 loss_train: 0.2223 acc_train: 0.9571 loss_val: 0.7572 acc_val: 0.7600 time: 0.5970s\n",
      "Epoch: 0167 loss_train: 0.2054 acc_train: 0.9429 loss_val: 0.7564 acc_val: 0.7567 time: 0.4293s\n",
      "Epoch: 0168 loss_train: 0.1860 acc_train: 0.9500 loss_val: 0.6923 acc_val: 0.8100 time: 0.4066s\n",
      "Epoch: 0169 loss_train: 0.1201 acc_train: 0.9714 loss_val: 0.6718 acc_val: 0.8233 time: 0.4479s\n",
      "Epoch: 0170 loss_train: 0.0798 acc_train: 0.9929 loss_val: 0.7191 acc_val: 0.8167 time: 0.4155s\n",
      "Epoch: 0171 loss_train: 0.0657 acc_train: 0.9929 loss_val: 0.7896 acc_val: 0.7933 time: 0.4078s\n",
      "Epoch: 0172 loss_train: 0.0571 acc_train: 0.9929 loss_val: 0.8471 acc_val: 0.7900 time: 0.4023s\n",
      "Epoch: 0173 loss_train: 0.0463 acc_train: 0.9929 loss_val: 0.8760 acc_val: 0.7833 time: 0.4132s\n",
      "Epoch: 0174 loss_train: 0.0324 acc_train: 1.0000 loss_val: 0.8766 acc_val: 0.7800 time: 0.3978s\n",
      "Epoch: 0175 loss_train: 0.0217 acc_train: 1.0000 loss_val: 0.8601 acc_val: 0.8033 time: 0.4430s\n",
      "Epoch: 0176 loss_train: 0.0160 acc_train: 1.0000 loss_val: 0.8454 acc_val: 0.8100 time: 0.4162s\n",
      "Epoch: 0177 loss_train: 0.0132 acc_train: 1.0000 loss_val: 0.8478 acc_val: 0.8100 time: 0.4465s\n",
      "Epoch: 0178 loss_train: 0.0125 acc_train: 1.0000 loss_val: 0.8633 acc_val: 0.8100 time: 0.4412s\n",
      "Epoch: 0179 loss_train: 0.0120 acc_train: 1.0000 loss_val: 0.8817 acc_val: 0.8100 time: 0.4070s\n",
      "Epoch: 0180 loss_train: 0.0105 acc_train: 1.0000 loss_val: 0.9006 acc_val: 0.8067 time: 0.4138s\n",
      "Epoch: 0181 loss_train: 0.0091 acc_train: 1.0000 loss_val: 0.9184 acc_val: 0.8033 time: 0.4212s\n",
      "Epoch: 0182 loss_train: 0.0085 acc_train: 1.0000 loss_val: 0.9305 acc_val: 0.8033 time: 0.4366s\n",
      "Epoch: 0183 loss_train: 0.0085 acc_train: 1.0000 loss_val: 0.9337 acc_val: 0.8067 time: 0.4363s\n",
      "Epoch: 0184 loss_train: 0.0086 acc_train: 1.0000 loss_val: 0.9294 acc_val: 0.8100 time: 0.4122s\n",
      "Epoch: 0185 loss_train: 0.0087 acc_train: 1.0000 loss_val: 0.9198 acc_val: 0.8100 time: 0.4342s\n",
      "Epoch: 0186 loss_train: 0.0092 acc_train: 1.0000 loss_val: 0.9054 acc_val: 0.8033 time: 0.4511s\n",
      "Epoch: 0187 loss_train: 0.0098 acc_train: 1.0000 loss_val: 0.8857 acc_val: 0.8067 time: 0.4072s\n",
      "Epoch: 0188 loss_train: 0.0103 acc_train: 1.0000 loss_val: 0.8636 acc_val: 0.8067 time: 0.4166s\n",
      "Epoch: 0189 loss_train: 0.0107 acc_train: 1.0000 loss_val: 0.8446 acc_val: 0.8133 time: 0.4110s\n",
      "Epoch: 0190 loss_train: 0.0113 acc_train: 1.0000 loss_val: 0.8321 acc_val: 0.8033 time: 0.4068s\n",
      "Epoch: 0191 loss_train: 0.0123 acc_train: 1.0000 loss_val: 0.8226 acc_val: 0.8067 time: 0.4215s\n",
      "Epoch: 0192 loss_train: 0.0130 acc_train: 1.0000 loss_val: 0.8192 acc_val: 0.8100 time: 0.3906s\n",
      "Epoch: 0193 loss_train: 0.0137 acc_train: 1.0000 loss_val: 0.8242 acc_val: 0.8167 time: 0.4054s\n",
      "Epoch: 0194 loss_train: 0.0146 acc_train: 1.0000 loss_val: 0.8275 acc_val: 0.8100 time: 0.3960s\n",
      "Epoch: 0195 loss_train: 0.0153 acc_train: 1.0000 loss_val: 0.8244 acc_val: 0.8067 time: 0.4033s\n",
      "Epoch: 0196 loss_train: 0.0162 acc_train: 1.0000 loss_val: 0.8139 acc_val: 0.8033 time: 0.3993s\n",
      "Epoch: 0197 loss_train: 0.0166 acc_train: 1.0000 loss_val: 0.7973 acc_val: 0.8067 time: 0.4101s\n",
      "Epoch: 0198 loss_train: 0.0171 acc_train: 1.0000 loss_val: 0.7815 acc_val: 0.8067 time: 0.4307s\n",
      "Epoch: 0199 loss_train: 0.0178 acc_train: 1.0000 loss_val: 0.7806 acc_val: 0.8067 time: 0.4449s\n",
      "Epoch: 0200 loss_train: 0.0184 acc_train: 1.0000 loss_val: 0.7870 acc_val: 0.8033 time: 0.4072s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 86.3186s\n",
      "Test set results: loss= 0.7559 accuracy= 0.7880\n",
      "inference time:  0.1291351318359375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([tensor(1.9467, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.8288, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.9938, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.7844, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.8181, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.7826, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.7075, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.5878, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.4491, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.3233, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.1683, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.0475, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9025, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8180, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7659, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6561, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.5746, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.5410, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.4596, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.4081, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.3659, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.3071, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.2579, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.2174, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.1758, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.1318, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.1043, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0838, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0730, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0601, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0524, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0530, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0558, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0555, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0513, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0523, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0517, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0588, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0734, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0918, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.1359, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.2017, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.3242, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.4434, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0766, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6047, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0443, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.3690, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.2734, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0689, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0528, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0673, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.1032, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.1371, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.1012, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0566, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0355, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0315, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0378, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0408, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0368, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0312, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0256, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0204, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0173, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0178, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0187, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0185, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0188, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0191, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0191, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0201, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0218, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0231, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0246, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0255, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0267, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0285, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0299, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0308, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0322, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0332, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0342, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0354, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0361, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0366, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0374, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0376, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0381, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0383, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0383, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0376, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0369, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0367, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0363, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0352, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0345, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0340, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0333, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0322, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0317, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0312, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0308, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0302, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0302, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0313, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0320, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0304, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0283, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0295, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0295, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0280, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0287, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0290, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0279, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0283, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0288, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0279, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0280, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0286, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0282, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0278, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0280, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0285, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0290, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0295, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0307, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0301, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0281, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0276, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0280, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0274, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0268, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0276, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0270, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0262, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0273, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0271, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0262, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0266, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0270, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0266, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0263, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0267, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0267, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0261, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0261, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0264, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0264, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0262, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0261, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0262, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0276, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0320, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0470, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0981, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.2723, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7853, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.2322, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.7792, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.5069, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.5779, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.3823, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.3761, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.2943, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.2223, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.2054, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.1860, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.1201, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0798, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0657, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0571, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0463, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0324, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0217, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0160, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0132, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0125, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0120, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0105, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0091, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0085, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0085, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0086, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0087, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0092, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0098, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0103, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0107, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0113, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0123, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0130, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0137, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0146, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0153, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0162, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0166, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0171, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0178, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.0184, grad_fn=<NllLossBackward0>)],\n",
       " [tensor(0.1500, dtype=torch.float64),\n",
       "  tensor(0.2929, dtype=torch.float64),\n",
       "  tensor(0.2929, dtype=torch.float64),\n",
       "  tensor(0.2929, dtype=torch.float64),\n",
       "  tensor(0.2000, dtype=torch.float64),\n",
       "  tensor(0.2000, dtype=torch.float64),\n",
       "  tensor(0.2000, dtype=torch.float64),\n",
       "  tensor(0.2000, dtype=torch.float64),\n",
       "  tensor(0.3786, dtype=torch.float64),\n",
       "  tensor(0.3000, dtype=torch.float64),\n",
       "  tensor(0.5929, dtype=torch.float64),\n",
       "  tensor(0.6714, dtype=torch.float64),\n",
       "  tensor(0.6214, dtype=torch.float64),\n",
       "  tensor(0.6714, dtype=torch.float64),\n",
       "  tensor(0.7214, dtype=torch.float64),\n",
       "  tensor(0.7429, dtype=torch.float64),\n",
       "  tensor(0.7429, dtype=torch.float64),\n",
       "  tensor(0.8286, dtype=torch.float64),\n",
       "  tensor(0.8929, dtype=torch.float64),\n",
       "  tensor(0.8643, dtype=torch.float64),\n",
       "  tensor(0.8643, dtype=torch.float64),\n",
       "  tensor(0.9000, dtype=torch.float64),\n",
       "  tensor(0.9429, dtype=torch.float64),\n",
       "  tensor(0.9857, dtype=torch.float64),\n",
       "  tensor(0.9786, dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(0.9857, dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(0.9571, dtype=torch.float64),\n",
       "  tensor(0.9500, dtype=torch.float64),\n",
       "  tensor(0.9000, dtype=torch.float64),\n",
       "  tensor(0.7857, dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(0.7429, dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(0.8286, dtype=torch.float64),\n",
       "  tensor(0.9071, dtype=torch.float64),\n",
       "  tensor(0.9786, dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(0.9786, dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(0.9786, dtype=torch.float64),\n",
       "  tensor(0.8857, dtype=torch.float64),\n",
       "  tensor(0.6643, dtype=torch.float64),\n",
       "  tensor(0.5000, dtype=torch.float64),\n",
       "  tensor(0.4071, dtype=torch.float64),\n",
       "  tensor(0.8071, dtype=torch.float64),\n",
       "  tensor(0.7857, dtype=torch.float64),\n",
       "  tensor(0.8929, dtype=torch.float64),\n",
       "  tensor(0.9000, dtype=torch.float64),\n",
       "  tensor(0.9357, dtype=torch.float64),\n",
       "  tensor(0.9571, dtype=torch.float64),\n",
       "  tensor(0.9429, dtype=torch.float64),\n",
       "  tensor(0.9500, dtype=torch.float64),\n",
       "  tensor(0.9714, dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(0.9929, dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64),\n",
       "  tensor(1., dtype=torch.float64)],\n",
       " [tensor(1.8242, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.9568, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.7933, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.8393, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.8175, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.7674, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.6644, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.5229, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.3986, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.3006, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.2416, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.1486, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.1113, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.1090, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.0544, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.0225, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.0511, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.0392, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.0338, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9550, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9060, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9537, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9648, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8970, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8475, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8300, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8085, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7704, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8328, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8029, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7867, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8305, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7501, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8290, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7837, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7824, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7954, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7615, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9308, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8980, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.2073, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.2419, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.6788, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.0729, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.9556, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8607, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.5186, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.4108, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8663, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7618, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8655, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.0597, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.1898, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.1039, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9256, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7912, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7397, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7636, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8063, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8268, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8258, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8148, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8058, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8121, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8372, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8635, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8757, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8711, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8503, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8259, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8123, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8120, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8120, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8044, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7878, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7763, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7794, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7835, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7695, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7549, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7526, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7454, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7313, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7398, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7398, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7289, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7335, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7238, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7281, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7263, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7280, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7298, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7290, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7270, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7285, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7411, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7367, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7341, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7344, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7393, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7451, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7376, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7552, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7366, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7631, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7410, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7702, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7457, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7416, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7660, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7462, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7431, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7600, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7494, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7458, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7586, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7473, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7474, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7625, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7432, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7574, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7521, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7506, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7582, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7706, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7439, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7896, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7460, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7566, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7743, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7512, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7600, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7646, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7557, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7605, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7621, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7584, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7586, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7598, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7541, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7602, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7620, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7477, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7705, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7514, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7549, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7649, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7544, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7582, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7630, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7498, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7832, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7592, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8997, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9394, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.4594, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.8629, grad_fn=<NllLossBackward0>),\n",
       "  tensor(2.7092, grad_fn=<NllLossBackward0>),\n",
       "  tensor(3.2998, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.3737, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.4513, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.0326, grad_fn=<NllLossBackward0>),\n",
       "  tensor(1.0417, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9242, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7922, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7572, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7564, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6923, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.6718, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7191, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7896, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8471, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8760, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8766, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8601, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8454, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8478, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8633, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8817, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9006, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9184, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9305, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9337, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9294, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9198, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.9054, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8857, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8636, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8446, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8321, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8226, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8192, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8242, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8275, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8244, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.8139, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7973, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7815, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7806, grad_fn=<NllLossBackward0>),\n",
       "  tensor(0.7870, grad_fn=<NllLossBackward0>)],\n",
       " [tensor(0.3500, dtype=torch.float64),\n",
       "  tensor(0.3500, dtype=torch.float64),\n",
       "  tensor(0.3500, dtype=torch.float64),\n",
       "  tensor(0.1567, dtype=torch.float64),\n",
       "  tensor(0.1567, dtype=torch.float64),\n",
       "  tensor(0.1567, dtype=torch.float64),\n",
       "  tensor(0.1700, dtype=torch.float64),\n",
       "  tensor(0.3600, dtype=torch.float64),\n",
       "  tensor(0.3500, dtype=torch.float64),\n",
       "  tensor(0.5400, dtype=torch.float64),\n",
       "  tensor(0.5633, dtype=torch.float64),\n",
       "  tensor(0.5400, dtype=torch.float64),\n",
       "  tensor(0.5767, dtype=torch.float64),\n",
       "  tensor(0.6100, dtype=torch.float64),\n",
       "  tensor(0.6067, dtype=torch.float64),\n",
       "  tensor(0.6200, dtype=torch.float64),\n",
       "  tensor(0.6633, dtype=torch.float64),\n",
       "  tensor(0.7133, dtype=torch.float64),\n",
       "  tensor(0.7033, dtype=torch.float64),\n",
       "  tensor(0.7233, dtype=torch.float64),\n",
       "  tensor(0.7533, dtype=torch.float64),\n",
       "  tensor(0.7700, dtype=torch.float64),\n",
       "  tensor(0.7667, dtype=torch.float64),\n",
       "  tensor(0.7633, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.7800, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.7767, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.7733, dtype=torch.float64),\n",
       "  tensor(0.7800, dtype=torch.float64),\n",
       "  tensor(0.7600, dtype=torch.float64),\n",
       "  tensor(0.7667, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.7633, dtype=torch.float64),\n",
       "  tensor(0.7867, dtype=torch.float64),\n",
       "  tensor(0.7400, dtype=torch.float64),\n",
       "  tensor(0.7400, dtype=torch.float64),\n",
       "  tensor(0.7133, dtype=torch.float64),\n",
       "  tensor(0.6533, dtype=torch.float64),\n",
       "  tensor(0.6100, dtype=torch.float64),\n",
       "  tensor(0.7133, dtype=torch.float64),\n",
       "  tensor(0.4567, dtype=torch.float64),\n",
       "  tensor(0.7667, dtype=torch.float64),\n",
       "  tensor(0.6600, dtype=torch.float64),\n",
       "  tensor(0.7200, dtype=torch.float64),\n",
       "  tensor(0.7867, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7467, dtype=torch.float64),\n",
       "  tensor(0.6967, dtype=torch.float64),\n",
       "  tensor(0.6667, dtype=torch.float64),\n",
       "  tensor(0.6933, dtype=torch.float64),\n",
       "  tensor(0.7433, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.8133, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.7867, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.7867, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.7867, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.7800, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7867, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7867, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7867, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.7800, dtype=torch.float64),\n",
       "  tensor(0.7867, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7867, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.7867, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7967, dtype=torch.float64),\n",
       "  tensor(0.8000, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7867, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7867, dtype=torch.float64),\n",
       "  tensor(0.7800, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.7500, dtype=torch.float64),\n",
       "  tensor(0.7367, dtype=torch.float64),\n",
       "  tensor(0.6500, dtype=torch.float64),\n",
       "  tensor(0.5567, dtype=torch.float64),\n",
       "  tensor(0.4067, dtype=torch.float64),\n",
       "  tensor(0.3000, dtype=torch.float64),\n",
       "  tensor(0.6400, dtype=torch.float64),\n",
       "  tensor(0.5633, dtype=torch.float64),\n",
       "  tensor(0.7267, dtype=torch.float64),\n",
       "  tensor(0.6733, dtype=torch.float64),\n",
       "  tensor(0.7300, dtype=torch.float64),\n",
       "  tensor(0.7533, dtype=torch.float64),\n",
       "  tensor(0.7600, dtype=torch.float64),\n",
       "  tensor(0.7567, dtype=torch.float64),\n",
       "  tensor(0.8100, dtype=torch.float64),\n",
       "  tensor(0.8233, dtype=torch.float64),\n",
       "  tensor(0.8167, dtype=torch.float64),\n",
       "  tensor(0.7933, dtype=torch.float64),\n",
       "  tensor(0.7900, dtype=torch.float64),\n",
       "  tensor(0.7833, dtype=torch.float64),\n",
       "  tensor(0.7800, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8100, dtype=torch.float64),\n",
       "  tensor(0.8100, dtype=torch.float64),\n",
       "  tensor(0.8100, dtype=torch.float64),\n",
       "  tensor(0.8100, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8100, dtype=torch.float64),\n",
       "  tensor(0.8100, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8133, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8100, dtype=torch.float64),\n",
       "  tensor(0.8167, dtype=torch.float64),\n",
       "  tensor(0.8100, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8067, dtype=torch.float64),\n",
       "  tensor(0.8033, dtype=torch.float64)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = ite_GCN(nfeat=features.shape[1],\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=0,\n",
    "            train_nite= 2,\n",
    "            eval_nite= 0,\n",
    "            allow_grad=True,\n",
    "            smooth_fac=smooth_fac)\n",
    "run_experiment(num_epochs, model2, lr, weight_decay, features, adj, idx_train, idx_val, idx_test, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  2\n",
      "Test set results: loss= 0.7559 accuracy= 0.7880\n",
      "inference time:  0.14795398712158203\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  3\n",
      "Test set results: loss= 17.2465 accuracy= 0.2160\n",
      "inference time:  0.22200822830200195\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  4\n",
      "Test set results: loss= 75.8431 accuracy= 0.4480\n",
      "inference time:  0.2838730812072754\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  5\n",
      "Test set results: loss= 800.0170 accuracy= 0.1070\n",
      "inference time:  0.3578760623931885\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  6\n",
      "Test set results: loss= 3249.5498 accuracy= 0.3010\n",
      "inference time:  0.4234731197357178\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  7\n",
      "Test set results: loss= 28781.5996 accuracy= 0.1100\n",
      "inference time:  0.5106401443481445\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  8\n",
      "Test set results: loss= 117155.7500 accuracy= 0.2800\n",
      "inference time:  0.6508870124816895\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  9\n",
      "Test set results: loss= 965784.3125 accuracy= 0.1080\n",
      "inference time:  0.5188648700714111\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  10\n",
      "Test set results: loss= 3718962.5000 accuracy= 0.2450\n",
      "inference time:  0.5706291198730469\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  11\n",
      "Test set results: loss= 26870170.0000 accuracy= 0.1070\n",
      "inference time:  0.6141819953918457\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  12\n",
      "Test set results: loss= 97503656.0000 accuracy= 0.2330\n",
      "inference time:  0.7489128112792969\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  13\n",
      "Test set results: loss= 638938880.0000 accuracy= 0.0750\n",
      "inference time:  0.7951960563659668\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  14\n",
      "Test set results: loss= 2225272320.0000 accuracy= 0.1880\n",
      "inference time:  0.8281900882720947\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  15\n",
      "Test set results: loss= 13089513472.0000 accuracy= 0.0450\n",
      "inference time:  0.85744309425354\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  16\n",
      "Test set results: loss= 41125421056.0000 accuracy= 0.1930\n",
      "inference time:  0.9573960304260254\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  17\n",
      "Test set results: loss= 196688248832.0000 accuracy= 0.0270\n",
      "inference time:  1.1460700035095215\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  18\n",
      "Test set results: loss= 374420176896.0000 accuracy= 0.2580\n",
      "inference time:  1.0091259479522705\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  19\n",
      "Test set results: loss= 1642948460544.0000 accuracy= 0.3060\n",
      "inference time:  0.986962080001831\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  20\n",
      "Test set results: loss= 3344269574144.0000 accuracy= 0.4940\n",
      "inference time:  1.1967089176177979\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  21\n",
      "Test set results: loss= 42751043305472.0000 accuracy= 0.2370\n",
      "inference time:  1.3096959590911865\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  22\n",
      "Test set results: loss= 230697507749888.0000 accuracy= 0.3240\n",
      "inference time:  1.311432123184204\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  23\n",
      "Test set results: loss= 1682921194782720.0000 accuracy= 0.0780\n",
      "inference time:  1.274811029434204\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  24\n",
      "Test set results: loss= 8122719459606528.0000 accuracy= 0.2500\n",
      "inference time:  1.4730169773101807\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  25\n",
      "Test set results: loss= 64099165667328000.0000 accuracy= 0.0970\n",
      "inference time:  1.3506290912628174\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  26\n",
      "Test set results: loss= 303410096245833728.0000 accuracy= 0.2450\n",
      "inference time:  1.5170021057128906\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  27\n",
      "Test set results: loss= 2149998918287491072.0000 accuracy= 0.1310\n",
      "inference time:  1.4517521858215332\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  28\n",
      "Test set results: loss= 8804377842323292160.0000 accuracy= 0.2520\n",
      "inference time:  1.8158142566680908\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  29\n",
      "Test set results: loss= 57787877045953363968.0000 accuracy= 0.1520\n",
      "inference time:  1.8785440921783447\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  30\n",
      "Test set results: loss= 219725735191686152192.0000 accuracy= 0.2660\n",
      "inference time:  1.784684181213379\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  31\n",
      "Test set results: loss= 1362110892548439408640.0000 accuracy= 0.1470\n",
      "inference time:  1.7142610549926758\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  32\n",
      "Test set results: loss= 4909340739749325832192.0000 accuracy= 0.1930\n",
      "inference time:  1.7486510276794434\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  33\n",
      "Test set results: loss= 27042796207669008924672.0000 accuracy= 0.0580\n",
      "inference time:  1.9169659614562988\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  34\n",
      "Test set results: loss= 86494999536171648811008.0000 accuracy= 0.2010\n",
      "inference time:  2.021972179412842\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  35\n",
      "Test set results: loss= 373449001510291065798656.0000 accuracy= 0.0370\n",
      "inference time:  2.2839128971099854\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  36\n",
      "Test set results: loss= 788617044125533192847360.0000 accuracy= 0.3030\n",
      "inference time:  2.228412389755249\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  37\n",
      "Test set results: loss= 3470363480617638112002048.0000 accuracy= 0.3570\n",
      "inference time:  2.2128870487213135\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  38\n",
      "Test set results: loss= 14701377108901803811930112.0000 accuracy= 0.3800\n",
      "inference time:  2.60479998588562\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  39\n",
      "Test set results: loss= 108234665985756381375889408.0000 accuracy= 0.2560\n",
      "inference time:  2.680731773376465\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  40\n",
      "Test set results: loss= 563364670815734128925736960.0000 accuracy= 0.2620\n",
      "inference time:  2.2507522106170654\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  41\n",
      "Test set results: loss= 3986469783667387122696847360.0000 accuracy= 0.1050\n",
      "inference time:  2.560859203338623\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  42\n",
      "Test set results: loss= 22424421696429550997367422976.0000 accuracy= 0.1850\n",
      "inference time:  2.4548590183258057\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  43\n",
      "Test set results: loss= 161340463134276482304900595712.0000 accuracy= 0.0790\n",
      "inference time:  2.4405858516693115\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  44\n",
      "Test set results: loss= 787544902665665807000293867520.0000 accuracy= 0.2250\n",
      "inference time:  2.7106659412384033\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  45\n",
      "Test set results: loss= 4952329863434014493595077181440.0000 accuracy= 0.1550\n",
      "inference time:  2.9562010765075684\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  46\n",
      "Test set results: loss= 21567671835220045743261074063360.0000 accuracy= 0.2830\n",
      "inference time:  2.674359083175659\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  47\n",
      "Test set results: loss= 129522232961101632615839202017280.0000 accuracy= 0.2240\n",
      "inference time:  2.7927350997924805\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  48\n",
      "Test set results: loss= 525846792585598187301080894799872.0000 accuracy= 0.2830\n",
      "inference time:  2.75791597366333\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  49\n",
      "Test set results: loss= 2980272248392382494559453392666624.0000 accuracy= 0.1970\n",
      "inference time:  2.8506109714508057\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  50\n",
      "Test set results: loss= 11105652937932092849640660847820800.0000 accuracy= 0.2040\n",
      "inference time:  2.878675937652588\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  51\n",
      "Test set results: loss= 56729429244198793731276000179781632.0000 accuracy= 0.0590\n",
      "inference time:  2.949317216873169\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  52\n",
      "Test set results: loss= 189353406933191424504467796248231936.0000 accuracy= 0.1420\n",
      "inference time:  3.243298053741455\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  53\n",
      "Test set results: loss= inf accuracy= 0.0510\n",
      "inference time:  3.4192709922790527\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  54\n",
      "Test set results: loss= inf accuracy= 0.3170\n",
      "inference time:  4.035023212432861\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  55\n",
      "Test set results: loss= inf accuracy= 0.2560\n",
      "inference time:  3.451939821243286\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  56\n",
      "Test set results: loss= inf accuracy= 0.3670\n",
      "inference time:  3.4441840648651123\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  57\n",
      "Test set results: loss= nan accuracy= 0.1090\n",
      "inference time:  3.215801239013672\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  58\n",
      "Test set results: loss= nan accuracy= 0.1180\n",
      "inference time:  3.708193778991699\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  59\n",
      "Test set results: loss= nan accuracy= 0.1180\n",
      "inference time:  3.5708467960357666\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  60\n",
      "Test set results: loss= nan accuracy= 0.1180\n",
      "inference time:  3.71754789352417\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  61\n",
      "Test set results: loss= nan accuracy= 0.1180\n",
      "inference time:  3.7334961891174316\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  62\n",
      "Test set results: loss= nan accuracy= 0.1180\n",
      "inference time:  3.6180260181427\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  63\n",
      "Test set results: loss= nan accuracy= 0.1180\n",
      "inference time:  3.639159917831421\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  64\n",
      "Test set results: loss= nan accuracy= 0.1180\n",
      "inference time:  3.236729145050049\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  65\n",
      "Test set results: loss= nan accuracy= 0.1180\n",
      "inference time:  3.4324288368225098\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  66\n",
      "Test set results: loss= nan accuracy= 0.1180\n",
      "inference time:  3.49904203414917\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  67\n",
      "Test set results: loss= nan accuracy= 0.1180\n",
      "inference time:  3.549757957458496\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  68\n",
      "Test set results: loss= nan accuracy= 0.1180\n",
      "inference time:  3.660885810852051\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  69\n",
      "Test set results: loss= nan accuracy= 0.1180\n",
      "inference time:  3.848414182662964\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  70\n",
      "Test set results: loss= nan accuracy= 0.1180\n",
      "inference time:  4.086971044540405\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  71\n",
      "Test set results: loss= nan accuracy= 0.1180\n",
      "inference time:  4.274924993515015\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  72\n",
      "Test set results: loss= nan accuracy= 0.1180\n",
      "inference time:  4.162032842636108\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  73\n",
      "Test set results: loss= nan accuracy= 0.1180\n",
      "inference time:  4.319934844970703\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  74\n",
      "Test set results: loss= nan accuracy= 0.1180\n",
      "inference time:  3.78802490234375\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n",
      "i:  75\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(model2\u001b[39m.\u001b[39mstate_dict()\u001b[39m.\u001b[39mcopy())\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mi: \u001b[39m\u001b[39m\"\u001b[39m, i)\n\u001b[0;32m---> 11\u001b[0m test(model, features, adj, idx_test, labels)\n",
      "File \u001b[0;32m~/Desktop/GitHub Repos/IterativeMethods/GCNexperiments/pygcn-master/pygcn/utils.py:116\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, features, adj, idx_test, labels)\u001b[0m\n\u001b[1;32m    114\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m    115\u001b[0m t \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 116\u001b[0m output \u001b[39m=\u001b[39m model(features, adj)\n\u001b[1;32m    117\u001b[0m loss_test \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mnll_loss(output[idx_test], labels[idx_test])\n\u001b[1;32m    118\u001b[0m acc_test \u001b[39m=\u001b[39m accuracy(output[idx_test], labels[idx_test])\n",
      "File \u001b[0;32m~/Desktop/GitHub Repos/IterativeMethods/iterENV/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[29], line 72\u001b[0m, in \u001b[0;36mite_GCN.forward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[39m# for name, param in self.named_parameters():\u001b[39;00m\n\u001b[1;32m     69\u001b[0m             \u001b[39m#         print(name, param.grad)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_nite):\n\u001b[0;32m---> 72\u001b[0m         x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_one_layer(x, adj)\n\u001b[1;32m     74\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear_no_bias(x)\n\u001b[1;32m     75\u001b[0m \u001b[39m# self.gc.weight.requires_grad_()\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[39m# print(\"???\")\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[39m# for name, param in self.named_parameters():\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[39m#     if param.grad is not None:\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39m#         print(name, param.grad.abs().sum())\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[29], line 48\u001b[0m, in \u001b[0;36mite_GCN.run_one_layer\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m     46\u001b[0m x_old \u001b[39m=\u001b[39m x\n\u001b[1;32m     47\u001b[0m x_new \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgc(x, adj)\n\u001b[0;32m---> 48\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msmooth_fac \u001b[39m*\u001b[39;49m x_old \u001b[39m+\u001b[39;49m (\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msmooth_fac) \u001b[39m*\u001b[39;49m x_new)\n\u001b[1;32m     49\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[1;32m     50\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Desktop/GitHub Repos/IterativeMethods/iterENV/lib/python3.9/site-packages/torch/nn/functional.py:1457\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu_(\u001b[39minput\u001b[39m)\n\u001b[1;32m   1456\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m   1458\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(2,100):\n",
    "    model = ite_GCN(nfeat=features.shape[1],\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=0,\n",
    "            train_nite= 3,\n",
    "            eval_nite= i,\n",
    "            allow_grad=True,\n",
    "            smooth_fac=smooth_fac)\n",
    "    model.load_state_dict(model2.state_dict().copy())\n",
    "    print(\"i: \", i)\n",
    "    test(model, features, adj, idx_test, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iterENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
