{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils import load_data, accuracy, run_experiment\n",
    "from models import GCN_3, ite_GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n"
     ]
    }
   ],
   "source": [
    "adj, features, labels, idx_train, idx_val, idx_test = load_data(path=\"../data/cora/\", dataset=\"cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 16\n",
    "dropout = 0.5\n",
    "lr = 0.01\n",
    "weight_decay = 5e-4\n",
    "num_epochs = 200\n",
    "smooth_fac = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intialize a 3-layer GCN\n"
     ]
    }
   ],
   "source": [
    "model1 = GCN_3(nfeat=features.shape[1],\n",
    "            nhid=hidden,\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=dropout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unspecified or invalid number of iterations for inference\n",
      "Initialize a 1-layer GCN with  3 iterations\n",
      "Gradient flows to all iterations:  True\n"
     ]
    }
   ],
   "source": [
    "model2 = ite_GCN(nfeat=features.shape[1],\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=dropout,\n",
    "            train_nite= 3,\n",
    "            eval_nite= 0,\n",
    "            allow_grad=True,\n",
    "            smooth_fac=smooth_fac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runrunrun!\n",
      "Epoch: 0001 loss_train: 2.0306 acc_train: 0.2000 time: 0.0235s\n",
      "Epoch: 0002 loss_train: 1.9886 acc_train: 0.2000 time: 0.0151s\n",
      "Epoch: 0003 loss_train: 1.9655 acc_train: 0.2000 time: 0.0185s\n",
      "Epoch: 0004 loss_train: 1.9333 acc_train: 0.2000 time: 0.0090s\n",
      "Epoch: 0005 loss_train: 1.9009 acc_train: 0.2000 time: 0.0100s\n",
      "Epoch: 0006 loss_train: 1.8844 acc_train: 0.2000 time: 0.0100s\n",
      "Epoch: 0007 loss_train: 1.8505 acc_train: 0.2714 time: 0.0142s\n",
      "Epoch: 0008 loss_train: 1.8535 acc_train: 0.3357 time: 0.0120s\n",
      "Epoch: 0009 loss_train: 1.8327 acc_train: 0.3143 time: 0.0108s\n",
      "Epoch: 0010 loss_train: 1.8131 acc_train: 0.2929 time: 0.0087s\n",
      "Epoch: 0011 loss_train: 1.7981 acc_train: 0.3000 time: 0.0117s\n",
      "Epoch: 0012 loss_train: 1.8260 acc_train: 0.2929 time: 0.0082s\n",
      "Epoch: 0013 loss_train: 1.7958 acc_train: 0.2929 time: 0.0077s\n",
      "Epoch: 0014 loss_train: 1.7843 acc_train: 0.2929 time: 0.0093s\n",
      "Epoch: 0015 loss_train: 1.8240 acc_train: 0.2929 time: 0.0083s\n",
      "Epoch: 0016 loss_train: 1.7817 acc_train: 0.2929 time: 0.0128s\n",
      "Epoch: 0017 loss_train: 1.7795 acc_train: 0.2929 time: 0.0093s\n",
      "Epoch: 0018 loss_train: 1.7663 acc_train: 0.3000 time: 0.0082s\n",
      "Epoch: 0019 loss_train: 1.7670 acc_train: 0.3071 time: 0.0124s\n",
      "Epoch: 0020 loss_train: 1.7530 acc_train: 0.3000 time: 0.0124s\n",
      "Epoch: 0021 loss_train: 1.7457 acc_train: 0.3214 time: 0.0110s\n",
      "Epoch: 0022 loss_train: 1.7291 acc_train: 0.3429 time: 0.0081s\n",
      "Epoch: 0023 loss_train: 1.7129 acc_train: 0.3357 time: 0.0097s\n",
      "Epoch: 0024 loss_train: 1.7189 acc_train: 0.4143 time: 0.0092s\n",
      "Epoch: 0025 loss_train: 1.7044 acc_train: 0.3929 time: 0.0095s\n",
      "Epoch: 0026 loss_train: 1.6812 acc_train: 0.3857 time: 0.0098s\n",
      "Epoch: 0027 loss_train: 1.6753 acc_train: 0.4286 time: 0.0110s\n",
      "Epoch: 0028 loss_train: 1.6559 acc_train: 0.4071 time: 0.0111s\n",
      "Epoch: 0029 loss_train: 1.6036 acc_train: 0.4357 time: 0.0134s\n",
      "Epoch: 0030 loss_train: 1.6422 acc_train: 0.4143 time: 0.0087s\n",
      "Epoch: 0031 loss_train: 1.6212 acc_train: 0.4143 time: 0.0103s\n",
      "Epoch: 0032 loss_train: 1.5684 acc_train: 0.4286 time: 0.0081s\n",
      "Epoch: 0033 loss_train: 1.5651 acc_train: 0.4571 time: 0.0083s\n",
      "Epoch: 0034 loss_train: 1.5258 acc_train: 0.4286 time: 0.0171s\n",
      "Epoch: 0035 loss_train: 1.5057 acc_train: 0.4571 time: 0.0111s\n",
      "Epoch: 0036 loss_train: 1.4869 acc_train: 0.4571 time: 0.0088s\n",
      "Epoch: 0037 loss_train: 1.4281 acc_train: 0.4714 time: 0.0079s\n",
      "Epoch: 0038 loss_train: 1.4068 acc_train: 0.4714 time: 0.0097s\n",
      "Epoch: 0039 loss_train: 1.3729 acc_train: 0.4929 time: 0.0114s\n",
      "Epoch: 0040 loss_train: 1.3907 acc_train: 0.4714 time: 0.0089s\n",
      "Epoch: 0041 loss_train: 1.3329 acc_train: 0.4643 time: 0.0085s\n",
      "Epoch: 0042 loss_train: 1.3079 acc_train: 0.4786 time: 0.0114s\n",
      "Epoch: 0043 loss_train: 1.2630 acc_train: 0.5000 time: 0.0111s\n",
      "Epoch: 0044 loss_train: 1.2098 acc_train: 0.5143 time: 0.0120s\n",
      "Epoch: 0045 loss_train: 1.1994 acc_train: 0.5857 time: 0.0088s\n",
      "Epoch: 0046 loss_train: 1.1530 acc_train: 0.5786 time: 0.0119s\n",
      "Epoch: 0047 loss_train: 1.1244 acc_train: 0.6500 time: 0.0605s\n",
      "Epoch: 0048 loss_train: 1.1215 acc_train: 0.7071 time: 0.0102s\n",
      "Epoch: 0049 loss_train: 1.0599 acc_train: 0.6714 time: 0.0086s\n",
      "Epoch: 0050 loss_train: 1.0447 acc_train: 0.7143 time: 0.0152s\n",
      "Epoch: 0051 loss_train: 1.0074 acc_train: 0.7429 time: 0.0340s\n",
      "Epoch: 0052 loss_train: 0.9810 acc_train: 0.7214 time: 0.1017s\n",
      "Epoch: 0053 loss_train: 0.9703 acc_train: 0.6929 time: 0.0160s\n",
      "Epoch: 0054 loss_train: 0.9236 acc_train: 0.7214 time: 0.0144s\n",
      "Epoch: 0055 loss_train: 0.8947 acc_train: 0.7286 time: 0.0118s\n",
      "Epoch: 0056 loss_train: 0.8805 acc_train: 0.7714 time: 0.0143s\n",
      "Epoch: 0057 loss_train: 0.8613 acc_train: 0.7214 time: 0.0094s\n",
      "Epoch: 0058 loss_train: 0.8509 acc_train: 0.7500 time: 0.0157s\n",
      "Epoch: 0059 loss_train: 0.7896 acc_train: 0.7643 time: 0.0111s\n",
      "Epoch: 0060 loss_train: 0.8034 acc_train: 0.8214 time: 0.0173s\n",
      "Epoch: 0061 loss_train: 0.7416 acc_train: 0.7643 time: 0.0111s\n",
      "Epoch: 0062 loss_train: 0.7371 acc_train: 0.7929 time: 0.0199s\n",
      "Epoch: 0063 loss_train: 0.6967 acc_train: 0.8000 time: 0.0147s\n",
      "Epoch: 0064 loss_train: 0.7043 acc_train: 0.8214 time: 0.0090s\n",
      "Epoch: 0065 loss_train: 0.7092 acc_train: 0.7786 time: 0.0108s\n",
      "Epoch: 0066 loss_train: 0.6432 acc_train: 0.8143 time: 0.0098s\n",
      "Epoch: 0067 loss_train: 0.6440 acc_train: 0.8071 time: 0.0121s\n",
      "Epoch: 0068 loss_train: 0.6181 acc_train: 0.8143 time: 0.0120s\n",
      "Epoch: 0069 loss_train: 0.5784 acc_train: 0.8429 time: 0.0123s\n",
      "Epoch: 0070 loss_train: 0.6092 acc_train: 0.8143 time: 0.0097s\n",
      "Epoch: 0071 loss_train: 0.5729 acc_train: 0.8143 time: 0.0119s\n",
      "Epoch: 0072 loss_train: 0.6108 acc_train: 0.7786 time: 0.0122s\n",
      "Epoch: 0073 loss_train: 0.5686 acc_train: 0.8214 time: 0.0100s\n",
      "Epoch: 0074 loss_train: 0.5648 acc_train: 0.8643 time: 0.0116s\n",
      "Epoch: 0075 loss_train: 0.5729 acc_train: 0.8286 time: 0.0090s\n",
      "Epoch: 0076 loss_train: 0.5898 acc_train: 0.8286 time: 0.0117s\n",
      "Epoch: 0077 loss_train: 0.5089 acc_train: 0.8714 time: 0.0109s\n",
      "Epoch: 0078 loss_train: 0.4836 acc_train: 0.8786 time: 0.0101s\n",
      "Epoch: 0079 loss_train: 0.4870 acc_train: 0.8643 time: 0.0119s\n",
      "Epoch: 0080 loss_train: 0.4580 acc_train: 0.8643 time: 0.0096s\n",
      "Epoch: 0081 loss_train: 0.4595 acc_train: 0.8714 time: 0.0145s\n",
      "Epoch: 0082 loss_train: 0.4766 acc_train: 0.8643 time: 0.0085s\n",
      "Epoch: 0083 loss_train: 0.4419 acc_train: 0.8571 time: 0.0135s\n",
      "Epoch: 0084 loss_train: 0.4265 acc_train: 0.8929 time: 0.0235s\n",
      "Epoch: 0085 loss_train: 0.4102 acc_train: 0.8643 time: 0.0123s\n",
      "Epoch: 0086 loss_train: 0.4237 acc_train: 0.8929 time: 0.0236s\n",
      "Epoch: 0087 loss_train: 0.4144 acc_train: 0.8714 time: 0.0196s\n",
      "Epoch: 0088 loss_train: 0.4181 acc_train: 0.8643 time: 0.0114s\n",
      "Epoch: 0089 loss_train: 0.4075 acc_train: 0.9000 time: 0.0145s\n",
      "Epoch: 0090 loss_train: 0.4288 acc_train: 0.8714 time: 0.0214s\n",
      "Epoch: 0091 loss_train: 0.3936 acc_train: 0.8786 time: 0.0127s\n",
      "Epoch: 0092 loss_train: 0.3873 acc_train: 0.8857 time: 0.0153s\n",
      "Epoch: 0093 loss_train: 0.3746 acc_train: 0.9143 time: 0.0090s\n",
      "Epoch: 0094 loss_train: 0.3651 acc_train: 0.9000 time: 0.0132s\n",
      "Epoch: 0095 loss_train: 0.3398 acc_train: 0.9000 time: 0.0123s\n",
      "Epoch: 0096 loss_train: 0.3401 acc_train: 0.9000 time: 0.0101s\n",
      "Epoch: 0097 loss_train: 0.3455 acc_train: 0.8929 time: 0.0113s\n",
      "Epoch: 0098 loss_train: 0.3449 acc_train: 0.9071 time: 0.0103s\n",
      "Epoch: 0099 loss_train: 0.3356 acc_train: 0.8929 time: 0.0097s\n",
      "Epoch: 0100 loss_train: 0.3172 acc_train: 0.9286 time: 0.0114s\n",
      "Epoch: 0101 loss_train: 0.3271 acc_train: 0.9143 time: 0.0094s\n",
      "Epoch: 0102 loss_train: 0.3271 acc_train: 0.8786 time: 0.0126s\n",
      "Epoch: 0103 loss_train: 0.3055 acc_train: 0.9214 time: 0.0099s\n",
      "Epoch: 0104 loss_train: 0.3031 acc_train: 0.9000 time: 0.0111s\n",
      "Epoch: 0105 loss_train: 0.3031 acc_train: 0.9143 time: 0.0102s\n",
      "Epoch: 0106 loss_train: 0.2727 acc_train: 0.9143 time: 0.0125s\n",
      "Epoch: 0107 loss_train: 0.3009 acc_train: 0.9357 time: 0.0112s\n",
      "Epoch: 0108 loss_train: 0.3031 acc_train: 0.9429 time: 0.0121s\n",
      "Epoch: 0109 loss_train: 0.3404 acc_train: 0.9143 time: 0.0109s\n",
      "Epoch: 0110 loss_train: 0.2957 acc_train: 0.9214 time: 0.0083s\n",
      "Epoch: 0111 loss_train: 0.2751 acc_train: 0.9643 time: 0.0151s\n",
      "Epoch: 0112 loss_train: 0.2640 acc_train: 0.9357 time: 0.0120s\n",
      "Epoch: 0113 loss_train: 0.2596 acc_train: 0.9286 time: 0.0149s\n",
      "Epoch: 0114 loss_train: 0.2914 acc_train: 0.9143 time: 0.0158s\n",
      "Epoch: 0115 loss_train: 0.2779 acc_train: 0.9286 time: 0.0091s\n",
      "Epoch: 0116 loss_train: 0.2410 acc_train: 0.9286 time: 0.0090s\n",
      "Epoch: 0117 loss_train: 0.2581 acc_train: 0.9143 time: 0.0105s\n",
      "Epoch: 0118 loss_train: 0.2801 acc_train: 0.9000 time: 0.0123s\n",
      "Epoch: 0119 loss_train: 0.3023 acc_train: 0.8929 time: 0.0097s\n",
      "Epoch: 0120 loss_train: 0.2800 acc_train: 0.9286 time: 0.0083s\n",
      "Epoch: 0121 loss_train: 0.2549 acc_train: 0.9500 time: 0.0103s\n",
      "Epoch: 0122 loss_train: 0.2341 acc_train: 0.9571 time: 0.0106s\n",
      "Epoch: 0123 loss_train: 0.2731 acc_train: 0.9071 time: 0.0149s\n",
      "Epoch: 0124 loss_train: 0.2562 acc_train: 0.9429 time: 0.0639s\n",
      "Epoch: 0125 loss_train: 0.2559 acc_train: 0.9357 time: 0.0099s\n",
      "Epoch: 0126 loss_train: 0.2162 acc_train: 0.9429 time: 0.0093s\n",
      "Epoch: 0127 loss_train: 0.2376 acc_train: 0.9500 time: 0.0098s\n",
      "Epoch: 0128 loss_train: 0.2608 acc_train: 0.9357 time: 0.0156s\n",
      "Epoch: 0129 loss_train: 0.2645 acc_train: 0.9143 time: 0.0349s\n",
      "Epoch: 0130 loss_train: 0.2745 acc_train: 0.9357 time: 0.0205s\n",
      "Epoch: 0131 loss_train: 0.2586 acc_train: 0.9500 time: 0.0125s\n",
      "Epoch: 0132 loss_train: 0.2073 acc_train: 0.9571 time: 0.0211s\n",
      "Epoch: 0133 loss_train: 0.2592 acc_train: 0.9214 time: 0.0181s\n",
      "Epoch: 0134 loss_train: 0.2222 acc_train: 0.9357 time: 0.0158s\n",
      "Epoch: 0135 loss_train: 0.2109 acc_train: 0.9643 time: 0.0151s\n",
      "Epoch: 0136 loss_train: 0.2035 acc_train: 0.9500 time: 0.0163s\n",
      "Epoch: 0137 loss_train: 0.2305 acc_train: 0.9643 time: 0.0107s\n",
      "Epoch: 0138 loss_train: 0.2131 acc_train: 0.9714 time: 0.0157s\n",
      "Epoch: 0139 loss_train: 0.1926 acc_train: 0.9643 time: 0.0176s\n",
      "Epoch: 0140 loss_train: 0.2049 acc_train: 0.9714 time: 0.0115s\n",
      "Epoch: 0141 loss_train: 0.2429 acc_train: 0.9214 time: 0.0121s\n",
      "Epoch: 0142 loss_train: 0.1987 acc_train: 0.9500 time: 0.0126s\n",
      "Epoch: 0143 loss_train: 0.2096 acc_train: 0.9571 time: 0.0139s\n",
      "Epoch: 0144 loss_train: 0.2360 acc_train: 0.9357 time: 0.0119s\n",
      "Epoch: 0145 loss_train: 0.2220 acc_train: 0.9500 time: 0.0117s\n",
      "Epoch: 0146 loss_train: 0.2395 acc_train: 0.9429 time: 0.0180s\n",
      "Epoch: 0147 loss_train: 0.2011 acc_train: 0.9429 time: 0.0132s\n",
      "Epoch: 0148 loss_train: 0.1949 acc_train: 0.9714 time: 0.0100s\n",
      "Epoch: 0149 loss_train: 0.1826 acc_train: 0.9643 time: 0.0145s\n",
      "Epoch: 0150 loss_train: 0.2031 acc_train: 0.9357 time: 0.0115s\n",
      "Epoch: 0151 loss_train: 0.2279 acc_train: 0.9500 time: 0.0138s\n",
      "Epoch: 0152 loss_train: 0.1996 acc_train: 0.9429 time: 0.0085s\n",
      "Epoch: 0153 loss_train: 0.2022 acc_train: 0.9429 time: 0.0103s\n",
      "Epoch: 0154 loss_train: 0.1897 acc_train: 0.9571 time: 0.0136s\n",
      "Epoch: 0155 loss_train: 0.1926 acc_train: 0.9571 time: 0.0078s\n",
      "Epoch: 0156 loss_train: 0.1599 acc_train: 0.9714 time: 0.0094s\n",
      "Epoch: 0157 loss_train: 0.1845 acc_train: 0.9643 time: 0.0086s\n",
      "Epoch: 0158 loss_train: 0.1699 acc_train: 0.9643 time: 0.0160s\n",
      "Epoch: 0159 loss_train: 0.1897 acc_train: 0.9571 time: 0.0122s\n",
      "Epoch: 0160 loss_train: 0.1868 acc_train: 0.9643 time: 0.0079s\n",
      "Epoch: 0161 loss_train: 0.1898 acc_train: 0.9571 time: 0.0079s\n",
      "Epoch: 0162 loss_train: 0.1613 acc_train: 0.9786 time: 0.0072s\n",
      "Epoch: 0163 loss_train: 0.1890 acc_train: 0.9714 time: 0.0109s\n",
      "Epoch: 0164 loss_train: 0.1969 acc_train: 0.9500 time: 0.0143s\n",
      "Epoch: 0165 loss_train: 0.1775 acc_train: 0.9643 time: 0.0225s\n",
      "Epoch: 0166 loss_train: 0.1829 acc_train: 0.9714 time: 0.0149s\n",
      "Epoch: 0167 loss_train: 0.1436 acc_train: 0.9786 time: 0.0239s\n",
      "Epoch: 0168 loss_train: 0.1720 acc_train: 0.9857 time: 0.0097s\n",
      "Epoch: 0169 loss_train: 0.1651 acc_train: 0.9714 time: 0.0094s\n",
      "Epoch: 0170 loss_train: 0.2069 acc_train: 0.9429 time: 0.0099s\n",
      "Epoch: 0171 loss_train: 0.1326 acc_train: 0.9786 time: 0.0127s\n",
      "Epoch: 0172 loss_train: 0.1752 acc_train: 0.9714 time: 0.0101s\n",
      "Epoch: 0173 loss_train: 0.1914 acc_train: 0.9571 time: 0.0109s\n",
      "Epoch: 0174 loss_train: 0.1664 acc_train: 0.9786 time: 0.0083s\n",
      "Epoch: 0175 loss_train: 0.1979 acc_train: 0.9714 time: 0.0121s\n",
      "Epoch: 0176 loss_train: 0.1919 acc_train: 0.9714 time: 0.0095s\n",
      "Epoch: 0177 loss_train: 0.1818 acc_train: 0.9571 time: 0.0099s\n",
      "Epoch: 0178 loss_train: 0.1636 acc_train: 0.9643 time: 0.0106s\n",
      "Epoch: 0179 loss_train: 0.1523 acc_train: 0.9714 time: 0.0096s\n",
      "Epoch: 0180 loss_train: 0.1674 acc_train: 0.9429 time: 0.0095s\n",
      "Epoch: 0181 loss_train: 0.1271 acc_train: 0.9786 time: 0.0106s\n",
      "Epoch: 0182 loss_train: 0.1797 acc_train: 0.9643 time: 0.0129s\n",
      "Epoch: 0183 loss_train: 0.1725 acc_train: 0.9714 time: 0.0122s\n",
      "Epoch: 0184 loss_train: 0.1392 acc_train: 0.9714 time: 0.0100s\n",
      "Epoch: 0185 loss_train: 0.1241 acc_train: 0.9714 time: 0.0134s\n",
      "Epoch: 0186 loss_train: 0.1723 acc_train: 0.9500 time: 0.0096s\n",
      "Epoch: 0187 loss_train: 0.1571 acc_train: 0.9643 time: 0.0112s\n",
      "Epoch: 0188 loss_train: 0.1585 acc_train: 0.9714 time: 0.0125s\n",
      "Epoch: 0189 loss_train: 0.1512 acc_train: 0.9571 time: 0.0096s\n",
      "Epoch: 0190 loss_train: 0.1499 acc_train: 0.9571 time: 0.0113s\n",
      "Epoch: 0191 loss_train: 0.1283 acc_train: 0.9857 time: 0.0078s\n",
      "Epoch: 0192 loss_train: 0.1660 acc_train: 0.9643 time: 0.0124s\n",
      "Epoch: 0193 loss_train: 0.1465 acc_train: 0.9571 time: 0.0131s\n",
      "Epoch: 0194 loss_train: 0.1596 acc_train: 0.9714 time: 0.0124s\n",
      "Epoch: 0195 loss_train: 0.1656 acc_train: 0.9786 time: 0.0083s\n",
      "Epoch: 0196 loss_train: 0.1515 acc_train: 0.9714 time: 0.0088s\n",
      "Epoch: 0197 loss_train: 0.1616 acc_train: 0.9714 time: 0.0160s\n",
      "Epoch: 0198 loss_train: 0.1716 acc_train: 0.9714 time: 0.0096s\n",
      "Epoch: 0199 loss_train: 0.1982 acc_train: 0.9429 time: 0.0100s\n",
      "Epoch: 0200 loss_train: 0.1536 acc_train: 0.9929 time: 0.0101s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 2.6278s\n",
      "Test set results: loss= 0.7051 accuracy= 0.8030\n",
      "inference time:  0.003885984420776367\n"
     ]
    }
   ],
   "source": [
    "run_experiment(num_epochs=num_epochs, model=model1, lr=lr, weight_decay=weight_decay, features=features, adj=adj, idx_train=idx_train, idx_val=idx_val, idx_test=idx_test, labels=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runrunrun!\n",
      "Epoch: 0001 loss_train: 1.9485 acc_train: 0.0929 time: 0.9472s\n",
      "Epoch: 0002 loss_train: 2.0067 acc_train: 0.2929 time: 0.7092s\n",
      "Epoch: 0003 loss_train: 1.9422 acc_train: 0.1500 time: 0.6798s\n",
      "Epoch: 0004 loss_train: 1.9350 acc_train: 0.1500 time: 0.6416s\n",
      "Epoch: 0005 loss_train: 1.9311 acc_train: 0.1786 time: 0.6771s\n",
      "Epoch: 0006 loss_train: 1.9162 acc_train: 0.2929 time: 0.6072s\n",
      "Epoch: 0007 loss_train: 1.8808 acc_train: 0.2357 time: 0.6201s\n",
      "Epoch: 0008 loss_train: 1.8166 acc_train: 0.2571 time: 0.7154s\n",
      "Epoch: 0009 loss_train: 1.8278 acc_train: 0.2929 time: 0.5828s\n",
      "Epoch: 0010 loss_train: 1.7718 acc_train: 0.2929 time: 0.6602s\n",
      "Epoch: 0011 loss_train: 1.7429 acc_train: 0.2929 time: 0.6073s\n",
      "Epoch: 0012 loss_train: 1.7089 acc_train: 0.2929 time: 0.6709s\n",
      "Epoch: 0013 loss_train: 1.6465 acc_train: 0.2929 time: 0.5674s\n",
      "Epoch: 0014 loss_train: 1.5402 acc_train: 0.2929 time: 0.6092s\n",
      "Epoch: 0015 loss_train: 1.4454 acc_train: 0.3214 time: 0.6600s\n",
      "Epoch: 0016 loss_train: 1.3754 acc_train: 0.4143 time: 0.6177s\n",
      "Epoch: 0017 loss_train: 1.3112 acc_train: 0.3714 time: 0.7032s\n",
      "Epoch: 0018 loss_train: 1.2284 acc_train: 0.4357 time: 0.6259s\n",
      "Epoch: 0019 loss_train: 1.1709 acc_train: 0.4286 time: 0.6469s\n",
      "Epoch: 0020 loss_train: 1.0946 acc_train: 0.5000 time: 0.5708s\n",
      "Epoch: 0021 loss_train: 1.0019 acc_train: 0.4857 time: 0.6205s\n",
      "Epoch: 0022 loss_train: 0.9344 acc_train: 0.5643 time: 0.5979s\n",
      "Epoch: 0023 loss_train: 0.7881 acc_train: 0.6929 time: 0.6203s\n",
      "Epoch: 0024 loss_train: 0.7634 acc_train: 0.6786 time: 0.9113s\n",
      "Epoch: 0025 loss_train: 0.8717 acc_train: 0.6143 time: 0.8622s\n",
      "Epoch: 0026 loss_train: 0.6545 acc_train: 0.7571 time: 0.7203s\n",
      "Epoch: 0027 loss_train: 0.7495 acc_train: 0.6786 time: 0.6030s\n",
      "Epoch: 0028 loss_train: 0.4808 acc_train: 0.8286 time: 0.6284s\n",
      "Epoch: 0029 loss_train: 0.4467 acc_train: 0.8214 time: 0.7085s\n",
      "Epoch: 0030 loss_train: 0.4429 acc_train: 0.8000 time: 0.5767s\n",
      "Epoch: 0031 loss_train: 0.3975 acc_train: 0.8000 time: 0.6245s\n",
      "Epoch: 0032 loss_train: 0.3780 acc_train: 0.8214 time: 0.5707s\n",
      "Epoch: 0033 loss_train: 0.2913 acc_train: 0.8714 time: 0.6489s\n",
      "Epoch: 0034 loss_train: 0.3405 acc_train: 0.8714 time: 0.5890s\n",
      "Epoch: 0035 loss_train: 0.2577 acc_train: 0.8929 time: 0.6083s\n",
      "Epoch: 0036 loss_train: 0.2351 acc_train: 0.9000 time: 0.5973s\n",
      "Epoch: 0037 loss_train: 0.2144 acc_train: 0.9357 time: 0.6947s\n",
      "Epoch: 0038 loss_train: 0.1464 acc_train: 0.9429 time: 0.7024s\n",
      "Epoch: 0039 loss_train: 0.2223 acc_train: 0.9143 time: 0.6018s\n",
      "Epoch: 0040 loss_train: 0.1795 acc_train: 0.9214 time: 0.6570s\n",
      "Epoch: 0041 loss_train: 0.1209 acc_train: 0.9714 time: 0.6068s\n",
      "Epoch: 0042 loss_train: 0.1823 acc_train: 0.9214 time: 0.6239s\n",
      "Epoch: 0043 loss_train: 0.1132 acc_train: 0.9786 time: 0.6743s\n",
      "Epoch: 0044 loss_train: 0.1129 acc_train: 0.9286 time: 0.6164s\n",
      "Epoch: 0045 loss_train: 0.1682 acc_train: 0.9429 time: 0.6600s\n",
      "Epoch: 0046 loss_train: 0.0962 acc_train: 0.9643 time: 0.6004s\n",
      "Epoch: 0047 loss_train: 0.1128 acc_train: 0.9643 time: 0.7463s\n",
      "Epoch: 0048 loss_train: 0.0636 acc_train: 0.9714 time: 0.6176s\n",
      "Epoch: 0049 loss_train: 0.0577 acc_train: 0.9857 time: 0.6981s\n",
      "Epoch: 0050 loss_train: 0.0474 acc_train: 0.9929 time: 0.6016s\n",
      "Epoch: 0051 loss_train: 0.0880 acc_train: 0.9714 time: 0.6145s\n",
      "Epoch: 0052 loss_train: 0.0566 acc_train: 0.9857 time: 0.6426s\n",
      "Epoch: 0053 loss_train: 0.0520 acc_train: 0.9786 time: 0.5797s\n",
      "Epoch: 0054 loss_train: 0.0762 acc_train: 0.9857 time: 0.5494s\n",
      "Epoch: 0055 loss_train: 0.0538 acc_train: 0.9929 time: 0.6526s\n",
      "Epoch: 0056 loss_train: 0.0512 acc_train: 0.9857 time: 0.6414s\n",
      "Epoch: 0057 loss_train: 0.0295 acc_train: 1.0000 time: 0.5680s\n",
      "Epoch: 0058 loss_train: 0.0421 acc_train: 0.9929 time: 0.6554s\n",
      "Epoch: 0059 loss_train: 0.0456 acc_train: 0.9857 time: 0.5980s\n",
      "Epoch: 0060 loss_train: 0.0453 acc_train: 0.9857 time: 0.5894s\n",
      "Epoch: 0061 loss_train: 0.0314 acc_train: 0.9929 time: 0.5604s\n",
      "Epoch: 0062 loss_train: 0.0346 acc_train: 1.0000 time: 0.6090s\n",
      "Epoch: 0063 loss_train: 0.0341 acc_train: 1.0000 time: 0.6039s\n",
      "Epoch: 0064 loss_train: 0.0233 acc_train: 0.9929 time: 0.6629s\n",
      "Epoch: 0065 loss_train: 0.0823 acc_train: 0.9786 time: 0.8420s\n",
      "Epoch: 0066 loss_train: 0.0400 acc_train: 0.9929 time: 0.7769s\n",
      "Epoch: 0067 loss_train: 0.0546 acc_train: 0.9929 time: 0.6758s\n",
      "Epoch: 0068 loss_train: 0.0465 acc_train: 0.9857 time: 0.6064s\n",
      "Epoch: 0069 loss_train: 0.0244 acc_train: 0.9929 time: 0.7810s\n",
      "Epoch: 0070 loss_train: 0.0173 acc_train: 1.0000 time: 0.7678s\n",
      "Epoch: 0071 loss_train: 0.0721 acc_train: 0.9643 time: 0.6315s\n",
      "Epoch: 0072 loss_train: 0.0184 acc_train: 1.0000 time: 0.5894s\n",
      "Epoch: 0073 loss_train: 0.0943 acc_train: 0.9571 time: 0.6262s\n",
      "Epoch: 0074 loss_train: 0.0292 acc_train: 1.0000 time: 0.6966s\n",
      "Epoch: 0075 loss_train: 0.0563 acc_train: 0.9786 time: 0.5985s\n",
      "Epoch: 0076 loss_train: 0.0743 acc_train: 0.9714 time: 0.6633s\n",
      "Epoch: 0077 loss_train: 0.0320 acc_train: 0.9929 time: 0.5737s\n",
      "Epoch: 0078 loss_train: 0.0792 acc_train: 0.9643 time: 0.6294s\n",
      "Epoch: 0079 loss_train: 0.0214 acc_train: 1.0000 time: 0.5932s\n",
      "Epoch: 0080 loss_train: 0.0961 acc_train: 0.9714 time: 0.6270s\n",
      "Epoch: 0081 loss_train: 0.1580 acc_train: 0.9500 time: 0.6198s\n",
      "Epoch: 0082 loss_train: 0.0711 acc_train: 0.9714 time: 0.6377s\n",
      "Epoch: 0083 loss_train: 0.2242 acc_train: 0.9214 time: 0.9833s\n",
      "Epoch: 0084 loss_train: 0.0279 acc_train: 1.0000 time: 0.7750s\n",
      "Epoch: 0085 loss_train: 0.5312 acc_train: 0.8143 time: 0.7041s\n",
      "Epoch: 0086 loss_train: 0.0942 acc_train: 0.9714 time: 0.6642s\n",
      "Epoch: 0087 loss_train: 0.6038 acc_train: 0.7643 time: 0.6357s\n",
      "Epoch: 0088 loss_train: 0.0726 acc_train: 0.9857 time: 0.7536s\n",
      "Epoch: 0089 loss_train: 0.2008 acc_train: 0.8929 time: 0.6436s\n",
      "Epoch: 0090 loss_train: 0.2097 acc_train: 0.9214 time: 0.6999s\n",
      "Epoch: 0091 loss_train: 0.1448 acc_train: 0.9643 time: 0.8629s\n",
      "Epoch: 0092 loss_train: 0.1046 acc_train: 0.9786 time: 1.1440s\n",
      "Epoch: 0093 loss_train: 0.0778 acc_train: 0.9786 time: 0.6089s\n",
      "Epoch: 0094 loss_train: 0.0983 acc_train: 0.9500 time: 0.6807s\n",
      "Epoch: 0095 loss_train: 0.0550 acc_train: 1.0000 time: 0.6585s\n",
      "Epoch: 0096 loss_train: 0.0671 acc_train: 0.9786 time: 0.5652s\n",
      "Epoch: 0097 loss_train: 0.0568 acc_train: 0.9857 time: 0.6607s\n",
      "Epoch: 0098 loss_train: 0.0381 acc_train: 0.9929 time: 0.5757s\n",
      "Epoch: 0099 loss_train: 0.0397 acc_train: 0.9857 time: 0.6067s\n",
      "Epoch: 0100 loss_train: 0.0389 acc_train: 0.9857 time: 0.5825s\n",
      "Epoch: 0101 loss_train: 0.0273 acc_train: 0.9929 time: 0.6405s\n",
      "Epoch: 0102 loss_train: 0.0646 acc_train: 0.9786 time: 0.5851s\n",
      "Epoch: 0103 loss_train: 0.0215 acc_train: 0.9929 time: 0.5864s\n",
      "Epoch: 0104 loss_train: 0.0501 acc_train: 0.9786 time: 0.6634s\n",
      "Epoch: 0105 loss_train: 0.0169 acc_train: 1.0000 time: 0.6081s\n",
      "Epoch: 0106 loss_train: 0.0188 acc_train: 0.9929 time: 0.7485s\n",
      "Epoch: 0107 loss_train: 0.0267 acc_train: 0.9929 time: 0.8039s\n",
      "Epoch: 0108 loss_train: 0.0210 acc_train: 1.0000 time: 0.8603s\n",
      "Epoch: 0109 loss_train: 0.0117 acc_train: 1.0000 time: 0.6091s\n",
      "Epoch: 0110 loss_train: 0.0161 acc_train: 1.0000 time: 0.6189s\n",
      "Epoch: 0111 loss_train: 0.0188 acc_train: 1.0000 time: 0.6563s\n",
      "Epoch: 0112 loss_train: 0.0160 acc_train: 0.9929 time: 0.7949s\n",
      "Epoch: 0113 loss_train: 0.0127 acc_train: 1.0000 time: 0.7073s\n",
      "Epoch: 0114 loss_train: 0.0220 acc_train: 1.0000 time: 0.6082s\n",
      "Epoch: 0115 loss_train: 0.0158 acc_train: 1.0000 time: 0.6614s\n",
      "Epoch: 0116 loss_train: 0.0233 acc_train: 0.9857 time: 0.5933s\n",
      "Epoch: 0117 loss_train: 0.0108 acc_train: 1.0000 time: 0.6241s\n",
      "Epoch: 0118 loss_train: 0.0212 acc_train: 1.0000 time: 0.6919s\n",
      "Epoch: 0119 loss_train: 0.0186 acc_train: 1.0000 time: 0.5870s\n",
      "Epoch: 0120 loss_train: 0.0129 acc_train: 1.0000 time: 0.6434s\n",
      "Epoch: 0121 loss_train: 0.0165 acc_train: 0.9929 time: 0.5948s\n",
      "Epoch: 0122 loss_train: 0.0130 acc_train: 1.0000 time: 0.6606s\n",
      "Epoch: 0123 loss_train: 0.0146 acc_train: 1.0000 time: 0.5779s\n",
      "Epoch: 0124 loss_train: 0.0251 acc_train: 1.0000 time: 0.6074s\n",
      "Epoch: 0125 loss_train: 0.0204 acc_train: 1.0000 time: 0.7367s\n",
      "Epoch: 0126 loss_train: 0.0181 acc_train: 1.0000 time: 0.5898s\n",
      "Epoch: 0127 loss_train: 0.0116 acc_train: 1.0000 time: 0.6546s\n",
      "Epoch: 0128 loss_train: 0.0169 acc_train: 1.0000 time: 0.5990s\n",
      "Epoch: 0129 loss_train: 0.0266 acc_train: 0.9929 time: 0.6099s\n",
      "Epoch: 0130 loss_train: 0.0196 acc_train: 0.9929 time: 0.5871s\n",
      "Epoch: 0131 loss_train: 0.0188 acc_train: 1.0000 time: 0.6108s\n",
      "Epoch: 0132 loss_train: 0.0254 acc_train: 1.0000 time: 0.6853s\n",
      "Epoch: 0133 loss_train: 0.0387 acc_train: 0.9929 time: 0.5975s\n",
      "Epoch: 0134 loss_train: 0.0219 acc_train: 0.9929 time: 0.6888s\n",
      "Epoch: 0135 loss_train: 0.0253 acc_train: 0.9929 time: 0.6816s\n",
      "Epoch: 0136 loss_train: 0.0153 acc_train: 1.0000 time: 0.8100s\n",
      "Epoch: 0137 loss_train: 0.0229 acc_train: 1.0000 time: 0.6701s\n",
      "Epoch: 0138 loss_train: 0.0181 acc_train: 1.0000 time: 0.7364s\n",
      "Epoch: 0139 loss_train: 0.0241 acc_train: 1.0000 time: 0.6600s\n",
      "Epoch: 0140 loss_train: 0.0273 acc_train: 0.9929 time: 0.7755s\n",
      "Epoch: 0141 loss_train: 0.0331 acc_train: 1.0000 time: 0.6716s\n",
      "Epoch: 0142 loss_train: 0.0147 acc_train: 1.0000 time: 0.5951s\n",
      "Epoch: 0143 loss_train: 0.0268 acc_train: 1.0000 time: 0.6584s\n",
      "Epoch: 0144 loss_train: 0.0371 acc_train: 0.9929 time: 0.5808s\n",
      "Epoch: 0145 loss_train: 0.0323 acc_train: 0.9929 time: 0.6272s\n",
      "Epoch: 0146 loss_train: 0.0401 acc_train: 0.9929 time: 0.5902s\n",
      "Epoch: 0147 loss_train: 0.0313 acc_train: 1.0000 time: 0.6589s\n",
      "Epoch: 0148 loss_train: 0.0260 acc_train: 1.0000 time: 0.6893s\n",
      "Epoch: 0149 loss_train: 0.0178 acc_train: 1.0000 time: 0.5980s\n",
      "Epoch: 0150 loss_train: 0.0320 acc_train: 0.9857 time: 0.6913s\n",
      "Epoch: 0151 loss_train: 0.0147 acc_train: 1.0000 time: 0.6224s\n",
      "Epoch: 0152 loss_train: 0.0257 acc_train: 1.0000 time: 0.6248s\n",
      "Epoch: 0153 loss_train: 0.0213 acc_train: 1.0000 time: 0.5946s\n",
      "Epoch: 0154 loss_train: 0.0212 acc_train: 1.0000 time: 0.6499s\n",
      "Epoch: 0155 loss_train: 0.0185 acc_train: 1.0000 time: 0.7629s\n",
      "Epoch: 0156 loss_train: 0.0181 acc_train: 1.0000 time: 0.5720s\n",
      "Epoch: 0157 loss_train: 0.0218 acc_train: 1.0000 time: 0.6541s\n",
      "Epoch: 0158 loss_train: 0.0176 acc_train: 1.0000 time: 0.5777s\n",
      "Epoch: 0159 loss_train: 0.0181 acc_train: 1.0000 time: 0.6215s\n",
      "Epoch: 0160 loss_train: 0.0149 acc_train: 1.0000 time: 0.5976s\n",
      "Epoch: 0161 loss_train: 0.0170 acc_train: 1.0000 time: 0.6339s\n",
      "Epoch: 0162 loss_train: 0.0135 acc_train: 1.0000 time: 0.5855s\n",
      "Epoch: 0163 loss_train: 0.0194 acc_train: 1.0000 time: 0.5971s\n",
      "Epoch: 0164 loss_train: 0.0323 acc_train: 0.9929 time: 0.5979s\n",
      "Epoch: 0165 loss_train: 0.0189 acc_train: 1.0000 time: 0.6187s\n",
      "Epoch: 0166 loss_train: 0.0218 acc_train: 1.0000 time: 0.6571s\n",
      "Epoch: 0167 loss_train: 0.0120 acc_train: 1.0000 time: 0.5688s\n",
      "Epoch: 0168 loss_train: 0.0105 acc_train: 1.0000 time: 0.6445s\n",
      "Epoch: 0169 loss_train: 0.0290 acc_train: 0.9929 time: 0.5795s\n",
      "Epoch: 0170 loss_train: 0.0250 acc_train: 1.0000 time: 0.6478s\n",
      "Epoch: 0171 loss_train: 0.0223 acc_train: 0.9929 time: 0.5751s\n",
      "Epoch: 0172 loss_train: 0.0146 acc_train: 1.0000 time: 0.6591s\n",
      "Epoch: 0173 loss_train: 0.0212 acc_train: 1.0000 time: 0.5902s\n",
      "Epoch: 0174 loss_train: 0.0209 acc_train: 1.0000 time: 0.6415s\n",
      "Epoch: 0175 loss_train: 0.0159 acc_train: 1.0000 time: 0.6793s\n",
      "Epoch: 0176 loss_train: 0.0235 acc_train: 1.0000 time: 0.5736s\n",
      "Epoch: 0177 loss_train: 0.0342 acc_train: 0.9929 time: 0.6709s\n",
      "Epoch: 0178 loss_train: 0.0183 acc_train: 1.0000 time: 0.6007s\n",
      "Epoch: 0179 loss_train: 0.0336 acc_train: 0.9929 time: 0.6156s\n",
      "Epoch: 0180 loss_train: 0.0254 acc_train: 1.0000 time: 0.6054s\n",
      "Epoch: 0181 loss_train: 0.0258 acc_train: 1.0000 time: 0.6124s\n",
      "Epoch: 0182 loss_train: 0.0192 acc_train: 1.0000 time: 0.6612s\n",
      "Epoch: 0183 loss_train: 0.0331 acc_train: 0.9857 time: 0.5931s\n",
      "Epoch: 0184 loss_train: 0.0119 acc_train: 1.0000 time: 1.0154s\n",
      "Epoch: 0185 loss_train: 0.0344 acc_train: 0.9929 time: 0.7609s\n",
      "Epoch: 0186 loss_train: 0.0187 acc_train: 1.0000 time: 0.6678s\n",
      "Epoch: 0187 loss_train: 0.0204 acc_train: 1.0000 time: 0.7577s\n",
      "Epoch: 0188 loss_train: 0.0306 acc_train: 1.0000 time: 0.5904s\n",
      "Epoch: 0189 loss_train: 0.0178 acc_train: 1.0000 time: 0.6744s\n",
      "Epoch: 0190 loss_train: 0.0611 acc_train: 0.9714 time: 0.5877s\n",
      "Epoch: 0191 loss_train: 0.0180 acc_train: 1.0000 time: 0.6320s\n",
      "Epoch: 0192 loss_train: 0.0950 acc_train: 0.9500 time: 0.5971s\n",
      "Epoch: 0193 loss_train: 0.0841 acc_train: 0.9857 time: 0.6610s\n",
      "Epoch: 0194 loss_train: 0.0603 acc_train: 0.9857 time: 0.6597s\n",
      "Epoch: 0195 loss_train: 0.0538 acc_train: 0.9929 time: 0.6756s\n",
      "Epoch: 0196 loss_train: 0.0539 acc_train: 0.9857 time: 0.6928s\n",
      "Epoch: 0197 loss_train: 0.0172 acc_train: 1.0000 time: 0.5741s\n",
      "Epoch: 0198 loss_train: 0.0986 acc_train: 0.9643 time: 0.7453s\n",
      "Epoch: 0199 loss_train: 0.0240 acc_train: 1.0000 time: 0.5815s\n",
      "Epoch: 0200 loss_train: 0.0924 acc_train: 0.9714 time: 0.6410s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 130.8085s\n",
      "Test set results: loss= 1.1325 accuracy= 0.7410\n",
      "inference time:  0.1991262435913086\n"
     ]
    }
   ],
   "source": [
    "run_experiment(num_epochs=num_epochs, model=model2, lr=lr, weight_decay=weight_decay, features=features, adj=adj, idx_train=idx_train, idx_val=idx_val, idx_test=idx_test, labels=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = ite_GCN(nfeat=features.shape[1],\n",
    "            nclass=labels.max().item() + 1,\n",
    "            dropout=dropout,\n",
    "            nite = 3,\n",
    "            allow_grad=False,\n",
    "            smooth_fac=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(num_epochs=num_epochs, model=model3, lr=lr, weight_decay=weight_decay, features=features, adj=adj, idx_train=idx_train, idx_val=idx_val, idx_test=idx_test, labels=labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iterativeENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
